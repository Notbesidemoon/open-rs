[
    {
        "question": "In what country is Normandy located?",
        "answers": [
            "France",
            "France",
            "France",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When were the Normans in Normandy?",
        "answers": [
            "10th and 11th centuries",
            "in the 10th and 11th centuries",
            "10th and 11th centuries",
            "10th and 11th centuries"
        ],
        "model_ans": "911",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 911 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From which countries did the Norse originate?",
        "answers": [
            "Denmark, Iceland and Norway",
            "Denmark, Iceland and Norway",
            "Denmark, Iceland and Norway",
            "Denmark, Iceland and Norway"
        ],
        "model_ans": "Scandinavia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scandinavia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the Norse leader?",
        "answers": [
            "Rollo",
            "Rollo",
            "Rollo",
            "Rollo"
        ],
        "model_ans": "Odin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Odin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What century did the Normans first gain their separate identity?",
        "answers": [
            "10th century",
            "the first half of the 10th century",
            "10th",
            "10th"
        ],
        "model_ans": "9th century\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "9th century\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the duke in the battle of Hastings?",
        "answers": [
            "William the Conqueror",
            "William the Conqueror",
            "William the Conqueror"
        ],
        "model_ans": "William the Conqueror",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William the Conqueror </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who ruled the duchy of Normandy",
        "answers": [
            "Richard I",
            "Richard I",
            "Richard I"
        ],
        "model_ans": "William the Conqueror",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William the Conqueror </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What religion were the Normans",
        "answers": [
            "Catholic",
            "Catholic orthodoxy",
            "Catholic"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the original meaning of the word Norman?",
        "answers": [
            "Viking",
            "Norseman, Viking",
            "Norseman, Viking"
        ],
        "model_ans": "Answer:  Northman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " Answer: <answer> Northman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Latin version of the word Norman first recorded?",
        "answers": [
            "9th century",
            "9th century",
            "9th century"
        ],
        "model_ans": "12th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Duchy of Normandy founded?",
        "answers": [
            "911",
            "911",
            "911"
        ],
        "model_ans": "911\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "911\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Rollo sign the treaty of Saint-Clair-sur-Epte with?",
        "answers": [
            "King Charles III",
            "King Charles III",
            "King Charles III"
        ],
        "model_ans": "Odo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Odo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river originally bounded the Duchy",
        "answers": [
            "Seine",
            "Epte",
            "Seine"
        ],
        "model_ans": "Meuse",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Meuse </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who upon arriving gave the original viking settlers a common identity?",
        "answers": [
            "Rollo",
            "Rollo",
            "Rollo"
        ],
        "model_ans": "Odin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Odin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Norman religion?",
        "answers": [
            "Catholicism",
            "Catholicism",
            "Catholicism"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What part of France were the Normans located?",
        "answers": [
            "north",
            "the north",
            "north"
        ],
        "model_ans": "Normandy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Normandy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was one of the Norman's major exports?",
        "answers": [
            "fighting horsemen",
            "fighting horsemen",
            "fighting horsemen"
        ],
        "model_ans": "wool",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wool </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the Normans' main enemy in Italy, the Byzantine Empire and Armenia?",
        "answers": [
            "Seljuk Turks",
            "the Pechenegs, the Bulgars, and especially the Seljuk Turks",
            "the Seljuk Turks"
        ],
        "model_ans": "The Lombards",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Lombards </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Herve serve as a Byzantine general?",
        "answers": [
            "1050s",
            "in the 1050s",
            "in the 1050s"
        ],
        "model_ans": "1060",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1060 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Robert Crispin go up against the Turks?",
        "answers": [
            "1060s",
            "In the 1060s",
            "In the 1060s"
        ],
        "model_ans": "1922",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1922 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who ruined Roussel de Bailleul's plans for an independent state?",
        "answers": [
            "Alexius Komnenos",
            "Alexius Komnenos",
            "Alexius Komnenos"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the Norman castle?",
        "answers": [
            "Afranji",
            "Afranji",
            "Afranji"
        ],
        "model_ans": "The White Tower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The White Tower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the leader when the Franks entered the Euphrates valley?",
        "answers": [
            "Oursel",
            "Oursel",
            "Oursel"
        ],
        "model_ans": "Clovis I",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Clovis I </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Normans team up with in Anatolia?",
        "answers": [
            "Turkish forces",
            "Turkish forces",
            "Turkish forces"
        ],
        "model_ans": "Seljuk Turks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Seljuk Turks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the origins of the Raouliii family?",
        "answers": [
            "Norman mercenary",
            "an Italo-Norman named Raoul",
            "descended from an Italo-Norman named Raoul"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the count of Apulia ",
        "answers": [
            "Robert Guiscard",
            "Robert Guiscard",
            "Robert Guiscard"
        ],
        "model_ans": "Robert Guiscard",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Robert Guiscard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Dyrrachium  fall to the Normans?",
        "answers": [
            "1082",
            "February 1082",
            "February 1082"
        ],
        "model_ans": "1081",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1081 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many men were in Robert's army?",
        "answers": [
            "30,000",
            "30,000",
            "30,000"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the Normans and Byzantines sign the peace treaty?",
        "answers": [
            "Deabolis",
            "Deabolis",
            "Deabolis"
        ],
        "model_ans": "Constantinople",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Constantinople </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Robert's son?",
        "answers": [
            "Bohemond",
            "Bohemond",
            "Bohemond"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river was Petrela located by?",
        "answers": [
            "Deabolis",
            "the river Deabolis",
            "Deabolis"
        ],
        "model_ans": "Vardar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vardar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Normans attack Dyrrachium?",
        "answers": [
            "1185",
            "in 1185",
            "1185"
        ],
        "model_ans": "1081\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1081\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the naval base called?",
        "answers": [
            "Dyrrachium",
            "Dyrrachium",
            "Dyrrachium"
        ],
        "model_ans": "Pearl Harbor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pearl Harbor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was Dyrrachium located?",
        "answers": [
            "the Adriatic",
            "the Adriatic",
            "Adriatic"
        ],
        "model_ans": "Albania",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albania </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did Emma Marry?",
        "answers": [
            "King Ethelred II",
            "Ethelred II",
            "King Ethelred II"
        ],
        "model_ans": "Leonardo DiCaprio",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Leonardo DiCaprio </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Emma's brother?",
        "answers": [
            "Duke Richard II",
            "Duke Richard II",
            "Duke Richard II"
        ],
        "model_ans": "Frank Churchill",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Frank Churchill </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To where did Ethelred flee?",
        "answers": [
            "Normandy",
            "Normandy",
            "Normandy"
        ],
        "model_ans": "Normandy",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Normandy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who kicked Ethelred out?",
        "answers": [
            "Sweyn Forkbeard",
            "Sweyn Forkbeard",
            "Sweyn Forkbeard"
        ],
        "model_ans": "William the Conqueror",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> William the Conqueror </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Edward the Confessor's half-brother?",
        "answers": [
            "Harthacnut",
            "Harthacnut",
            "Harthacnut"
        ],
        "model_ans": "Harold Godwinson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harold Godwinson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Edward return?",
        "answers": [
            "1041",
            "in 1041",
            "1041"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Edward make archbishop of Canterbury?",
        "answers": [
            "Robert of Jumi\u00e8ges",
            "Robert of Jumi\u00e8ges",
            "Robert of Jumi\u00e8ges"
        ],
        "model_ans": "Thomas Becket",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Becket </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Harold II die?",
        "answers": [
            "Battle of Hastings",
            "the Battle of Hastings",
            "at the Battle of Hastings"
        ],
        "model_ans": "Hastings",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hastings </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who killed Harold II? ",
        "answers": [
            "William II",
            "Duke William II",
            "Duke William II"
        ],
        "model_ans": "William the Conqueror",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> William the Conqueror </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Battle of Hastings?",
        "answers": [
            "1066",
            "In 1066",
            "1066"
        ],
        "model_ans": "1066\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1066\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the ruling class ahead of the Normans?",
        "answers": [
            "Anglo-Saxons",
            "the Anglo-Saxons",
            "Anglo-Saxons"
        ],
        "model_ans": "Vikings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vikings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Anglo-Norman language's final form?",
        "answers": [
            "Modern English",
            "Modern English",
            "Modern English"
        ],
        "model_ans": "Middle English",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Middle English </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did the Norman's invade at Bannow Bay?",
        "answers": [
            "1169",
            "1169",
            "1169"
        ],
        "model_ans": "1169\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1169\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What country did the Normans invade in 1169?",
        "answers": [
            "Ireland",
            "Ireland",
            "Ireland"
        ],
        "model_ans": "Ireland",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ireland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What culture did the Normans combine with in Ireland?",
        "answers": [
            "Irish",
            "Irish",
            "Irish"
        ],
        "model_ans": "Celtic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Celtic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Margaret's brother?",
        "answers": [
            "Edgar",
            "Edgar",
            "Edgar Atheling"
        ],
        "model_ans": "David",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Margaret's husband?",
        "answers": [
            "King Malcolm III of Scotland",
            "King Malcolm III",
            "King Malcolm III"
        ],
        "model_ans": "Lord Snow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lord Snow </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Scotland invaded by William?",
        "answers": [
            "1072",
            "1072",
            "1072"
        ],
        "model_ans": "1066\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1066\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the hostage?",
        "answers": [
            "Duncan",
            "Duncan",
            "Duncan"
        ],
        "model_ans": "",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>  </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Alexander I marry?",
        "answers": [
            "Sybilla of Normandy",
            "Sybilla of Normandy",
            "Sybilla"
        ],
        "model_ans": "Elizabeth Alexeievna",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elizabeth Alexeievna </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What culture's arrival in Scotland is know as the \"Davidian Revolution\"?",
        "answers": [
            "Norman",
            "Norman",
            "Norman"
        ],
        "model_ans": "Scottish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was Ralph earl of?",
        "answers": [
            "Hereford",
            "Hereford",
            "Hereford"
        ],
        "model_ans": "Earl of Chester",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Earl of Chester </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Ralph in charge of being at war with?",
        "answers": [
            "the Welsh",
            "the Welsh",
            "the Welsh"
        ],
        "model_ans": "Germany",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who made Ralph earl?",
        "answers": [
            "Edward the Confessor",
            "Edward the Confessor",
            "Edward the Confessor"
        ],
        "model_ans": "Ralph Lauren",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ralph Lauren </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What country was under the control of Norman barons?",
        "answers": [
            "Wales",
            "Wales",
            "Wales"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year did Roger de Tosny fail to accomplish what he set out to do?",
        "answers": [
            "1018",
            "1064",
            "1018"
        ],
        "model_ans": "1153",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1153 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was in charge of the papal army in the War of Barbastro?",
        "answers": [
            "William of Montreuil",
            "William of Montreuil",
            "William of Montreuil"
        ],
        "model_ans": "Pope Innocent III",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pope Innocent III </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Siege of Antioch take place?",
        "answers": [
            "1097",
            "1097",
            "1097"
        ],
        "model_ans": "1097-1098\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1097-1098\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of Bohemond's nephew?",
        "answers": [
            "Tancred",
            "Tancred",
            "Tancred"
        ],
        "model_ans": "Raymond",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Raymond </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What major conquest did Tancred play a roll in?",
        "answers": [
            "Jerusalem",
            "Jerusalem",
            "Jerusalem"
        ],
        "model_ans": "The Crusades",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Crusades </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long did Western Europe control Cyprus?",
        "answers": [
            "380 years",
            "380 years",
            "380 years"
        ],
        "model_ans": "1878-1960",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1878-1960 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What ruined Richard's plans to reach Acre?",
        "answers": [
            "a storm",
            "a storm",
            "a storm"
        ],
        "model_ans": "Saladin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saladin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Richard's fiancee?",
        "answers": [
            "Berengaria",
            "Berengaria",
            "Berengaria"
        ],
        "model_ans": "Elizabeth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elizabeth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did the storm hit Richard's fleet?",
        "answers": [
            "1191",
            "1191",
            "1191"
        ],
        "model_ans": "1545",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1545 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who ruled Cyprus in 1191?",
        "answers": [
            "Isaac Komnenos",
            "Isaac",
            "Isaac Komnenos"
        ],
        "model_ans": "Richard the Lionheart",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Richard the Lionheart </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Guy's Rival?",
        "answers": [
            "Conrad of Montferrat",
            "Conrad of Montferrat",
            "Conrad of Montferrat"
        ],
        "model_ans": "John",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were Isaac's chains made out of?",
        "answers": [
            "silver",
            "silver",
            "silver"
        ],
        "model_ans": "Iron",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iron </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who led Richard's troops when Cyprus was conquered?",
        "answers": [
            "Guy de Lusignan",
            "Guy de Lusignan",
            "Guy de Lusignan"
        ],
        "model_ans": "Richard the Lionheart",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard the Lionheart </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What continent are the Canarian Islands off the coast of?",
        "answers": [
            "Africa",
            "Africa",
            "Africa"
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who became the King of the Canary Islands?",
        "answers": [
            "Bethencourt",
            "Bethencourt",
            "Bethencourt"
        ],
        "model_ans": "Juan de Bethencourt",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Juan de Bethencourt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who bought the rights?",
        "answers": [
            "Enrique P\u00e9rez de Guzm\u00e1n",
            "Enrique P\u00e9rez de Guzm\u00e1n",
            "Enrique P\u00e9rez de Guzm\u00e1n"
        ],
        "model_ans": "Sony",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sony </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who sold the rights?",
        "answers": [
            "Maciot de Bethencourt",
            "Maciot de Bethencourt",
            "Maciot de Bethencourt"
        ],
        "model_ans": "Sony",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sony </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are Jersey and Guernsey",
        "answers": [
            "Channel Islands",
            "the Channel Islands",
            "the Channel Islands"
        ],
        "model_ans": "Channel Islands",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Channel Islands </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many customaries does Norman customary law have?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Norman architecture idiom?",
        "answers": [
            "Romanesque",
            "Romanesque",
            "Romanesque"
        ],
        "model_ans": "Romanesque",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Romanesque </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of arches does Norman architecture have?",
        "answers": [
            "rounded",
            "rounded",
            "rounded"
        ],
        "model_ans": "Gothic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What architecture type came after Norman in England?",
        "answers": [
            "Early Gothic",
            "Early Gothic",
            "Early Gothic"
        ],
        "model_ans": "Gothic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What architecture type came before Norman in England?",
        "answers": [
            "Anglo-Saxon",
            "Anglo-Saxon",
            "Anglo-Saxon"
        ],
        "model_ans": "Anglo-Saxon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anglo-Saxon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What place had the Norman Arab architectural style?",
        "answers": [
            "Sicily",
            "Sicily",
            "Kingdom of Sicily"
        ],
        "model_ans": "Cairo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cairo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the church reform begin?",
        "answers": [
            "early 11th century",
            "11th century",
            "in the early 11th century"
        ],
        "model_ans": "1517",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1517 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who used the church to unify themselves?",
        "answers": [
            "dukes",
            "the dukes",
            "dukes"
        ],
        "model_ans": "Catholic Church",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholic Church </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When were the French wars of religion?",
        "answers": [
            "16th century",
            "the 16th century",
            "in the 16th century"
        ],
        "model_ans": "1562-1598\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1562-1598\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of needlework was used in the creation of the Bayeux Tapestry?",
        "answers": [
            "embroidery",
            "embroidery",
            "embroidery"
        ],
        "model_ans": "Embroidery",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Embroidery </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is Norman art's most well known piece?",
        "answers": [
            "Bayeux Tapestry",
            "the Bayeux Tapestry",
            "the Bayeux Tapestry"
        ],
        "model_ans": "The Bayeux Tapestry",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Bayeux Tapestry </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who commissioned the Tapestry?",
        "answers": [
            "Odo",
            "Odo",
            "Odo"
        ],
        "model_ans": "King Charles II",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> King Charles II </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most important type of Norman art preserved in churches?",
        "answers": [
            "mosaics",
            "mosaics",
            "mosaics"
        ],
        "model_ans": "Romanesque",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Romanesque </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what century did important classical music developments occur in Normandy?",
        "answers": [
            "11th",
            "the 11th",
            "11th"
        ],
        "model_ans": "17th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 17th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who were the two abbots at F\u00e9camp Abbey?",
        "answers": [
            "William of Volpiano and John of Ravenna",
            "William of Volpiano and John of Ravenna",
            "William of Volpiano and John of Ravenna"
        ],
        "model_ans": "Saint-Aubin and Saint-Louis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saint-Aubin and Saint-Louis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the monks flee to?",
        "answers": [
            "southern Italy",
            "southern Italy",
            "southern Italy"
        ],
        "model_ans": "Tibet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tibet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What monastery did the Saint-Evroul monks establish in Italy?",
        "answers": [
            "Latin monastery at Sant'Eufemia.",
            "a Latin monastery at Sant'Eufemia",
            "Sant'Eufemia"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who patronized the monks in Italy? ",
        "answers": [
            "Robert Guiscard",
            "Robert Guiscard",
            "Robert Guiscard"
        ],
        "model_ans": "The Pope",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Pope </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tradition were the Saint-Evroul monks known for?",
        "answers": [
            "singing",
            "singing",
            "singing"
        ],
        "model_ans": "Illuminated manuscripts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Illuminated manuscripts </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?",
        "answers": [
            "Computational complexity theory",
            "Computational complexity theory",
            "Computational complexity theory"
        ],
        "model_ans": "Complexity Theory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Complexity Theory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By what main attribute are computational problems classified utilizing computational complexity theory? ",
        "answers": [
            "inherent difficulty",
            "their inherent difficulty",
            "inherent difficulty"
        ],
        "model_ans": "time complexity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> time complexity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term for a task that generally lends itself to being solved by a computer?",
        "answers": [
            "computational problems",
            "A computational problem",
            "computational problem"
        ],
        "model_ans": "Algorithm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Algorithm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What measure of a computational problem broadly defines the inherent difficulty of the solution?",
        "answers": [
            "if its solution requires significant resources",
            "its solution requires significant resources",
            "if its solution requires significant resources"
        ],
        "model_ans": "computational complexity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> computational complexity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What method is used to intuitively assess or quantify the amount of resources required to solve a computational problem?",
        "answers": [
            "mathematical models of computation",
            "mathematical models of computation",
            "mathematical models of computation"
        ],
        "model_ans": "Big O notation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Big O notation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are two basic primary resources used to guage complexity?",
        "answers": [
            "time and storage",
            "time and storage",
            "time and storage"
        ],
        "model_ans": "entropy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> entropy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What unit is measured to determine circuit complexity?",
        "answers": [
            "number of gates in a circuit",
            "number of gates in a circuit",
            "number of gates"
        ],
        "model_ans": "Gates",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gates </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What practical role does defining the complexity of problems play in everyday computing?",
        "answers": [
            "determine the practical limits on what computers can and cannot do",
            "what computers can and cannot do",
            "determine the practical limits on what computers can and cannot do"
        ],
        "model_ans": "It helps in identifying the most critical components of a system and prioritizing efforts to address them.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It helps in identifying the most critical components of a system and prioritizing efforts to address them.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What two fields of theoretical computer science closely mirror computational complexity theory?",
        "answers": [
            "analysis of algorithms and computability theory",
            "analysis of algorithms and computability theory",
            "analysis of algorithms and computability theory"
        ],
        "model_ans": "Type theory and Category theory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Type theory and Category theory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What field of computer science analyzes the resource requirements of a specific algorithm isolated unto itself within a given problem?",
        "answers": [
            "analysis of algorithms",
            "analysis of algorithms",
            "analysis of algorithms"
        ],
        "model_ans": "Algorithmic analysis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Algorithmic analysis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What field of computer science analyzes all possible algorithms in aggregate to determine the resource requirements needed to solve to a given problem?  ",
        "answers": [
            "computational complexity theory",
            "computational complexity theory",
            "computational complexity theory"
        ],
        "model_ans": "Algorithmic analysis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Algorithmic analysis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What field of computer science is primarily concerned with determining the likelihood of whether or not a problem can ultimately be solved using algorithms?",
        "answers": [
            "computability theory",
            "computability theory",
            "computability theory"
        ],
        "model_ans": "Computational Complexity Theory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Computational Complexity Theory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name given to the input string of a computational problem?",
        "answers": [
            "problem instance",
            "a problem instance",
            "problem instance"
        ],
        "model_ans": "Input",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Input </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In computational complexity theory, what is the term given to describe the baseline abstract question needing to be solved? ",
        "answers": [
            "the problem",
            "a problem",
            "problem"
        ],
        "model_ans": "P vs. NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> P vs. NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Is a problem instance typically characterized as abstract or concrete?",
        "answers": [
            "concrete",
            "concrete",
            "abstract"
        ],
        "model_ans": "abstract",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> abstract </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is another name for any given measure of input associated with a problem?",
        "answers": [
            "instances",
            "the instance",
            "instance"
        ],
        "model_ans": "Variable",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Variable </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the general term used to describe the output to any given input in a problem instance?",
        "answers": [
            "solution",
            "the solution",
            "solution"
        ],
        "model_ans": "solution",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> solution </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By how many kilometers does the traveling salesman problem seek to classify a route between the 15 largest cities in Germany?",
        "answers": [
            "2000",
            "2000",
            "2000"
        ],
        "model_ans": "1000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?",
        "answers": [
            "round trip through all sites in Milan",
            "asking for a round trip through all sites in Milan whose total length is at most 10 km",
            "a round trip through all sites in Milan whose total length is at most 10 km"
        ],
        "model_ans": "The TSP does not provide a solution for the case where the salesman has to visit a specific city twice.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The TSP does not provide a solution for the case where the salesman has to visit a specific city twice. </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does computational complexity theory most specifically seek to answer? ",
        "answers": [
            "computational problems",
            "computational problems",
            "computational problems"
        ],
        "model_ans": "the resources required to solve computational problems",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the resources required to solve computational problems </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In a computational problem, what can be described as a string over an alphabet?",
        "answers": [
            "problem instance",
            "a problem instance",
            "problem instance"
        ],
        "model_ans": "A sequence of characters",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A sequence of characters </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the alphabet is most commonly used in a problem instance?",
        "answers": [
            "binary alphabet",
            "binary",
            "binary"
        ],
        "model_ans": "Latin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Latin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another term for the string of a problem instance?",
        "answers": [
            "bitstrings",
            "bitstrings",
            "bitstrings"
        ],
        "model_ans": "Instance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Instance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In the encoding of mathematical objects, what is the way in which integers are commonly expressed?",
        "answers": [
            "binary notation",
            "binary notation",
            "binary notation"
        ],
        "model_ans": "decimal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> decimal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one way in which graphs can be encoded? ",
        "answers": [
            "adjacency matrices",
            "directly via their adjacency matrices"
        ],
        "model_ans": "SVG",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SVG </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of problems are one of the main topics studied in computational complexity theory?",
        "answers": [
            "Decision problems",
            "Decision problems",
            "Decision"
        ],
        "model_ans": "algorithmic problems",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> algorithmic problems </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two simple word responses to a decision problem?",
        "answers": [
            "yes or no",
            "yes or no",
            "yes or no"
        ],
        "model_ans": "Yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yes </answer> <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two integer responses to a decision problem?",
        "answers": [
            "1 or 0",
            "1 or 0",
            "1 or 0"
        ],
        "model_ans": "0 and 1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "0 and 1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What will the output be for a member of the language of a decision problem?",
        "answers": [
            "yes",
            "yes",
            "yes"
        ],
        "model_ans": "decision",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> decision </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What answer denotes that an algorithm has accepted an input string?",
        "answers": [
            "yes",
            "yes",
            "yes"
        ],
        "model_ans": "ACCEPT",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ACCEPT </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of graph is an example of an input used in a decision problem?",
        "answers": [
            "arbitrary graph",
            "arbitrary",
            "arbitrary"
        ],
        "model_ans": "Decision Tree",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Decision Tree </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for the set of all connected graphs related to this decision problem?",
        "answers": [
            "formal language",
            "The formal language",
            "The formal language associated with this decision problem"
        ],
        "model_ans": "polytope",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> polytope </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What encoding decision needs to be made in order to determine an exact definition of the formal language?",
        "answers": [
            "how graphs are encoded as binary strings",
            "how graphs are encoded as binary strings",
            "how graphs are encoded as binary strings"
        ],
        "model_ans": "prefix",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> prefix </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A function problem is an example of what?",
        "answers": [
            "a computational problem",
            "a computational problem",
            "a computational problem"
        ],
        "model_ans": "a programming problem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a programming problem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many outputs are expected for each input in a function problem?",
        "answers": [
            "a single output",
            "single",
            "single"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The traveling salesman problem is an example of what type of problem?",
        "answers": [
            "A function problem",
            "function",
            "function problem"
        ],
        "model_ans": "NP-hard",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In addition to the traveling salesman problem, what is another example of a function problem?",
        "answers": [
            "the integer factorization problem",
            "integer factorization",
            "integer factorization problem"
        ],
        "model_ans": "Knapsack problem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Knapsack problem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Is the output of a functional problem typically characterized by a simple or complex answer?",
        "answers": [
            "complex",
            "complex",
            "complex"
        ],
        "model_ans": "complex",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> complex </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How can function problems typically be restated?",
        "answers": [
            "decision problems",
            "as decision problems",
            "as decision problems"
        ],
        "model_ans": "as optimization problems",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> as optimization problems </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If two integers are multiplied and output a value, what is this expression set called?",
        "answers": [
            "set of triples",
            "triple",
            "the set of triples (a, b, c) such that the relation a \u00d7 b = c holds"
        ],
        "model_ans": "product",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> product </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a commonly used measurement used to determine the complexity of a computational problem?",
        "answers": [
            "how much time the best algorithm requires to solve the problem",
            "time",
            "time"
        ],
        "model_ans": "NP-hard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one variable on which the running time may be contingent?",
        "answers": [
            "the instance",
            "the instance",
            "the size of the instance"
        ],
        "model_ans": "Distance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Distance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is the time needed to obtain the solution to a problem calculated?",
        "answers": [
            "as a function of the size of the instance",
            "as a function of the size of the instance",
            "a function of the size of the instance"
        ],
        "model_ans": "The time needed to obtain the solution to a problem is calculated by considering the complexity of the problem, the expertise of the person solving it, and the resources available.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The time needed to obtain the solution to a problem is calculated by considering the complexity of the problem, the expertise of the person solving it, and the resources available.</answer>\n<confidence</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what unit is the size of the input measured?",
        "answers": [
            "bits",
            "bits",
            "bits"
        ],
        "model_ans": "bytes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> bytes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Complexity theory seeks to define the relationship between the scale of algorithms with respect to what other variable?",
        "answers": [
            "an increase in the input size",
            "input size",
            "input size"
        ],
        "model_ans": "computational resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> computational resources </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Whose thesis states that the solution to a problem is solvable with reasonable resources assuming it allows for a polynomial time algorithm?",
        "answers": [
            "Cobham's thesis",
            "Cobham's",
            "Cobham"
        ],
        "model_ans": "Donald Knuth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Donald Knuth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If input size is is equal to n, what can respectively be assumed is the function of n?",
        "answers": [
            "the time taken",
            "the time taken",
            "the time taken"
        ],
        "model_ans": "input size",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> input size </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What term corresponds to the maximum measurement of time across all functions of n? ",
        "answers": [
            "worst-case time complexity",
            "worst-case time complexity",
            "the worst-case time complexity"
        ],
        "model_ans": "epoch",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> epoch </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is worst-case time complexity written as an expression?",
        "answers": [
            "T(n)",
            "T(n)",
            "T(n)"
        ],
        "model_ans": "O(n)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>O(n)</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Assuming that T represents a polynomial in T(n), what is the term given to the corresponding algorithm?",
        "answers": [
            "polynomial time algorithm",
            "polynomial time",
            "polynomial time algorithm"
        ],
        "model_ans": "O(T(n))",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O(T(n)) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term for a mathematical model that theoretically represents a general computing machine?",
        "answers": [
            "A Turing machine",
            "A Turing machine",
            "Turing machine"
        ],
        "model_ans": "Turing Machine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turing Machine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "It is generally assumed that a Turing machine can solve anything capable of also being solved using what?",
        "answers": [
            "an algorithm",
            "an algorithm",
            "an algorithm"
        ],
        "model_ans": "a computer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a computer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most commonplace model utilized in complexity theory?",
        "answers": [
            "the Turing machine",
            "the Turing machine",
            "Turing machine"
        ],
        "model_ans": "Cellular Automata",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cellular Automata </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does a Turing machine handle on a strip of tape?",
        "answers": [
            "symbols",
            "symbols",
            "symbols"
        ],
        "model_ans": "symbols",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> symbols </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is generally considered to be the most basic iteration of a Turing machine?",
        "answers": [
            "A deterministic Turing machine",
            "deterministic",
            "deterministic Turing machine"
        ],
        "model_ans": "The original Turing machine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The original Turing machine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What fixed set of factors determine the actions of a deterministic Turing machine",
        "answers": [
            "rules",
            "rules",
            "a fixed set of rules to determine its future actions"
        ],
        "model_ans": "Input tape",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Input tape </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term used to identify a deterministic Turing machine that has additional random bits?",
        "answers": [
            "A probabilistic Turing machine",
            "probabilistic",
            "probabilistic Turing machine"
        ],
        "model_ans": "Probabilistic Turing Machine",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Probabilistic Turing Machine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of Turing machine is capable of multiple actions and extends into a variety of computational paths?",
        "answers": [
            "A non-deterministic Turing machine",
            "non-deterministic",
            "non-deterministic Turing machine"
        ],
        "model_ans": "Multi-tape Turing machine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Multi-tape Turing machine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term given to algorithms that utilize random bits?",
        "answers": [
            "randomized algorithms",
            "randomized algorithms",
            "randomized algorithms"
        ],
        "model_ans": "Pseudorandom",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pseudorandom </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Turing machines are commonly employed to define what? ",
        "answers": [
            "complexity classes",
            "complexity classes",
            "complexity classes"
        ],
        "model_ans": "formal languages",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> formal languages </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are two factors that directly effect how powerful a Turing machine may or may not be?",
        "answers": [
            "time or space",
            "time or space",
            "time or space"
        ],
        "model_ans": "tape length and number of states",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> tape length and number of states </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the determination of complexity classes, what are two examples of types of Turing machines?",
        "answers": [
            "probabilistic Turing machines, non-deterministic Turing machines",
            "probabilistic Turing machines, non-deterministic Turing machines"
        ],
        "model_ans": "Deterministic Turing Machine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deterministic Turing Machine </answer>\n<answer> Nondeterministic Turing Machine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an example of a machine model that deviates from a generally accepted multi-tape Turing machine?",
        "answers": [
            "random access machines",
            "random access machines",
            "random access machines"
        ],
        "model_ans": "Quantum Turing Machine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quantum Turing Machine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In considering Turing machines and alternate variables, what measurement left unaffected by conversion between machine models? ",
        "answers": [
            "computational power",
            "computational power",
            "computational power"
        ],
        "model_ans": "Time",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Time </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What two resources commonly consumed by alternate models are typically known to vary?",
        "answers": [
            "time and memory",
            "time and memory consumption",
            "time and memory consumption"
        ],
        "model_ans": "Water and Food",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water and Food </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What commonality do alternate machine models, such as random access machines, share with Turing machines?",
        "answers": [
            "the machines operate deterministically",
            "deterministically",
            "the machines operate deterministically"
        ],
        "model_ans": "They are both Turing complete",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They are both Turing complete </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of Turing machine can be characterized by checking multiple possibilities at the same time?",
        "answers": [
            "non-deterministic",
            "non-deterministic",
            "non-deterministic Turing machine"
        ],
        "model_ans": "Nondeterministic Turing machine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nondeterministic Turing machine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What often affects or facilitates ease of analysis in computational problems?",
        "answers": [
            "unusual resources",
            "more unusual resources",
            "more unusual resources"
        ],
        "model_ans": "Complexity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Complexity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A non-deterministic Turing machine has the ability to capture what facet of useful analysis?",
        "answers": [
            "mathematical models",
            "mathematical models",
            "branching"
        ],
        "model_ans": "Uncertainty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uncertainty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most critical resource in the analysis of computational problems associated with non-deterministic Turing machines?",
        "answers": [
            "time",
            "non-deterministic time",
            "non-deterministic time"
        ],
        "model_ans": "Time",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Time </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The time required to output an answer on a deterministic Turing machine is expressed as what?",
        "answers": [
            "state transitions",
            "the total number of state transitions, or steps",
            "total number of state transitions, or steps, the machine makes before it halts and outputs the answer"
        ],
        "model_ans": "O(1)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O(1) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Complexity theory classifies problems based on what primary attribute?",
        "answers": [
            "difficulty",
            "difficulty",
            "difficulty"
        ],
        "model_ans": "computational resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> computational resources </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the expression used to identify any given series of problems capable of being solved within time on a deterministic Turing machine?",
        "answers": [
            "DTIME(f(n))",
            "DTIME(f(n)).",
            "DTIME(f(n))"
        ],
        "model_ans": "decidability",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> decidability </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most critical resource measured to in assessing the determination of a Turing machine's ability to solve any given set of problems?",
        "answers": [
            "time",
            "time",
            "time"
        ],
        "model_ans": "Time",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Time </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Time and space are both examples of what type of resource?",
        "answers": [
            "complexity resources",
            "complexity resources",
            "complexity"
        ],
        "model_ans": "abstract",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> abstract </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A complexity resource can also be described as what other type of resource?",
        "answers": [
            "computational resource",
            "computational",
            "computational"
        ],
        "model_ans": "Information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Information </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is typically used to broadly define complexity measures?",
        "answers": [
            "Blum complexity axioms",
            "the Blum complexity axioms",
            "the Blum complexity axioms"
        ],
        "model_ans": "Entropy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Entropy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Communication complexity is an example of what type of measure?",
        "answers": [
            "Complexity measures",
            "complexity measures",
            "complexity"
        ],
        "model_ans": "computational complexity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> computational complexity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Decision tree is an example of what type of measure?",
        "answers": [
            "Complexity measures",
            "complexity measures",
            "complexity"
        ],
        "model_ans": "Supervised learning",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supervised learning </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the three primary expressions used to represent case complexity?",
        "answers": [
            "best, worst and average",
            "best, worst and average case",
            "best, worst and average case complexity"
        ],
        "model_ans": "Simple, Complex, and Compound",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Simple, Complex, and Compound </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Case complexity likelihoods provide variable probabilities of what general measure? ",
        "answers": [
            "complexity measure",
            "complexity",
            "complexity"
        ],
        "model_ans": "accuracy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> accuracy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one common example of a critical complexity measure?",
        "answers": [
            "time",
            "time complexity",
            "time complexity"
        ],
        "model_ans": "Shannon entropy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shannon entropy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Case complexities provide three likelihoods of what differing variable that remains the same size? ",
        "answers": [
            "inputs",
            "inputs",
            "inputs"
        ],
        "model_ans": "length",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> length </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What provides a solution to a list of integers provided as input that ned to be sorted?",
        "answers": [
            "deterministic sorting algorithm quicksort",
            "quicksort",
            "the deterministic sorting algorithm quicksort"
        ],
        "model_ans": "Bubble sort",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bubble sort </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When extensive time is required to sort integers, this represents what case complexity?",
        "answers": [
            "worst-case",
            "worst",
            "worst-case"
        ],
        "model_ans": "O(n log n)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> O(n log n) </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the expression used to denote a worst case complexity as expressed by time taken?",
        "answers": [
            "O(n2)",
            "O(n2)",
            "O(n2)"
        ],
        "model_ans": "O(n)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O(n) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Classification of resources is contingent on determining the upper and lower bounds of minimum time required by what?  ",
        "answers": [
            "the most efficient algorithm",
            "the most efficient algorithm",
            "the most efficient algorithm solving a given problem"
        ],
        "model_ans": "users",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> users </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The analysis of a specific algorithm is typically assigned to what field of computational science?",
        "answers": [
            "analysis of algorithms",
            "analysis of algorithms",
            "analysis of algorithms"
        ],
        "model_ans": "Computer Science",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Computer Science </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which bound of time is more difficult to establish?",
        "answers": [
            "lower bounds",
            "lower",
            "lower bounds"
        ],
        "model_ans": "Past",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Past </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A specific algorithm demonstrating T(n) represents what measure of time complexity?",
        "answers": [
            "upper bound",
            "upper and lower bounds",
            "upper bound"
        ],
        "model_ans": "O(n)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O(n) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the colloquial phrase used to convey the continuum of algorithms with unlimited availability irrespective of time? ",
        "answers": [
            "all possible algorithms",
            "all possible algorithms",
            "all possible algorithms"
        ],
        "model_ans": "Always Available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Always Available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What expression is generally used to convey upper or lower bounds?",
        "answers": [
            "big O notation",
            "big O notation",
            "big O notation"
        ],
        "model_ans": "interval",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> interval </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does a big O notation hide?",
        "answers": [
            "constant factors and smaller terms",
            "constant factors and smaller terms",
            "constant factors and smaller terms"
        ],
        "model_ans": "constant factors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> constant factors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How would one write T(n) = 7n2 + 15n + 40 in big O notation? ",
        "answers": [
            "T(n) = O(n2)",
            "T(n) = O(n2)",
            "T(n) = O(n2)"
        ],
        "model_ans": "O(n^2)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O(n^2) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Big O notation provides autonomy to upper and lower bounds with relationship to what? ",
        "answers": [
            "the computational model",
            "specific details of the computational model used",
            "the specific details of the computational model used"
        ],
        "model_ans": "time complexity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> time complexity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has complicated definitions that prevent classification into a framework?",
        "answers": [
            "complexity classes",
            "complexity classes",
            "some complexity classes"
        ],
        "model_ans": "Chaos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chaos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Complexity classes are generally classified into what?",
        "answers": [
            "framework",
            "framework",
            "framework"
        ],
        "model_ans": "polynomial time",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> polynomial time </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Difficulty in establishing a framework for complexity classes can be caused by what variable?",
        "answers": [
            "complicated definitions",
            "complicated definitions",
            "definitions"
        ],
        "model_ans": "NP-hardness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NP-hardness </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Concrete bounding of computation time frequently produces complexity classes contingent upon what?",
        "answers": [
            "chosen machine model",
            "the chosen machine model",
            "the chosen machine model"
        ],
        "model_ans": "the choice of computational model",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the choice of computational model </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A multi-tape Turing machine requires what type of time for a solution?",
        "answers": [
            "linear time",
            "linear",
            "linear"
        ],
        "model_ans": "exponential",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> exponential </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A language solved in quadratic time implies the use of what type of Turing machine?",
        "answers": [
            "single-tape Turing machines",
            "single-tape",
            "single-tape"
        ],
        "model_ans": "Non-deterministic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Non-deterministic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What thesis specifies that a polynomial relationship exists within time complexities in a computational model? ",
        "answers": [
            "Cobham-Edmonds thesis",
            "Cobham-Edmonds",
            "Cobham-Edmonds thesis"
        ],
        "model_ans": "Master's thesis by David Harel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Master's thesis by David Harel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Decision problems capable of being solved by a deterministic Turing machine while maintaining adherence to polynomial time belong to what class?",
        "answers": [
            "complexity class P",
            "P",
            "complexity class P"
        ],
        "model_ans": "P",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> P </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are two examples of measurements are bound within algorithms to establish complexity classes?",
        "answers": [
            "time or space",
            "time or space",
            "time or space"
        ],
        "model_ans": "Time and Space",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Time and Space </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What function is used by algorithms to define measurements like time or space?",
        "answers": [
            "bounding",
            "bounding",
            "bounding"
        ],
        "model_ans": "metric",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> metric </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Bounding of time and space or similar measurements is often used by algorithms to define what?",
        "answers": [
            "complexity classes",
            "complexity classes",
            "complexity classes"
        ],
        "model_ans": "a region",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a region </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are three examples of complexity classes associated with definitions established by probabilistic Turing machines?",
        "answers": [
            "BPP, ZPP and RP",
            "BPP, ZPP and RP",
            "BPP, ZPP and RP"
        ],
        "model_ans": "BPP, RP, and ZPP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BPP, RP, and ZPP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "AC and NC are complexity classes typically associated with what type of circuit?",
        "answers": [
            "Boolean",
            "Boolean",
            "Boolean circuits;"
        ],
        "model_ans": "Boolean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boolean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "BQP and QMA are examples of complexity classes most commonly associated with what type of Turing machine?",
        "answers": [
            "quantum",
            "quantum",
            "quantum"
        ],
        "model_ans": "Quantum",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantum </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the expression used to represent a complexity class of counting problems?",
        "answers": [
            "#P",
            "#P",
            "#P"
        ],
        "model_ans": "#P",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> #P </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "IP and AM are most commonly defined by what type of proof system?",
        "answers": [
            "Interactive",
            "Interactive",
            "Interactive"
        ],
        "model_ans": "Hilbert-style proof system",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hilbert-style proof system </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of a measurement within a complexity class that would create a bigger set of problems if the bounds were relaxed?",
        "answers": [
            "computation time",
            "computation time",
            "computation time"
        ],
        "model_ans": "NP-hard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what expression can one expect to find DTIME(n)",
        "answers": [
            "DTIME(n2)",
            "DTIME(n2)",
            "DTIME(n2)"
        ],
        "model_ans": "Big O notation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Big O notation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What theorems are responsible for determining questions of time and space requirements?",
        "answers": [
            "time and space hierarchy theorems",
            "time and space hierarchy theorems",
            "time and space hierarchy theorems"
        ],
        "model_ans": "Big O notation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Big O notation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Resources are constrained by hierarchy theorems to produce what?",
        "answers": [
            "a proper hierarchy on the classes defined",
            "a proper hierarchy on the classes",
            "a proper hierarchy"
        ],
        "model_ans": "optimal solutions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> optimal solutions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of statement is made in the effort of establishing the time and space requirements needed to enhance the ultimate number of problems solved?",
        "answers": [
            "quantitative statements",
            "quantitative",
            "quantitative"
        ],
        "model_ans": "Hypothetical",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hypothetical </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the foundation for separation results within complexity classes?",
        "answers": [
            "time and space hierarchy theorems",
            "The time and space hierarchy theorems",
            "time and space hierarchy theorems"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is responsible for constraining P according to the time hierarchy theorem?",
        "answers": [
            "EXPTIME",
            "EXPTIME",
            "EXPTIME"
        ],
        "model_ans": "The time hierarchy theorem itself",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The time hierarchy theorem itself </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Within what variable is L constrained according to the space hierarchy theorem?",
        "answers": [
            "PSPACE",
            "PSPACE",
            "PSPACE"
        ],
        "model_ans": "L is constrained within the variable of space",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> L is constrained within the variable of space </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What concept is frequently used to define complexity classes?",
        "answers": [
            "reduction",
            "a reduction",
            "reduction"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Reduction essentially takes one problem and converts into what?",
        "answers": [
            "another problem",
            "another problem",
            "another problem"
        ],
        "model_ans": "an equivalent problem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> an equivalent problem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to reduction, if X and Y can be solved by the same algorithm then X performs what function in relationship to Y?",
        "answers": [
            "reduces",
            "reduces",
            "X reduces to Y"
        ],
        "model_ans": "equivalent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> equivalent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are two examples of different types of reduction?",
        "answers": [
            "Karp reductions and Levin reductions",
            "Cook reductions, Karp reductions"
        ],
        "model_ans": "chemical reduction and reduction in size",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> chemical reduction and reduction in size </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Polynomial time reductions are an example of what?",
        "answers": [
            "the bound on the complexity of reductions",
            "types of reductions",
            "the bound on the complexity of reductions"
        ],
        "model_ans": "reductions",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>reductions</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most frequently employed type of reduction?",
        "answers": [
            "polynomial-time reduction",
            "polynomial-time",
            "polynomial-time reduction"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What equates to a squared integer according to polynomial time reduction?",
        "answers": [
            "multiplying two integers",
            "multiplying two integers",
            "multiplying two integers"
        ],
        "model_ans": "a perfect square",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a perfect square </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What measurement of time is used in polynomial time reduction?",
        "answers": [
            "polynomial time",
            "polynomial",
            "polynomial time"
        ],
        "model_ans": "polynomial time",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> polynomial time </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What would need to remain constant in a multiplication algorithm to produce the same outcome whether multiplying or squaring two integers?  ",
        "answers": [
            "input",
            "input",
            "input"
        ],
        "model_ans": "the order of operations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the order of operations </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to polynomial time reduction squaring can ultimately be logically reduced to what?",
        "answers": [
            "multiplication",
            "multiplication",
            "multiplication"
        ],
        "model_ans": "multiplication",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> multiplication </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The complexity of problems often depends on what?",
        "answers": [
            "the type of reduction being used",
            "the type of reduction being used"
        ],
        "model_ans": "the number of variables involved",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the number of variables involved </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What would create a conflict between a problem X and problem C within the context of reduction? ",
        "answers": [
            "if every problem in C can be reduced to X",
            "problem in C is harder than X"
        ],
        "model_ans": "The reduction process",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The reduction process </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "An algorithm for X which reduces to C would us to do what?",
        "answers": [
            "solve any problem in C",
            "solve any problem in C",
            "solve any problem in C"
        ],
        "model_ans": "reduce",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> reduce </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A problem set that that is hard for the expression NP can also be stated how?",
        "answers": [
            "NP-hard",
            "NP-hard",
            "NP-hard problems"
        ],
        "model_ans": "NP-hard",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The hardest problems in NP can be analogously written as what class of problems?",
        "answers": [
            "NP-complete",
            "NP-complete",
            "NP-complete"
        ],
        "model_ans": "NP-hard",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "NP complete problems contain the lowest likelihood of being located in what problem class?",
        "answers": [
            "NP",
            "P",
            "P"
        ],
        "model_ans": "P",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> P </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "If P = NP is unsolved, and reduction is applied to a known NP-complete problem vis a vis \u03a02 to  \u03a01, what conclusion can be drawn for \u03a01?",
        "answers": [
            "there is no known polynomial-time solution",
            "no known polynomial-time solution",
            "there is no known polynomial-time solution"
        ],
        "model_ans": "\u03a01 is NP-complete",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u03a01 is NP-complete </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If polynomial time can be utilized within an NP-complete problem, what does the imply P is equal to?",
        "answers": [
            "NP",
            "NP",
            "NP"
        ],
        "model_ans": "NP",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> NP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What complexity class is characterized by a computational tasks and efficient algorithms?",
        "answers": [
            "P",
            "P",
            "P"
        ],
        "model_ans": "P",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> P </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What hypothesis is associated with the complexity class of P viewed as a mathematical abstraction with efficient algorithmic functionality?",
        "answers": [
            "Cobham\u2013Edmonds thesis",
            "Cobham\u2013Edmonds thesis",
            "Cobham\u2013Edmonds thesis"
        ],
        "model_ans": "NP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What complexity class is commonly characterized by unknown algorithms to enhance solvability?",
        "answers": [
            "NP",
            "NP",
            "NP"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an example of a problem that rests within the NP complexity class?",
        "answers": [
            "Boolean satisfiability problem",
            "Boolean satisfiability problem"
        ],
        "model_ans": "The Traveling Salesman Problem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Traveling Salesman Problem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what theoretical machine is it confirmed that a problem in P belies membership in the NP class?",
        "answers": [
            "Turing machines",
            "deterministic Turing machines",
            "deterministic Turing machines"
        ],
        "model_ans": "Turing Machine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turing Machine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If P is ultimately proven to be equal tot NP, what effect would this have on the efficiency of problems?",
        "answers": [
            "more efficient solutions",
            "shown to have more efficient solutions",
            "many important problems can be shown to have more efficient solutions"
        ],
        "model_ans": "It would mean that all problems in NP can be solved efficiently",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It would mean that all problems in NP can be solved efficiently </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a particular problem in biology that would benefit from determining that P = NP?",
        "answers": [
            "protein structure prediction",
            "protein structure prediction",
            "protein structure prediction"
        ],
        "model_ans": "protein folding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> protein folding </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the prize offered for finding a solution to P=NP?",
        "answers": [
            "$1,000,000",
            "US$1,000,000",
            "US$1,000,000"
        ],
        "model_ans": "1 million dollars",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1 million dollars </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who demonstrated that P= NP implies problems not present in P or NP-complete?",
        "answers": [
            "Ladner",
            "Ladner",
            "Ladner"
        ],
        "model_ans": "Richard Karp",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Karp </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name for a problem that meets Ladner's assertion?",
        "answers": [
            "NP-intermediate problems",
            "NP-intermediate problems",
            "NP-intermediate"
        ],
        "model_ans": "Fixed point",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fixed point </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of an NP-intermediate problem not known to exist in P or NP-complete? ",
        "answers": [
            "graph isomorphism problem",
            "the discrete logarithm problem",
            "graph isomorphism problem, the discrete logarithm problem and the integer factorization problem"
        ],
        "model_ans": "The problem of determining whether a given graph is a planar graph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The problem of determining whether a given graph is a planar graph </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the problem attributed to defining if two finite graphs are isomorphic?",
        "answers": [
            "The graph isomorphism problem",
            "graph isomorphism",
            "The graph isomorphism problem"
        ],
        "model_ans": "Graph isomorphism problem",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Graph isomorphism problem </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What class is most commonly not ascribed to the graph isomorphism problem in spite of definitive determination?",
        "answers": [
            "NP-complete",
            "NP-complete",
            "NP-complete"
        ],
        "model_ans": "NP-complete",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> NP-complete </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What finite hierarchy implies that the graph isomorphism problem is NP-complete? ",
        "answers": [
            "polynomial time hierarchy",
            "polynomial time",
            "polynomial time hierarchy"
        ],
        "model_ans": "Cook-Levin theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cook-Levin theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To what level would the polynomial time hierarchy collapse if graph isomorphism is NP-complete?",
        "answers": [
            "second level",
            "second",
            "second"
        ],
        "model_ans": "PH",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> PH </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who are commonly associated with the algorithm typically considered the most effective with respect to finite polynomial hierarchy and graph isomorphism?",
        "answers": [
            "Laszlo Babai and Eugene Luks",
            "Babai and Eugene Luks",
            "Laszlo Babai and Eugene Luks"
        ],
        "model_ans": "Peter Shor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Peter Shor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What computational problem is commonly associated with prime factorization?",
        "answers": [
            "The integer factorization problem",
            "integer factorization",
            "integer factorization problem"
        ],
        "model_ans": "Integer factorization",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Integer factorization </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The integer factorization problem essentially seeks to determine if the value of of an input is less than what variable? ",
        "answers": [
            "k",
            "k",
            "k"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "That there currently exists no known integer factorization problem underpins what commonly used system?",
        "answers": [
            "modern cryptographic systems",
            "modern cryptographic systems",
            "RSA algorithm"
        ],
        "model_ans": "RSA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RSA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most well-known algorithm associated with the integer factorization problem?",
        "answers": [
            "the general number field sieve",
            "RSA",
            "general number field sieve"
        ],
        "model_ans": "RSA",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RSA </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the unproven assumption generally ascribed to the value of complexity classes?",
        "answers": [
            "suspected to be unequal",
            "unequal",
            "Many known complexity classes are suspected to be unequal"
        ],
        "model_ans": "NP-hardness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NP-hardness </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an expression that can be used to illustrate the suspected inequality of complexity classes?",
        "answers": [
            "P \u2286 NP \u2286 PP \u2286 PSPACE",
            "P \u2286 NP \u2286 PP \u2286 PSPACE",
            "P \u2286 NP \u2286 PP \u2286 PSPACE"
        ],
        "model_ans": "NP vs P",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP vs P </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where can the complexity classes RP, BPP, PP, BQP, MA, and PH be located?",
        "answers": [
            "between P and PSPACE",
            "between P and PSPACE",
            "between P and PSPACE"
        ],
        "model_ans": "Complexity Zoo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Complexity Zoo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What evidence between and among complexity classes would signify a theoretical watershed for complexity theory?",
        "answers": [
            "Proving that any of these classes are unequal",
            "Proving that any of these classes are unequal",
            "Proving that any of these classes are unequal"
        ],
        "model_ans": "NP vs. P",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP vs. P </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what complexity class do complement problems of NP problems exist?",
        "answers": [
            "co-NP",
            "co-NP",
            "co-NP"
        ],
        "model_ans": "co-NP",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>co-NP</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How do the yes/no answers of a complement problem of NP appear?",
        "answers": [
            "reversed",
            "reversed",
            "reversed"
        ],
        "model_ans": "NP-complete",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-complete </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is commonly believed to be the value relationship between P and co-NP",
        "answers": [
            "not equal",
            "not equal",
            "not equal"
        ],
        "model_ans": "P=co-NP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> P=co-NP </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What implication can be derived for P and NP if P and co-NP are established to be unequal?",
        "answers": [
            "P is not equal to NP",
            "not equal",
            "P is not equal to NP"
        ],
        "model_ans": "If P and co-NP are established to be unequal, then NP is not equal to co-NP.",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> If P and co-NP are established to be unequal, then NP is not equal to co-NP. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What variable is associated with all problems solved within logarithmic space?",
        "answers": [
            "L",
            "L",
            "L"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Though unkown, what are the most commonly ascribed attributes of L in relation to P",
        "answers": [
            "strictly contained in P or equal to P",
            "contained in P or equal to P.",
            "strictly contained in P or equal to P"
        ],
        "model_ans": "L is a letter",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> L is a letter </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What lies between L and P that prevents a definitive determination of the relationship between L and P?",
        "answers": [
            "complexity classes",
            "many complexity classes",
            "many complexity classes"
        ],
        "model_ans": "M",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> M </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are two complexity classes between L and P?",
        "answers": [
            "NL and NC",
            "NL and NC",
            "NL and NC"
        ],
        "model_ans": "NL and NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NL and NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P?",
        "answers": [
            "if they are distinct or equal classes",
            "if they are distinct or equal classes",
            "if they are distinct or equal classes"
        ],
        "model_ans": "The complexity classes between L and P are not well-defined",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The complexity classes between L and P are not well-defined </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Problems capable of theoretical solutions but consuming unreasonable time in practical application are known as what?",
        "answers": [
            "intractable problems",
            "intractable problems",
            "intractable",
            "intractable"
        ],
        "model_ans": "NP-hard problems",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-hard problems </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Intractable problems lacking polynomial time solutions necessarily negate the practical efficacy of what type of algorithm?",
        "answers": [
            "exponential-time algorithms",
            "exponential-time",
            "exponential-time algorithms",
            "exponential-time algorithms"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If NP is not equal to P, viewed through this lens, what type of problems can also be considered intractable?",
        "answers": [
            "NP-complete problems",
            "NP-complete",
            "NP-complete",
            "NP-complete"
        ],
        "model_ans": "NP-complete problems",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-complete problems </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What eponymous variation of arithmetic presents a decision problem not evidenced in P?",
        "answers": [
            "Presburger arithmetic",
            "Presburger",
            "Presburger arithmetic"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Despite the Presburger problem, and in view of intractability, what has been done to establish solutions in reasonable periods of time?",
        "answers": [
            "algorithms have been written",
            "algorithms have been written",
            "algorithms have been written that solve the problem in reasonable times in most cases"
        ],
        "model_ans": "Automated theorem proving",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Automated theorem proving </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of a problem to which effective algorithms have provided a solution in spite of the intractability associated with the breadth of sizes?",
        "answers": [
            "NP-complete knapsack problem",
            "NP-complete knapsack",
            "the NP-complete knapsack problem"
        ],
        "model_ans": "Sorting",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sorting </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How quickly can an algorithm solve an NP-complete knapsack problem?",
        "answers": [
            "in less than quadratic time",
            "less than quadratic time",
            "less than quadratic time"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the example of another problem characterized by large instances that is routinely solved by SAT handlers employing efficient algorithms?",
        "answers": [
            "NP-complete Boolean satisfiability problem",
            "NP-complete Boolean satisfiability",
            "the NP-complete Boolean satisfiability problem"
        ],
        "model_ans": "Scheduling",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Scheduling </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What tactic did researchers employ to offset the former deficit of work surrounding the complexity of algorithmic problems?",
        "answers": [
            "foundations were laid out",
            "numerous foundations were laid out",
            "numerous foundations were laid out by various researchers"
        ],
        "model_ans": "Divide and Conquer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Divide and Conquer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the most influential researcher among those grappling with the deficit of work surrounding the complexity posed by algorithmic problems?",
        "answers": [
            "Alan Turing",
            "Alan Turing",
            "Alan Turing"
        ],
        "model_ans": "Alan Turing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alan Turing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What theoretical device is attributed to Alan Turing?",
        "answers": [
            "Turing machines",
            "Turing machines",
            "Turing machines"
        ],
        "model_ans": "Turing Machine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turing Machine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the Alan Turing's definitional model of a computing device received?",
        "answers": [
            "1936",
            "1936",
            "1936"
        ],
        "model_ans": "1936\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1936\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the most basic sense what did a Turing machine emulate?",
        "answers": [
            "a computer",
            "a computer",
            "a computer"
        ],
        "model_ans": "A human",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A human </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What paper is commonly considered the bellwether ushering in systematic studies computational complexity?",
        "answers": [
            "On the Computational Complexity of Algorithms",
            "On the Computational Complexity of Algorithms",
            "\"On the Computational Complexity of Algorithms\""
        ],
        "model_ans": "Journal of the ACM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Journal of the ACM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What individuals were responsible for authoring \"On the Computational Complexity of Algorithms\"?",
        "answers": [
            "Juris Hartmanis and Richard Stearns",
            "Juris Hartmanis and Richard Stearns",
            "Juris Hartmanis and Richard Stearns"
        ],
        "model_ans": "Michael Sipser",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Sipser </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was Hatmanis and Stearn's seminal work in computational complexity received? ",
        "answers": [
            "1965",
            "1965",
            "1965"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What complex measurements were defined by \"On the Computational Complexity of Algorithms\"?",
        "answers": [
            "time and space",
            "definitions of time and space complexity",
            "time and space complexity"
        ],
        "model_ans": "NP-complete",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP-complete </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did Edmond's characterize a \"good\" algorithm?",
        "answers": [
            "1965",
            "1965",
            "1965"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who provided a definition of linear bounded automata in 1960?",
        "answers": [
            "John Myhill",
            "John Myhill",
            "John Myhill"
        ],
        "model_ans": "Michael Sipser",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Sipser </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Raymond Sullivan publish a study of rudimentary sets?",
        "answers": [
            "1961",
            "1961",
            "1961"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1962, who was responsible for the authorship of a paper published on real time-computations?",
        "answers": [
            "Hisao Yamada",
            "Hisao Yamada",
            "Hisao Yamada"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the concrete choice typically assumed by most complexity-theoretic theorems?",
        "answers": [
            "input encoding",
            "input encoding",
            "input encoding"
        ],
        "model_ans": "NP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In the effort of maintaining a level of abstraction, what choice is typically left independent?",
        "answers": [
            "encoding",
            "encoding",
            "encoding"
        ],
        "model_ans": "Abstraction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abstraction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is responsible for axiomatic complexity theory?",
        "answers": [
            "Manuel Blum",
            "Manuel Blum",
            "Manuel Blum"
        ],
        "model_ans": "Gregory Chaitin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gregory Chaitin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What theorem was implicated by Manuel Blum's axioms?",
        "answers": [
            "speed-up theorem",
            "speed-up theorem",
            "speed-up theorem"
        ],
        "model_ans": "Blum's axioms",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Blum's axioms </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the paper written by Richard Karp in 1972 that ushered in a new era of understanding between intractability and NP-complete problems?",
        "answers": [
            "\"Reducibility Among Combinatorial Problems\"",
            "Reducibility Among Combinatorial Problems",
            "\"Reducibility Among Combinatorial Problems\""
        ],
        "model_ans": "Every NP-Complete Problem Preserves Strong Reducibility Under Linear-Time Reductions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Every NP-Complete Problem Preserves Strong Reducibility Under Linear-Time Reductions </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many combinatory and graph theoretical problems, formerly believed to be plagued by intractability, did Karp's paper address?",
        "answers": [
            "21",
            "21",
            "21"
        ],
        "model_ans": "21\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "21\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Southern California often abbreviated as?",
        "answers": [
            "SoCal",
            "SoCal",
            "SoCal"
        ],
        "model_ans": "SoCal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SoCal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Despite being traditionall described as \"eight counties\", how many counties does this region actually have?",
        "answers": [
            "10 counties",
            "10",
            "10"
        ],
        "model_ans": "8",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 8 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a major importance of Southern California in relation to California and the United States?",
        "answers": [
            "economic center",
            "major economic center",
            "economic center"
        ],
        "model_ans": "Economy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the ties that best described what the \"eight counties\" are based on?",
        "answers": [
            "demographics and economic ties",
            "economic",
            "demographics and economic"
        ],
        "model_ans": "geographical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> geographical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The reasons for the las two counties to be added are based on what?",
        "answers": [
            "historical political divisions",
            "historical political divisions",
            "historical political divisions"
        ],
        "model_ans": "The 1997 Hong Kong reversion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The 1997 Hong Kong reversion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the region that is not defined by the eight or 10 county definitions?",
        "answers": [
            "Southern California Megaregion",
            "the greater Southern California Megaregion",
            "Southern California Megaregion"
        ],
        "model_ans": "Midwest",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Midwest </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many megaregions are there in the United States?",
        "answers": [
            "11",
            "11",
            "11"
        ],
        "model_ans": "11\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "11\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the state that the megaregion expands to in the east?",
        "answers": [
            "Nevada",
            "Nevada",
            "Nevada"
        ],
        "model_ans": "Pennsylvania",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pennsylvania </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which border does the megaregion extend over?",
        "answers": [
            "Mexican",
            "Mexican",
            "Mexican"
        ],
        "model_ans": "Europe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the area past the border that the megaregion extends into?",
        "answers": [
            "Tijuana",
            "Tijuana",
            "Tijuana"
        ],
        "model_ans": "The Megalopolis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Megalopolis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which coastline does Southern California touch?",
        "answers": [
            "Pacific",
            "Pacific",
            "Pacific"
        ],
        "model_ans": "Pacific",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pacific </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many metropolitan areas does Southern California's population encompass?",
        "answers": [
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many inhabitants does the Los Angeles area contain?",
        "answers": [
            "12 million",
            "over 12 million inhabitants",
            "12 million"
        ],
        "model_ans": "approximately 13.2 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> approximately 13.2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which of the three heavily populated areas has the least number of inhabitants?",
        "answers": [
            "San Diego",
            "the San Diego area",
            "San Diego"
        ],
        "model_ans": "Tokyo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tokyo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people does the Greater Los Angeles Area have?",
        "answers": [
            "17.5 million",
            "over 17.5 million",
            "17.5 million"
        ],
        "model_ans": "13,291,486",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13,291,486 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the water body that is found to the east?",
        "answers": [
            "Colorado River",
            "the Colorado River",
            "Colorado River"
        ],
        "model_ans": "Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the desert on the border of Arizona?",
        "answers": [
            "Colorado Desert",
            "the Colorado Desert",
            "Colorado Desert"
        ],
        "model_ans": "Sonoran Desert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sonoran Desert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the desert near the border of Nevada?",
        "answers": [
            "Mojave Desert",
            "the Mojave Desert",
            "Mojave Desert"
        ],
        "model_ans": "Mojave",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mojave </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the border to the south?",
        "answers": [
            "Mexico\u2013United States border",
            "the Mexico\u2013United States border",
            "Mexico\u2013United States border"
        ],
        "model_ans": "Mexico-US border",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mexico-US border </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The cities of Los Angeles and San Diego are a part of which state?",
        "answers": [
            "California",
            "California",
            "California"
        ],
        "model_ans": "California",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the population of Los Angeles?",
        "answers": [
            "3,792,621",
            "3,792,621",
            "3,792,621"
        ],
        "model_ans": "3,999,759\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3,999,759\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which city is the most populous in California?",
        "answers": [
            "Los Angeles",
            "Los Angeles",
            "Los Angeles"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the eighth most populous city in the nation?",
        "answers": [
            "San Diego",
            "San Diego",
            "San Diego"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which cardinal direction from Los Angeles is San Diego?",
        "answers": [
            "south",
            "south"
        ],
        "model_ans": "South",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Orange, San Diego, Riverside and San Bernardino make up four of the five counties. What is the name of the last county?",
        "answers": [
            "Los Angeles",
            "Los Angeles",
            "Riverside"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What country are all the counties in?",
        "answers": [
            "United States",
            "the United States",
            "Los Angeles"
        ],
        "model_ans": "United States",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> United States </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are Los Angeles, Orange, San Diego, San Bernardino and Riverside?",
        "answers": [
            "counties",
            "counties",
            "five most populous in the state"
        ],
        "model_ans": "counties",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> counties </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the lowest ranking one of the counties could have in terms of most populous counties in the United States?",
        "answers": [
            "15",
            "15",
            "Riverside"
        ],
        "model_ans": "3,142",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3,142 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the smallest geographical region discussed?",
        "answers": [
            "counties",
            "Riverside"
        ],
        "model_ans": "Shao Qiao",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shao Qiao </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name given to the district that is associated with the motion picture industry?",
        "answers": [
            "Hollywood",
            "Hollywood",
            "Hollywood"
        ],
        "model_ans": "Hollywood",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hollywood </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which city does the Hollywood district belong to?",
        "answers": [
            "Los Angeles",
            "Los Angeles",
            "Los Angeles"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which company owns ABC?",
        "answers": [
            "The Walt Disney Company",
            "The Walt Disney Company",
            "The Walt Disney Company"
        ],
        "model_ans": "Disney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Disney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than the motion picture and television industry, what other major industry is centered in Los Angeles?",
        "answers": [
            "music",
            "major record companies"
        ],
        "model_ans": "Aerospace",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aerospace </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than Universal and Warner Brothers, what other company runs a major record company?",
        "answers": [
            "Sony",
            "Sony",
            "Sony"
        ],
        "model_ans": "Sony",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sony </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than surf, what other culture is southern California home to?",
        "answers": [
            "skateboard",
            "skateboard",
            "skateboard"
        ],
        "model_ans": "Latin American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Latin American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the professional skateboarder that lives in southern California?",
        "answers": [
            "Tony Hawk",
            "Tony Hawk",
            "Tony Hawk"
        ],
        "model_ans": "Tony Hawk",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tony Hawk </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What famous snowbaorder lives in southern California?",
        "answers": [
            "Shaun White",
            "Shaun White",
            "Shaun White"
        ],
        "model_ans": "Shaun White",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shaun White </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Southern California is second to which island in terms of famous serf breaks?",
        "answers": [
            "Oahu",
            "Oahu",
            "Oahu"
        ],
        "model_ans": "Bali",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bali </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the shortened name of the annual yacht race that takes place?",
        "answers": [
            "Transpac",
            "Transpac",
            "Transpac"
        ],
        "model_ans": "America's Cup",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> America's Cup </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the desert city?",
        "answers": [
            "Palm Springs",
            "Palm Springs",
            "Palm Springs"
        ],
        "model_ans": "Marrakech",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marrakech </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than the desert city why do many locals and tourists frequent southern California?",
        "answers": [
            "beaches",
            "for its popular beaches",
            "beaches"
        ],
        "model_ans": "beaches",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> beaches </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which region of California is Palm Springs located in?",
        "answers": [
            "southern",
            "the desert",
            "southern"
        ],
        "model_ans": "Coachella Valley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coachella Valley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than for its resort feel, what is Palm Springs popular for?",
        "answers": [
            "open spaces",
            "nearby open spaces",
            "nearby open spaces"
        ],
        "model_ans": "Mid-century modern architecture",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mid-century modern architecture </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Geographically speaking, where is California's north - south midway point in terms of latitude?",
        "answers": [
            "37\u00b0 9' 58.23\"",
            "37\u00b0 9' 58.23\"",
            "37\u00b0 9' 58.23\""
        ],
        "model_ans": "36.5\u00b0 N",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 36.5\u00b0 N </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many miles south of San Jose is the north - south midway point located?",
        "answers": [
            "11",
            "11",
            "11"
        ],
        "model_ans": "45 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 45 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The term \"southern\" California usually refers to how many of the southern-most counties of the state?",
        "answers": [
            "ten",
            "ten",
            "ten"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than Point Conception, what landmark is used in the other definition of southern California?",
        "answers": [
            "Tehachapi Mountains",
            "Tehachapi Mountains"
        ],
        "model_ans": "San Diego",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Diego </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Point Conception is an example of a landmark among what boundary of southern California?",
        "answers": [
            "northern",
            "the Tehachapi Mountains",
            "northern"
        ],
        "model_ans": "coastline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> coastline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country used to rule California?",
        "answers": [
            "Mexico",
            "Mexico",
            "Mexico"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Los Angeles is in the lower part of what?",
        "answers": [
            "Alta California",
            "Alta California",
            "Alta California"
        ],
        "model_ans": "California",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which Californio is located in the upper part?",
        "answers": [
            "Monterey",
            "Monterey",
            "Monterey"
        ],
        "model_ans": "San Francisco",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> San Francisco </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the legislation passed in 1850?",
        "answers": [
            "the Missouri Compromise",
            "the Compromise of 1850",
            "Compromise of 1850"
        ],
        "model_ans": "Fugitive Slave Act",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fugitive Slave Act </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The legislation allowed California to be admitted to the Union as what kind of state?",
        "answers": [
            "free",
            "a free state",
            "free"
        ],
        "model_ans": "Free",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Free </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than land laws, what else were the Californios dissatisfied with?",
        "answers": [
            "inequitable taxes",
            "inequitable taxes",
            "inequitable taxes"
        ],
        "model_ans": "taxation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> taxation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name given to the regions in which the pro - slavery southerners lived?",
        "answers": [
            "Cow Counties",
            "Cow Counties",
            "Cow Counties"
        ],
        "model_ans": "Border States",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Border States </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many times did southern California attempt to achieve a separate statehood?",
        "answers": [
            "three",
            "three",
            "three"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of people that voted in favor of the Pico Act of 1859?",
        "answers": [
            "75",
            "75%",
            "75"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which Senator was a strong advocate for the Pico Act?",
        "answers": [
            "Milton Latham",
            "Milton Latham",
            "Milton Latham"
        ],
        "model_ans": "Mazie Hirono",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mazie Hirono </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which newspaper defined southern California?",
        "answers": [
            "Los Angeles Times",
            "the Los Angeles Times",
            "Los Angeles Times"
        ],
        "model_ans": "Los Angeles Times",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles Times </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In which year did the newspaper define southern California?",
        "answers": [
            "1900",
            "1900",
            "1900"
        ],
        "model_ans": "1886",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1886 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which year did the newspaper change its previous definition?",
        "answers": [
            "1999",
            "1999",
            "1999"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the newer county added to the list?",
        "answers": [
            "Imperial",
            "Imperial",
            "1999"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many counties initially made up the definition of southern California?",
        "answers": [
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which organizations most commonly divide and promote the state?",
        "answers": [
            "regional tourism groups",
            "regional tourism groups",
            "AAA Auto Clubs"
        ],
        "model_ans": "Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than the Automobile Club of Southern California, what other AAA Auto Club chose to simplify the divide?",
        "answers": [
            "California State Automobile Association",
            "the California State Automobile Association",
            "California State Automobile Association"
        ],
        "model_ans": "AAA Mid-Atlantic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AAA Mid-Atlantic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The two AAA clubs divided the state into a northern and southern California as opposed to what point of view?",
        "answers": [
            "three-region",
            "the three-region point of view",
            "three-region"
        ],
        "model_ans": "AAA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> AAA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which mountain range influenced the split of the regions?",
        "answers": [
            "Tehachapis",
            "the Tehachapis",
            "Tehachapis"
        ],
        "model_ans": "Himalayas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Himalayas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the definition based off the mountain range, which region would the desert portions of north Los Angeles County be included in?",
        "answers": [
            "southern",
            "southern California",
            "southern California"
        ],
        "model_ans": "Mojave Desert\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Mojave Desert\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does southern California's megalopolis standard in terms of population nationwide?",
        "answers": [
            "third",
            "third",
            "third"
        ],
        "model_ans": "2nd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2nd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Although southern california consts of a heavily developed urban environment, how much of it has been left undeveloped?",
        "answers": [
            "vast areas",
            "vast areas",
            "vast areas"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Southern Californian communities are well known to be large, spread - out, and what other characteristic?",
        "answers": [
            "suburban",
            "suburban",
            "suburban communities and use of automobiles and highways"
        ],
        "model_ans": "car-dependent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> car-dependent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Outside of its use of automobiles, what else is southern California famous for using?",
        "answers": [
            "highways",
            "highways"
        ],
        "model_ans": "Film",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Film </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of region can be found inside the urban area of southern California?",
        "answers": [
            "international metropolitan",
            "an international metropolitan region",
            "international metropolitan"
        ],
        "model_ans": "Coastal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coastal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the main gap to continued urbanization?",
        "answers": [
            "Camp Pendleton",
            "Camp Pendleton",
            "Camp Pendleton"
        ],
        "model_ans": "Infrastructure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Infrastructure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than the San Diego metropolitan area, what other area are the communities along Interstates 15 and 215 connected with?",
        "answers": [
            "Inland Empire",
            "Temecula and Murrieta"
        ],
        "model_ans": "Las Vegas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Las Vegas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who considers Los Angeles County to be a separate metropolitan area?",
        "answers": [
            "United States Census Bureau",
            "the United States Census Bureau",
            "United States Census Bureau"
        ],
        "model_ans": "The United States Census Bureau",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The United States Census Bureau </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than L.A. which other county do many people commute to?",
        "answers": [
            "Orange",
            "Orange Counties",
            "Orange"
        ],
        "model_ans": "Orange",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Orange </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than the 1980s, in which decade did most of San Bernardino and Riverside Counties develop?",
        "answers": [
            "1990s",
            "1990s",
            "1990s"
        ],
        "model_ans": "1950s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of climate does southern California maintain?",
        "answers": [
            "Mediterranean",
            "a Mediterranean climate",
            "Mediterranean"
        ],
        "model_ans": "Mediterranean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mediterranean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than many sunny days, what characteristic is typical for the climate in souther California?",
        "answers": [
            "infrequent rain",
            "infrequent rain",
            "infrequent rain"
        ],
        "model_ans": "Mild winters",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mild winters </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the low end of the temperature range in summer?",
        "answers": [
            "60's",
            "60's",
            "60's"
        ],
        "model_ans": "64\u00b0F",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 64\u00b0F </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How frequent is snow in the Southwest of the state?",
        "answers": [
            "very rare",
            "very rare",
            "very rare"
        ],
        "model_ans": "Rare",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rare </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the high end of the temperature range in winter?",
        "answers": [
            "70",
            "70",
            "70"
        ],
        "model_ans": "32\u00b0F",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 32\u00b0F </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What term best describes southern California's collection of landscapes?",
        "answers": [
            "varied",
            "varied",
            "natural ecosystem"
        ],
        "model_ans": "Coastal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coastal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The region spans starting at islands found in which body of water?",
        "answers": [
            "Pacific Ocean",
            "Pacific Ocean",
            "Pacific Ocean"
        ],
        "model_ans": "Pacific",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pacific </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of landscapes other than geologic and natural ecosystem landscapes can be found in southern California?",
        "answers": [
            "topographic",
            "topographic",
            "topographic"
        ],
        "model_ans": "Urban",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Urban </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The region spans which mountains other than the Transverse ranges?",
        "answers": [
            "Peninsular",
            "Peninsular Ranges",
            "Peninsular Ranges"
        ],
        "model_ans": "Sierra Nevada",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sierra Nevada </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The mountain ranges tail off into what kind of geographical formation?",
        "answers": [
            "valleys",
            "valleys",
            "interior valleys"
        ],
        "model_ans": "hills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many earthquakes does southern California experience in a year?",
        "answers": [
            "10,000",
            "10,000",
            "10,000"
        ],
        "model_ans": "10,000 to 20,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10,000 to 20,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Generally speaking, what size are the earthquakes that hit southern California?",
        "answers": [
            "small",
            "small",
            "small"
        ],
        "model_ans": "3-6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3-6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What magnitude was the 1994 Northridge earthquake?",
        "answers": [
            "6.7",
            "6.7",
            "6.7"
        ],
        "model_ans": "6.7\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "6.7\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kind of destruction did the 1994 earthquake cause the most of in US history?",
        "answers": [
            "property damage",
            "property damage"
        ],
        "model_ans": "Northridge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Northridge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much was the 1994 earthquake estimated to have cost?",
        "answers": [
            "$20 billion",
            "over $20 billion",
            "over $20 billion"
        ],
        "model_ans": "$30 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $30 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which fault can produce a magnitude earthquake of 8.0?",
        "answers": [
            "San Andreas",
            "the San Andreas Fault",
            "San Andreas Fault"
        ],
        "model_ans": "San Andreas Fault",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> San Andreas Fault </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What magnitude of earthquake can many faults produce?",
        "answers": [
            "6.7",
            "6.7+",
            "6.7+"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than the San Jacinto Fault, and the Elsinore Fault, name one other fault.",
        "answers": [
            "Puente Hills",
            "the Puente Hills Fault",
            "Puente Hills Fault"
        ],
        "model_ans": "Hayward Fault",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hayward Fault </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which organization released a California Earthquake forecast?",
        "answers": [
            "USGS",
            "The USGS",
            "USGS"
        ],
        "model_ans": "USGS",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> USGS </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The earthquake forecast models what features of earthquakes in California?",
        "answers": [
            "occurrence",
            "occurrence",
            "occurrence"
        ],
        "model_ans": "magnitude, depth, location",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> magnitude, depth, location </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Southern California's distinctive regions are divided culturally, politically and what other trait?",
        "answers": [
            "economically",
            "economically",
            "economically"
        ],
        "model_ans": "geographically",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> geographically </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Outside of national recognition, what other kind of recognition do some of the cities get?",
        "answers": [
            "global",
            "global",
            "global"
        ],
        "model_ans": "cultural",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> cultural </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cities that anchor the regions are often the hub for what kind of activity?",
        "answers": [
            "economic",
            "economic",
            "economic activity"
        ],
        "model_ans": "commerce",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> commerce </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Southern California had a population of 22,680,010 according to the census from which year?",
        "answers": [
            "2010",
            "2010",
            "2010"
        ],
        "model_ans": "2020\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2020\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does southern California have a reputation for?",
        "answers": [
            "high growth rates",
            "high growth rates",
            "high growth rates"
        ],
        "model_ans": "Surfing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Surfing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the state average growth rate?",
        "answers": [
            "10.0%",
            "10.0%",
            "10.0%"
        ],
        "model_ans": "1.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of economy did northern California start to grow in the 2000s?",
        "answers": [
            "tech-oriented",
            "tech-oriented"
        ],
        "model_ans": "Tech",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tech </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which region began to grow and assert itself in the 2000s?",
        "answers": [
            "Greater Sacramento",
            "Greater Sacramento",
            "Greater Sacramento"
        ],
        "model_ans": "Asia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name associated with the eight areas that make up a part of southern California?",
        "answers": [
            "Metropolitan Statistical Areas",
            "Metropolitan Statistical Areas",
            "Metropolitan Statistical Areas"
        ],
        "model_ans": "South Bay",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> South Bay </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many extended metropolitan areas are there?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Each of the extended metropolitan areas has a population that exceeds what number?",
        "answers": [
            "five million",
            "five million",
            "five million"
        ],
        "model_ans": "1 million\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1 million\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the El Centro metropolitan area and San Diego-Carslbad-San Marcos metropolitan area form?",
        "answers": [
            "Southern Border Region",
            "the Southern Border Region",
            "Southern Border Region"
        ],
        "model_ans": "The San Diego-Carlsbad-San Marcos metropolitan area",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The San Diego-Carlsbad-San Marcos metropolitan area </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the population of the Greater Los Angeles Area?",
        "answers": [
            "17,786,419",
            "17,786,419",
            "17,786,419"
        ],
        "model_ans": "13,291,486",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13,291,486 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the largest city in all of California?",
        "answers": [
            "Los Angeles",
            "Los Angeles",
            "Los Angeles"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the population of the second largest city in California?",
        "answers": [
            "1.3 million",
            "1.3 million",
            "San Diego"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many cities in southern California have over 200,000 residents?",
        "answers": [
            "twelve",
            "twelve",
            "twelve"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There are 34 cities in southern California that have a population exceeding what number?",
        "answers": [
            "100,000",
            "100,000",
            "100,000"
        ],
        "model_ans": "100,000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "100,000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than San Bernardino, which other developed southern Californian city is not in close proximity to the coast?",
        "answers": [
            "Riverside",
            "Riverside",
            "Riverside"
        ],
        "model_ans": "Ontario",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ontario </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What resource is the economy of southern California depedent on?",
        "answers": [
            "petroleum",
            "petroleum",
            "petroleum"
        ],
        "model_ans": "Tourism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tourism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Southern California is most famous for tourism and what notably named district?",
        "answers": [
            "Hollywood",
            "Hollywood",
            "Hollywood"
        ],
        "model_ans": "Hollywood",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hollywood </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The region was a leader in what event between 2001 - 2007?",
        "answers": [
            "the housing bubble",
            "the housing bubble"
        ],
        "model_ans": "the dot-com bubble",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the dot-com bubble </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Southern California's economy can be described as one of the largest in the United States and what other characteristic?",
        "answers": [
            "diverse",
            "diverse",
            "diverse"
        ],
        "model_ans": "diverse",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> diverse </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the effect of the housing crash on the region?",
        "answers": [
            "heavily impacted",
            "heavily impacted"
        ],
        "model_ans": "The housing crash led to a significant decline in housing prices, a rise in foreclosures, and a decrease in consumer spending, which had a ripple effect on the overall economy.</answer</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The housing crash led to a significant decline in housing prices, a rise in foreclosures, and a decrease in consumer spending, which had a ripple effect on the overall economy.</answer</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Motion pictures, petroleum and aircraft manufacturing have been major industries since which decade?",
        "answers": [
            "1920s",
            "1920s",
            "1920s"
        ],
        "model_ans": "20th",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 20th </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What characteristic best describes the agricultural regions that could be found?",
        "answers": [
            "richest",
            "rich",
            "one of the richest"
        ],
        "model_ans": "diverse",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> diverse </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which type of livestock was the argricultural region known for?",
        "answers": [
            "cattle",
            "cattle",
            "cattle"
        ],
        "model_ans": "cattle",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> cattle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Outside of livestock, what else was considered a major industry in the agriculture regions?",
        "answers": [
            "citrus",
            "citrus",
            "citrus"
        ],
        "model_ans": "Manufacturing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Manufacturing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What industry has managed to survive major military spending cutbacks?",
        "answers": [
            "aerospace",
            "aerospace",
            "aerospace"
        ],
        "model_ans": "Defense",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Defense </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of district is southern California home to many of?",
        "answers": [
            "business",
            "major business",
            "major business"
        ],
        "model_ans": "Beach",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beach </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does CBD stand for?",
        "answers": [
            "Central business districts",
            "Central business districts",
            "Central business districts"
        ],
        "model_ans": "Cannabidiol",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Cannabidiol</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the only district in the CBD to not have \"downtown\" in it's name?",
        "answers": [
            "South Coast Metro",
            "South Coast Metro",
            "South Coast Metro"
        ],
        "model_ans": "Chinatown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chinatown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Downtown Burbank is an example of what kind of district?",
        "answers": [
            "business",
            "major business districts",
            "major business"
        ],
        "model_ans": "Downtown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Downtown Santa Monica and Downtown Glendale are a part of which area?",
        "answers": [
            "Los Angeles Area",
            "the Los Angeles Area",
            "major business"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Warner Center is located in which area?",
        "answers": [
            "San Fernando Valley",
            "the San Fernando Valley",
            "San Fernando Valley"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Century City is an example of a district that belongs to which city?",
        "answers": [
            "Los Angeles",
            "Los Angeles",
            "Los Angeles"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Sand Bernardino - Riverside area maintains what kind of district?",
        "answers": [
            "business",
            "business districts",
            "business"
        ],
        "model_ans": "San Bernardino",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> San Bernardino </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than San Bernardino, what is the name of the other city that maintains the districts including University Town?",
        "answers": [
            "Riverside",
            "Riverside",
            "Downtown Riverside"
        ],
        "model_ans": "Hong Kong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hong Kong </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than Downtown San Bernardino, and University Town, what is the name of another business district in the San Bernardino-Riverside area?",
        "answers": [
            "Hospitality Business/Financial Centre",
            "Downtown Riverside",
            "Hospitality Business/Financial Centre"
        ],
        "model_ans": "Hospitality Lane",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hospitality Lane </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which county is developing its business center?",
        "answers": [
            "Orange",
            "Orange County",
            "Orange County"
        ],
        "model_ans": "Montgomery County",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Montgomery County </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are international corporations headquartered?",
        "answers": [
            "University of California, Irvine",
            "the University of California, Irvine",
            "University of California"
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Jamboree Business Parks belongs to which business center?",
        "answers": [
            "West Irvine",
            "West Irvine",
            "West Irvine"
        ],
        "model_ans": "Jamboree",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jamboree </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other business district does Orange County envelop outside of Downtown Santa Ana and Newport Center?",
        "answers": [
            "South Coast Metro",
            "the South Coast Metro",
            "South Coast Metro"
        ],
        "model_ans": "Irvine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Irvine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At what rate is Orange County developing its business centers?",
        "answers": [
            "rapidly",
            "rapidly",
            "rapidly"
        ],
        "model_ans": "5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the central business district of San Diego?",
        "answers": [
            "Downtown San Diego",
            "Downtown San Diego",
            "Downtown"
        ],
        "model_ans": "Downtown",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than its main central  business district, where are the majority of San Diego's business districts located?",
        "answers": [
            "Northern San Diego",
            "Northern San Diego",
            "Northern San Diego"
        ],
        "model_ans": "Mission Valley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mission Valley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Outside of Northern San Diego, which other region contains business districts?",
        "answers": [
            "North County",
            "North County",
            "North County regions"
        ],
        "model_ans": "Downtown Los Angeles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Downtown Los Angeles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "University City is an example of a business district located in which city?",
        "answers": [
            "San Diego",
            "San Diego",
            "San Diego"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the second busiest airport in the United States?",
        "answers": [
            "Los Angeles International Airport",
            "Los Angeles International Airport",
            "Los Angeles International Airport"
        ],
        "model_ans": "Los Angeles International Airport (LAX)",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Los Angeles International Airport (LAX) </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the metric they use to determine how busy airports are?",
        "answers": [
            "passenger volume",
            "passenger volume",
            "passenger volume"
        ],
        "model_ans": "Passenger Traffic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Passenger Traffic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What ranking in terms of busiest airports from international passenger volume is the Los Angeles International Airport?",
        "answers": [
            "third",
            "third",
            "third"
        ],
        "model_ans": "6th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which airport is home to the busiest single runway in the world?",
        "answers": [
            "San Diego International Airport",
            "San Diego International Airport",
            "San Diego International Airport"
        ],
        "model_ans": "London Heathrow Airport",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London Heathrow Airport </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the world's busiest general aviation airport?",
        "answers": [
            "Van Nuys Airport",
            "Van Nuys Airport",
            "Van Nuys Airport"
        ],
        "model_ans": "McCarran International Airport",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> McCarran International Airport </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the commuter rail system?",
        "answers": [
            "Metrolink",
            "Metrolink",
            "Metrolink"
        ],
        "model_ans": "MBTA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MBTA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many lines does the commuter rail system have?",
        "answers": [
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many lines run out of Downtown Los Angeles?",
        "answers": [
            "Six",
            "Six",
            "Six"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A single line connects San Bernardino, Riverside and what other county?",
        "answers": [
            "Orange",
            "Orange",
            "Orange"
        ],
        "model_ans": "San Diego",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Diego </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the United States busiest commercial port?",
        "answers": [
            "Port of Los Angeles",
            "the Port of Los Angeles",
            "Port of Los Angeles"
        ],
        "model_ans": "Port of Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Port of Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the second busiest container port in the United States?",
        "answers": [
            "Port of San Diego",
            "Port of Long Beach",
            "Port of Long Beach"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Port of Long Beach belongs to which region of California?",
        "answers": [
            "Southern",
            "Southern California",
            "Southern"
        ],
        "model_ans": "Southern",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Southern </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the moniker that is being used to describe the region's diversified technology?",
        "answers": [
            "The Tech Coast",
            "The Tech Coast",
            "Tech Coast"
        ],
        "model_ans": "Silicon Valley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Silicon Valley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of universities is the region famous for?",
        "answers": [
            "research",
            "research",
            "research"
        ],
        "model_ans": "University of Tokyo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University of Tokyo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of university is the California Institute of Technology?",
        "answers": [
            "private",
            "private",
            "private"
        ],
        "model_ans": "Private",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Private </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many campuses does the University of California have?",
        "answers": [
            "5",
            "5",
            "5"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many campuses does the California State University have?",
        "answers": [
            "12",
            "12",
            "12"
        ],
        "model_ans": "23",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 23 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Los Angeles Rams are an example of what kind of sports team?",
        "answers": [
            "NFL",
            "Professional",
            "NFL"
        ],
        "model_ans": "football",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> football </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Los Angeles Clippers are a team belonging to which sport?",
        "answers": [
            "NBA",
            "NBA",
            "NBA"
        ],
        "model_ans": "basketball",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> basketball </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Los Angeles Angels of Anaheim are from which sport?",
        "answers": [
            "MLB",
            "MLB",
            "MLB"
        ],
        "model_ans": "baseball",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> baseball </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the other NHL team aside from the Anaheim Ducks to reside in Southern California?",
        "answers": [
            "Los Angeles Kings",
            "Los Angeles Kings",
            "Los Angeles Kings"
        ],
        "model_ans": "Los Angeles Kings",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles Kings </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the lone MLS team that belongs to southern California?",
        "answers": [
            "LA Galaxy",
            "LA Galaxy",
            "LA Galaxy"
        ],
        "model_ans": "LA Galaxy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> LA Galaxy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which team was suspended from the MLS?",
        "answers": [
            "Chivas USA",
            "Chivas",
            "Chivas"
        ],
        "model_ans": "Montreal Impact",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Montreal Impact </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many teams did Los Angeles used to have?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which year resulted in the suspension of one of the two soccer teams?",
        "answers": [
            "2014",
            "2014",
            "2014"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the stadium that the teams played in?",
        "answers": [
            "StubHub Center",
            "the StubHub Center",
            "StubHub Center"
        ],
        "model_ans": "Wembley Stadium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wembley Stadium </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is the suspended team scheduled to return?",
        "answers": [
            "2018",
            "in 2018",
            "2018"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other kind of sport is popular in southern California?",
        "answers": [
            "College",
            "College",
            "College"
        ],
        "model_ans": "Surfing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Surfing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Bruins belong to which college?",
        "answers": [
            "UCLA",
            "UCLA",
            "UCLA"
        ],
        "model_ans": "Boston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Boston</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the team from USC?",
        "answers": [
            "Trojans",
            "Trojans",
            "Trojans"
        ],
        "model_ans": "Trojans",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trojans </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which conference do the teams in southern California play in?",
        "answers": [
            "Pac-12",
            "the Pac-12",
            "Pac-12"
        ],
        "model_ans": "NBA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NBA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The two listed teams play for which NCAA group?",
        "answers": [
            "Division I",
            "Division I",
            "Division I"
        ],
        "model_ans": "Division I",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Division I </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a growing sport in southern California?",
        "answers": [
            "Rugby",
            "Rugby",
            "Rugby"
        ],
        "model_ans": "Surfing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Surfing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At which level of education is this sport becoming more popular?",
        "answers": [
            "high school",
            "high school",
            "high school"
        ],
        "model_ans": "High school",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> High school </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is rugby rapidly becoming with high schools?",
        "answers": [
            "an official school sport",
            "an official school",
            "official school sport"
        ],
        "model_ans": "popular",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> popular </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What company was formed by the merger of Sky Television and British Satellite Broadcasting?",
        "answers": [
            "BSkyB",
            "BSkyB",
            "BSkyB"
        ],
        "model_ans": "BBC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the UK's largest digital subscription television company?",
        "answers": [
            "BSkyB",
            "BSkyB",
            "BSkyB"
        ],
        "model_ans": "BBC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year did BSkyB acquire Sky Italia?",
        "answers": [
            "2014",
            "2014",
            "2014"
        ],
        "model_ans": "2003\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2003\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the holding company for BSkyB?",
        "answers": [
            "Sky plc",
            "British Sky Broadcasting Group plc",
            "British Sky Broadcasting Group plc"
        ],
        "model_ans": "BskyB",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BskyB</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the United Kingdom operation for BSkyB?",
        "answers": [
            "Sky UK Limited",
            "Sky UK Limited",
            "Sky UK Limited"
        ],
        "model_ans": "BBC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year was Setanta Sports awarded Primeier Leage rights to broadcast?",
        "answers": [
            "2006",
            "2006",
            "2006"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many of the six total packages available to broadcasters was Setanta awarded?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who purhcased the remaining 4 pacakages available to broadcasters?",
        "answers": [
            "Sky",
            "Sky",
            "Sky"
        ],
        "model_ans": "BBC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BBC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much did Sky bid to win the 4 broadcast pacakges they bought?",
        "answers": [
            "\u00a31.3bn",
            "\u00a31.3bn",
            "\u00a34.2bn"
        ],
        "model_ans": "\u00a33.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a33.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What consortium was BSkyB excluded from?",
        "answers": [
            "ONdigital",
            "ONdigital",
            "ONdigital"
        ],
        "model_ans": "ITV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ITV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did BSkyB team up with because it was not part of the consortium?",
        "answers": [
            "Freeview",
            "ITV Digital",
            "ITV Digital"
        ],
        "model_ans": "Virgin Media",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Virgin Media </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many BSkyB channels were available to customers prior to October 2005?",
        "answers": [
            "three",
            "three",
            "three"
        ],
        "model_ans": "9",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What channel replaced Sky Travel?",
        "answers": [
            "Sky Three",
            "Sky Three",
            "Sky Three"
        ],
        "model_ans": "Sky Living",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sky Living </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Sky Travel later rebranded as?",
        "answers": [
            "Pick TV",
            "Pick TV",
            "Pick TV"
        ],
        "model_ans": "Thomas Cook",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Cook </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What service did BSkyB chare additional subscription fees for?",
        "answers": [
            "Sky+ PVR",
            "Sky+ PVR",
            "Sky+ PVR"
        ],
        "model_ans": "Sky Sports",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky Sports </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Sky launch a TV advertising campaign target towards women?",
        "answers": [
            "September 2007",
            "September 2007",
            "March 2008"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "WHat allows customers to get Sky+ functions if they do not subscribe to BSkyB's channels?",
        "answers": [
            "monthly fee",
            "a monthly fee",
            "SkyHD box"
        ],
        "model_ans": "Sky Go",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky Go </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did BSkyB discontinue the Sky+ Box?",
        "answers": [
            "January 2010",
            "In January 2010",
            "February 2011"
        ],
        "model_ans": "2006",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What replaced the Sky+Box?",
        "answers": [
            "Sky+HD Box",
            "Sky+HD Box",
            "Sky+HD Box"
        ],
        "model_ans": "Sky Q",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky Q </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the TV scrambling system BSkyB uses?",
        "answers": [
            "VideoGuard",
            "VideoGuard pay-TV",
            "VideoGuard"
        ],
        "model_ans": "DVB-S",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> DVB-S </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is VideoGuard owned by?",
        "answers": [
            "NDS",
            "NDS",
            "NDS"
        ],
        "model_ans": "Cisco Systems",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cisco Systems </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the parent company of NDS?",
        "answers": [
            "Cisco Systems",
            "Cisco Systems",
            "Cisco Systems company"
        ],
        "model_ans": "News Corporation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> News Corporation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who has design authority over all of the digital satellite receivers that are capable of using their service?",
        "answers": [
            "BSkyB",
            "BSkyB",
            "BSkyB"
        ],
        "model_ans": "DirecTV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> DirecTV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name brand of the personal video recorder that BSkyB offers?",
        "answers": [
            "Sky+",
            "Sky+",
            "PVR"
        ],
        "model_ans": "Sky+",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky+ </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What year did BSkyB and Virgin Media have a dispute over the carriage of Sky Channels on cable TV?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What channels were removed from the network in March of 2007?",
        "answers": [
            "basic channels",
            "the basic channels",
            "the basic channels"
        ],
        "model_ans": "MTV2, MTVX, MTVJ, MTVU",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> MTV2, MTVX, MTVJ, MTVU </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Virgin Media claim BSkyB did that resulted Virgin not carrying the channels anymore?",
        "answers": [
            "substantially increased the asking price",
            "that BSkyB had substantially increased the asking price for the channels",
            "increased the asking price"
        ],
        "model_ans": "Sky Sports",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sky Sports </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What additional srevice did BSkyB offer besides HD channels that they claimed offered \"substantially more value\"?",
        "answers": [
            "Video On Demand",
            "Video On Demand content",
            "HD channels and Video On Demand"
        ],
        "model_ans": "Broadband internet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Broadband internet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What additional srevice did BSkyB offer besides Video on Demand that they claimed offered \"substantially more value\"?",
        "answers": [
            "HD channels",
            "HD channels",
            "HD channels"
        ],
        "model_ans": "Sky Broadband",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sky Broadband </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the English High court find Microsoft's use of the term \"SkyDrive\" infringed on Sky's right?",
        "answers": [
            "July 2013",
            "In July 2013",
            "July 2013"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did BSkyB and Microsoft announce their settlement?",
        "answers": [
            "2013",
            "2013",
            "31 July 2013"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Microsoft announce that it would rename Sky Drive to?",
        "answers": [
            "OneDrive",
            "OneDrive",
            "OneDrive"
        ],
        "model_ans": "OneDrive",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> OneDrive </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Microsoft announce that it would rename Sky Drive Pro to?",
        "answers": [
            "OneDrive for Business",
            "OneDrive for Business",
            "OneDrive for Business"
        ],
        "model_ans": "Microsoft 365",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Microsoft 365 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of service is the SkyDrive Service?",
        "answers": [
            "cloud storage",
            "cloud storage",
            "cloud storage service"
        ],
        "model_ans": "Cloud Storage",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cloud Storage </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the chief executive officer when the service began?",
        "answers": [
            "Sam Chisholm",
            "Sam Chisholm",
            "Sam Chisholm and Rupert Murdoch"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who's satellites would the new free-to-air channels be broadcast from?",
        "answers": [
            "Astra",
            "Astra's",
            "Astra's satellites"
        ],
        "model_ans": "Astra",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Astra </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did BSkyB end their analogue service?",
        "answers": [
            "27 September 2001",
            "27 September 2001",
            "September 2001"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What platform caused BSkyB to end their analogue service?",
        "answers": [
            "Sky Digital",
            "Sky Digital",
            "Sky Digital platform"
        ],
        "model_ans": "Digital",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Digital </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many households had BSkyB service in 1994?",
        "answers": [
            "3.5 million",
            "3.5 million",
            "3.5 million"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Sky UK Limited is formerly known by what name?",
        "answers": [
            "BSkyB",
            "British Sky Broadcasting",
            "British Sky Broadcasting"
        ],
        "model_ans": "BBC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>BBC </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of company is Sky UK Limited?",
        "answers": [
            "telecommunications",
            "telecommunications",
            "British telecommunications company"
        ],
        "model_ans": "Telecommunications",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Telecommunications </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many customers does Sky UK Limited have as a pay-TV broadcaster as of 2015?",
        "answers": [
            "11 million",
            "11 million",
            "11 million customers"
        ],
        "model_ans": "12 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what other digital TV service took Sky UK Limited's most popular spot?",
        "answers": [
            "Freeview",
            "Freeview",
            "Freeview"
        ],
        "model_ans": "Virgin Media",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virgin Media </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of Sky Q's broadband router?",
        "answers": [
            "Sky Q Hub",
            "Sky Q Hub",
            "Sky Q Hub"
        ],
        "model_ans": "Sky Hub",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky Hub </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the Sky Q mini set top boxes able to connect to?",
        "answers": [
            "Sky Q Silver set top boxes",
            "the Sky Q Silver set top boxes",
            "Sky Q Silver"
        ],
        "model_ans": "Wi-Fi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wi-Fi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does connecting different Sky Q boxes enable them to do?",
        "answers": [
            "share recordings",
            "to share recordings and other media",
            "share recordings"
        ],
        "model_ans": "stream content to other devices",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> stream content to other devices </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is Sky going to introduce UHD broadcasts?",
        "answers": [
            "2016",
            "later in 2016",
            "2016"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When are the new Sky Q products going to be available?",
        "answers": [
            "2016",
            "in 2016",
            "2016"
        ],
        "model_ans": "Not specified",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not specified </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are BSkyB's standard definition broadcasts compliant with?",
        "answers": [
            "DVB-compliant MPEG-2",
            "DVB-compliant MPEG-2",
            "MPEG-2"
        ],
        "model_ans": "PAL",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> PAL </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Sky Movies and Sky Box office also include what optional soundtracks?",
        "answers": [
            "Dolby Digital",
            "Dolby Digital",
            "Dolby Digital"
        ],
        "model_ans": "5.1 Surround Sound\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5.1 Surround Sound\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Sky+ HD material broadcast using?",
        "answers": [
            "MPEG-4",
            "MPEG-4",
            "MPEG-4"
        ],
        "model_ans": "DVB-T",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DVB-T </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the proprietary system that Sky+HD uses?",
        "answers": [
            "OpenTV",
            "OpenTV",
            "OpenTV"
        ],
        "model_ans": "Sky",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does most of the HD material use as a standard?",
        "answers": [
            "DVB-S2",
            "DVB-S2",
            "DVB-compliant MPEG-2"
        ],
        "model_ans": "H.264",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> H.264 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Sky Digital launched?",
        "answers": [
            "1998",
            "1998",
            "1998"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What satellite was used when Sky digital was launched?",
        "answers": [
            "Astra 2A",
            "the Astra 2A",
            "Astra 2A"
        ],
        "model_ans": "Astra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Astra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What satellite enabled Sky Digital to launch an all new digital service?",
        "answers": [
            "Eutelsat's Eurobird 1",
            "Eutelsat's Eurobird 1",
            "Eutelsat's Eurobird 1"
        ],
        "model_ans": "Astra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Astra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many television and radio channels could the new digital service carry?",
        "answers": [
            "hundreds",
            "hundreds",
            "hundreds"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the position of the satellite that allowed sky to broadcast channels almost elclusively for the United Kingdom?",
        "answers": [
            "28.5\u00b0E",
            "28.5\u00b0E",
            "28.5\u00b0E"
        ],
        "model_ans": "Astra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Astra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did BSkyB launch it's HDTV service?",
        "answers": [
            "22 May 2006",
            "on 22 May 2006",
            "22 May 2006"
        ],
        "model_ans": "2006",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people were registered to receive the HD service prior to launch?",
        "answers": [
            "40,000",
            "40,000",
            "40,000"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the set top box manufacturer that BSkyB was having issues with?",
        "answers": [
            "Thomson",
            "Thomson",
            "STB"
        ],
        "model_ans": "Echostar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Echostar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the number of customers that the BBC  reported had yet to receive the service due to failed deliveries?",
        "answers": [
            "17,000",
            "17,000",
            "17,000"
        ],
        "model_ans": "1.5 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the total number of homes Sky announced that had Sky+HD in March of 2012?",
        "answers": [
            "4,222,000",
            "4,222,000",
            "4,222,000"
        ],
        "model_ans": "10 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did BSkyB announce it's intention to replace it's free-to-air digital channels?",
        "answers": [
            "8 February 2007",
            "On 8 February 2007",
            "8 February 2007"
        ],
        "model_ans": "2008",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2008 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Setanta Sports say it would launch as a subscription service?",
        "answers": [
            "March",
            "in March",
            "March"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What platform was Sentanta Sports planning on launching on?",
        "answers": [
            "digital terrestrial",
            "digital terrestrial",
            "digital terrestrial"
        ],
        "model_ans": "Roku",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Roku </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were NTL's services rebranded as?",
        "answers": [
            "Virgin Media",
            "Virgin Media",
            "Virgin Media"
        ],
        "model_ans": "Virgin Media",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Virgin Media </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does BSkyB's sport portfolio include?",
        "answers": [
            "English Premier League Football",
            "English Premier League Football",
            "sport (including English Premier League Football), films, entertainment and news"
        ],
        "model_ans": "Premier League, UEFA Champions League, Wimbledon, Formula 1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Premier League, UEFA Champions League, Wimbledon, Formula 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are free-to-air encrypted broadcasts known as?",
        "answers": [
            "free-to-view",
            "free-to-view",
            "free-to-air"
        ],
        "model_ans": "Pay-TV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pay-TV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do some encrypted broadcasts require to view?",
        "answers": [
            "monthly subscription",
            "a monthly subscription",
            "monthly subscription"
        ],
        "model_ans": "decryption keys",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> decryption keys </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does a receiver have to be equipped with to view encrypted content?",
        "answers": [
            "VideoGuard UK",
            "VideoGuard UK",
            "VideoGuard UK"
        ],
        "model_ans": "decryption key",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> decryption key </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the universal band that digital recievers will receive free to air channels on?",
        "answers": [
            "Ku band",
            "9.75/10.600 GHz",
            "universal Ku band"
        ],
        "model_ans": "DVB",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> DVB </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What service is a VideoGuard UK equipped receiver dedicated to decrypt?",
        "answers": [
            "Sky",
            "Sky",
            "Sky service"
        ],
        "model_ans": "Sky",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When were the talks held for braodcast right to the Primier league for a five year period from the 1992 season?",
        "answers": [
            "1991",
            "autumn of 1991",
            "1991"
        ],
        "model_ans": "1992",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who were the current rights holders for the Primer League?",
        "answers": [
            "ITV",
            "ITV",
            "ITV"
        ],
        "model_ans": "Sky",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sky </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did ITV increase their yearly offer for control of the rights to broadcast the Primer League to?",
        "answers": [
            "\u00a334m",
            "\u00a334m",
            "\u00a334m per year"
        ],
        "model_ans": "\u00a34.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a34.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was given the highlights of most of the matches?",
        "answers": [
            "BBC",
            "The BBC",
            "BBC"
        ],
        "model_ans": "BBC",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much was BSkyB going to pay for the Primier League rights?",
        "answers": [
            "\u00a3304m",
            "\u00a3304m",
            "\u00a3304m"
        ],
        "model_ans": "\u00a33.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a33.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who does BSkyB have an operating license from?",
        "answers": [
            "Ofcom",
            "Ofcom",
            "Ofcom"
        ],
        "model_ans": "Ofcom",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ofcom </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the fee range for accessing BSkyB's EPG?",
        "answers": [
            "\u00a315\u2013100,000",
            "\u00a315\u2013100,000",
            "\u00a315\u2013100,000"
        ],
        "model_ans": "\u00a310-\u00a350",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a310-\u00a350 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Can BSkyB veto the presence of channels on their EPG?",
        "answers": [
            "no",
            "no",
            "Third-party channels"
        ],
        "model_ans": "yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Does BSkyB carry any control over a channels content?",
        "answers": [
            "not",
            "not",
            "BSkyB does not carry any control"
        ],
        "model_ans": "yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Does BSkyB carry any control over the picture quality of a channel?",
        "answers": [
            "not",
            "not",
            "BSkyB does not carry any control"
        ],
        "model_ans": "yes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>yes</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was BSkyB's digital service launched?",
        "answers": [
            "1 October 1998",
            "1 October 1998",
            "1 October 1998"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of BSkyB's digital service launched under?",
        "answers": [
            "Sky Digital",
            "Sky Digital",
            "Sky Digital"
        ],
        "model_ans": "BBC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did BSkyB name their interactive service?",
        "answers": [
            "Sky Active",
            "Open",
            "Sky Active"
        ],
        "model_ans": "BBCi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>BBCi</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did BSkyB compete with initially?",
        "answers": [
            "ONdigital",
            "ONdigital",
            "ONdigital"
        ],
        "model_ans": "ITV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ITV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Within the 30 days how many digiboxes had been sold?",
        "answers": [
            "100,000",
            "over 100,000",
            "100,000"
        ],
        "model_ans": "1000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was virgin media rebranded from NTL Telewest?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2006  Virgin Media",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2006 <answer> Virgin Media </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was NTL Telewest re-branded to in 2007?",
        "answers": [
            "Virgin Media",
            "Virgin Media",
            "Virgin Media"
        ],
        "model_ans": "Virgin Media",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virgin Media </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Virgin Media concentrate on instead of offering linear channels?",
        "answers": [
            "Video On Demand",
            "Video On Demand service",
            "(HDTV)"
        ],
        "model_ans": "On-demand content",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> On-demand content </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the one linear HD channel Virgin Media carried from November 2006 to July 2009?",
        "answers": [
            "BBC HD",
            "BBC HD",
            "BBC HD"
        ],
        "model_ans": "Virgin1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virgin1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the name of the other HD channel Virgin media could carry in the future?",
        "answers": [
            "Channel 4 HD",
            "Channel 4 HD",
            "Channel 4 HD"
        ],
        "model_ans": "BBC HD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BBC HD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many homes had BSkyB's direct-to-home satellite service available to them in 2010?",
        "answers": [
            "10 million",
            "10 million",
            "10 million"
        ],
        "model_ans": "8 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How large was the audience BSkyB said they could reach?",
        "answers": [
            "25m",
            "25m people",
            "36% of households"
        ],
        "model_ans": "10 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did BSkyB first announce their target goal?",
        "answers": [
            "August 2004",
            "August 2004",
            "August 2004"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the target percentage of households BSkyB wanted to reach?",
        "answers": [
            "36%",
            "36% of households",
            "2.4m customers"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was happening to subscriber numbers in other areas of europe?",
        "answers": [
            "flattened",
            "flattened",
            "flattened"
        ],
        "model_ans": "decline",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> decline </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Alec Shelbrooke propose payments of benefits to be made on?",
        "answers": [
            "Welfare Cash Card",
            "Welfare Cash Card",
            "Welfare Cash Card"
        ],
        "model_ans": "Bank accounts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bank accounts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What could the Supplemental Nutrition Assistance Program purchase?",
        "answers": [
            "essentials",
            "only \"essentials\"",
            "essentials"
        ],
        "model_ans": "Food",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Food </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what did the UK parliment hear that a subscription to BSkyB was?",
        "answers": [
            "often damaging",
            "often damaging",
            "often damaging"
        ],
        "model_ans": "a subscription to BSkyB was a breach of the BBC's royal charter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a subscription to BSkyB was a breach of the BBC's royal charter </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the UK governments benefits agenchy checking in 2012?",
        "answers": [
            "Sky TV bills",
            "claimants' \"Sky TV bills",
            "claimants"
        ],
        "model_ans": "HM Revenue & Customs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> HM Revenue & Customs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the benefits agency think sports channels on a TV bill meant?",
        "answers": [
            "a man's presence",
            "mother is wrongly claiming to be living alone",
            "betray a man's presence in the household"
        ],
        "model_ans": "Sports channels on a TV bill meant that the user wanted to watch sports on their TV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sports channels on a TV bill meant that the user wanted to watch sports on their TV </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the annual carriage fees for the channels?",
        "answers": [
            "\u00a330m",
            "\u00a330m",
            "\u00a330m"
        ],
        "model_ans": "\u00a310",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a310 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Does the new deal include Video on demand and High Definition?",
        "answers": [
            "no",
            "no indication",
            "no indication"
        ],
        "model_ans": "No",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> No </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What company agreed to terminate high court proceedings with BSkyB?",
        "answers": [
            "Virgin Media",
            "Virgin Media",
            "Virgin Media"
        ],
        "model_ans": "News Corp",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> News Corp </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What company agreed to terminate high court proceedings with Virgin Media?",
        "answers": [
            "BSkyB",
            "BSkyB",
            "BSkyB"
        ],
        "model_ans": "TalkTalk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> TalkTalk </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were high court proceedings being held about?",
        "answers": [
            "basic channels",
            "the carriage of their respective basic channels",
            "carriage of their respective basic channels"
        ],
        "model_ans": "The case of the missing socks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The case of the missing socks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of economy does Victoria have?",
        "answers": [
            "diversified",
            "highly diversified",
            "highly diversified"
        ],
        "model_ans": "Market economy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Market economy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where according to gross state product does Victoria rank in Australia?",
        "answers": [
            "second",
            "second",
            "second"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what rank does GPS per capita set Victoria?",
        "answers": [
            "fourth",
            "fourth",
            "fourth"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What city in Victoria is called the sporting capital of Australia?",
        "answers": [
            "Melbourne",
            "Melbourne",
            "Melbourne"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the largest stadium in Australia?",
        "answers": [
            "Melbourne Cricket Ground",
            "The Melbourne Cricket Ground",
            "Melbourne Cricket Ground"
        ],
        "model_ans": "Melbourne Cricket Ground",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne Cricket Ground </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is the Asian influence strongest in Victoria?",
        "answers": [
            "Bendigo",
            "Bendigo",
            "Bendigo"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where were the Lambing Flat riots?",
        "answers": [
            "New South Wales",
            "New South Wales",
            "New South Wales"
        ],
        "model_ans": "Young",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Young </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the 1857 riot?",
        "answers": [
            "Buckland Valley",
            "Buckland Valley near Bright",
            "Buckland Valley"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many miners died in the typhoid outbreak of 1854?",
        "answers": [
            "over 1,000",
            "1,000",
            "1,000"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the conditions for miners in the gold fields in Victoria?",
        "answers": [
            "cramped and unsanitary",
            "cramped and unsanitary",
            "cramped and unsanitary"
        ],
        "model_ans": "harsh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> harsh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of representational system does the Victorian Legislative Council have?",
        "answers": [
            "multi-member proportional",
            "multi-member proportional",
            "multi-member proportional representation system"
        ],
        "model_ans": "Upper house",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Upper house </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many electorates does the State of Victoria have?",
        "answers": [
            "eight",
            "eight",
            "eight"
        ],
        "model_ans": "40",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many representatives does each electorate have?",
        "answers": [
            "five",
            "five",
            "five"
        ],
        "model_ans": "1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term of office for each house member?",
        "answers": [
            "four years",
            "four years",
            "four years"
        ],
        "model_ans": "2 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How often are elections held for the Victorian Parliament?",
        "answers": [
            "every four years",
            "every four years",
            "four years"
        ],
        "model_ans": "Every 4 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Every 4 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What political party is strongest in Melbourne's working class suburbs?",
        "answers": [
            "Australian Labor Party",
            "Australian Labor Party",
            "Labor"
        ],
        "model_ans": "Labor",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labor </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What party is strongest in Melbourne's affluent areas?",
        "answers": [
            "Liberal Party",
            "Liberal Party of Australia",
            "Liberals"
        ],
        "model_ans": "Liberal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Liberal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which party is strongest in Victoria's northwestern and eastern regions?",
        "answers": [
            "National Party",
            "National Party of Australia",
            "Nationals"
        ],
        "model_ans": "Labor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What party rules in Melbourne's inner regions?",
        "answers": [
            "The Greens",
            "Australian Greens",
            "Greens"
        ],
        "model_ans": "Labor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What party is favored in Bedigo and Geelong?",
        "answers": [
            "Labor",
            "Australian Labor Party",
            "Labor"
        ],
        "model_ans": "Labor",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Labor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of Victorians are Christian?",
        "answers": [
            "61.1%",
            "61.1%",
            "61.1%"
        ],
        "model_ans": "64%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 64% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Victorians are Catholic?",
        "answers": [
            "26.7%",
            "26.7%",
            "26.7%"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30% </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Victoria's largest non-Christian religion?",
        "answers": [
            "Buddhism",
            "Buddhism",
            "Buddhism"
        ],
        "model_ans": "Judaism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Judaism</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Victorians are Buddhist?",
        "answers": [
            "168,637",
            "168,637",
            "168,637"
        ],
        "model_ans": "1.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Victorians are non-religious?",
        "answers": [
            "20%",
            "20%",
            "20%"
        ],
        "model_ans": "22%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 22% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where in Australia is Victoria located?",
        "answers": [
            "south-east",
            "south-east",
            "the south-east of Australia"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How does Victoria rank as to population density?",
        "answers": [
            "most densely populated",
            "most",
            "most densely populated state"
        ],
        "model_ans": "4,000 people per square kilometer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,000 people per square kilometer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How populous is Victoria compared to other Australian states?",
        "answers": [
            "second",
            "second-most",
            "second-most populous"
        ],
        "model_ans": "Victoria has the second-largest population in Australia, with approximately 6.7 million people, accounting for around 25% of the country's total population.",
        "model_confidence": "",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Victoria has the second-largest population in Australia, with approximately 6.7 million people, accounting for around 25% of the country's total population. </answer>\n<confidence></confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What city is the capital of Victoria?",
        "answers": [
            "Melbourne",
            "Melbourne",
            "Melbourne"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Compared to other Australian cities, what is the size of Melbourne?",
        "answers": [
            "second-largest",
            "second-largest",
            "second-largest city"
        ],
        "model_ans": "medium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> medium </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for the original Aboriginal people of Victoria?",
        "answers": [
            "Koori",
            "Koori",
            "Koori"
        ],
        "model_ans": "Koori",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Koori </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Great Britain claim Australia? ",
        "answers": [
            "1788",
            "1788",
            "1788"
        ],
        "model_ans": "1788 \n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1788 \n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where was Victoria first set to be located in Australia?",
        "answers": [
            "New South Wales",
            "New South Wales",
            "New South Wales"
        ],
        "model_ans": "Sydney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sydney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the first settlement in Victoria?",
        "answers": [
            "Sullivan Bay",
            "Sullivan Bay",
            "Sullivan Bay"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Victoria first settled?",
        "answers": [
            "1803",
            "1803",
            "1803"
        ],
        "model_ans": "1788",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1788 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much Victorian farmland is farmed in grains?",
        "answers": [
            "26,000 square kilometres",
            "26,000 square kilometres",
            "26,000 square kilometres"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of farmland grows wheat?",
        "answers": [
            "50%",
            "50%",
            "50%"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of Victoria's farmland grows hay?",
        "answers": [
            "6,000 square kilometres",
            "6,000 square kilometres",
            "6,000 square kilometres"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much does Victoria produce in Australian pears?",
        "answers": [
            "90%",
            "90%",
            "90%"
        ],
        "model_ans": "1.5 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tonnes of tomatoes does Victoria produce?",
        "answers": [
            "270,000",
            "270,000",
            "121,200"
        ],
        "model_ans": "1,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Victoria enact its constitution?",
        "answers": [
            "1975",
            "1975",
            "1975"
        ],
        "model_ans": "1855",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1855 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what is Victoria's constitution based ?",
        "answers": [
            "1855 colonial constitution",
            "the 1855 colonial constitution",
            "1855 colonial constitution"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What group can amend the Victorian constitution?",
        "answers": [
            "Parliament of Victoria",
            "the Parliament of Victoria",
            "Parliament of Victoria"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the exceptions in the constitution  that require special considerations to amend?",
        "answers": [
            "\"entrenched\" provisions",
            "certain \"entrenched\" provisions",
            "\"entrenched\" provisions"
        ],
        "model_ans": "Article V",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Article V </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What document formed the Parliament of Victoria?",
        "answers": [
            "Victoria Constitution Act 1855",
            "the Victoria Constitution Act 1855",
            "Victoria Constitution Act 185"
        ],
        "model_ans": "The British Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The British Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the weather type of Mallee and upper Wimmera?",
        "answers": [
            "warmest regions",
            "semi-deserts",
            "semi-deserts"
        ],
        "model_ans": "hot",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hot </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the average temperatures exceed in the summer?",
        "answers": [
            "32 \u00b0C",
            "32 \u00b0C",
            "32 \u00b0C (90 \u00b0F)"
        ],
        "model_ans": "25 degrees Celsius",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 25 degrees Celsius </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How cold does this region of Victoria get in the winner?",
        "answers": [
            "15 \u00b0C",
            "15 \u00b0C",
            "15 \u00b0C (59 \u00b0F)"
        ],
        "model_ans": "I'm unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I'm unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Victoria's highest monthly temperature?",
        "answers": [
            "48.8 \u00b0C",
            "48.8 \u00b0C",
            "48.8 \u00b0C (119.8 \u00b0F)"
        ],
        "model_ans": "34.4\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 34.4\u00b0C </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the heatwave in which Hopetoun recorded its highest temperature?",
        "answers": [
            "2009",
            "the 2009 southeastern Australia heat wave",
            "7 February 2009"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are public schools in Victoria?",
        "answers": [
            "state or government",
            "state or government schools",
            "state or government schools"
        ],
        "model_ans": "Government schools",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government schools </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What organization runs the public schools in Victoria? ",
        "answers": [
            "Victoria Department of Education",
            "the Victoria Department of Education",
            "Victoria Department of Education"
        ],
        "model_ans": "Victoria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Victoria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Since students do not pay tuition, what do they have to pay for schooling in Victoria?",
        "answers": [
            "some extra costs",
            "some extra costs are levied",
            "extra costs"
        ],
        "model_ans": "Fees",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fees </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What church runs some private schools in Victoria?",
        "answers": [
            "Roman Catholic Church",
            "the Roman Catholic Church",
            "Roman Catholic"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What government set standards do all schools have to meet?",
        "answers": [
            "curriculum",
            "curriculum standards",
            "curriculum"
        ],
        "model_ans": "NAPLAN",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NAPLAN </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of manufacturing plant is Victoria soon losing?",
        "answers": [
            "major car brands",
            "major car brands",
            "car"
        ],
        "model_ans": "textile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> textile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When has Toyota said it will close its Victoria plant?",
        "answers": [
            "2017",
            "2017",
            "2017"
        ],
        "model_ans": "2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Holden announce that it will close its Victoria plant?",
        "answers": [
            "May 2013",
            "in May 2013",
            "2013"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When will Ford's manufacturing plants close?",
        "answers": [
            "October 2016",
            "in October 2016",
            "2013"
        ],
        "model_ans": "Ford has not announced any plans to close its manufacturing plants",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ford has not announced any plans to close its manufacturing plants </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What brand of car is manufactured in Broadmeadows?",
        "answers": [
            "Ford",
            "Ford"
        ],
        "model_ans": "Holden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Holden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How high are Victoria's alpine regions?",
        "answers": [
            "2,000 m",
            "almost 2,000 m",
            "2,000 m"
        ],
        "model_ans": "1,000 to 3,000 meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 to 3,000 meters </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the highest peak in Victoria?",
        "answers": [
            "Mount Bogong",
            "Mount Bogong",
            "Mount Bogong"
        ],
        "model_ans": "Mount Kosciuszko",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mount Kosciuszko </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How high is Victoria's Mount Bogong?",
        "answers": [
            "1,986 m",
            "1,986 m",
            "1,986 m"
        ],
        "model_ans": "1,986 meters\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1,986 meters\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of topological systems are found in numbers in Victoria?",
        "answers": [
            "river systems",
            "river systems",
            "river systems"
        ],
        "model_ans": "fractals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fractals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Victoria state bird?",
        "answers": [
            "helmeted honeyeater",
            "the helmeted honeyeater",
            "helmeted honeyeater"
        ],
        "model_ans": "Lyrebird",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lyrebird </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the coldest section of Victoria?",
        "answers": [
            "Victorian Alps",
            "The Victorian Alps",
            "Victorian Alps"
        ],
        "model_ans": "The Alpine region",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Alpine region </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Of what mountain system are the Victorian Alps a part?",
        "answers": [
            "Great Dividing Range",
            "the Great Dividing Range",
            "Great Dividing Range"
        ],
        "model_ans": "Australian Alps",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Australian Alps </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what direction does the mountain system extend?",
        "answers": [
            "east-west",
            "east-west",
            "east-west"
        ],
        "model_ans": "East-West",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> East-West </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the temperature in the highest portion of the mountain range in winter?",
        "answers": [
            "below 0 \u00b0C",
            "below 0 \u00b0C",
            "below 0 \u00b0C (32 \u00b0F)"
        ],
        "model_ans": "-40\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> -40\u00b0C </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the lowest recorded temperature in Victoria?",
        "answers": [
            "\u221211.7 \u00b0C",
            "\u221211.7 \u00b0C",
            "\u221211.7 \u00b0C (10.9 \u00b0F)"
        ],
        "model_ans": "-11.1\u00b0C\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " -11.1\u00b0C\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who owns the rail lines in Victoria?",
        "answers": [
            "government-owned",
            "government",
            "several private and public railway operators"
        ],
        "model_ans": "VicTrack",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> VicTrack </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which rail line operates in Melbourne?",
        "answers": [
            "Metro Trains Melbourne",
            "Metro Trains Melbourne",
            "Metro Trains Melbourne"
        ],
        "model_ans": "Metro",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Metro </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What entity owns V/Line?",
        "answers": [
            "Victorian Government",
            "the Victorian Government",
            "Victorian Government"
        ],
        "model_ans": "Victoria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Victoria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of rail line is Pacific National?",
        "answers": [
            "freight services",
            "freight",
            "freight"
        ],
        "model_ans": "freight",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> freight </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kind of rail system is Metro Trains Melbourne?",
        "answers": [
            "passenger",
            "extensive, electrified, passenger system",
            "passenger"
        ],
        "model_ans": "Commuter rail",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Commuter rail </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many seats does Victoria have in the Australian House of Representatives?",
        "answers": [
            "37",
            "37",
            "37"
        ],
        "model_ans": "11\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "11\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many seats does Victoria have in the Senate?",
        "answers": [
            "12",
            "12",
            "12"
        ],
        "model_ans": "12\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "12\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the lower house of the Victorian parliament called?",
        "answers": [
            "Legislative Assembly",
            "the Legislative Assembly",
            "Legislative Assembly"
        ],
        "model_ans": "Legislative Assembly",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Legislative Assembly </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the upper house of the Parliament of Victoria called?",
        "answers": [
            "Legislative Council",
            "the Legislative Council",
            "Legislative Council"
        ],
        "model_ans": "Legislative Council",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Legislative Council </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is the current Governor of Victoria?",
        "answers": [
            "Linda Dessau",
            "Linda Dessau",
            "Linda Dessau"
        ],
        "model_ans": "Linda Dessau",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Linda Dessau </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "On what date was Victoria declared independent from New South Wales?",
        "answers": [
            "1 July 1851",
            "1 July 1851",
            "1 July 1851"
        ],
        "model_ans": "1901-01-01\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1901-01-01\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was gold found near Ballarat?",
        "answers": [
            "1851",
            "in 1851",
            "1851"
        ],
        "model_ans": "1851\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1851\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the finding of gold in Victoria cause?",
        "answers": [
            "gold rush",
            "gold rush",
            "gold rushes"
        ],
        "model_ans": "The Australian Gold Rush",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Australian Gold Rush </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much did the population of Victoria increase in ten years after the discovery of gold?",
        "answers": [
            "sevenfold",
            "sevenfold",
            "76,000 to 540,000"
        ],
        "model_ans": "200,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much gold did Victoria produce in the years of 1851-1860?",
        "answers": [
            "20 million ounces",
            "20 million ounces",
            "20 million ounces"
        ],
        "model_ans": "1,000,000 ounces",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000,000 ounces </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By August 2010 how many public schools did Victoria have?",
        "answers": [
            "1,548",
            "1,548",
            "1,548"
        ],
        "model_ans": "2,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Catholic schools were in Victoria?",
        "answers": [
            "489",
            "489",
            "489"
        ],
        "model_ans": "144",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 144 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many students were enrolled in public schools in Victoria?",
        "answers": [
            "540,800",
            "540,800",
            "540,800"
        ],
        "model_ans": "1,144,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,144,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many full time teachers does Victoria have?",
        "answers": [
            "63,519",
            "63,519",
            "63,519"
        ],
        "model_ans": "13,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of private school students go to Catholic schools?",
        "answers": [
            "61",
            "61",
            "61"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What state in Australia is the center of dairy farming?",
        "answers": [
            "Victoria",
            "Victoria",
            "Victoria"
        ],
        "model_ans": "Victoria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Victoria </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many dairy cows are there in Australia?",
        "answers": [
            "3 million",
            "3 million",
            "3 million"
        ],
        "model_ans": "9.5 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9.5 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of Australia's dairy cattle are found in Victoria?",
        "answers": [
            "60%",
            "60%",
            "60%"
        ],
        "model_ans": "60%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 60% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of Australia's milk is produced in Victoria?",
        "answers": [
            "two-thirds",
            "nearly two-thirds",
            "two-thirds"
        ],
        "model_ans": "40%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To where is most of the abalone and lobster caught in Victorian waters shipped?",
        "answers": [
            "Asia",
            "Asia",
            "Asia"
        ],
        "model_ans": "Sydney",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sydney </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the gauge of the Victorian rail lines?",
        "answers": [
            "1,600 mm",
            "1,600 mm (5 ft 3 in) broad gauge",
            "1,600 mm (5 ft 3 in) broad gauge"
        ],
        "model_ans": "4 ft 8 1/2 in",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 4 ft 8 1/2 in </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To what gauge have some lines been changed in the west of Victoria?",
        "answers": [
            "1,435 mm",
            "1,435 mm (4 ft 8 1\u20442 in) standard gauge",
            "1,435 mm (4 ft 8 1\u20442 in) standard gauge"
        ],
        "model_ans": "50 kg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 kg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What gauge of rail lines do two tourist lines use?",
        "answers": [
            "760 mm",
            "760 mm (2 ft 6 in) narrow gauge lines",
            "760 mm (2 ft 6 in) narrow gauge lines"
        ],
        "model_ans": "3 ft",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 ft </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where were the narrow gauge rail lines built in Victoria?",
        "answers": [
            "mountainous areas",
            "mountainous areas",
            "mountainous areas"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many narrow gauge rail lines were previously government owned?",
        "answers": [
            "five",
            "five",
            "five"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the colony of New South Wales founded?",
        "answers": [
            "1788",
            "1788",
            "1788"
        ],
        "model_ans": "1788\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1788\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the name of the eastern half of the colony of 1788?",
        "answers": [
            "New South Wales",
            "New South Wales",
            "New South Wales"
        ],
        "model_ans": "New South Wales",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New South Wales </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What name was given to the western half of the colony?",
        "answers": [
            "New Holland",
            "New Holland",
            "New Holland"
        ],
        "model_ans": "New South Wales",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New South Wales </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the location of the colonial government that administered the new colony?",
        "answers": [
            "Sydney",
            "Sydney",
            "Sydney"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was there a armed protest at Ballarat about mining taxes?",
        "answers": [
            "1854",
            "1854",
            "1854"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the incident over taxes at Ballarat called?",
        "answers": [
            "Eureka Stockade",
            "Eureka Stockade",
            "Eureka Stockade"
        ],
        "model_ans": "Eureka Stockade",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eureka Stockade </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What armed group stopped the uprising at Ballarat?",
        "answers": [
            "British troops",
            "British troops",
            "British troops"
        ],
        "model_ans": "British Army",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British Army </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did colonial authorities  reduce because of the Ballarat revolt?",
        "answers": [
            "mining licence fees",
            "mining licence fees",
            "mining licence fees"
        ],
        "model_ans": "Licences",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Licences </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The passage of what act gave Victoria its own government?",
        "answers": [
            "Colony of Victoria Act",
            "the Colony of Victoria Act",
            "Colony of Victoria Act 1855"
        ],
        "model_ans": "British North America Act",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> British North America Act </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Premier of Victoria need to lead in the Legislative Assembly? ",
        "answers": [
            "most seats",
            "the most seats in the Legislative Assembly",
            "most seats in the Legislative Assembly"
        ],
        "model_ans": "majority",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> majority </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who sets the legislative agenda in Victoria?",
        "answers": [
            "Premier",
            "The Premier is the public face of government and, with cabinet",
            "Premier of Victoria"
        ],
        "model_ans": "The Victorian Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Victorian Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who can be in the Victorian cabinet?",
        "answers": [
            "representatives",
            "representatives elected to either house of parliament",
            "representatives elected to either house of parliament"
        ],
        "model_ans": "Australian citizens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Australian citizens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the current Premier of Victoria?",
        "answers": [
            "Daniel Andrews",
            "Daniel Andrews",
            "Daniel Andrews"
        ],
        "model_ans": "Daniel Andrews",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Daniel Andrews </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How are Victorian cabinet members chosen?",
        "answers": [
            "elected",
            "elected",
            "elected"
        ],
        "model_ans": "By the Prime Minister",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> By the Prime Minister </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much did the gross agricultural product increase from 2003-04?",
        "answers": [
            "$8.7 billion",
            "24%",
            "$8.7 billion"
        ],
        "model_ans": "12.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage was the increase of agricultural products in 2003-04?",
        "answers": [
            "17%",
            "17%",
            "17%"
        ],
        "model_ans": "12%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many farms are there in Victoria?",
        "answers": [
            "32,463",
            "32,463",
            "32,463"
        ],
        "model_ans": "27,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 27,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much land do farms use in Victoria?",
        "answers": [
            "136,000 square kilometres",
            "136,000 square kilometres",
            "136,000 square kilometres"
        ],
        "model_ans": "7.4 million hectares",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7.4 million hectares </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much percentage of Victoria's land is taken up by farms?",
        "answers": [
            "60%",
            "60%",
            "60%"
        ],
        "model_ans": "77%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 77% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What part do events in Victoria's economy  play? ",
        "answers": [
            "tourism",
            "tourism",
            "big"
        ],
        "model_ans": "significant",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> significant </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides cultural events, what other tourist attraction does Victoria have?",
        "answers": [
            "sports",
            "sports tourism",
            "sports"
        ],
        "model_ans": "Melbourne Cricket Ground",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne Cricket Ground </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On where are most tourist attractions focused in Victoria?",
        "answers": [
            "Melbourne",
            "Melbourne",
            "Melbourne"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where do other tourist events happen in Victoria outside of Melbourne?",
        "answers": [
            "regional cities",
            "in regional cities",
            "Phillip Island"
        ],
        "model_ans": "Geelong, Ballarat, Bendigo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Geelong, Ballarat, Bendigo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What event is held at Bells Beach in Victoria?",
        "answers": [
            "SurfClassic",
            "SurfClassic",
            "SurfClassic"
        ],
        "model_ans": "Rip Curl Pro",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rip Curl Pro </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was France's Huguenot population largely centered?",
        "answers": [
            "the southern and central parts of France",
            "southern and central parts of France,",
            "about one-eighth"
        ],
        "model_ans": "Paris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the proportion of Huguenots to Catholics at their peak?",
        "answers": [
            "about one-eighth the number",
            "about one-eighth",
            "about one-eighth"
        ],
        "model_ans": "1:3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1:3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were the Wars of Religion fought?",
        "answers": [
            "from 1562 to 1598",
            "1562 to 1598",
            "562 to 1598"
        ],
        "model_ans": "16th century",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 16th century </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What treaty ended the Wars of Religion?",
        "answers": [
            "the Edict of Nantes",
            "Edict of Nantes",
            "the Edict of Nantes"
        ],
        "model_ans": "Treaty of Westphalia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Westphalia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did this agreement do?",
        "answers": [
            "granted the Huguenots substantial religious, political and military autonomy",
            "granted the Huguenots substantial religious, political and military autonomy",
            "granted the Huguenots substantial religious, political and military autonomy"
        ],
        "model_ans": "I am not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The term Huguenot was originally meant to confer?",
        "answers": [
            "derision",
            "derision",
            "derision"
        ],
        "model_ans": "protection",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> protection </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The term may be related to what politician from Switzerland?",
        "answers": [
            "Besan\u00e7on Hugues",
            "Besan\u00e7on Hugues",
            "Besan\u00e7on Hugues"
        ],
        "model_ans": "Jean-Pascal Delamuraz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Pascal Delamuraz </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Swiss city was the center of the Calvinist movement?",
        "answers": [
            "Geneva",
            "Geneva",
            "Geneva"
        ],
        "model_ans": "Geneva",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geneva </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What name was given to the plot to usurp power from the French House of Guise?",
        "answers": [
            "Amboise plot",
            "Amboise",
            "the Amboise plot"
        ],
        "model_ans": "The Massacre of Saint Bartholomew",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Massacre of Saint Bartholomew </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did this attempt take place?",
        "answers": [
            "1560",
            "1560",
            "1560"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What helped spread Protestantism in France?",
        "answers": [
            "availability of the Bible in vernacular languages",
            "the Bible in vernacular languages",
            "The availability of the Bible in vernacular languages"
        ],
        "model_ans": "The Reformation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Reformation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the first French language bible appear?",
        "answers": [
            "Around 1294",
            "1294",
            "Around 1294"
        ],
        "model_ans": "1524\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1524\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who translated this version of the scriptures?",
        "answers": [
            "Guyard de Moulin",
            "Guyard de Moulin",
            "Guyard de Moulin"
        ],
        "model_ans": "Bible Society",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bible Society </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "An illustrated, paraphrased version of this appeared when?",
        "answers": [
            "1487",
            "1487",
            "1487"
        ],
        "model_ans": "2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Jean De Rely's illustrated French-language scriptures were first published in what city?",
        "answers": [
            "Paris",
            "Paris",
            "Paris"
        ],
        "model_ans": "Paris",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What were the towns granted to the Huguenots in 1598 collectively called?",
        "answers": [
            "villes de s\u00fbret\u00e9",
            "\"villes de s\u00fbret\u00e9\"",
            "villes de s\u00fbret\u00e9"
        ],
        "model_ans": "S\u00e9ries",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> S\u00e9ries </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the most important of these cities or towns?",
        "answers": [
            "Montpellier",
            "Montpellier",
            "Montpellier"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "France laid siege to Montpellier in what year?",
        "answers": [
            "1622",
            "1622",
            "1622"
        ],
        "model_ans": "1622\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1622\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What proclamation officially ended limited Huguenot autonomy?",
        "answers": [
            "Edict of Al\u00e8s",
            "Edict of Al\u00e8s",
            "Edict of Al\u00e8s"
        ],
        "model_ans": "Edict of Nantes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edict of Nantes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was this proclamation issued?",
        "answers": [
            "1629",
            "1629",
            "1629"
        ],
        "model_ans": "1863",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1863 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the first Huguenot colonists settle?",
        "answers": [
            "at the Cape of Good Hope",
            "Cape of Good Hope",
            "the Cape of Good Hope"
        ],
        "model_ans": "New Amsterdam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New Amsterdam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What modern city is located on the original Huguenot colony?",
        "answers": [
            "Cape Town",
            "Cape Town",
            "Cape Town"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the first Huguenot to arrive at the Cape of Good Hope?",
        "answers": [
            "Maria de la Queillerie",
            "Maria de la Queillerie",
            "Maria de la Queillerie"
        ],
        "model_ans": "Jean Ribault",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean Ribault </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What trading company helped settle Huguenots near the Cape?",
        "answers": [
            "Dutch East India Company",
            "Dutch East India Company",
            "Dutch East India Company"
        ],
        "model_ans": "Dutch East India Company",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dutch East India Company </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The number of new Huguenot colonists declined after what year?",
        "answers": [
            "1700",
            "1700",
            "1700"
        ],
        "model_ans": "1685\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1685\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Huguenots colonize in North America?",
        "answers": [
            "1624",
            "1624",
            "1624"
        ],
        "model_ans": "1608",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1608 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who led the North American Huguenot colonial expedition?",
        "answers": [
            "Jess\u00e9 de Forest",
            "Jess\u00e9 de Forest",
            "Jess\u00e9 de Forest"
        ],
        "model_ans": "Pierre Minuit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pierre Minuit </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the first Huguenot church in the New World?",
        "answers": [
            "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam",
            "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam",
            "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam (the French church in New Amsterdam)"
        ],
        "model_ans": "La Fl\u00e8che",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> La Fl\u00e8che </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what name is that first Huguenot church known today?",
        "answers": [
            "L'Eglise du Saint-Esprit",
            "L'Eglise du Saint-Esprit",
            "L'Eglise du Saint-Esprit"
        ],
        "model_ans": "Temple Church",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Temple Church </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Huguenots were the first Europeans to live in what modern New York borough?",
        "answers": [
            "Brooklyn",
            "Brooklyn",
            "Brooklyn"
        ],
        "model_ans": "Manhattan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manhattan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What southern city did the Huguenots settle near?",
        "answers": [
            "Charleston, South Carolina",
            "Charleston",
            "Charleston, South Carolina"
        ],
        "model_ans": "Charleston",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Charleston </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where in South Carolina did Huguenot nobility settle?",
        "answers": [
            "the Charleston Orange district",
            "Charleston Orange district",
            "Charleston Orange district"
        ],
        "model_ans": "Charleston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charleston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Huguenots secure the right to own land in the Baronies?",
        "answers": [
            "1697",
            "1697",
            "1697"
        ],
        "model_ans": "1598",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1598 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From whom did the Huguenots in South Carolina purchase land from?",
        "answers": [
            "the British Landgrave Edmund Bellinger",
            "Edmund Bellinger",
            "Edmund Bellinger"
        ],
        "model_ans": "The Native Americans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Native Americans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Charleston settler Elie Prioleau was from what French town?",
        "answers": [
            "Pons",
            "Pons in France",
            "Pons"
        ],
        "model_ans": "Bordeaux",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bordeaux </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Louis XIV's main rival?",
        "answers": [
            "William III of Orange",
            "Stadtholder William III of Orange",
            "Stadtholder William III of Orange"
        ],
        "model_ans": "Philip IV of Spain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Philip IV of Spain </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "William would eventually gain what throne?",
        "answers": [
            "King of England",
            "King of England",
            "King of England"
        ],
        "model_ans": "English throne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> English throne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What coalition rose up to oppose Louis XIV's France?",
        "answers": [
            "League of Augsburg",
            "League of Augsburg",
            "League of Augsburg"
        ],
        "model_ans": "Grand Alliance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Grand Alliance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "With what European country did the Huguenots feel kinship for emigration to?",
        "answers": [
            "Dutch Republic",
            "Dutch Republic",
            "Dutch Republic"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did France and the Dutch fight in the 17th century?",
        "answers": [
            "1672",
            "1672",
            "1672"
        ],
        "model_ans": "1672",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1672 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What proclamation abolished protestantism in France?",
        "answers": [
            "Edict of Fontainebleau",
            "Edict of Fontainebleau",
            "the Edict of Fontainebleau"
        ],
        "model_ans": "Edict of Fontainebleau",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Edict of Fontainebleau </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was this edict declared?",
        "answers": [
            "1685",
            "1685",
            "1685"
        ],
        "model_ans": "1234",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1234 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which French kind issued this declaration?",
        "answers": [
            "Louis XIV",
            "Louis XIV",
            "Louis XIV"
        ],
        "model_ans": "National Assembly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> National Assembly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many Huguenots fled France by the 1700s?",
        "answers": [
            "500,000",
            "500,000",
            "roughly 500,000"
        ],
        "model_ans": "200,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What group specifically opposed the Huguenots?",
        "answers": [
            "Catholic Church in France",
            "Catholic Church in France",
            "The Catholic Church in France"
        ],
        "model_ans": "Catholics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What event was the worst example of Huguenot persecution?",
        "answers": [
            "St. Bartholomew's Day massacre",
            "St. Bartholomew's Day massacre",
            "St. Bartholomew's Day massacre"
        ],
        "model_ans": "The St. Bartholomew's Day massacre",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The St. Bartholomew's Day massacre </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many Huguenots were killed during this purge?",
        "answers": [
            "5,000 to 30,000",
            "5,000 to 30,000",
            "5,000 to 30,000"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the Huguenots defend themselves?",
        "answers": [
            "their own militia",
            "the Huguenots had their own militia"
        ],
        "model_ans": "with swords and guns",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> with swords and guns </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was a non-religious reason for the massacre?",
        "answers": [
            "some of the Huguenots were nobles trying to establish separate centers of power in southern France",
            "political reasons",
            "some of the Huguenots were nobles trying to establish separate centers of power in southern France"
        ],
        "model_ans": "Economic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the civil wars caused by the Huguenots called?",
        "answers": [
            "Huguenot rebellions",
            "Huguenot rebellions",
            "the Huguenot rebellions"
        ],
        "model_ans": "Wars of Religion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wars of Religion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did these uprisings take place?",
        "answers": [
            "southwestern France",
            "southwestern France",
            "mainly in southwestern France"
        ],
        "model_ans": "Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did these rebellions take place?",
        "answers": [
            "between 1621 and 1629",
            "between 1621 and 1629",
            "between 1621 and 1629"
        ],
        "model_ans": "1857",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1857 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What King and former Huguenot looked out for the welfare of the group?",
        "answers": [
            "Henry IV",
            "Henry IV",
            "Henry IV"
        ],
        "model_ans": "Louis XIV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louis XIV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which successor to Henry resumed persecution of the Huguenots?",
        "answers": [
            "Louis XIII",
            "Louis XIII",
            "Louis XIII"
        ],
        "model_ans": "Louis XIV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis XIV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many protestants live in France today?",
        "answers": [
            "one million",
            "Approximately one million",
            "Approximately one million"
        ],
        "model_ans": "3 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of France's population is protestant today?",
        "answers": [
            "2%",
            "2%",
            "2%"
        ],
        "model_ans": "1%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What northern province in France has a large protestant population?",
        "answers": [
            "Alsace",
            "Alsace",
            "Alsace"
        ],
        "model_ans": "Alsace",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alsace </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the southern region where protestants are concentrated?",
        "answers": [
            "C\u00e9vennes",
            "C\u00e9vennes",
            "C\u00e9vennes mountain region"
        ],
        "model_ans": "Ulster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ulster </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What country currently has a group who call themselves Huguenots?",
        "answers": [
            "Australia",
            "Australia",
            "Australia"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What city north of New York was settled by Huguenots?",
        "answers": [
            "New Rochelle",
            "New Rochelle",
            "New Rochelle"
        ],
        "model_ans": "Albany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What town in upstate New York was settled by Huguenots?",
        "answers": [
            "New Paltz",
            "New Paltz",
            "New Paltz"
        ],
        "model_ans": "New Paltz",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Paltz </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What Huguenot area is designated as a historical landmark?",
        "answers": [
            "\"Huguenot Street Historic District\" in New Paltz",
            "Huguenot Street Historic District",
            "The \"Huguenot Street Historic District\" in New Paltz"
        ],
        "model_ans": "Wall Street",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wall Street </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is located within this district?",
        "answers": [
            "the oldest street in the United States of America",
            "the oldest street in the United States of America",
            "the oldest street in the United States of America"
        ],
        "model_ans": "Tokyo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tokyo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what borough is there a neighborhood called Huguenot?",
        "answers": [
            "Staten Island",
            "Staten Island",
            "Staten Island"
        ],
        "model_ans": "Staten Island",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Staten Island </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What country initially received the largest number of Huguenot refugees?",
        "answers": [
            "the Dutch Republic",
            "Dutch Republic",
            "Dutch Republic"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many refugees emigrated to the Dutch Republic?",
        "answers": [
            "an estimated total of 75,000 to 100,000 people",
            "75,000 to 100,000",
            "75,000 to 100,000"
        ],
        "model_ans": "200,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the population of the Dutch Republic before this emigration?",
        "answers": [
            "ca. 2 million",
            "2 million",
            "2 million"
        ],
        "model_ans": "2 million",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What two areas in the Republic were first to grant rights to the Huguenots?",
        "answers": [
            "Amsterdam and the area of West Frisia",
            "Amsterdam and the area of West Frisia",
            "Amsterdam and the area of West Frisia"
        ],
        "model_ans": "Normandy and Brittany",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Normandy and Brittany </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What declaration predicated the emigration of Huguenot refugees?",
        "answers": [
            "the revocation of the Edict of Nantes",
            "Edict of Nantes",
            "the revocation of the Edict of Nantes"
        ],
        "model_ans": "Edict of Nantes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edict of Nantes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where was the Gate of King Hugo?",
        "answers": [
            "Tours",
            "Tours",
            "Tours"
        ],
        "model_ans": "Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what other name was the Gate known?",
        "answers": [
            "Huguon",
            "Huguon",
            "Huguon"
        ],
        "model_ans": "The Gate of the Sun",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Gate of the Sun </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who allegedly haunted the gate?",
        "answers": [
            "the ghost of le roi Huguet",
            "ghost of le roi Huguet",
            "the ghost of le roi Huguet"
        ],
        "model_ans": "The White Lady",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The White Lady </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what name were the \"supposedly reformed\" known?",
        "answers": [
            "pr\u00e9tendus r\u00e9form\u00e9s",
            "pr\u00e9tendus r\u00e9form\u00e9s",
            "pr\u00e9tendus r\u00e9form\u00e9s"
        ],
        "model_ans": "Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What time of day did these reformed supposedly gather to engage in Huguenot rituals?",
        "answers": [
            "night",
            "night",
            "at night"
        ],
        "model_ans": "3:00 AM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3:00 AM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Huguenots and Walloons settle in England?",
        "answers": [
            "Canterbury",
            "Canterbury",
            "Canterbury"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What house was the site of a weaving school in Canterbury?",
        "answers": [
            "The Weavers",
            "The Weavers",
            "The Weavers"
        ],
        "model_ans": "Maison Dieu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maison Dieu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What social construct did Huguenot refugees in Canterbury practice?",
        "answers": [
            "economic separation",
            "economic separation",
            "worked as weavers"
        ],
        "model_ans": "Calvinism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Calvinism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other English towns were sites of Huguenot settlement?",
        "answers": [
            "Kent, particularly Sandwich, Faversham and Maidstone",
            "Sandwich, Faversham and Maidstone",
            "Sandwich, Faversham and Maidstone"
        ],
        "model_ans": "London, Bristol, Norwich, Southampton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London, Bristol, Norwich, Southampton </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is located on the site of The Weaving House currently?",
        "answers": [
            "a restaurant",
            "restaurant",
            "a restaurant"
        ],
        "model_ans": "The Weaving House",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Weaving House </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Irish cities had Huguenot mayors in the 1600s and 1700s?",
        "answers": [
            "Dublin, Cork, Youghal and Waterford",
            "Dublin, Cork, Youghal and Waterford",
            "Dublin, Cork, Youghal and Waterford"
        ],
        "model_ans": "Dublin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dublin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "French Church Street is in what Irish town?",
        "answers": [
            "Cork City",
            "Cork City",
            "Cork City"
        ],
        "model_ans": "Dublin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dublin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is D'Olier Street?",
        "answers": [
            "Dublin",
            "Dublin",
            "Dublin"
        ],
        "model_ans": "Dublin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dublin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "D'Olier Street is named after whom?",
        "answers": [
            "a High Sheriff and one of the founders of the Bank of Ireland",
            "High Sheriff",
            "a High Sheriff and one of the founders of the Bank of Ireland"
        ],
        "model_ans": "D'Olier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> D'Olier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The French church in Portarlington was built when?",
        "answers": [
            "1696",
            "1696",
            "1696"
        ],
        "model_ans": "1840",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1840 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the common term for the loss of key members of French society to Huguenot emigration?",
        "answers": [
            "brain drain",
            "brain drain",
            "brain drain"
        ],
        "model_ans": "Drain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Drain </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of France's primary colony in the New World?",
        "answers": [
            "New France",
            "New France",
            "New France"
        ],
        "model_ans": "Saint-Domingue",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saint-Domingue </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What persons were not allowed to settle in New France?",
        "answers": [
            "non-Catholics",
            "non-Catholics",
            "non-Catholics"
        ],
        "model_ans": "Jews",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jews</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The French and Indian War was the New World aspect of what European conflict?",
        "answers": [
            "Seven Years' War",
            "Seven Years' War",
            "Seven Years' War"
        ],
        "model_ans": "Seven Years' War",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Seven Years' War </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the British defeat New France?",
        "answers": [
            "1759-60",
            "1759-60",
            "1759-60"
        ],
        "model_ans": "1763\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1763\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Henry IV known as before taking the throne?",
        "answers": [
            "Henry of Navarre",
            "Henry of Navarre",
            "Henry of Navarre"
        ],
        "model_ans": "Henry Bolingbroke",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry Bolingbroke </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Henry issue the Edict of Nantes?",
        "answers": [
            "1598",
            "1598",
            "1598"
        ],
        "model_ans": "1598\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1598\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Edict do for Huguenots in France?",
        "answers": [
            "granted the Protestants equality with Catholics",
            "granted the Protestants equality",
            "granted the Protestants equality with Catholics under the throne and a degree of religious and political freedom within their domains"
        ],
        "model_ans": "granted toleration",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> granted toleration </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The edict protected Catholics by discouraging what?",
        "answers": [
            "the founding of new Protestant churches",
            "founding of new Protestant churches in Catholic-controlled regions",
            "the founding of new Protestant churches in Catholic-controlled regions"
        ],
        "model_ans": "persecution",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> persecution </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What religion did Henry renounce upon ascending the throne?",
        "answers": [
            "Protestantism",
            "Protestantism",
            "Protestantism"
        ],
        "model_ans": "Catholicism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholicism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was required of Huguenot children after the Edict was revoked?",
        "answers": [
            "education of children as Catholics",
            "education of children as Catholics",
            "required education of children as Catholics"
        ],
        "model_ans": "Conversion to Catholicism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Conversion to Catholicism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the revocation restrict Huguenot travel?",
        "answers": [
            "prohibited emigration",
            "prohibited emigration",
            "prohibited emigration"
        ],
        "model_ans": "The Edict of Nantes was revoked in 1685, restricting Huguenot travel and forcing many to flee France",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Edict of Nantes was revoked in 1685, restricting Huguenot travel and forcing many to flee France </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Huguenots emigrated to North America as colonists?",
        "answers": [
            "Four thousand",
            "Four thousand",
            "Four thousand"
        ],
        "model_ans": "150,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were Huguenots who stayed in France eventually known as?",
        "answers": [
            "\"new converts\"",
            "\"new converts\"",
            "new converts"
        ],
        "model_ans": "Protestants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Protestants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides Britain and North America, where else did Huguenot refugees settle?",
        "answers": [
            "Holland, Prussia, and South Africa",
            "Holland, Prussia, and South Africa",
            "Britain as well as Holland, Prussia, and South Africa"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were the first two destinations of Huguenot emigres?",
        "answers": [
            "Switzerland and the Netherlands",
            "Switzerland and the Netherlands.",
            "Switzerland and the Netherlands"
        ],
        "model_ans": "Amsterdam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amsterdam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the French colony in modern day Brazil founded?",
        "answers": [
            "1555",
            "1555",
            "1555"
        ],
        "model_ans": "1534\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1534\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Brazilian French colony called?",
        "answers": [
            "France Antarctique",
            "France Antarctique",
            "France Antarctique"
        ],
        "model_ans": "S\u00e3o Lu\u00eds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> S\u00e3o Lu\u00eds </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was Fort Coligny destroyed?",
        "answers": [
            "1560",
            "1560",
            "1560"
        ],
        "model_ans": "1568\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1568\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what document did the Huguenots confess their faith to the Portuguese in Brazil?",
        "answers": [
            "the Guanabara Confession of Faith",
            "Guanabara Confession of Faith",
            "the Guanabara Confession of Faith"
        ],
        "model_ans": "The Edict of Nantes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Edict of Nantes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Families with French names in South Africa speak what language today?",
        "answers": [
            "Afrikaans",
            "Afrikaans",
            "Afrikaans"
        ],
        "model_ans": "Afrikaans",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Afrikaans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What South African industry descended from Huguenot settlers?",
        "answers": [
            "wine industry",
            "wine",
            "The wine industry"
        ],
        "model_ans": "Wine industry",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wine industry </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where can one find the formerly Huguenot farms in South Africa?",
        "answers": [
            "Western Cape province",
            "Western Cape province"
        ],
        "model_ans": "Cape Town",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cape Town </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What characteristic identifies the French ancestry of some South Africans?",
        "answers": [
            "surnames",
            "names",
            "surnames"
        ],
        "model_ans": "French surnames",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> French surnames </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Revolutionary War midnight rider was a Huguenot descendant?",
        "answers": [
            "Paul Revere",
            "Paul Revere",
            "Paul Revere"
        ],
        "model_ans": "Paul Revere",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Revere </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What signer of the Articles of Confederation was descended from Huguenots?",
        "answers": [
            "Henry Laurens",
            "Henry Laurens",
            "Henry Laurens"
        ],
        "model_ans": "John Witherspoon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Witherspoon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what city is the last Huguenot congregation in the US?",
        "answers": [
            "Charleston, South Carolina",
            "Charleston",
            "Charleston, South Carolina"
        ],
        "model_ans": "New York City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What church in Virginia is maintained by Huguenots as a historic shrine?",
        "answers": [
            "Manakin Episcopal Church",
            "Manakin Episcopal Church",
            "Manakin Episcopal Church"
        ],
        "model_ans": "St. Luke's Church",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> St. Luke's Church </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what state is the largest Huguenot Society located?",
        "answers": [
            "Texas",
            "Texas",
            "Texas"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What industry was centered in Bedfordshire?",
        "answers": [
            "lace",
            "lace",
            "British lace"
        ],
        "model_ans": "pharmaceutical",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pharmaceutical </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What style of lace is erroneously believed by some to have Huguenot influence?",
        "answers": [
            "'Bucks Point'",
            "Bucks Point",
            "Bucks Point"
        ],
        "model_ans": "Honiton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Honiton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What reference is there to Huguenot lacemakers in the 19th century?",
        "answers": [
            "twenty-five widows who settled in Dover",
            "twenty-five widows who settled in Dover",
            "twenty-five widows who settled in Dover"
        ],
        "model_ans": "In the novel \"Madame Bovary\" by Gustave Flaubert",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In the novel \"Madame Bovary\" by Gustave Flaubert </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Mechlin lace develop?",
        "answers": [
            "first half of the eighteenth century",
            "first half of the eighteenth century",
            "first half of the eighteenth century"
        ],
        "model_ans": "16th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the two Huguenot neighborhoods created in Berlin?",
        "answers": [
            "Dorotheenstadt and Friedrichstadt",
            "Dorotheenstadt and Friedrichstadt",
            "Dorotheenstadt and Friedrichstadt"
        ],
        "model_ans": "Prenzlauer Berg and Kreuzberg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Prenzlauer Berg and Kreuzberg </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What portion of Berlin's population spoke French by 1700?",
        "answers": [
            "one-fifth",
            "one-fifth",
            "one-fifth"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Berlin Huguenots switch to German from French in their services?",
        "answers": [
            "in protest against the occupation of Prussia by Napoleon",
            "in protest",
            "in protest against the occupation of Prussia by Napoleon"
        ],
        "model_ans": "Because of the Edict of Nantes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because of the Edict of Nantes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What years did this occupation take place?",
        "answers": [
            "1806-07",
            "1806-07.",
            "1806-07"
        ],
        "model_ans": "1880-1920",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1880-1920 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other Northern European cities had Huguenot congregations?",
        "answers": [
            "Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden",
            "Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden",
            "Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden"
        ],
        "model_ans": "Amsterdam, Berlin, Hamburg, London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Amsterdam, Berlin, Hamburg, London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which central European country had a Calvinist ruler?",
        "answers": [
            "Prussia",
            "Great Elector Frederick William",
            "Prussia"
        ],
        "model_ans": "Hungary",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hungary </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After Huguenots fled France, their last remaining bastion was where?",
        "answers": [
            "C\u00e9vennes",
            "C\u00e9vennes",
            "C\u00e9vennes region in the south"
        ],
        "model_ans": "South Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> South Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the 18th century Huguenot group call themselves?",
        "answers": [
            "Camisards",
            "Camisards",
            "the Camisards"
        ],
        "model_ans": "French Protestants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French Protestants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Against whom did the Camisards rise up to fight?",
        "answers": [
            "the Catholic Church in the region",
            "Catholic Church",
            "the Catholic Church in the region"
        ],
        "model_ans": "Catholics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "French troops put down the Camisard uprisings between what years?",
        "answers": [
            "1702 and 1709",
            "1702 and 1709",
            "1702 and 1709"
        ],
        "model_ans": "1702-1710\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1702-1710\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There was a 16th century Huguenot settlement near what modern day Florida city?",
        "answers": [
            "Jacksonville",
            "Jacksonville",
            "Jacksonville"
        ],
        "model_ans": "St. Augustine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> St. Augustine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the leader who established the colony at Florida?",
        "answers": [
            "Jean Ribault",
            "Jean Ribault",
            "Jean Ribault"
        ],
        "model_ans": "Pedro Men\u00e9ndez de Avil\u00e9s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pedro Men\u00e9ndez de Avil\u00e9s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the Florida Huguenot colony?",
        "answers": [
            "Fort Caroline",
            "Fort Caroline",
            "Fort Caroline"
        ],
        "model_ans": "Fort Caroline",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fort Caroline </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which army attacked and destroyed this colony?",
        "answers": [
            "Spanish",
            "Spanish",
            "Spanish"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the colony destroyed?",
        "answers": [
            "1565",
            "1565",
            "1565"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the first Huguenot outpost in South Carolina?",
        "answers": [
            "Charlesfort",
            "Charlesfort",
            "Charlesfort"
        ],
        "model_ans": "Charles Town",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Town </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What present-day area was this settlement near?",
        "answers": [
            "Parris Island",
            "Southeastern U.S.",
            "Parris Island"
        ],
        "model_ans": "Tokyo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tokyo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which Spanish officer established the settlement at St. Augustine?",
        "answers": [
            "Pedro Men\u00e9ndez de Avil\u00e9s",
            "Pedro Men\u00e9ndez de Avil\u00e9s",
            "Pedro Men\u00e9ndez de Avil\u00e9s"
        ],
        "model_ans": "Pedro Men\u00e9ndez de Avil\u00e9s",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pedro Men\u00e9ndez de Avil\u00e9s </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Ribault first establish a settlement in South Carolina?",
        "answers": [
            "1562",
            "1562",
            "1564"
        ],
        "model_ans": "1562\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1562\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What European event caused the Huguenots to abandon Charlesfort?",
        "answers": [
            "The Wars of Religion",
            "The Wars of Religion",
            "The Wars of Religion"
        ],
        "model_ans": "The Thirty Years War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Thirty Years War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what English colony were Huguenot settlers promised land?",
        "answers": [
            "Virginia",
            "Virginia",
            "Virginia"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what area of this British colony were Huguenot land grants?",
        "answers": [
            "Lower Norfolk County",
            "Lower Norfolk County",
            "Lower Norfolk County"
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What town was actually granted to the Huguenots on arrival?",
        "answers": [
            "Manakin Town",
            "Manakin Town",
            "Manakin Town"
        ],
        "model_ans": "Saumur",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saumur </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many settlers original settled in Manakintown?",
        "answers": [
            "390",
            "390",
            "390"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were these settlers naturalized as English colonists?",
        "answers": [
            "12 May 1705",
            "1705",
            "12 May 1705"
        ],
        "model_ans": "1607",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1607 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Dutch Revolt?",
        "answers": [
            "1568\u20131609",
            "1568\u20131609",
            "1568\u20131609"
        ],
        "model_ans": "1568-1648\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1568-1648\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Dutch fight in the Dutch Revolt?",
        "answers": [
            "Spain",
            "Spain",
            "Spain"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What Dutch document condemned the Spanish Inquisition?",
        "answers": [
            "\"Apologie\"",
            "Apologie\" of William the Silent",
            "Apologie"
        ],
        "model_ans": "The Synod of Utrecht",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Synod of Utrecht </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What leader led the Dutch Revolt and wrote Apologie?",
        "answers": [
            "William the Silent",
            "Pierre L'Oyseleur",
            "William the Silent"
        ],
        "model_ans": "William the Silent",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William the Silent </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the Dutch leader's religious affiliation?",
        "answers": [
            "Calvinist",
            "Calvinist",
            "Walloon"
        ],
        "model_ans": "Calvinist",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Calvinist </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What English law made that country more welcoming to Huguenots?",
        "answers": [
            "Foreign Protestants Naturalization Act",
            "Foreign Protestants Naturalization Act,",
            "Foreign Protestants Naturalization Act"
        ],
        "model_ans": "Act of Uniformity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Act of Uniformity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was this naturalization act passed?",
        "answers": [
            "1708",
            "1708",
            "1708"
        ],
        "model_ans": "1790\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1790\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "About how many Walloons and Huguenots emigrated to England and Ireland in this era?",
        "answers": [
            "50,000",
            "50,000",
            "50,000"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the famous Huguenot theologian and writer in London?",
        "answers": [
            "Andrew Lortie",
            "Andrew Lortie",
            "Andrew Lortie"
        ],
        "model_ans": "Pierre du Moulin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pierre du Moulin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Catholic Church liturgical belief did Lortie criticize openly?",
        "answers": [
            "the doctrine of transubstantiation",
            "doctrine of transubstantiation during Mass",
            "the Pope and the doctrine of transubstantiation"
        ],
        "model_ans": "The Mass",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Mass </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What war in Ireland featured Huguenot regiments?",
        "answers": [
            "Williamite war",
            "Williamite",
            "the Williamite war"
        ],
        "model_ans": "Nine Years' War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nine Years' War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under which leader did the Huguenots fight in this conflict?",
        "answers": [
            "William of Orange",
            "William of Orange",
            "William of Orange"
        ],
        "model_ans": "Henry IV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry IV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which Irish cities had large Huguenot enclaves?",
        "answers": [
            "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal",
            "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal",
            "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal"
        ],
        "model_ans": "Dublin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dublin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Huguenots in Killeshandra and County Cavan expanded what agricultural industry?",
        "answers": [
            "flax cultivation",
            "flax",
            "flax cultivation"
        ],
        "model_ans": "flax",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> flax </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What textile industry did the Huguenots contribute to in Ireland?",
        "answers": [
            "Irish linen industry",
            "linen",
            "Irish linen"
        ],
        "model_ans": "Silk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Silk </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which noble helped establish the Huguenot settlement in Saarland?",
        "answers": [
            "Prince Louis de Cond\u00e9",
            "Louis de Cond\u00e9",
            "Prince Louis de Cond\u00e9"
        ],
        "model_ans": "Louis XIV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louis XIV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which Count did the Prince strike an arrangement with?",
        "answers": [
            "Count Ludwig von Nassau-Saarbr\u00fccken",
            "Ludwig von Nassau-Saarbr\u00fccken",
            "Count Ludwig von Nassau-Saarbr\u00fccken"
        ],
        "model_ans": "Prince",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prince </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What industry did the nobleman establish with this settlement?",
        "answers": [
            "glass-making",
            "glass-making",
            "glass-making"
        ],
        "model_ans": "textile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> textile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what era did some members of this community emigrate to the US?",
        "answers": [
            "1890s",
            "1890s",
            "1890s"
        ],
        "model_ans": "19th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 19th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the agreement to allow the Saarland settlement reached?",
        "answers": [
            "1604",
            "1604",
            "1604"
        ],
        "model_ans": "1935\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1935\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What two member nations of the Holy Roman Empire received Huguenot refugees?",
        "answers": [
            "Electorate of Brandenburg and Electorate of the Palatinate",
            "the Electorate of Brandenburg and Electorate of the Palatinate",
            "the Electorate of Brandenburg and Electorate of the Palatinate"
        ],
        "model_ans": "France and Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France and Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What general religious belief did the nations that received Huguenot refugees have in common?",
        "answers": [
            "Protestant",
            "Protestant",
            "Protestant"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What area in South Africa accepted Huguenot colonists?",
        "answers": [
            "Dutch Cape Colony",
            "Dutch Cape Colony",
            "Dutch Cape Colony"
        ],
        "model_ans": "Cape Town",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cape Town </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What area in modern-day Canada received Huguenot immigrants?",
        "answers": [
            "Quebec",
            "Quebec",
            "Quebec"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What made emigration to these colonies attractive?",
        "answers": [
            "they were accepted and allowed to worship freely",
            "allowed to worship freely",
            "they were accepted and allowed to worship freely"
        ],
        "model_ans": "Economic opportunities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economic opportunities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "From what French King did the Huguenot name possibly descend?",
        "answers": [
            "Hugues Capet",
            "Hugues Capet",
            "Hugues Capet"
        ],
        "model_ans": "Henri",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Henri </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the theory that this King's name is the origin of \"Huguenot\" called?",
        "answers": [
            "The \"Hugues hypothesis\"",
            "\"Hugues hypothesis\"",
            "Hugues hypothesis"
        ],
        "model_ans": "The theory is called the \"Huguenot theory\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The theory is called the \"Huguenot theory\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is one prominent advocate of this theory?",
        "answers": [
            "Janet Gray",
            "Janet Gray",
            "Janet Gray"
        ],
        "model_ans": "Richard Dawkins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Dawkins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to the theory, what does the name \"Huguenot\" mean?",
        "answers": [
            "little Hugos, or those who want Hugo",
            "little Hugos",
            "little Hugos, or those who want Hugo."
        ],
        "model_ans": "French Protestant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French Protestant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other theories of the word's origin can be generally classed as what?",
        "answers": [
            "double or triple non-French linguistic origins",
            "non-French linguistic origins"
        ],
        "model_ans": "etymological",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> etymological </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was one French pro-reform Roman Catholic of the 15th century? ",
        "answers": [
            "Jacques Lefevre",
            "Jacques Lefevre",
            "Jacques Lefevre"
        ],
        "model_ans": "Jacques Lef\u00e8vre d'\u00c9taples",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jacques Lef\u00e8vre d'\u00c9taples </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did this pro-reform leader teach?",
        "answers": [
            "University of Paris",
            "University of Paris",
            "University of Paris"
        ],
        "model_ans": "Beijing University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did this leader publish a French language Bible?",
        "answers": [
            "1530",
            "1523",
            "1530"
        ],
        "model_ans": "1528",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1528 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What leader of the Swiss reformation was a student of Lefevre?",
        "answers": [
            "William Farel",
            "William Farel",
            "William Farel"
        ],
        "model_ans": "Huldrych Zwingli",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Huldrych Zwingli </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other European Protestant leader was educated at the University of Paris?",
        "answers": [
            "Jean Cauvin (John Calvin)",
            "Jean Cauvin",
            "Jean Cauvin"
        ],
        "model_ans": "John Calvin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Calvin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the St. Bartholomew's Day Massacre?",
        "answers": [
            "24 August \u2013 3 October 1572",
            "24 August \u2013 3 October 1572",
            "24 August \u2013 3 October 1572"
        ],
        "model_ans": "1572\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1572\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What group killed thousands of Huguenots?",
        "answers": [
            "Catholics",
            "Catholics",
            "Catholics"
        ],
        "model_ans": "Catholics",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholics </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many Huguenots were killed in Toulouse?",
        "answers": [
            "Nearly 3,000",
            "Nearly 3,000",
            "Nearly 3,000"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was amnesty granted to those responsible for the massacre?",
        "answers": [
            "1573",
            "1573",
            "1573"
        ],
        "model_ans": "1994",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1994 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Reports document that how many Parisien Protestants were killed by September 17?",
        "answers": [
            "almost 25,000",
            "almost 25,000",
            "almost 25,000"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who became king in 1643?",
        "answers": [
            "Louis XIV",
            "Louis XIV",
            "Louis XIV"
        ],
        "model_ans": "Charles I",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles I </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the new king react to the Huguenots?",
        "answers": [
            "acted increasingly aggressively to force the Huguenots to convert",
            "aggressively",
            "increasingly aggressively"
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the king's first approach to the Huguenots?",
        "answers": [
            "he sent missionaries, backed by a fund to financially reward converts",
            "missionaries",
            "At first he sent missionaries, backed by a fund to financially reward converts to Catholicism"
        ],
        "model_ans": "tolerance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> tolerance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the king do to regarding Huguenot education?",
        "answers": [
            "closed Huguenot schools",
            "closed Huguenot schools",
            "closed Huguenot schools and excluded them from favored professions"
        ],
        "model_ans": "banned",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> banned </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The practice of occupying and looting Huguenot homes was called?",
        "answers": [
            "dragonnades",
            "dragonnades",
            "dragonnades"
        ],
        "model_ans": "dragonnades",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> dragonnades </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What present day county is New Rochelle in?",
        "answers": [
            "Westchester",
            "Westchester",
            "Westchester"
        ],
        "model_ans": "Westchester",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Westchester </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where did the Huguenots land in New York originally?",
        "answers": [
            "\"Bauffet's Point\"",
            "Bauffet's Point",
            "Bauffet's Point"
        ],
        "model_ans": "Manhattan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manhattan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "From whom did the Huguenots purchase the land where they settled?",
        "answers": [
            "John Pell, Lord of Pelham Manor",
            "John Pell",
            "John Pell"
        ],
        "model_ans": "The Dutch",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Dutch </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What French City was New Rochelle named after?",
        "answers": [
            "La Rochelle",
            "La Rochelle",
            "La Rochelle"
        ],
        "model_ans": "Rouen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rouen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the third, permanent Huguenot church in New Rochelle?",
        "answers": [
            "Trinity-St. Paul's Episcopal Church",
            "Trinity-St. Paul's Episcopal Church",
            "Trinity-St. Paul's Episcopal Church"
        ],
        "model_ans": "The French Church",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The French Church </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Huguenots evolve their religious beliefs in the New World?",
        "answers": [
            "affiliated with other Protestant denominations",
            "affiliated with other Protestant denominations",
            "affiliated with other Protestant denominations with more numerous members"
        ],
        "model_ans": "They evolved their religious beliefs through a combination of their French Calvinist heritage and their experiences in the New World, including interactions with Native Americans and other European colonizers.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They evolved their religious beliefs through a combination of their French Calvinist heritage and their experiences in the New World, including interactions with Native Americans and other European colonizers. </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How were Huguenot settlers assimilated into North American society at large?",
        "answers": [
            "married outside their immediate French communities",
            "married outside their immediate French communities",
            "adapted quickly and often married outside their immediate French communities"
        ],
        "model_ans": "They were assimilated through intermarriage, conversion to Anglicanism, and adoption of English customs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They were assimilated through intermarriage, conversion to Anglicanism, and adoption of English customs </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was one prominent Huguenot-descended arms manufacturer?",
        "answers": [
            "E.I. du Pont",
            "E.I. du Pont",
            "E.I. du Pont"
        ],
        "model_ans": "Remington",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Remington </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For how long did Huguenots continue to use French names?",
        "answers": [
            "into the nineteenth century",
            "well into the nineteenth century",
            "well into the nineteenth century"
        ],
        "model_ans": "200 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of du Pont's gunpowder operation?",
        "answers": [
            "Eleutherian gunpowder mills",
            "Eleutherian gunpowder mills.",
            "Eleutherian"
        ],
        "model_ans": "Brandywine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brandywine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was a prominent Huguenot in Holland?",
        "answers": [
            "Pierre Bayle",
            "Pierre Bayle",
            "Pierre Bayle"
        ],
        "model_ans": "William the Silent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> William the Silent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did he begin teaching?",
        "answers": [
            "Rotterdam",
            "Rotterdam",
            "Rotterdam"
        ],
        "model_ans": "London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What books did Bayle publish?",
        "answers": [
            "Historical and Critical Dictionary",
            "Historical and Critical Dictionary",
            "Historical and Critical Dictionary"
        ],
        "model_ans": "Dictionnaire Historique et Critique",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dictionnaire Historique et Critique </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "These books became a foundational text for what library?",
        "answers": [
            "US Library of Congress",
            "US Library of Congress",
            "US Library of Congress"
        ],
        "model_ans": "The Library of Alexandria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Library of Alexandria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the patron saint of the Huguenots?",
        "answers": [
            "Saint Nicolas",
            "Saint Nicolas",
            "Saint Nicolas"
        ],
        "model_ans": "St. Louis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> St. Louis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What early Huguenot Church was established in England?",
        "answers": [
            "The French Protestant Church of London",
            "The French Protestant Church of London",
            "The French Protestant Church of London"
        ],
        "model_ans": "The French Church of London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The French Church of London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the charter for this church signed?",
        "answers": [
            "1550",
            "1550",
            "1550"
        ],
        "model_ans": "1559",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1559 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the present-day location of this church?",
        "answers": [
            "Soho Square",
            "Soho Square",
            "Soho Square"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What London neighborhood attracted Huguenot refugees?",
        "answers": [
            "Shoreditch",
            "Shoreditch",
            "Shoreditch"
        ],
        "model_ans": "Spitalfields",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spitalfields </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Old Truman Brewery founded?",
        "answers": [
            "1724",
            "1724",
            "1724"
        ],
        "model_ans": "1866",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1866 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What protestant religions made Northern European counties safe for Huguenot immigration?",
        "answers": [
            "Lutheran and Reformed",
            "Lutheran and Reformed",
            "Lutheran and Reformed"
        ],
        "model_ans": "Lutheran",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lutheran </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which areas of Northern Europe practiced those religions?",
        "answers": [
            "Germany and Scandinavia",
            "Germany and Scandinavia",
            "Germany and Scandinavia"
        ],
        "model_ans": "Scandinavia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scandinavia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What proclamation gave Huguenots special privileges in Brandenburg?",
        "answers": [
            "Edict of Potsdam",
            "Edict of Potsdam",
            "Edict of Potsdam"
        ],
        "model_ans": "Edict of Potsdam",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edict of Potsdam </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What dual titles did Frederick William hold?",
        "answers": [
            "Elector of Brandenburg and Duke of Prussia",
            "Elector of Brandenburg and Duke of Prussia",
            "Elector of Brandenburg and Duke of Prussia"
        ],
        "model_ans": "King in Prussia and Elector of Brandenburg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> King in Prussia and Elector of Brandenburg </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What military impact did Huguenot immigration have on Frederick's army?",
        "answers": [
            "Huguenots furnished two new regiments",
            "two new regiments",
            "furnished two new regiments of his army"
        ],
        "model_ans": "The Huguenot immigration had a significant impact on Frederick's army, as they brought with them their military expertise and tactics, which helped to modernize the Prussian army. </</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Huguenot immigration had a significant impact on Frederick's army, as they brought with them their military expertise and tactics, which helped to modernize the Prussian army. </</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What German ruler invited Huguenot immigration?",
        "answers": [
            "Frederick William",
            "Frederick William",
            "Frederick William"
        ],
        "model_ans": "Frederick William",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Frederick William </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What German poet was descended from Huguenots?",
        "answers": [
            "Theodor Fontane",
            "Theodor Fontane",
            "Theodor Fontane"
        ],
        "model_ans": "Goethe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Goethe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What German general and fighter pilot was of Huguenot ancestry?",
        "answers": [
            "Adolf Galland",
            "Adolf Galland",
            "Adolf Galland"
        ],
        "model_ans": "Adolf Galland",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Adolf Galland </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the final Prime Minister of East Germany?",
        "answers": [
            "Lothar de Maizi\u00e8re",
            "Lothar de Maizi\u00e8re",
            "Lothar de Maizi\u00e8re"
        ],
        "model_ans": "Lothar de Maizi\u00e8re",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lothar de Maizi\u00e8re </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Thomas de Maiziere serves what role in the German cabinet?",
        "answers": [
            "Federal Minister of the Interior",
            "Minister of the Interior",
            "Federal Minister of the Interior"
        ],
        "model_ans": "Minister of the Interior",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Minister of the Interior </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Along with geothermal and nuclear, what is a notable non-combustion heat source?",
        "answers": [
            "solar",
            "solar power",
            "solar power, nuclear power or geothermal energy",
            "solar"
        ],
        "model_ans": "solar",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> solar </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What ideal thermodynamic cycle analyzes the process by which steam engines work?",
        "answers": [
            "Rankine",
            "Rankine cycle",
            "Rankine cycle",
            "Rankine cycle"
        ],
        "model_ans": "Carnot cycle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carnot cycle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In the Rankine cycle, what does water turn into when heated?",
        "answers": [
            "steam",
            "steam",
            "steam",
            "steam"
        ],
        "model_ans": "steam",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> steam </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "At what pressure is water heated in the Rankine cycle?",
        "answers": [
            "high",
            "high",
            "high pressure",
            "high"
        ],
        "model_ans": "220 bar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 220 bar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of engines are steam engines?",
        "answers": [
            "external combustion",
            "external combustion",
            "external combustion engines",
            "external combustion"
        ],
        "model_ans": "steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the first true engine that was commercially successful?",
        "answers": [
            "atmospheric engine",
            "atmospheric engine",
            "atmospheric engine",
            "the atmospheric engine"
        ],
        "model_ans": "Steam engine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam engine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the inventor of the atmospheric engine?",
        "answers": [
            "Thomas Newcomen",
            "Thomas Newcomen",
            "Thomas Newcomen",
            "Thomas Newcomen"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "About what year was the atmospheric engine invented?",
        "answers": [
            "1712",
            "around 1712",
            "1712",
            "1712"
        ],
        "model_ans": "1698",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1698 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was invented by Savery?",
        "answers": [
            "steam pump",
            "steam pump",
            "steam pump",
            "steam pump"
        ],
        "model_ans": "Steam Pump",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Steam Pump </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who conceptualized the piston?",
        "answers": [
            "Papin",
            "Papin",
            "Papin",
            "Papin"
        ],
        "model_ans": "Otto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Otto </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what country was a full-scale working railway steam locomotive first invented?",
        "answers": [
            "United Kingdom",
            "United Kingdom",
            "United Kingdom"
        ],
        "model_ans": "United Kingdom",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Kingdom </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "On what date did the first railway trip in the world occur?",
        "answers": [
            "21 February 1804",
            "21 February 1804",
            "21 February 1804"
        ],
        "model_ans": "September 21, 1825",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 21, 1825 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the world's first railway journey terminate?",
        "answers": [
            "Abercynon",
            "Abercynon in south Wales",
            "Abercynon"
        ],
        "model_ans": "Liverpool",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Liverpool </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what constituent country of the United Kingdom is Merthyr Tydfil located?",
        "answers": [
            "Wales",
            "south Wales",
            "Wales"
        ],
        "model_ans": "Wales",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wales </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what geographical portion of Wales is Abercynon located?",
        "answers": [
            "south",
            "south",
            "south"
        ],
        "model_ans": "South Wales",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South Wales </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What device is used to recycle the boiler water in most steam engines?",
        "answers": [
            "water pump",
            "water pump",
            "water pump"
        ],
        "model_ans": "Condenser",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Condenser </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of pumps are typically used in industrial boilers?",
        "answers": [
            "multi-stage centrifugal",
            "multi-stage centrifugal",
            "multi-stage centrifugal pumps"
        ],
        "model_ans": "Centrifugal pumps",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Centrifugal pumps </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what decade were injectors widely used in steam engines?",
        "answers": [
            "1850s",
            "1850s",
            "1850s"
        ],
        "model_ans": "19th",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 19th </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a notable application of injectors today?",
        "answers": [
            "steam locomotives",
            "steam locomotives",
            "steam locomotives"
        ],
        "model_ans": "Diesel engines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diesel engines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are injectors used to supply?",
        "answers": [
            "lower-pressure boiler feed water",
            "water",
            "lower-pressure boiler feed water"
        ],
        "model_ans": "fuel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fuel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many expansion stages are used by the triple expansion engine?",
        "answers": [
            "three",
            "three or four",
            "three"
        ],
        "model_ans": "3\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "3\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are engines using four expansion stages known as?",
        "answers": [
            "quadruple expansion engines",
            "quadruple",
            "quadruple expansion engines"
        ],
        "model_ans": "Compound",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Compound </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what century was the Yarrow-Schlick-Tweedy balancing system used?",
        "answers": [
            "19th",
            "19th",
            "19th"
        ],
        "model_ans": "19th",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 19th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What sort of engines utilized the Yarrow-Schlick-Tweedy balancing system?",
        "answers": [
            "marine triple expansion",
            "marine triple expansion",
            "marine triple expansion engines"
        ],
        "model_ans": "Steam turbines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Steam turbines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What class of ships is an example of large passenger liners?",
        "answers": [
            "Olympic",
            "Olympic",
            "Olympic class"
        ],
        "model_ans": "Ocean Liner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ocean Liner </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with poppet valve gears, what type of gears utilized separate admission and exhaust valves to give ideal events?",
        "answers": [
            "Corliss",
            "patent valve",
            "Corliss"
        ],
        "model_ans": "Overhead camshaft",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Overhead camshaft </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with Stephenson and Walschaerts, what is an example of a simple motion?",
        "answers": [
            "Joy",
            "Joy",
            "Joy"
        ],
        "model_ans": "Allan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Allan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is lap provided by overlapping the admission side port?",
        "answers": [
            "lengthening rubbing surfaces of the valve",
            "lengthening rubbing surfaces",
            "lengthening rubbing surfaces of the valve"
        ],
        "model_ans": "Lap",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lap </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are sometimes present in the boiler's firebox crown?",
        "answers": [
            "Lead fusible plugs",
            "Lead fusible plugs",
            "Lead fusible plugs"
        ],
        "model_ans": "refractory linings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> refractory linings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to the lead fusible plugs if the water level of the boiler drops?",
        "answers": [
            "melts",
            "melts",
            "the lead melts"
        ],
        "model_ans": "They melt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They melt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens after the lead melts?",
        "answers": [
            "steam escapes",
            "steam escapes,",
            "the steam escapes"
        ],
        "model_ans": "Liquid",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Liquid </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After the operators are warned by the escape of the steam, what may they then do?",
        "answers": [
            "manually suppress the fire",
            "manually suppress the fire",
            "manually suppress the fire"
        ],
        "model_ans": "Shut off the steam valve",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shut off the steam valve </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the escape of the steam unlikely to accomplish in all but the smallest boilers?",
        "answers": [
            "dampening the fire",
            "dampening the fire",
            "dampening the fire"
        ],
        "model_ans": "Reduce the pressure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Reduce the pressure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who patented a steam engine in 1781?",
        "answers": [
            "James Watt",
            "James Watt",
            "James Watt",
            "James Watt"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What sort of motion did Watt's steam engine continuously produce?",
        "answers": [
            "rotary",
            "rotary",
            "rotary motion",
            "continuous rotary motion"
        ],
        "model_ans": "rotary",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rotary </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many horsepower was Watt's engine?",
        "answers": [
            "ten",
            "ten-horsepower",
            "ten-horsepower",
            "ten"
        ],
        "model_ans": "5 horsepower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 horsepower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "As of what year were 10000 horsepower engines available?",
        "answers": [
            "1883",
            "1883",
            "1883",
            "1883"
        ],
        "model_ans": "1920s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the steam engine an important component of?",
        "answers": [
            "Industrial Revolution",
            "Industrial Revolution",
            "Industrial Revolution",
            "the Industrial Revolution"
        ],
        "model_ans": "Industrial Revolution",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Industrial Revolution </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what century did the history of the steam engine begin?",
        "answers": [
            "first",
            "first century AD",
            "first century AD",
            "first century AD"
        ],
        "model_ans": "17th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 17th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who conceptualized the aeolipile?",
        "answers": [
            "Hero of Alexandria",
            "Hero of Alexandria",
            "Hero of Alexandria",
            "Hero of Alexandria"
        ],
        "model_ans": "Hero of Alexandria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hero of Alexandria </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was Hero of Alexandria's nationality?",
        "answers": [
            "Greek",
            "Greek",
            "Greek",
            "Greek"
        ],
        "model_ans": "Greek",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greek </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who described a steam turbine in 1629?",
        "answers": [
            "Giovanni Branca",
            "Giovanni Branca",
            "Giovanni Branca",
            "Giovanni Branca"
        ],
        "model_ans": "Giovanni Battista Della Porta",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Giovanni Battista Della Porta </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Jer\u00f3nimo de Ayanz y Beaumont patent a water pump for draining mines?",
        "answers": [
            "1606",
            "1606",
            "1606",
            "1606"
        ],
        "model_ans": "1606\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1606\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of engines became widespread around the end of the 19th century?",
        "answers": [
            "compound",
            "compound",
            "compound engines"
        ],
        "model_ans": "Steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the stages in a compound engine called?",
        "answers": [
            "expansions",
            "expansions",
            "expansions"
        ],
        "model_ans": "cylinders",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cylinders </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what field were double and triple expansion engines common?",
        "answers": [
            "shipping",
            "shipping",
            "shipping"
        ],
        "model_ans": "Steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What product was notably shipped in vessels equipped with double and triple expansion engines?",
        "answers": [
            "coal",
            "coal"
        ],
        "model_ans": "Oil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oil </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with electric motors, what power sources overtook steam engines in the 20th century?",
        "answers": [
            "internal combustion engines",
            "internal combustion engines",
            "internal combustion engines"
        ],
        "model_ans": "Diesel engines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Diesel engines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The use of what device represented the last major evolution of the steam engine?",
        "answers": [
            "steam turbines",
            "steam turbines",
            "steam turbines"
        ],
        "model_ans": "Corliss steam engine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Corliss steam engine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what part of the 19th century were steam turbines introduced?",
        "answers": [
            "late",
            "late part",
            "late"
        ],
        "model_ans": "late 19th century",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> late 19th century </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Above what horsepower are steam turbines usually more efficient than steam engines that use reciprocating pistons?",
        "answers": [
            "several hundred",
            "several hundred horsepower",
            "several hundred"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of electrical power in the United States is made by steam turbines?",
        "answers": [
            "90",
            "90%",
            "90%"
        ],
        "model_ans": "60%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Most power of what sort is generated by steam turbines today?",
        "answers": [
            "electric",
            "electric",
            "electric"
        ],
        "model_ans": "electricity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> electricity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the usual source of heat for boiling water in the steam engine?",
        "answers": [
            "burning combustible materials",
            "burning combustible materials",
            "burning combustible materials"
        ],
        "model_ans": "Fire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Aside from firebox, what is another name for the space in which combustible material is burned in the engine?",
        "answers": [
            "combustion chamber",
            "combustion chamber",
            "combustion chamber"
        ],
        "model_ans": "Furnace",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Furnace </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with nuclear, geothermal and internal combustion engine waste heat, what sort of energy might supply the heat for a steam engine?",
        "answers": [
            "solar",
            "solar",
            "solar"
        ],
        "model_ans": "solar",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> solar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of heating element is often used in toy steam engines?",
        "answers": [
            "electric",
            "electric heating element",
            "electric"
        ],
        "model_ans": "Electric",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Electric </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What instrument is used to examine steam engine performance?",
        "answers": [
            "steam engine indicator",
            "steam engine indicator",
            "steam engine indicator"
        ],
        "model_ans": "Pressure gauge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pressure gauge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year saw the earliest recorded use of the steam engine indicator?",
        "answers": [
            "1851",
            "1851",
            "1851"
        ],
        "model_ans": "1790",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1790 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What company developed the most successful steam engine indicator?",
        "answers": [
            "Charles Porter",
            "Charles Porter",
            "Charles Porter"
        ],
        "model_ans": "Taylor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taylor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who developed a successful steam engine indicator for Charles Porter?",
        "answers": [
            "Charles Richard",
            "Charles Richard",
            "Charles Richard"
        ],
        "model_ans": "Porter",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Porter </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the Charles Porter steam engine indicator shown?",
        "answers": [
            "London Exhibition",
            "London Exhibition",
            "London Exhibition"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At what degree are the pistons of a two-cylinder compound connected to the cranks?",
        "answers": [
            "90",
            "90\u00b0",
            "90\u00b0"
        ],
        "model_ans": "180 degrees\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "180 degrees\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In a 4-cylinder compound engine, what degree were the individual pistons balanced at?",
        "answers": [
            "180",
            "180\u00b0",
            "180\u00b0"
        ],
        "model_ans": "180 degrees\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "180 degrees\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what angle were the groups of pistons set in relation to one another in a 4-cylinder compound?",
        "answers": [
            "90",
            "90\u00b0 to each other",
            "90\u00b0"
        ],
        "model_ans": "90 degrees\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "90 degrees\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a term for the reversing of steam flow in a piston engine after each stroke?",
        "answers": [
            "counterflow",
            "counterflow",
            "counterflow"
        ],
        "model_ans": "Exhaust",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exhaust </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many piston strokes occur in an engine cycle?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "4\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "4\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many crank rotations are there in an engine cycle?",
        "answers": [
            "one",
            "one",
            "one"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many events occur in an engine cycle?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with admission, exhaust and compression, what is an event in the engine cycle?",
        "answers": [
            "expansion",
            "expansion",
            "expansion"
        ],
        "model_ans": "Intake",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Intake </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of a uniflow engine that takes in steam in hot areas and exhausts it in cold?",
        "answers": [
            "Quasiturbine",
            "Quasiturbine",
            "Quasiturbine"
        ],
        "model_ans": "Uniflow Steam Engine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uniflow Steam Engine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The uniflow engine is an attempt to fix an issue that arises in what cycle?",
        "answers": [
            "counterflow",
            "counterflow",
            "counterflow"
        ],
        "model_ans": "Otto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Otto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What part is added to the uniflow engine to resolve the issue in the counterflow cycle?",
        "answers": [
            "port",
            "additional port",
            "an additional port"
        ],
        "model_ans": "exhaust",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> exhaust </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of steam engine doesn't need valves to direct steam?",
        "answers": [
            "oscillating cylinder",
            "oscillating cylinder",
            "oscillating"
        ],
        "model_ans": "Corliss steam engine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Corliss steam engine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another term for the pivot mounting?",
        "answers": [
            "trunnion",
            "trunnion",
            "trunnion"
        ],
        "model_ans": "trunnion",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> trunnion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with toys, where are oscillating cylinder steam engines typically used?",
        "answers": [
            "models",
            "models",
            "models"
        ],
        "model_ans": "factories",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> factories </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Full size working engines on what vehicles sometimes use oscillating cylinder steam engines?",
        "answers": [
            "ships",
            "ships",
            "ships"
        ],
        "model_ans": "Steam Locomotives",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam Locomotives </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What happens to the working fluid in a closed loop system?",
        "answers": [
            "recycled continuously",
            "recycled continuously",
            "recycled continuously"
        ],
        "model_ans": "It is re-circulated",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It is re-circulated </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What sort of system releases the exhaust steam into the atmosphere?",
        "answers": [
            "open loop",
            "open loop",
            "open loop"
        ],
        "model_ans": "Power Plant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Power Plant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What working fluid is used in a mercury vapor turbine?",
        "answers": [
            "Mercury",
            "Mercury",
            "Mercury"
        ],
        "model_ans": "Mercury",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mercury </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the typical working fluid in a steam engine?",
        "answers": [
            "water",
            "water",
            "water"
        ],
        "model_ans": "Water",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What limits the Rankine cycle's efficiency?",
        "answers": [
            "working fluid",
            "working fluid",
            "the working fluid"
        ],
        "model_ans": "Heat transfer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heat transfer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the turbine entry temperature of a steam turbine, in degrees Celsius?",
        "answers": [
            "565",
            "565 \u00b0C",
            "565 \u00b0C"
        ],
        "model_ans": "500\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "500\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is  565 \u00b0C the creep limit of?",
        "answers": [
            "stainless steel",
            "stainless steel",
            "stainless steel"
        ],
        "model_ans": "Steel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steel </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the approximate condenser temperature in a turbine?",
        "answers": [
            "30 \u00b0C",
            "30 \u00b0C",
            "30 \u00b0C"
        ],
        "model_ans": "40-60\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40-60\u00b0C </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a turbine's theoretical Carnot efficiency?",
        "answers": [
            "63%",
            "63%",
            "63%"
        ],
        "model_ans": "1 - (Tc / Th) where Tc is the temperature of the cold reservoir and Th is the temperature of the hot reservoir.\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1 - (Tc / Th) where Tc is the temperature of the cold reservoir and Th is the temperature of the hot reservoir.\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What devices have been credited as the moving force of the Industrial Revolution?",
        "answers": [
            "Steam engines",
            "Steam engines",
            "Steam engines",
            "Steam engines"
        ],
        "model_ans": "Steam Engine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam Engine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with road vehicles, locomotives and ships, on what vehicles were steam engines used during the Industrial Revolution?",
        "answers": [
            "steamboats",
            "steamboats",
            "steamboats and road vehicles",
            "steamboats"
        ],
        "model_ans": "Trains",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trains </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an example of a steam-powered automobile?",
        "answers": [
            "Stanley Steamer",
            "Stanley Steamer",
            "Stanley Steamer",
            "Stanley Steamer"
        ],
        "model_ans": "Stanley Steamer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stanley Steamer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Along with mills and mines, in what industrial locations did steam drive machines?",
        "answers": [
            "factories",
            "factories",
            "factories",
            "factories"
        ],
        "model_ans": "factories",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> factories </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did the use of steam engines in farming lead to?",
        "answers": [
            "increase in the land available for cultivation",
            "increase in the land available for cultivation",
            "farm tractors",
            "an increase in the land available for cultivation"
        ],
        "model_ans": "Increased efficiency",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Increased efficiency </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the locomotive that debuted in 1808?",
        "answers": [
            "Catch Me Who Can",
            "Catch Me Who Can",
            "Catch Me Who Can"
        ],
        "model_ans": "Penydarren",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Penydarren </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who designed Salamanca?",
        "answers": [
            "Matthew Murray",
            "Matthew Murray",
            "Matthew Murray"
        ],
        "model_ans": "Santiago Calatrava",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Santiago Calatrava </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of locomotive was Salamanca?",
        "answers": [
            "twin-cylinder",
            "twin-cylinder",
            "twin-cylinder"
        ],
        "model_ans": "Steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "On what railroad was Salamanca used?",
        "answers": [
            "Middleton Railway",
            "Middleton Railway",
            "Middleton Railway"
        ],
        "model_ans": "Erie Railroad",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Erie Railroad </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For what railroad did Stephenson build a locomotive in 1825?",
        "answers": [
            "Stockton and Darlington",
            "Stockton and Darlington Railway",
            "Stockton and Darlington Railway"
        ],
        "model_ans": "Liverpool and Manchester Railway",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Liverpool and Manchester Railway </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who patented a high-pressure compound engine in 1805?",
        "answers": [
            "Arthur Woolf",
            "Arthur Woolf",
            "Arthur Woolf"
        ],
        "model_ans": "Richard Trevithick",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Richard Trevithick </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What nationality was Arthur Woolf?",
        "answers": [
            "British",
            "British",
            "British"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is decreased by staging expansion across multiple cylinders?",
        "answers": [
            "torque variability",
            "torque variability",
            "torque variability"
        ],
        "model_ans": "Compression ratio",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Compression ratio </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What needs to be larger to get the same work out of lower pressure steam?",
        "answers": [
            "cylinder volume",
            "cylinder",
            "cylinder volume"
        ],
        "model_ans": "Boiler",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boiler </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of electricity was made by steam turbine in the 1990s?",
        "answers": [
            "90",
            "90%",
            "90%"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What marine engines were less efficient than steam turbines?",
        "answers": [
            "reciprocating steam engines",
            "reciprocating",
            "reciprocating steam engines"
        ],
        "model_ans": "Diesel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diesel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with diesel engines, what engines have overtaken steam engines for marine propulsion?",
        "answers": [
            "gas turbines",
            "gas turbines",
            "gas turbines"
        ],
        "model_ans": "Gas turbines",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Gas turbines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What engines were used throughout most of the 20th century to propel ships?",
        "answers": [
            "steam turbines",
            "steam turbines with reduction gearing",
            "steam turbines"
        ],
        "model_ans": "Diesel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diesel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What gearing was used on steam turbine marine engines in the 20th century?",
        "answers": [
            "reduction",
            "reduction",
            "reduction"
        ],
        "model_ans": "1:1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1:1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the steam engine's thermodynamic basis?",
        "answers": [
            "Rankine cycle",
            "The Rankine cycle",
            "The Rankine cycle"
        ],
        "model_ans": "Carnot cycle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carnot cycle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to waste heat in the Rankine cycle?",
        "answers": [
            "removed in a condenser",
            "removed in a condenser",
            "removed in a condenser"
        ],
        "model_ans": "It is dissipated into the environment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It is dissipated into the environment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what decade did the Rankine cycle create 90% of electric power?",
        "answers": [
            "1990s",
            "1990s",
            "1990s"
        ],
        "model_ans": "20th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with solar, coal and nuclear, what sort of plants notable use the Rankine process?",
        "answers": [
            "biomass",
            "biomass",
            "biomass"
        ],
        "model_ans": "Geothermal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geothermal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is William Rankine's nationality?",
        "answers": [
            "Scottish",
            "Scottish",
            "Scottish"
        ],
        "model_ans": "American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was the efficiency of a steam engine typically evaluated?",
        "answers": [
            "duty",
            "duty"
        ],
        "model_ans": "By measuring the amount of work it could perform in a given time, typically measured in horsepower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By measuring the amount of work it could perform in a given time, typically measured in horsepower </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who invented the notion of a steam engine's duty?",
        "answers": [
            "Watt",
            "Watt",
            "Watt"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the weight of a bushel of coal in pounds?",
        "answers": [
            "94",
            "94 pounds",
            "94 pounds"
        ],
        "model_ans": "2,000 pounds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,000 pounds </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the ideal duty of a Newcomen engine?",
        "answers": [
            "7 million",
            "7 million",
            "7 million"
        ],
        "model_ans": "Pumping water out of mines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pumping water out of mines </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the average duty of a low-pressure Watt engine?",
        "answers": [
            "17",
            "17.",
            "17"
        ],
        "model_ans": "10-15 horsepower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10-15 horsepower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of engines became popular for power generation after piston steam engines?",
        "answers": [
            "steam turbines",
            "internal combustion engines",
            "Reciprocating piston",
            "steam turbines"
        ],
        "model_ans": "Gas turbines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gas turbines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of steam engines produced most power up to the early 20th century?",
        "answers": [
            "Reciprocating piston",
            "steam turbines",
            "electric motors and internal combustion",
            "Reciprocating piston type"
        ],
        "model_ans": "Steam locomotive",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam locomotive </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of steam engine produces most electricity in the world today?",
        "answers": [
            "turbine",
            "turbine type",
            "electric motors",
            "turbine type"
        ],
        "model_ans": "Steam Turbine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam Turbine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Along with electric motors, what type of engines superseded piston steam engines?",
        "answers": [
            "internal combustion",
            "internal combustion",
            "internal combustion"
        ],
        "model_ans": "Diesel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diesel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who developed the first commercial steam powered device?",
        "answers": [
            "Thomas Savery",
            "Thomas Savery.",
            "Thomas Savery",
            "Thomas Savery"
        ],
        "model_ans": "Richard Trevithick",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Richard Trevithick </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the first steam powered device used commercially?",
        "answers": [
            "water pump",
            "water pump",
            "vacuum",
            "water pump"
        ],
        "model_ans": "Steam engine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam engine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the first commercial steam powered device invented?",
        "answers": [
            "1698",
            "1698",
            "1698",
            "1698"
        ],
        "model_ans": "1698",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1698 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who notably improved the Savery water pump?",
        "answers": [
            "Bento de Moura Portugal",
            "Bento de Moura Portugal",
            "Bento de Moura Portugal",
            "Bento de Moura Portugal"
        ],
        "model_ans": "Thomas Newcomen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Newcomen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote of the Savery water pump in 1751's Philosophical Transactions?",
        "answers": [
            "John Smeaton",
            "John Smeaton",
            "John Smeaton",
            "John Smeaton"
        ],
        "model_ans": "Thomas Savery",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Savery </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who invented a high-pressure steam engine around 1800?",
        "answers": [
            "Richard Trevithick",
            "Richard Trevithick",
            "Richard Trevithick",
            "Richard Trevithick"
        ],
        "model_ans": "Richard Trevithick",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Trevithick </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who created an engine using high pressure steam in 1801?",
        "answers": [
            "Oliver Evans",
            "Oliver Evans",
            "Oliver Evans",
            "Oliver Evans"
        ],
        "model_ans": "Richard Trevithick",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Trevithick </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did Richard Trevithick patent his device?",
        "answers": [
            "1802",
            "1802",
            "1802",
            "1802"
        ],
        "model_ans": "1804\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1804\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "High pressure steam engines were small enough that they could be used in what application?",
        "answers": [
            "transport",
            "transport",
            "transport applications",
            "transport"
        ],
        "model_ans": "locomotives",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> locomotives </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were steam engines used as a source of?",
        "answers": [
            "power",
            "power",
            "power source"
        ],
        "model_ans": "power",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> power </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What modern company has been notably working on a steam engine using modern materials?",
        "answers": [
            "Energiprojekt AB",
            "Energiprojekt AB",
            "Energiprojekt AB"
        ],
        "model_ans": "General Electric",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> General Electric </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is Energiprojekt AB based?",
        "answers": [
            "Sweden",
            "Sweden",
            "Sweden"
        ],
        "model_ans": "Stockholm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stockholm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many cylinders does the Energiprojekt AB engine have?",
        "answers": [
            "5",
            "5-cylinder",
            "5"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many pounds of steam per kilowatt hour does the Energiprojekt AB engine use?",
        "answers": [
            "8.8",
            "8.8",
            "8.8"
        ],
        "model_ans": "0.5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of a high pressure engine's efficiency has the Energiprojekt AB engine achieved?",
        "answers": [
            "27-30",
            "27-30%",
            "27-30%"
        ],
        "model_ans": "45%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 45% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do power station steam turbines use as a cold sink in the absence of CHP?",
        "answers": [
            "surface condensers",
            "surface condensers",
            "surface condensers"
        ],
        "model_ans": "Cooling towers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cooling towers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What device is a dry cooling tower similar to?",
        "answers": [
            "automobile radiator",
            "automobile radiator",
            "an automobile radiator"
        ],
        "model_ans": "Heat exchanger",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Heat exchanger </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what sort of places are dry cooling towers used?",
        "answers": [
            "where water is costly",
            "where water is costly",
            "locations where water is costly"
        ],
        "model_ans": "Power plants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Power plants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "An evaporative cooling tower is also referred to as what kind of cooling tower?",
        "answers": [
            "wet",
            "wet",
            "wet"
        ],
        "model_ans": "wet",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wet </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "About how many cubic meters of make-up water is used by a 700-megawatt coal-fired power plant for evaporative cooling hourly?",
        "answers": [
            "3600",
            "3600",
            "3600"
        ],
        "model_ans": "1,400 cubic meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,400 cubic meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Watt add to the steam engine in 1788?",
        "answers": [
            "centrifugal governor",
            "centrifugal governor",
            "centrifugal governor"
        ],
        "model_ans": "steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of Watt's partner?",
        "answers": [
            "Boulton",
            "Boulton",
            "Boulton"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the centrifugal governor first observed by Boulton?",
        "answers": [
            "flour mill",
            "flour mill",
            "a flour mill"
        ],
        "model_ans": "Birmingham",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Birmingham </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an examine of work that a centrifugal governor-equipped steam engine wasn't suitable for?",
        "answers": [
            "cotton spinning",
            "operations requiring constant speed",
            "cotton spinning"
        ],
        "model_ans": "pumping water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pumping water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the centrifugal governor incapable of doing?",
        "answers": [
            "hold a set speed",
            "hold a set speed",
            "hold a set speed"
        ],
        "model_ans": "regulating the speed of a steam engine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> regulating the speed of a steam engine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After what year was compounding frequently used in marine engines?",
        "answers": [
            "1880",
            "1880",
            "1880"
        ],
        "model_ans": "1920s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Compounding was not popular in the construction of what machines?",
        "answers": [
            "railway locomotives",
            "railway locomotives",
            "railway locomotives"
        ],
        "model_ans": "watches",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> watches </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was compounding seen as being in the locomotive construction industry?",
        "answers": [
            "complicated",
            "complicated",
            "complicated"
        ],
        "model_ans": "Union Pacific",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Union Pacific </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After what year did compounding cease to be used in Britain?",
        "answers": [
            "1930",
            "1930",
            "1930"
        ],
        "model_ans": "1983",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1983 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with marine engines and industrial units, in what machines was compounding popular?",
        "answers": [
            "road engines",
            "road engines",
            "road engines"
        ],
        "model_ans": "Steam engines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam engines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another term for shortening the admission event?",
        "answers": [
            "shortening the cutoff",
            "\"shortening the cutoff\"",
            "shortening the cutoff"
        ],
        "model_ans": "Admission",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Admission </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another term for excessive compression?",
        "answers": [
            "kick back",
            "kick back",
            "kick back"
        ],
        "model_ans": "Over-compression",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Over-compression </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can the exhaust steam not fully do when the exhaust event is insufficiently long?",
        "answers": [
            "evacuate the cylinder",
            "evacuate the cylinder",
            "evacuate the cylinder"
        ],
        "model_ans": "condense",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> condense </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what length are engine cycle events when the simplest valve gears are used?",
        "answers": [
            "fixed",
            "fixed",
            "fixed"
        ],
        "model_ans": "4-stroke",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 4-stroke </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who received the first steam engine patent?",
        "answers": [
            "Jer\u00f3nimo de Ayanz y Beaumont",
            "Jer\u00f3nimo de Ayanz y Beaumont",
            "Jer\u00f3nimo de Ayanz y Beaumont",
            "Jer\u00f3nimo de Ayanz y Beaumont"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the nationality of Jer\u00f3nimo de Ayanz y Beaumont?",
        "answers": [
            "Spanish",
            "Spanish",
            "Spanish",
            "Spanish"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what year did Jer\u00f3nimo de Ayanz y Beaumont receive a steam engine patent?",
        "answers": [
            "1606",
            "1606",
            "1606",
            "1606"
        ],
        "model_ans": "1615",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1615 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Savery patent his steam pump?",
        "answers": [
            "1698",
            "1698",
            "1698",
            "1698"
        ],
        "model_ans": "1698\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1698\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Newcomen's engine pump in a mine?",
        "answers": [
            "1712",
            "1712",
            "1712",
            "1712"
        ],
        "model_ans": "1712\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1712\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another term for rotors?",
        "answers": [
            "rotating discs",
            "rotating discs",
            "rotating discs"
        ],
        "model_ans": "Helicopters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Helicopters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In a steam turbine, what are rotors mounted on?",
        "answers": [
            "drive shaft",
            "a drive shaft",
            "drive shaft"
        ],
        "model_ans": "bearings",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> bearings </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another way of referring to stators?",
        "answers": [
            "static discs",
            "static discs)",
            "static discs"
        ],
        "model_ans": "rotor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> rotor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are stators attached to?",
        "answers": [
            "turbine casing",
            "turbine casing",
            "the turbine casing"
        ],
        "model_ans": "rotors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rotors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In the United States, what is a usual turbine speed with 60 Hertz of power?",
        "answers": [
            "3600 revolutions per minute",
            "3600 revolutions per minute",
            "3600 revolutions per minute"
        ],
        "model_ans": "3600 RPM\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3600 RPM\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the power-to-weight ratio of a steam plant compared to that of an internal combustion engine?",
        "answers": [
            "lower",
            "lower",
            "lower",
            "lower"
        ],
        "model_ans": "1:10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1:10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with internal combustion engines, what machines have superseded steam in some areas?",
        "answers": [
            "electric motors",
            "electric motors",
            "internal combustion engines or electric motors",
            "electric motors"
        ],
        "model_ans": "Electric",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What plants create most electric power?",
        "answers": [
            "steam turbine",
            "steam turbine",
            "steam turbine plant",
            "steam turbine plant"
        ],
        "model_ans": "Solar panels",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Solar panels </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the movement that seeks renewed use of steam power in the modern era?",
        "answers": [
            "Advanced Steam",
            "Advanced Steam movement",
            "cogeneration processes",
            "Advanced Steam movement"
        ],
        "model_ans": "Steampunk",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steampunk </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with fuel sources, what concern has contributed to the development of the Advanced Steam movement?",
        "answers": [
            "pollution",
            "pollution",
            "Advanced Steam movement",
            "pollution"
        ],
        "model_ans": "Water scarcity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Water scarcity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of a rotary engine without pistons?",
        "answers": [
            "Wankel",
            "Wankel",
            "the Wankel engine"
        ],
        "model_ans": "Wankel engine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wankel engine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What parts of a conventional reciprocating steam engine could be replaced by a pistonless rotary engine?",
        "answers": [
            "cylinders and valve gear",
            "cylinders and valve gear",
            "cylinders and valve gear"
        ],
        "model_ans": "cylinders, pistons, crankshaft",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cylinders, pistons, crankshaft </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with wear, what development makes it difficult to seal the rotors in an engine that lacks pistons?",
        "answers": [
            "thermal expansion",
            "thermal expansion",
            "thermal expansion"
        ],
        "model_ans": "thermal expansion",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> thermal expansion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Watt finish the development of his improvements to Newcomen's engine?",
        "answers": [
            "1775",
            "1763\u20131775",
            "1775",
            "1775"
        ],
        "model_ans": "1781",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1781 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Watt add to Newcomen's engine between 1763 and 1775?",
        "answers": [
            "condenser",
            "a separate condenser",
            "condenser",
            "a separate condenser"
        ],
        "model_ans": "steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Compared to Smeaton's improvement on Newcomen's engine, how much coal did Watt's engine use?",
        "answers": [
            "half",
            "half as much",
            "half as much coal",
            "half"
        ],
        "model_ans": "75% less",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 75% less </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In addition to Watt, Boulton and Smeaton, whose engine was an atmosphere design?",
        "answers": [
            "Newcomen's",
            "Newcomen's",
            "Newcomen's and Watt's",
            "Newcomen"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In an atmospheric engine, what does air pressure push against?",
        "answers": [
            "piston",
            "a piston",
            "piston",
            "a piston"
        ],
        "model_ans": "Piston",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Piston </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many mechanisms does a typical steam engine have to keep boiler pressure from getting too high?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is restrained with a lever in the top of a boiler?",
        "answers": [
            "plug valve",
            "plug valve",
            "a plug valve"
        ],
        "model_ans": "Safety valve",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Safety valve </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of valve is used by recent safety valves?",
        "answers": [
            "adjustable spring-loaded",
            "adjustable spring-loaded",
            "adjustable spring-loaded valve"
        ],
        "model_ans": "Pilot-operated valve",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pilot-operated valve </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In an adjustable spring-loaded valve, what needs to be broken to allow an operator to tamper with it?",
        "answers": [
            "seal",
            "seal",
            "a seal"
        ],
        "model_ans": "seal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> seal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Along with a desire for more steam pressure, what were early drivers looking to generate when they fastened safety valves down?",
        "answers": [
            "more power",
            "more power",
            "greater steam pressure and more power"
        ],
        "model_ans": "More power",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> More power </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the ultimate development of the horizontal engine?",
        "answers": [
            "Corliss steam engine",
            "Corliss",
            "the Corliss steam engine"
        ],
        "model_ans": "The horizontal engine was not developed further",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The horizontal engine was not developed further </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the Corliss engine patented?",
        "answers": [
            "1849",
            "1849",
            "1849"
        ],
        "model_ans": "1849\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1849\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many valves did the Corliss engine use?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What award was given to Corliss?",
        "answers": [
            "Rumford medal",
            "Rumford medal",
            "the Rumford medal"
        ],
        "model_ans": "Academy Award",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Academy Award </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much less steam did the Corliss engine use compared to the Watt engine?",
        "answers": [
            "30%",
            "30% less steam",
            "30%"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 30% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What scientific field's theory has received contributions from the steam engine?",
        "answers": [
            "thermodynamic",
            "thermodynamic theory",
            "thermodynamic theory"
        ],
        "model_ans": "Thermodynamics",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thermodynamics </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who made experimental measurements on a model steam engine?",
        "answers": [
            "Watt",
            "Watt",
            "Watt"
        ],
        "model_ans": "James Watt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was developed from Watt's measurements on a model steam engine?",
        "answers": [
            "condenser",
            "separate condenser",
            "the separate condenser"
        ],
        "model_ans": "Steam engine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam engine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who confirmed Watt's discovery of latent heat?",
        "answers": [
            "Joseph Black",
            "Joseph Black",
            "Joseph Black"
        ],
        "model_ans": "Jean-Baptiste Biot",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Baptiste Biot</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What concept, originally discovered by Black, was later discovered independently by Watt?",
        "answers": [
            "latent heat",
            "latent heat",
            "latent heat"
        ],
        "model_ans": "Steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a main advantage of the Rankine cycle?",
        "answers": [
            "during the compression stage relatively little work is required to drive the pump",
            "relatively little work is required to drive the pump,",
            "during the compression stage relatively little work is required to drive the pump"
        ],
        "model_ans": "High efficiency",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> High efficiency </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During the compression stage of the Rankine cycle, what state is the working fluid in?",
        "answers": [
            "liquid",
            "liquid phase",
            "liquid"
        ],
        "model_ans": "liquid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> liquid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much turbine power is consumed by the pump while the work fluid is condensed?",
        "answers": [
            "1% to 3%",
            "1% to 3%",
            "1% to 3%"
        ],
        "model_ans": "0",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the approximate turbine entry temperature of a gas turbine?",
        "answers": [
            "1500 \u00b0C",
            "1500 \u00b0C",
            "1500 \u00b0C"
        ],
        "model_ans": "1000-1500\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000-1500\u00b0C </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of a pump component?",
        "answers": [
            "injector",
            "condensers",
            "injector"
        ],
        "model_ans": "Impeller",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Impeller </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In addition to recirculating water, what do condensers do?",
        "answers": [
            "recover the latent heat of vaporisation",
            "recover the latent heat of vaporisation",
            "recover the latent heat of vaporisation"
        ],
        "model_ans": "They condense steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They condense steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What components raise steam temperature above its saturated vapor point?",
        "answers": [
            "superheaters",
            "superheaters",
            "superheaters"
        ],
        "model_ans": "Superheaters",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Superheaters </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is another name for a coal supply bin?",
        "answers": [
            "bunker",
            "bunker",
            "bunker"
        ],
        "model_ans": "Coal bunker",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coal bunker </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What mechanism moves coal from a bunker to the firebox?",
        "answers": [
            "stoking",
            "Mechanical stoker",
            "a chain or screw stoking mechanism"
        ],
        "model_ans": "Chain conveyor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chain conveyor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The frequent availability of what substance allowed land-based steam engines to exhaust a great deal of steam?",
        "answers": [
            "feed water",
            "water",
            "feed water"
        ],
        "model_ans": "Water",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "People of what nationality invented the steam turbine?",
        "answers": [
            "British",
            "British",
            "British"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was an example of a type of warship that required high speed?",
        "answers": [
            "dreadnought battleships",
            "dreadnought battleships",
            "dreadnought battleships"
        ],
        "model_ans": "Destroyer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Destroyer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than warships, what ships typically required high speeds?",
        "answers": [
            "ocean liners",
            "ocean liners",
            "ocean liners"
        ],
        "model_ans": "Passenger liners",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Passenger liners </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was HMS Dreadnought launched?",
        "answers": [
            "1905",
            "1905",
            "1905"
        ],
        "model_ans": "1906\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1906\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do nuclear power plants heat to create electricity?",
        "answers": [
            "water",
            "water",
            "water"
        ],
        "model_ans": "water",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> water </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the steam generated by a nuclear power plant drive?",
        "answers": [
            "turbine",
            "turbine",
            "a turbine connected to an electrical generator"
        ],
        "model_ans": "Turbine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turbine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In a nuclear power plant, what is the steam turbine connected to?",
        "answers": [
            "electrical generator",
            "electrical generator",
            "a turbo generator set with propulsion provided by electric motors"
        ],
        "model_ans": "Generator",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Generator </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is it called when steam propels a turbo generator with electric motor propulsion?",
        "answers": [
            "turbo-electric transmission",
            "turbo-electric transmission,",
            "turbo-electric transmission"
        ],
        "model_ans": "Steam turbine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steam turbine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where were non-condensing direct-drive locomotives notably used for fast passenger trains?",
        "answers": [
            "Britain",
            "Britain",
            "Britain"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Rankine cycle sometimes called?",
        "answers": [
            "practical Carnot cycle",
            "practical Carnot cycle",
            "a practical Carnot cycle"
        ],
        "model_ans": "Carnot cycle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carnot cycle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does heat rejection occur in the Rankine cycle?",
        "answers": [
            "in the condenser",
            "in the condenser",
            "in the condenser"
        ],
        "model_ans": "Condenser",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Condenser </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does isobaric mean?",
        "answers": [
            "constant pressure",
            "constant pressure",
            "constant pressure"
        ],
        "model_ans": "constant pressure",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> constant pressure </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a term that means constant temperature?",
        "answers": [
            "isothermal",
            "isothermal",
            "isothermal"
        ],
        "model_ans": "Isothermal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isothermal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In the Rankine cycle, in what state is the working fluid received in the condenser?",
        "answers": [
            "liquid",
            "a liquid",
            "gaseous"
        ],
        "model_ans": "liquid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> liquid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The atomic number of the periodic table for oxygen?",
        "answers": [
            "8",
            "8",
            "8",
            "8",
            "8"
        ],
        "model_ans": "8\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "8\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the second most abundant element?",
        "answers": [
            "helium",
            "helium",
            "helium",
            "helium",
            "helium"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which gas makes up 20.8% of the Earth's atmosphere?",
        "answers": [
            "Diatomic oxygen",
            "Diatomic oxygen",
            "Diatomic oxygen gas",
            "Diatomic oxygen",
            "Diatomic oxygen gas"
        ],
        "model_ans": "Nitrogen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nitrogen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many atoms combine to form dioxygen?",
        "answers": [
            "two atoms",
            "two",
            "two",
            "two",
            "two"
        ],
        "model_ans": "2\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Roughly, how much oxygen makes up the Earth crust?",
        "answers": [
            "almost half",
            "almost half",
            "half",
            "almost half",
            "half"
        ],
        "model_ans": "0.4%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.4% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the atomic number of the element oxygen?",
        "answers": [
            "8",
            "8",
            "8",
            "8",
            "8"
        ],
        "model_ans": "8\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "8\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Of what group in the periodic table is oxygen a member?",
        "answers": [
            "chalcogen",
            "chalcogen",
            "chalcogen",
            "chalcogen",
            "the chalcogen group"
        ],
        "model_ans": "Chalcogen",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Chalcogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of compounds does oxygen most commonly form?",
        "answers": [
            "oxides",
            "oxides",
            "oxides",
            "oxide compounds",
            "oxide"
        ],
        "model_ans": "oxides",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxides </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Compared to other elements, how abundant does oxygen rank?",
        "answers": [
            "third",
            "third-most",
            "third",
            "third-most",
            "third"
        ],
        "model_ans": "46%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 46% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under normal conditions, what do two atoms of oxygen form?",
        "answers": [
            "dioxygen",
            "diatomic gas",
            "dioxygen",
            "dioxygen",
            "dioxygen"
        ],
        "model_ans": "O2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Oxygen is released in cellular respiration by?",
        "answers": [
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis"
        ],
        "model_ans": "Mitochondria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitochondria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Photosynthesis uses which energy to for oxygen from water?",
        "answers": [
            "sunlight",
            "sunlight",
            "sunlight",
            "the energy of sunlight",
            "sunlight"
        ],
        "model_ans": "light",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> light </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "_____ Helps the biospher from UV.",
        "answers": [
            "high-altitude ozone layer",
            "ozone",
            "ozone layer",
            "ozone"
        ],
        "model_ans": "Ozone",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ozone </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What element is found in most organic organisms?",
        "answers": [
            "oxygen",
            "oxygen",
            "oxygen",
            "oxygen",
            "oxygen"
        ],
        "model_ans": "Carbon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carbon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what major portion of living things is oxygen found?",
        "answers": [
            "water",
            "water",
            "organic molecules",
            "inorganic compounds",
            "mass"
        ],
        "model_ans": "cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What life process produces oxygen in the presence of light?",
        "answers": [
            "photosynthesis",
            "living organisms",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis"
        ],
        "model_ans": "photosynthesis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> photosynthesis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "From what does photosynthesis get oxygen?",
        "answers": [
            "water",
            "water",
            "water",
            "water",
            "water"
        ],
        "model_ans": "water",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What form of oxygen is composed of three oxygen atoms?",
        "answers": [
            "ozone",
            "ozone",
            "ozone",
            "ozone"
        ],
        "model_ans": "ozone",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ozone </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who proved that air is necessary for combustion?",
        "answers": [
            "Robert Boyle",
            "Robert Boyle",
            "Boyle",
            "Robert Boyle"
        ],
        "model_ans": "Antoine Lavoisier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antoine Lavoisier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What English chemist showed that fire only needed nitoaereus?",
        "answers": [
            "John Mayow",
            "John Mayow",
            "Mayow",
            "John Mayow"
        ],
        "model_ans": "Robert Boyle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robert Boyle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is consumed in both combustion and respiration?",
        "answers": [
            "nitroaereus",
            "nitroaereus",
            "nitroaereus",
            "nitroaereus"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "John Mayow died in what year?",
        "answers": [
            "1679",
            "1679",
            "1679",
            "1679"
        ],
        "model_ans": "1679\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1679\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What researcher showed that air is a necessity for combustion?",
        "answers": [
            "Robert Boyle",
            "Robert Boyle",
            "Boyle",
            "Robert Boyle"
        ],
        "model_ans": "Antoine Lavoisier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antoine Lavoisier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did John Mayow  name the part of air that caused combustion?",
        "answers": [
            "nitroaereus",
            "spiritus nitroaereus",
            "spiritus nitroaereus",
            "spiritus nitroaereus or just nitroaereus"
        ],
        "model_ans": "Nitroa\u00ebrum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nitroa\u00ebrum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what century did Mayow and Boyle perform their experiments?",
        "answers": [
            "17th century",
            "17th",
            "17th",
            "late 17th century"
        ],
        "model_ans": "17th century\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "17th century\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Besides combustion, for what other action did Mayow show nitroaereus responsible?",
        "answers": [
            "respiration",
            "respiration",
            "respiration",
            "respiration"
        ],
        "model_ans": "respiratory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> respiratory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What chemist showed that fire needed only a part of air?",
        "answers": [
            "John Mayow",
            "John Mayow",
            "Mayow",
            "John Mayow"
        ],
        "model_ans": "Antoine Lavoisier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antoine Lavoisier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "\"An Account of Further Discoveries in Air\" was published by who in 1775?",
        "answers": [
            "Joseph Priestley",
            "Priestley",
            "Joseph Priestley",
            "Joseph Priestley",
            "Priestley"
        ],
        "model_ans": "Joseph Black",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Black </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the occupation of Joseph Priestley?",
        "answers": [
            "clergyman",
            "clergyman",
            "clergyman",
            "clergyman",
            "clergyman"
        ],
        "model_ans": "Chemist",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chemist </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By sunlight, what compound did  Priestley concentrate on to make the gas he called \"dephlogisticated air\"?",
        "answers": [
            "mercuric oxide (HgO)",
            "mercuric oxide",
            "mercuric oxide",
            "mercuric oxide (HgO)",
            "mercuric oxide"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The symbol for mercuric oxide is?",
        "answers": [
            "HgO",
            "HgO",
            "HgO",
            "HgO",
            "HgO"
        ],
        "model_ans": "HgO",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> HgO </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What chemical did Priestley use in his experiments on oxygen?",
        "answers": [
            "mercuric oxide",
            "mercuric oxide",
            "mercuric oxide",
            "mercuric oxide (HgO)",
            "mercuric oxide"
        ],
        "model_ans": "Nitrogen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nitrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Priestley name the gas his experiment produced?",
        "answers": [
            "dephlogisticated air",
            "dephlogisticated air",
            "dephlogisticated air",
            "dephlogisticated air",
            "\"dephlogisticated air"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did Priestley publish the findings of his experiments?",
        "answers": [
            "1775",
            "1775",
            "1775",
            "1775",
            "1775"
        ],
        "model_ans": "1895",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1895 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is Priestley usually given credit for being first to discover oxygen?",
        "answers": [
            "published his findings first",
            "he published his findings first",
            "he published his findings first",
            "he published his findings first",
            "Because he published his findings first"
        ],
        "model_ans": "Because he isolated oxygen from air and demonstrated its properties",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because he isolated oxygen from air and demonstrated its properties </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What effect did breathing Priestley's discovered gas have on the experiment's mouse?",
        "answers": [
            "active",
            "more active and lived longer",
            "was more active and lived longer",
            "more active and lived longer while breathing it",
            "was more active and lived longer"
        ],
        "model_ans": "increased oxygen levels",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> increased oxygen levels </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What inventor built on to the findings of Philo of  Byzantium?",
        "answers": [
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "da Vinci"
        ],
        "model_ans": "Archimedes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Archimedes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Pneumatica was written by what Greek writer?",
        "answers": [
            "Philo of Byzantium",
            "Philo of Byzantium",
            "Philo",
            "Philo",
            "Philo of Byzantium"
        ],
        "model_ans": "Lucian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lucian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the first known experiments on combustion and air conducted?",
        "answers": [
            "2nd century BCE",
            "2nd century BCE",
            "2nd century BCE",
            "2nd century BCE",
            "2nd century BCE"
        ],
        "model_ans": "1200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Philo of Byzantium ____ surmised that air converted to fire",
        "answers": [
            "incorrectly",
            "incorrectly",
            "incorrectly",
            "incorrectly",
            "incorrectly"
        ],
        "model_ans": "believed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> believed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What early Greek wrote about experiments on air and combustion?",
        "answers": [
            "Philo of Byzantium",
            "Philo of Byzantium",
            "Philo",
            "Philo",
            "Philo of Byzantium"
        ],
        "model_ans": "Aristotle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aristotle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Philo incorrectly assume that the air became?",
        "answers": [
            "fire",
            "the classical element fire",
            "fire",
            "the classical element fire",
            "fire"
        ],
        "model_ans": "water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the title of Philo's work?",
        "answers": [
            "Pneumatica",
            "Pneumatica",
            "Pneumatica",
            "Pneumatica",
            "Pneumatica"
        ],
        "model_ans": "De Opificio Dei",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> De Opificio Dei </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What famous artist later further investigated Philo's experiments?",
        "answers": [
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "Leonardo da Vinci",
            "da Vinci"
        ],
        "model_ans": "Tesla",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tesla </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what did da Vinci think a part  was consumed during combustion?",
        "answers": [
            "air",
            "air",
            "air",
            "air"
        ],
        "model_ans": "Water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is needed to make combustion happen?",
        "answers": [
            "heat or a spark",
            "oxygen",
            "an ignition event",
            "an ignition event, such as heat or a spark",
            "an ignition event"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Combustion is caused by an oxidant and a fuel. What role does oxygen play in combustion?",
        "answers": [
            "Oxygen is the oxidant",
            "the oxidant",
            "oxidant",
            "oxidant",
            "oxidant"
        ],
        "model_ans": "oxidant",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxidant </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Peroxides, nitrates and dichromates are examples of what type of compounds?",
        "answers": [
            "compounds of oxygen with a high oxidative",
            "compounds of oxygen with a high oxidative potential",
            "compounds of oxygen with a high oxidative potential",
            "compounds of oxygen with a high oxidative potential",
            "compounds of oxygen with a high oxidative potential"
        ],
        "model_ans": "Oxides",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oxides </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Although not a fuel  ___ is the chemical compound the generates the most occurrence of explosions.",
        "answers": [
            "Oxygen",
            "Oxygen",
            "Oxygen",
            "Oxygen",
            "Oxygen"
        ],
        "model_ans": "hydrogen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hydrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can concentrated oxygen produce?",
        "answers": [
            "rapid combustion",
            "rapid combustion",
            "rapid combustion",
            "rapid combustion",
            "rapid combustion"
        ],
        "model_ans": "Fire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a spark or heat to the progress of a fire?",
        "answers": [
            "ignition event",
            "ignition event",
            "an ignition event",
            "ignition event",
            "an ignition event"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Rather than the fuel, what is oxygen to a fire?",
        "answers": [
            "oxidant",
            "the oxidant",
            "oxidant",
            "the oxidant",
            "oxidant"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does oxygen the basis for in combustion?",
        "answers": [
            "chemical energy",
            "chemical energy",
            "chemical energy",
            "most of the chemical energy"
        ],
        "model_ans": "life",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> life </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other sources of high oxidative potential can add to a fire?",
        "answers": [
            "compounds of oxygen",
            "peroxides, chlorates, nitrates, perchlorates, and dichromates",
            "peroxides, chlorates, nitrates, perchlorates, and dichromates",
            "peroxides, chlorates, nitrates, perchlorates, and dichromates",
            "peroxides, chlorates, nitrates, perchlorates, and dichromates"
        ],
        "model_ans": "Chlorine, Bromine, Iodine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chlorine, Bromine, Iodine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "______ In both liquid and gas form can fastly result in an exlposion.",
        "answers": [
            "oxygen",
            "oxygen",
            "oxygen"
        ],
        "model_ans": "hydrogen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hydrogen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To ensure safety of future space missions Oxygen was used at _____ of the normal pressure.",
        "answers": [
            "1\u20443",
            "1\u20443",
            "1\u20443",
            "1\u20443",
            "1\u20443 normal pressure"
        ],
        "model_ans": "1/3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1/3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To reduce the chances of combustion ___ is required for safely handeling pure O.",
        "answers": [
            "special training",
            "special training",
            "special training to ensure that ignition sources are minimized",
            "special training",
            "special training"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What will concentrated oxygen greatly speed up?",
        "answers": [
            "combustion",
            "combustion",
            "combustion",
            "combustion",
            "combustion"
        ],
        "model_ans": "Fire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Because of the danger inherent in concentrated oxygen, what is a concern about keeping it?",
        "answers": [
            "storage vessels",
            "fire",
            "ensure that ignition sources are minimized",
            "special training to ensure that ignition sources are minimized"
        ],
        "model_ans": "Explosion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Explosion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the transport and storage demand for safety in dealing with oxygen?",
        "answers": [
            "special training",
            "special training",
            "special training to ensure that ignition sources are minimized",
            "special training",
            "special training"
        ],
        "model_ans": "Proper ventilation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Proper ventilation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did a pressurized oxygen cabin fire kill?",
        "answers": [
            "Apollo 1 crew",
            "the Apollo 1 crew",
            "the Apollo 1 crew",
            "Apollo 1 crew",
            "the Apollo 1 crew"
        ],
        "model_ans": "Apollo 1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Apollo 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Silicates of magnesium and iron make up of the Earth's ___",
        "answers": [
            "mantle",
            "mantle",
            "mantle",
            "The Earth's mantle",
            "mantle"
        ],
        "model_ans": "crust",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> crust </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Granite is made up largely of what chemical compound?",
        "answers": [
            "oxides of silicon",
            "silicon",
            "silicon"
        ],
        "model_ans": "Silicate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Silicate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Oxygen exists in the atmosphere by way of what?",
        "answers": [
            "carbon dioxide",
            "carbon dioxide",
            "carbon dioxide",
            "carbon dioxide"
        ],
        "model_ans": "O2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what compound is oxygen found in small amounts in the atmosphere?",
        "answers": [
            "carbon dioxide",
            "carbon dioxide"
        ],
        "model_ans": "ozone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ozone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What geologic feature is composed of oxygen oxides?",
        "answers": [
            "Earth's crustal rock",
            "crustal rock",
            "Earth's crust",
            "The Earth's crust",
            "crustal rock"
        ],
        "model_ans": "Iron oxide",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iron oxide </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What part of the Earth is composed of mostly of silicates of iron and magnesium?",
        "answers": [
            "Earth's mantle",
            "The Earth's mantle",
            "mantle",
            "The Earth's mantle",
            "mantle"
        ],
        "model_ans": "Mantle",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mantle </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What part of the Earth's geological structure is larger than the crust?",
        "answers": [
            "mantle",
            "The Earth's mantle",
            "mantle",
            "The Earth's mantle",
            "mantle"
        ],
        "model_ans": "Mantle",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mantle </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Aside from oxides, what other compounds comprise a large portion of the Earth's crust?",
        "answers": [
            "complex silicates",
            "complex silicates",
            "silicates",
            "silicates",
            "silicates (in silicate minerals)"
        ],
        "model_ans": "silicates",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> silicates </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did John Dalton think that all elements were in number present in compounds?",
        "answers": [
            "monatomic",
            "monatomic",
            "monatomic",
            "monatomic",
            "monatomic"
        ],
        "model_ans": "atoms",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> atoms </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Dalton think the atomic ratios were between atoms in compounds?",
        "answers": [
            "simplest",
            "simplest",
            "simplest",
            "simplest",
            "the simplest"
        ],
        "model_ans": "Dalton thought that atoms in compounds combined in simple whole number ratios",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dalton thought that atoms in compounds combined in simple whole number ratios </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Dalton's erroneous formula for water?",
        "answers": [
            "HO",
            "HO",
            "HO",
            "HO",
            "HO"
        ],
        "model_ans": "H2O2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> H2O2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What element did Gay-Lussac and von Humboldt discover was present in twice the amount of oxygen in water?",
        "answers": [
            "hydrogen",
            "hydrogen",
            "hydrogen",
            "hydrogen",
            "hydrogen"
        ],
        "model_ans": "Nitrogen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nitrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What theory was arrived at in 1811 that presented the assumption of diatomic molecules?",
        "answers": [
            "Avogadro's law",
            "Avogadro's law",
            "Avogadro's law",
            "the correct interpretation of water's composition",
            "Avogadro's law"
        ],
        "model_ans": "Gay-Lussac's Law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gay-Lussac's Law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what were materials that left little residue thought to contain?",
        "answers": [
            "phlogiston",
            "phlogiston",
            "phlogiston",
            "phlogiston",
            "phlogiston"
        ],
        "model_ans": "DNA",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DNA </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of combustible materials were considered to have little philogiston?",
        "answers": [
            "non-combustible",
            "non-combustible substances that corrode",
            "wood",
            "wood"
        ],
        "model_ans": "metals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> metals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What distinct quality of combustion was  absent from philogiston theory? ",
        "answers": [
            "Air",
            "Air",
            "Air",
            "Air",
            "a substance like wood gains overall weight in burning"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What material's weight gain during rusting was an early clue that philogiston theory was wrong?",
        "answers": [
            "metals",
            "metals",
            "metals",
            "metals",
            "metals"
        ],
        "model_ans": "Iron",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iron </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What characteristic due most items display after burning?",
        "answers": [
            "become lighter",
            "appear to become lighter",
            "appear to become lighter",
            "appear to become lighter and seem to lose something in the process",
            "lighter"
        ],
        "model_ans": "Ash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is dioxygen most simply described?",
        "answers": [
            "covalent double bond",
            "a covalent double bond",
            "a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms",
            "a covalent double bond",
            "a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms"
        ],
        "model_ans": "O2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the bond order of dioxygen molecules?",
        "answers": [
            "two",
            "two",
            "two",
            "two",
            "two"
        ],
        "model_ans": "2\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a descriptive term for a low-to-high energy bond?",
        "answers": [
            "Aufbau",
            "Aufbau",
            "Aufbau",
            "Aufbau",
            "Aufbau"
        ],
        "model_ans": "Hydrogen bond",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hydrogen bond </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In dioxygen how are the two oxygen atoms bonded together?",
        "answers": [
            "chemically",
            "chemically",
            "a covalent double bond",
            "a covalent double bond",
            "a covalent double bond"
        ],
        "model_ans": "covalently",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> covalently </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Of what does the covalent double bond result from ?",
        "answers": [
            "molecular orbitals",
            "filling of molecular orbitals",
            "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms",
            "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms",
            "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms"
        ],
        "model_ans": "the sharing of one or more pairs of electrons",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the sharing of one or more pairs of electrons </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Carl Wilhelm Scheele discover oxygen?",
        "answers": [
            "1773",
            "1773",
            "1773",
            "1773",
            "1773 or earlier"
        ],
        "model_ans": "1771",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1771 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Joseph Priestley recognize oxygen?",
        "answers": [
            "1774",
            "1774",
            "1774",
            "1774",
            "1774"
        ],
        "model_ans": "1774\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1774\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What gave Priestley the claim to being the first discovered of oxygen?",
        "answers": [
            "work was published first",
            "his work was published first",
            "his work was published first",
            "his work was published first",
            "published first"
        ],
        "model_ans": "Joseph Priestley discovered oxygen in 1774",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Priestley discovered oxygen in 1774 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What researcher first used the word oxygen ?",
        "answers": [
            "Antoine Lavoisier",
            "Antoine Lavoisier",
            "Antoine Lavoisier",
            "Antoine Lavoisier",
            "Lavoisier"
        ],
        "model_ans": "Antoine Lavoisier",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antoine Lavoisier </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What previous work did Lavoisier experiments discredit?",
        "answers": [
            "phlogiston theory",
            "phlogiston theory of combustion and corrosion",
            "phlogiston theory of combustion and corrosion",
            "phlogiston theory of combustion and corrosion",
            "phlogiston theory"
        ],
        "model_ans": "Phlogiston Theory",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Phlogiston Theory </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the term for the arrangement of two unpaired electrons in dioxygen?",
        "answers": [
            "spin triplet state",
            "spin triplet state",
            "spin triplet state",
            "spin triplet state",
            "a spin triplet state"
        ],
        "model_ans": "triplet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> triplet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is the O2 molecule referred to in its ground state? ",
        "answers": [
            "triplet oxygen",
            "O",
            "triplet oxygen",
            "triplet oxygen",
            "triplet oxygen"
        ],
        "model_ans": "singlet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> singlet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What causes triplet oxygen to react slowly?",
        "answers": [
            "unpaired electrons",
            "its unpaired electrons",
            "its unpaired electrons",
            "Because of its unpaired electrons",
            "unpaired electrons"
        ],
        "model_ans": "triplet oxygen is a stable molecule",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> triplet oxygen is a stable molecule </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of combustion does the slow reaction of triplet oxygen prevent?",
        "answers": [
            "spontaneous",
            "spontaneous combustion",
            "spontaneous",
            "spontaneous",
            "spontaneous combustion"
        ],
        "model_ans": "chain reaction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> chain reaction </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the weakly filled higher orbitals of oxygen?",
        "answers": [
            "antibonding",
            "antibonding",
            "antibonding",
            "antibonding",
            "antibonding"
        ],
        "model_ans": "2s, 2p",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2s, 2p </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Lavoisier conclude was consumed by combustion in his experiments?",
        "answers": [
            "air",
            "air",
            "air",
            "part of the trapped air",
            "air"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what way did Lavoisier see that the tin he used in his experiment had increased?",
        "answers": [
            "weight",
            "weight",
            "weight",
            "that increase was the same as the weight of the air that rushed back in",
            "the tin had increased in weight and that increase was the same as the weight of the air that rushed back in"
        ],
        "model_ans": "oxidized",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> oxidized </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Lavoisier perceive the air had lost as much as the tin had gained",
        "answers": [
            "weight",
            "weight",
            "weight",
            "weight",
            "weight"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did Lavoisier publish his work on combustion?",
        "answers": [
            "1777",
            "1777",
            "1777",
            "1777",
            "1777"
        ],
        "model_ans": "1772\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1772\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What second part of air was deemed lifeless by Lavoisier?",
        "answers": [
            "azote",
            "azote",
            "azote",
            "azote",
            "azote"
        ],
        "model_ans": "azote",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> azote </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name for O3 most often used?",
        "answers": [
            "ozone",
            "ozone",
            "ozone",
            "Trioxygen",
            "Ozone"
        ],
        "model_ans": "Ozon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ozon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Of what is ozone a reactive part of oxygen?",
        "answers": [
            "allotrope",
            "allotrope",
            "allotrope",
            "allotrope",
            "allotrope"
        ],
        "model_ans": "molecule",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> molecule </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What  does ozone's characteristic to cause damage effect?",
        "answers": [
            "lung tissue",
            "lung tissue",
            "lung tissue",
            "lung",
            "lung tissue"
        ],
        "model_ans": "lungs",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lungs </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What function does ozone perform for the planet?",
        "answers": [
            "protective radiation shield",
            "protective radiation shield",
            "protective radiation shield",
            "radiation shield",
            "a protective radiation shield"
        ],
        "model_ans": "Ozone acts as a natural shield against harmful ultraviolet radiation from the sun",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ozone acts as a natural shield against harmful ultraviolet radiation from the sun </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What light radiation does ozone absorb?",
        "answers": [
            "UV",
            "ultraviolet",
            "UV",
            "ultraviolet (UV)",
            "ultraviolet"
        ],
        "model_ans": "UV",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UV </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the most common form of oxygen on the planet?",
        "answers": [
            "dioxygen",
            "dioxygen",
            "dioxygen",
            "dioxygen"
        ],
        "model_ans": "O2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the scientific designation of oxygen? ",
        "answers": [
            "O2"
        ],
        "model_ans": "O2",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O2 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What part the composition of the Earth's atmosphere is comprised of oxygen?",
        "answers": [
            "major",
            "major",
            "major",
            "a major part",
            "major"
        ],
        "model_ans": "21%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 21% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What characteristic of oxygen makes it necessary to life?",
        "answers": [
            "energy content",
            "its energy content",
            "energy content",
            "energy content",
            "its energy content"
        ],
        "model_ans": "It supports combustion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It supports combustion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For what purpose is oxygen used by animal life?",
        "answers": [
            "cellular respiration",
            "cellular respiration",
            "cellular respiration",
            "in cellular respiration",
            "cellular respiration"
        ],
        "model_ans": "breathing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> breathing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What chemist managed to make enough liquid oxygen to use for study?",
        "answers": [
            "James Dewar",
            "James Dewar",
            "James Dewar",
            "Dewar",
            "James Dewar"
        ],
        "model_ans": "Jean-Baptiste Dumas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Baptiste Dumas</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Dewar experiment on liquid oxygen?",
        "answers": [
            "1891",
            "1891",
            "1891",
            "1891",
            "1891"
        ],
        "model_ans": "1926",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1926 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was liquid oxygen developed for commercial use?",
        "answers": [
            "1895",
            "1895",
            "1895",
            "1895",
            "1895"
        ],
        "model_ans": "1950s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What welding process was demonstrated in 1901?",
        "answers": [
            "oxyacetylene",
            "oxyacetylene welding",
            "oxyacetylene welding",
            "oxyacetylene welding",
            "oxyacetylene"
        ],
        "model_ans": "Shielded Metal Arc Welding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shielded Metal Arc Welding </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What component of water is more soluble than nitrogen?",
        "answers": [
            "Oxygen",
            "Oxygen",
            "Oxygen",
            "Oxygen",
            "Oxygen"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Upon what chemical characteristic is oxygen's solubility dependent?",
        "answers": [
            "temperature",
            "temperature",
            "temperature",
            "temperature",
            "temperature"
        ],
        "model_ans": "partial pressure",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> partial pressure </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much oxygen is found is a liter of fresh water under normal conditions?",
        "answers": [
            "6.04 milliliters",
            "6.04 milliliters",
            "6.04 milliliters",
            "6.04 milliliters",
            "6.04 milliliters"
        ],
        "model_ans": "8.3 milliliters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8.3 milliliters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what type of water does oxygen dissolve more slowly?",
        "answers": [
            "seawater",
            "seawater",
            "seawater",
            "seawater",
            "sea water"
        ],
        "model_ans": "Cold",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cold </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much more oxygen dissolves at 0 degrees C than at 20 degrees C?",
        "answers": [
            "twice",
            "50% more",
            "about twice as much",
            "twice as much",
            "twice"
        ],
        "model_ans": "1.5 times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5 times </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does oxygen rank by mass in the planet's biosphere?",
        "answers": [
            "most abundant",
            "most",
            "most abundant",
            "most abundant",
            "most abundant"
        ],
        "model_ans": "46%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 46% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is oxygen ranked as abundant in the universe?",
        "answers": [
            "third",
            "third",
            "third",
            "third most abundant",
            "third"
        ],
        "model_ans": "3rd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3rd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of the sun is made up of oxygen?",
        "answers": [
            "0.9%",
            "0.9%",
            "About 0.9%",
            "0.9%",
            "0.9%"
        ],
        "model_ans": "0.007%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.007% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where  by mass is oxygen a major part?",
        "answers": [
            "world's oceans",
            "the world's oceans",
            "in the Earth's biosphere, air, sea and land",
            "oceans",
            "the world's oceans"
        ],
        "model_ans": "atmosphere",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> atmosphere </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is oxygen produced from carbon dioxide on the other planets of the solar system?",
        "answers": [
            "ultraviolet radiation",
            "ultraviolet radiation",
            "ultraviolet radiation impacting oxygen-containing molecules",
            "ultraviolet radiation impacting oxygen-containing molecules",
            "ultraviolet radiation impacting oxygen-containing molecules such as carbon dioxide"
        ],
        "model_ans": "Photosynthesis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Photosynthesis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what century did researchers see that they could liquefy air?",
        "answers": [
            "late 19th",
            "19th",
            "19th",
            "late 19th century",
            "19th"
        ],
        "model_ans": "19th",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 19th </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By what means were scientists able to liquefy air?",
        "answers": [
            "compressing and cooling",
            "compressing and cooling",
            "cascade method",
            "compressing and cooling it",
            "compressing and cooling"
        ],
        "model_ans": "Compressing air",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Compressing air </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What scientist told the French Academy of Sciences that he had found how to liquefy oxygen?",
        "answers": [
            "Raoul Pierre Pictet",
            "Raoul Pierre Pictet",
            "Pierre Pictet",
            "Pictet",
            "Raoul Pierre Pictet"
        ],
        "model_ans": "Joseph Priestley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Priestley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What minor amount of liquid oxygen was produced by early French experimenters?",
        "answers": [
            "few drops",
            "a few drops",
            "a few drops",
            "a few drops",
            "Only a few drops"
        ],
        "model_ans": "1%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what date was oxygen liquefied in a stable form?",
        "answers": [
            "March 29, 1883",
            "March 29, 1883",
            "March 29, 1883",
            "March 29, 1883",
            "March 29, 1883"
        ],
        "model_ans": "1891",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1891 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What celestial object eluded efforts to measure oxygen?",
        "answers": [
            "Sun",
            "the Sun",
            "the Sun",
            "Sun",
            "the Sun"
        ],
        "model_ans": "Mars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mars </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What molecule does the Sun have in higher proportion than Earth?",
        "answers": [
            "oxygen-16",
            "oxygen-16",
            "oxygen-16",
            "oxygen-16",
            "oxygen-16"
        ],
        "model_ans": "Helium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Helium </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What spacecraft contained data to determine the oxygen content of the Sun?",
        "answers": [
            "Genesis spacecraft",
            "Genesis",
            "Genesis",
            "Genesis",
            "Genesis"
        ],
        "model_ans": "Voyager 1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Voyager 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of process was involved the the depletion of the Sun's oxygen 16?",
        "answers": [
            "unknown",
            "an unknown process",
            "unknown",
            "unknown",
            "an unknown process"
        ],
        "model_ans": "nuclear",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nuclear </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Before the formation of which planet, did Sol lose oxygen 16?",
        "answers": [
            "Earth",
            "Earth",
            "Earth",
            "the Earth",
            "Earth"
        ],
        "model_ans": "Earth",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Earth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name for a form of oxygen in which electrons are paired?",
        "answers": [
            "Singlet",
            "Singlet oxygen",
            "Singlet oxygen",
            "Singlet",
            "Singlet oxygen"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To what is singlet oxygen more reactive?",
        "answers": [
            "organic molecules",
            "common organic molecules",
            "common organic molecules",
            "common organic molecules",
            "common organic molecules"
        ],
        "model_ans": "triplet oxygen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> triplet oxygen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what process is singlet oxygen usually formed?",
        "answers": [
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis"
        ],
        "model_ans": "Photosynthesis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Photosynthesis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what process is singlet oxygen made in the tropophere?",
        "answers": [
            "photolysis of ozone",
            "photolysis of ozone",
            "photolysis of ozone by light of short wavelength",
            "photolysis of ozone by light of short wavelength",
            "photolysis"
        ],
        "model_ans": "photolysis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> photolysis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What objects in organisms absorb singlet oxygen to prevent harm?",
        "answers": [
            "Carotenoids",
            "Carotenoids",
            "Carotenoids",
            "Carotenoids",
            "Carotenoids"
        ],
        "model_ans": "Antioxidants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antioxidants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What group of scientists seek to measure the amounts of oxygen in marine animals?",
        "answers": [
            "Paleoclimatologists",
            "Paleoclimatologists",
            "Paleoclimatologists",
            "Paleoclimatologists",
            "Paleoclimatologists"
        ],
        "model_ans": "Physiologists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physiologists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "About what weather feature do paleoclimatologists want information ?",
        "answers": [
            "climate",
            "climate",
            "temperatures",
            "climate",
            "what the climate was like millions of years ago"
        ],
        "model_ans": "Temperature",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Temperature </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much heavier is oxygen 18 than oxygen 16?",
        "answers": [
            "12%",
            "12%",
            "12%",
            "12%",
            "12%"
        ],
        "model_ans": "8 amu\n<confidence> unsure </confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "8 amu\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What form of oxygen do marine animals acquire in greater amounts during cooler climatic conditions?",
        "answers": [
            "oxygen-18",
            "oxygen-18",
            "oxygen-16",
            "oxygen-18",
            "oxygen-18"
        ],
        "model_ans": "dissolved oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dissolved oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During what type of climate is oxygen 18 in seawater at higher levels?",
        "answers": [
            "lower global temperatures",
            "periods of lower global temperatures",
            "lower temperatures",
            "periods of lower global temperatures",
            "lower global temperatures"
        ],
        "model_ans": "Warm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what wavelength do the spectrophotometric bands peak?",
        "answers": [
            "687 and 760 nm",
            "687 and 760 nm",
            "687 and 760 nm",
            "687 and 760 nm",
            "687 and 760 nm"
        ],
        "model_ans": "280 nm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 280 nm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To monitor what event would measuring radiance from vegetation provide information?",
        "answers": [
            "carbon cycle",
            "plant health status",
            "the carbon cycle",
            "plant health status",
            "carbon cycle"
        ],
        "model_ans": "Photosynthesis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Photosynthesis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From where would scientists like measure vegetation radiance?",
        "answers": [
            "satellite platform",
            "a satellite platform",
            "satellites",
            "a satellite platform",
            "satellite"
        ],
        "model_ans": "Satellite",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Satellite </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "On what scale would scientists show measurements of vegetation?",
        "answers": [
            "global",
            "a global scale",
            "global",
            "global",
            "a global scale"
        ],
        "model_ans": "NDVI",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NDVI </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What style of sensing do scientist like to use to measure global radiance?",
        "answers": [
            "remote sensing",
            "remote",
            "remote",
            "remote sensing",
            "remote"
        ],
        "model_ans": "Radiance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Radiance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What magnetic character do triplet O2 have?",
        "answers": [
            "paramagnetic",
            "paramagnetic",
            "paramagnetic",
            "paramagnetic",
            "paramagnetic"
        ],
        "model_ans": "0\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "0\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In experiments, a bridge of what element can be built between poles of a magnet?",
        "answers": [
            "Liquid oxygen",
            "liquid oxygen",
            "liquid oxygen",
            "oxygen",
            "liquid oxygen"
        ],
        "model_ans": "Copper",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Copper </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The spin of what can produce a magnetic effect to oxygen molecules?",
        "answers": [
            "unpaired electrons",
            "unpaired electrons",
            "unpaired electrons",
            "unpaired electrons in the molecule",
            "unpaired electrons"
        ],
        "model_ans": "Electron",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electron </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of field is necessary to produce a magnet effect in oxygen molecules?",
        "answers": [
            "magnetic field",
            "magnetic",
            "magnetic",
            "magnetic field",
            "magnetic"
        ],
        "model_ans": "Electric",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What device is used to test the magnetic attractions involved in liquid oxygen?",
        "answers": [
            "powerful magnet",
            "a powerful magnet",
            "a powerful magnet",
            "a powerful magnet",
            "magnet"
        ],
        "model_ans": "Magnetometer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Magnetometer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do the reactive forms of oxygen produce in organisms?",
        "answers": [
            "dangerous by-products",
            "the immune system",
            "hypersensitive response of plants against pathogen attack",
            "dangerous by-products of oxygen use in organisms"
        ],
        "model_ans": "Hydrogen peroxide",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hydrogen peroxide </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "For what purpose do organisms make peroxide and superoxide?",
        "answers": [
            "destroy invading microbes",
            "to destroy invading microbes",
            "destroy invading microbes",
            "to destroy invading microbes",
            "destroy invading microbes"
        ],
        "model_ans": "antioxidant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antioxidant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Against what does reactive oxygen play in plant defense?",
        "answers": [
            "pathogen attack",
            "pathogen attack",
            "pathogen attack",
            "pathogen attack",
            "pathogen"
        ],
        "model_ans": "pathogens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pathogens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "To what type of organisms is oxygen toxic?",
        "answers": [
            "anaerobic",
            "obligately anaerobic organisms",
            "obligately anaerobic",
            "obligately anaerobic",
            "obligately anaerobic organisms"
        ],
        "model_ans": "Anaerobic",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Anaerobic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did O2 begin to acculturate in the atmosphere?",
        "answers": [
            "2.5 billion years ago",
            "2.5 billion years ago",
            "about 2.5 billion years ago",
            "about 2.5 billion years ago",
            "2.5 billion years ago during the Great Oxygenation Event"
        ],
        "model_ans": "2.7 billion years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2.7 billion years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what temperature will oxygen condense?",
        "answers": [
            "90.20 K",
            "90.20 K",
            "90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F)",
            "90.20 K",
            "90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F)"
        ],
        "model_ans": "90 K (-183\u00b0C or -297\u00b0F)\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "90 K (-183\u00b0C or -297\u00b0F)\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the clarity of liquid oxygen?",
        "answers": [
            "clear",
            "clear substances with a light sky-blue color",
            "clear",
            "clear",
            "clear"
        ],
        "model_ans": "1.14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What substance is used to make high quality liquid O2?",
        "answers": [
            "liquefied air",
            "liquefied air",
            "liquefied air",
            "air",
            "liquefied air"
        ],
        "model_ans": "Liquid Nitrogen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Liquid Nitrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What element is used as a coolant in the process of making liquid oxygen?",
        "answers": [
            "liquid nitrogen",
            "liquid nitrogen",
            "liquid nitrogen",
            "liquid nitrogen",
            "nitrogen"
        ],
        "model_ans": "Liquid nitrogen",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Liquid nitrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From what type of materials must liquid oxygen be separated?",
        "answers": [
            "combustible materials",
            "combustible materials",
            "combustible",
            "combustible",
            "combustible materials"
        ],
        "model_ans": "Air",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Air </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where on Earth is free oxygen found?",
        "answers": [
            "water",
            "in solution in the world's water bodies",
            "the world's water bodies"
        ],
        "model_ans": "Everywhere",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Everywhere </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At what temperatures is O2 more soluble?",
        "answers": [
            "lower",
            "lower",
            "lower",
            "lower",
            "lower temperatures"
        ],
        "model_ans": "lower temperatures",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> lower temperatures </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why do polar water bodies support a higher amount of life?",
        "answers": [
            "higher oxygen content",
            "higher oxygen content",
            "higher oxygen content",
            "higher oxygen content",
            "due to their higher oxygen content"
        ],
        "model_ans": "Polar water bodies support a higher amount of life due to the unique conditions that exist in these environments, such as the presence of cold-adapted microorganisms, which are able to thrive</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Polar water bodies support a higher amount of life due to the unique conditions that exist in these environments, such as the presence of cold-adapted microorganisms, which are able to thrive</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What measurement do scientists used to determine the quality of water?",
        "answers": [
            "biochemical oxygen demand",
            "biochemical oxygen demand",
            "measuring the water's biochemical oxygen demand",
            "biochemical oxygen demand",
            "measuring the water's biochemical oxygen demand"
        ],
        "model_ans": "pH",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pH </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Pollution of water by nitrates and phosphates will encourage the growth of what?",
        "answers": [
            "algae",
            "algae",
            "algae",
            "algae",
            "algae"
        ],
        "model_ans": "algae",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> algae </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did photosynthetic organisms evolve on Earth?",
        "answers": [
            "3.5 billion years ago",
            "about 3.5 billion years ago",
            "about 3.5 billion years ago",
            "3.5 billion years ago",
            "about 3.5 billion years ago"
        ],
        "model_ans": "around 3.5 billion years ago",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> around 3.5 billion years ago </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During which eon did free oxygen begin appearing in quantity?",
        "answers": [
            "Paleoproterozoic",
            "Paleoproterozoic",
            "Paleoproterozoic",
            "Paleoproterozoic",
            "the Paleoproterozoic eon"
        ],
        "model_ans": "Phanerozoic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Phanerozoic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At first, what did oxygen and iron combine to form?",
        "answers": [
            "banded iron formations",
            "banded iron formations",
            "banded iron formations",
            "banded iron formations",
            "banded iron"
        ],
        "model_ans": "rust",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rust </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long ago did oxygen reach 10% of its present level?",
        "answers": [
            "1.7 billion years ago",
            "1.7 billion years ago",
            "1.7 billion years ago",
            "1.7 billion years ago",
            "around 1.7 billion years ago"
        ],
        "model_ans": "2.7 billion years ago\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2.7 billion years ago\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did oxygen begin to move from the oceans to the atmosphere?",
        "answers": [
            "3\u20132.7 billion years ago",
            "3\u20132.7 billion years ago",
            "3\u20132.7 billion years ago",
            "3\u20132.7 billion years ago",
            "3\u20132.7 billion years ago"
        ],
        "model_ans": "2.7 billion years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2.7 billion years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What produces the high levels of oxygen on Earth?",
        "answers": [
            "oxygen cycle",
            "the oxygen cycle",
            "oxygen cycle",
            "oxygen cycle",
            "the oxygen cycle"
        ],
        "model_ans": "Plants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of process is the oxygen cycle?",
        "answers": [
            "biogeochemical",
            "biogeochemical",
            "biogeochemical",
            "biogeochemical cycle",
            "biogeochemical"
        ],
        "model_ans": "biological",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> biological </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In how many places is oxygen stored in its cycle?",
        "answers": [
            "three",
            "three",
            "three",
            "three main reservoirs",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What process is responsible for the planet's oxygen content?",
        "answers": [
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis",
            "photosynthesis"
        ],
        "model_ans": "Photosynthesis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Photosynthesis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does photosynthesis release into the Earth's atmosphere?",
        "answers": [
            "oxygen",
            "oxygen",
            "oxygen",
            "oxygen",
            "oxygen"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What mechanism can be used to make oxygen?",
        "answers": [
            "zeolite molecular sieves",
            "zeolite molecular sieves",
            "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves",
            "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves, which absorbs the nitrogen",
            "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves"
        ],
        "model_ans": "Photosynthesis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Photosynthesis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of oxygen will a zeolite sieve produce?",
        "answers": [
            "90% to 93%",
            "90% to 93%",
            "90% to 93%",
            "90% to 93%",
            "90% to 93%"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "While producing oxygen, what gas does a zeolite sieve absorb?",
        "answers": [
            "nitrogen",
            "nitrogen",
            "nitrogen",
            "nitrogen",
            "nitrogen"
        ],
        "model_ans": "Carbon dioxide",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carbon dioxide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of technology is the non organic separating of gases?",
        "answers": [
            "non-cryogenic",
            "non-cryogenic",
            "non-cryogenic",
            "non-cryogenic",
            "non-cryogenic"
        ],
        "model_ans": "Cryogenic separation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cryogenic separation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much is the sieve method of gas production used?",
        "answers": [
            "major method",
            "increasingly",
            "major method",
            "increasingly"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Electrolysis of what can be used to produce oxygen and hydrogen?",
        "answers": [
            "water",
            "water",
            "water",
            "water"
        ],
        "model_ans": "Water",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the electrolysis of water produce?",
        "answers": [
            "oxygen and hydrogen",
            "oxygen and hydrogen",
            "molecular oxygen and hydrogen",
            "molecular oxygen and hydrogen",
            "Oxygen gas"
        ],
        "model_ans": "Hydrogen and Oxygen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hydrogen and Oxygen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of electric current is needed for electrolysis?",
        "answers": [
            "DC",
            "DC electricity",
            "DC",
            "DC electricity"
        ],
        "model_ans": "Direct current",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Direct current </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the source of oxygen production through electrocatalytic means?",
        "answers": [
            "oxides and oxoacids",
            "oxides and oxoacids",
            "oxides and oxoacids",
            "oxides and oxoacids",
            "oxides and oxoacids"
        ],
        "model_ans": "Water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other catalysts can be used to produce oxygen?",
        "answers": [
            "Chemical",
            "Chemical",
            "Chemical",
            "chemical oxygen generators or oxygen candles",
            "Chemical"
        ],
        "model_ans": "Platinum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Platinum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "As a euphoric how is oxygen used in bars?",
        "answers": [
            "recreational",
            "recreational",
            "recreational"
        ],
        "model_ans": "Oxygen is used in bars to create a euphoric atmosphere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen is used in bars to create a euphoric atmosphere </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the effect on humans of oxygen?",
        "answers": [
            "mild euphoric",
            "a supposed mild euphoric",
            "a supposed mild euphoric",
            "euphoric"
        ],
        "model_ans": "necessary for life",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> necessary for life </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do professional athletes seek to boost from breathing oxygen?",
        "answers": [
            "performance",
            "performance",
            "performance",
            "performance",
            "a \"boost\" in performance"
        ],
        "model_ans": "Endurance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Endurance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of exercise does research show receives a boost in performance from oxygen?",
        "answers": [
            "aerobic",
            "aerobic",
            "aerobic",
            "aerobic",
            "aerobic exercise"
        ],
        "model_ans": "High-Intensity Interval Training",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> High-Intensity Interval Training </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most likely effect of breathing oxygen?",
        "answers": [
            "placebo",
            "placebo",
            "placebo",
            "a placebo effect",
            "placebo"
        ],
        "model_ans": "Increased oxygenation of the body",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Increased oxygenation of the body </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What device is used to treat various conditions such as carbon monoxide poisoning?",
        "answers": [
            "Hyperbaric (high-pressure) medicine",
            "special oxygen chambers",
            "oxygen chambers",
            "oxygen chambers",
            "oxygen chambers"
        ],
        "model_ans": "Hyperbaric chamber",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hyperbaric chamber </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does increased oxygen concentrations in the patient's lungs displace?",
        "answers": [
            "carbon monoxide",
            "carbon monoxide",
            "carbon monoxide",
            "carbon monoxide",
            "carbon monoxide"
        ],
        "model_ans": "Carbon dioxide",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carbon dioxide </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To what pathogen that causes gas gangrene is oxygen poisonous?",
        "answers": [
            "anaerobic bacteria",
            "anaerobic bacteria",
            "anaerobic bacteria",
            "anaerobic bacteria",
            "anaerobic bacteria"
        ],
        "model_ans": "Clostridium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Clostridium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What occurs after a dive in which a diver decompresses too quickly?",
        "answers": [
            "Decompression sickness",
            "bubbles of inert gas, mostly nitrogen and helium, forming in their blood",
            "Decompression sickness",
            "decompression sickness (the 'bends')",
            "Decompression sickness"
        ],
        "model_ans": "Decompression sickness",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Decompression sickness </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what process is the uptake from oxygen necessary?",
        "answers": [
            "respiration",
            "respiration",
            "respiration",
            "respiration",
            "respiration"
        ],
        "model_ans": "cellular respiration",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cellular respiration </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What medical treatment is used to increase oxygen uptake in a patient?",
        "answers": [
            "oxygen supplementation",
            "oxygen supplementation",
            "oxygen supplementation",
            "Oxygen therapy",
            "Oxygen therapy"
        ],
        "model_ans": "Hyperbaric oxygen therapy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hyperbaric oxygen therapy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By decreasing resistance to blood flow in the lungs, what organ's workload  can be eased?",
        "answers": [
            "heart",
            "the heart",
            "heart",
            "the heart",
            "heart"
        ],
        "model_ans": "heart",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> heart </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What medical treatment is used to benefit patients with hearth and lung disorders?",
        "answers": [
            "Oxygen therapy",
            "Oxygen therapy",
            "Oxygen therapy",
            "Oxygen therapy",
            "Oxygen therapy"
        ],
        "model_ans": "Cardiology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cardiology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does  oxygen therapy promote the body to take up?",
        "answers": [
            "gaseous oxygen.",
            "gaseous oxygen",
            "gaseous oxygen",
            "oxygen",
            "gaseous oxygen"
        ],
        "model_ans": "oxygen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxygen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What characteristic of oxygen causes it to form bonds with other elements?",
        "answers": [
            "electronegativity",
            "electronegativity",
            "electronegativity",
            "electronegativity",
            "electronegativity"
        ],
        "model_ans": "its electronegativity",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> its electronegativity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is usual form of oxygen bound compounds?",
        "answers": [
            "oxides",
            "oxides",
            "oxides",
            "oxides",
            "oxides"
        ],
        "model_ans": "oxides",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxides </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the mineral wustite?",
        "answers": [
            "FeO",
            "FeO",
            "FeO",
            "FeO",
            "FeO"
        ],
        "model_ans": "Iron oxide",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Iron oxide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does oxygen cause to form on metals?",
        "answers": [
            "oxide",
            "a thin film of oxide",
            "a thin film of oxide",
            "oxide",
            "a thin film of oxide"
        ],
        "model_ans": "Rust",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rust </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the film of oxide on metals delay?",
        "answers": [
            "corrosion",
            "further corrosion",
            "further corrosion",
            "further corrosion",
            "corrosion"
        ],
        "model_ans": "corrosion",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> corrosion </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What event would necessitate airline passengers to need a supplemental supply of oxygen? ",
        "answers": [
            "cabin depressurization",
            "cabin depressurization",
            "cabin depressurization",
            "cabin depressurization",
            "depressurization"
        ],
        "model_ans": "High-altitude flight",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> High-altitude flight </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the type of oxygen production for emergency oxygen in airlines?",
        "answers": [
            "chemical",
            "chemical oxygen",
            "chemical",
            "chemical oxygen generators",
            "chemical"
        ],
        "model_ans": "Oxygen generator",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen generator </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of reaction is present in the emergency oxygen generator of an airplane?",
        "answers": [
            "exothermic",
            "exothermic",
            "exothermic",
            "exothermic",
            "exothermic reaction"
        ],
        "model_ans": "Chemical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chemical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What gas does the airline exothermic reaction produce?",
        "answers": [
            "oxygen gas",
            "oxygen",
            "oxygen",
            "oxygen",
            "oxygen"
        ],
        "model_ans": "Oxygen",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Oxygen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do oxygen tanks, cryogenics, and chemical compounds serve as for oxygen?",
        "answers": [
            "storage",
            "storage",
            "storage methods",
            "storage",
            "storage methods"
        ],
        "model_ans": "storage",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> storage </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what state is oxygen shipped in bulk?",
        "answers": [
            "liquid",
            "as a liquid",
            "liquid",
            "as a liquid in specially insulated tankers"
        ],
        "model_ans": "liquid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> liquid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By what means is bulk oxygen shipped?",
        "answers": [
            "insulated tankers",
            "insulated tankers",
            "insulated tankers",
            "specially insulated tankers"
        ],
        "model_ans": "Tankers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tankers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what form is oxygen transported in smaller containers?",
        "answers": [
            "compressed gas",
            "compressed gas",
            "compressed gas;",
            "compressed gas",
            "compressed gas"
        ],
        "model_ans": "liquid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> liquid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of organization would need large quantities of pure oxygen?",
        "answers": [
            "hospitals",
            "hospitals",
            "hospitals",
            "hospitals",
            "hospitals"
        ],
        "model_ans": "Hospitals",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hospitals </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of compounds such as acetone,contain oxygen?",
        "answers": [
            "organic solvents",
            "organic solvents",
            "organic solvents",
            "solvents",
            "organic solvents"
        ],
        "model_ans": "Organic compounds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Organic compounds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what group of compounds is oxygen a necessary part?",
        "answers": [
            "organic compounds",
            "organic",
            "solvents",
            "organic solvents"
        ],
        "model_ans": "Peroxides",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Peroxides </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What function do compounds like phenol and acetone serve in the manufacture of many other substances?",
        "answers": [
            "feeder materials",
            "as feeder materials",
            "feeder materials",
            "feeder materials",
            "as feeder materials"
        ],
        "model_ans": "Solvents",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Solvents </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what compound is oxygen part of a ring arrangement?",
        "answers": [
            "Epoxides",
            "Epoxides",
            "Epoxides",
            "Epoxides",
            "Epoxides"
        ],
        "model_ans": "Benzene",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Benzene </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are the compounds that contain oxygen considered in commerce?",
        "answers": [
            "important",
            "important",
            "important",
            "important"
        ],
        "model_ans": "oxides",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oxides </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what type of molecules are oxygen found?",
        "answers": [
            "biomolecules",
            "biomolecules",
            "biomolecules",
            "biomolecules",
            "almost all biomolecules that are important to (or generated by) life"
        ],
        "model_ans": "compounds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> compounds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many biomolecules contain no oxygen?",
        "answers": [
            "Only a few",
            "Only a few",
            "a few",
            "Only a few",
            "a few"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which organic compounds contain the greatest amount of oxygen by mass?",
        "answers": [
            "carbohydrates",
            "carbohydrates",
            "carbohydrates",
            "carbohydrates",
            "carbohydrates"
        ],
        "model_ans": "Carboxylic acids",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carboxylic acids </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides fats, fatty acids, and amino acids,what other organic compounds contain oxygen?",
        "answers": [
            "proteins",
            "proteins",
            "proteins",
            "proteins",
            "proteins"
        ],
        "model_ans": "carbohydrates",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> carbohydrates </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what calcium containing body part is oxygen a part?",
        "answers": [
            "bones",
            "bones",
            "bones",
            "bones",
            "bones"
        ],
        "model_ans": "Bone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bone</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What health condition can deep sea diving cause?",
        "answers": [
            "Oxygen toxicity",
            "Oxygen toxicity",
            "Oxygen toxicity",
            "Oxygen toxicity",
            "Oxygen toxicity to the lungs and central nervous system"
        ],
        "model_ans": "Decompression sickness",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Decompression sickness </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To what can the use of prolonged breathing of oxygen at 60 kPa lead?",
        "answers": [
            "pulmonary fibrosis",
            "permanent pulmonary fibrosis",
            "permanent pulmonary fibrosis",
            "permanent pulmonary fibrosis",
            "pulmonary fibrosis"
        ],
        "model_ans": "Pulmonary edema",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pulmonary edema </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Pressures greater than what can lead to convulsions?",
        "answers": [
            "160 kPa",
            "160 kPa",
            "160 kPa (about 1.6 atm)",
            "160 kPa (about 1.6 atm)",
            "160 kPa"
        ],
        "model_ans": "40 mmHg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40 mmHg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most feared condition that divers want to avoid?",
        "answers": [
            "Acute oxygen toxicity",
            "Acute oxygen toxicity",
            "seizures",
            "seizures",
            "seizures"
        ],
        "model_ans": "Nitrogen Narcosis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nitrogen Narcosis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What physical condition can acute oxygen toxicity cause?",
        "answers": [
            "seizures",
            "seizures",
            "seizures",
            "seizures",
            "seizures"
        ],
        "model_ans": "Pulmonary edema",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pulmonary edema </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is breathing oxygen in space craft not dangerous to health?",
        "answers": [
            "low total pressures",
            "low total pressures used",
            "low total pressures",
            "low total pressures",
            "the low total pressures used"
        ],
        "model_ans": "Because the oxygen is pressurized and the spacecraft is designed to maintain a safe environment",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because the oxygen is pressurized and the spacecraft is designed to maintain a safe environment </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the oxygen partial pressure of space suits?",
        "answers": [
            "30 kPa",
            "about 30 kPa",
            "about 30 kPa",
            "30 kPa",
            "about 30 kPa (1.4 times normal)"
        ],
        "model_ans": "0.3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of normal is the oxygen breathed in space suits?",
        "answers": [
            "1.4 times normal",
            "1.4 times",
            "1.4 times",
            "1.4 times normal",
            "1.4 times normal"
        ],
        "model_ans": "21%",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 21% </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What si the comparison to sea level with the oxygen level in space suits?",
        "answers": [
            "only marginally more",
            "marginally more than normal",
            "marginally more",
            "marginally more",
            "only marginally more"
        ],
        "model_ans": "1/3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1/3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much damage does breathing oxygen in space conditions cause?",
        "answers": [
            "no damage",
            "no damage",
            "no",
            "no",
            "no damage"
        ],
        "model_ans": "1-2% of lung tissue damage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1-2% of lung tissue damage </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When can oxygen gas produce a toxic condition?",
        "answers": [
            "at elevated partial pressures",
            "elevated partial pressures",
            "at elevated partial pressures",
            "at elevated partial pressures",
            "elevated partial pressures"
        ],
        "model_ans": "When it is inhaled in high concentrations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> When it is inhaled in high concentrations </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what point does oxygen toxicity begin to happen?",
        "answers": [
            "50 kilopascals",
            "at partial pressures more than 50 kilopascals",
            "50 kilopascals",
            "more than 50 kilopascals",
            "at partial pressures more than 50 kilopascals"
        ],
        "model_ans": "1-2 hours",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1-2 hours </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To what is 50 kilopascals equal?",
        "answers": [
            "50% oxygen",
            "about 50% oxygen composition at standard pressure",
            "about 50% oxygen composition at standard pressure"
        ],
        "model_ans": "50 kPa\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "50 kPa\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What medical appliance can be a concern for oxygen toxicity?",
        "answers": [
            "mechanical ventilators",
            "mechanical ventilators",
            "mechanical ventilators",
            "oxygen masks",
            "mechanical ventilators"
        ],
        "model_ans": "Oxygen mask",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oxygen mask </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of oxygen is usually supplied by a medical mask?",
        "answers": [
            "30%\u201350%",
            "30%\u201350%",
            "30%\u201350%",
            "30%\u201350%"
        ],
        "model_ans": "60-80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60-80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the 1973 oil crisis begin?",
        "answers": [
            "October 1973",
            "October 1973",
            "October 1973",
            "October",
            "1973"
        ],
        "model_ans": "1973\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1973\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the price of oil in March of 1974?",
        "answers": [
            "nearly $12",
            "$12",
            "$12",
            "$12",
            "$12"
        ],
        "model_ans": "$3.45",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $3.45 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the second oil crisis?",
        "answers": [
            "1979",
            "1979",
            "1979",
            "1979",
            "1979"
        ],
        "model_ans": "1979\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1979\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was another term used for the oil crisis?",
        "answers": [
            "first oil shock",
            "shock",
            "shock",
            "first oil shock",
            "shock"
        ],
        "model_ans": "Energy Crisis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Energy Crisis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who proclaimed the oil embargo?",
        "answers": [
            "members of the Organization of Arab Petroleum Exporting Countries",
            "members of the Organization of Arab Petroleum Exporting Countries",
            "Organization of Arab Petroleum Exporting Countries",
            "members of the Organization of Arab Petroleum Exporting Countries",
            "OAPEC"
        ],
        "model_ans": "OPEC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> OPEC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did the European nations and Japan separated themselves from United States during the crisis?",
        "answers": [
            "to avoid being targeted by the boycott",
            "to avoid being targeted by the boycott",
            "to avoid being targeted by the boycott",
            "to avoid being targeted by the boycott",
            "to avoid being targeted by the boycott"
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the Nixon administration negotiate with the uncooperative countries?",
        "answers": [
            "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights.",
            "multilateral",
            "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights",
            "multilateral negotiations",
            "multilateral"
        ],
        "model_ans": "Diplomacy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diplomacy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "On what date did Henry Kissinger negotiate an Israeli troop withdrawal from the Sinai Peninsula?",
        "answers": [
            "January 18, 1974,",
            "January 18, 1974",
            "January 18, 1974",
            "January 18, 1974",
            "January 18, 1974"
        ],
        "model_ans": "March 4, 1974",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 4, 1974 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Arab oil producers lift the embargo?",
        "answers": [
            "March 1974",
            "March 1974",
            "March 1974",
            "March 1974.",
            "March 1974"
        ],
        "model_ans": "1988\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1988\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the United States withdraw from the Bretton Woods Accord?",
        "answers": [
            "On August 15, 1971",
            "August 15, 1971",
            "August 15, 1971",
            "August 15, 1971",
            "August 15, 1971"
        ],
        "model_ans": "1971\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1971\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does it mean when currencies are left to \"float?\"",
        "answers": [
            "to \"float\" (rise and fall according to market demand)",
            "(rise and fall according to market demand",
            "rise and fall according to market demand",
            "rise and fall according to market demand",
            "rise and fall according to market demand"
        ],
        "model_ans": "When currencies are left to \"float,\" it means that their exchange rates are determined by the foreign exchange market, rather than being fixed by a government or central bank.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> When currencies are left to \"float,\" it means that their exchange rates are determined by the foreign exchange market, rather than being fixed by a government or central bank. </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why was there a depreciation of the industrialized nations dollars?",
        "answers": [
            "industrialized nations increased their reserves",
            "industrialized nations increased their reserves (by expanding their money supplies) in amounts far greater than before",
            "industrialized nations increased their reserves",
            "industrialized nations increased their reserves",
            "the industrialized nations increased their reserves"
        ],
        "model_ans": "The depreciation of the dollar was caused by a combination of factors, including a decline in the value of the dollar against other currencies, a decrease in the value of the dollar against other currencies</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The depreciation of the dollar was caused by a combination of factors, including a decline in the value of the dollar against other currencies, a decrease in the value of the dollar against other currencies</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did oil start getting priced in the terms of gold?",
        "answers": [
            "In September 1971",
            "September 1971",
            "September 1971",
            "September 1971",
            "September 1971"
        ],
        "model_ans": "1971",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1971 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did oil start getting priced in terms of gold?",
        "answers": [
            "oil was priced in dollars, oil producers' real income decreased",
            "Because oil was priced in dollars, oil producers' real income decreased.",
            "Because oil was priced in dollars, oil producers' real income decreased",
            "Because oil was priced in dollars, oil producers' real income decreased",
            "Because oil was priced in dollars, oil producers' real income decreased"
        ],
        "model_ans": "Oil was first priced in terms of gold in the early 20th century, as the US dollar was pegged to gold at a fixed rate of $20.67 per ounce.</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oil was first priced in terms of gold in the early 20th century, as the US dollar was pegged to gold at a fixed rate of $20.67 per ounce.</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "From 1947 to 1967, how much did the price of oil increase?",
        "answers": [
            "risen by less than two percent per year",
            "less than two percent per year",
            "less than two percent per year",
            "by less than two percent per year",
            "less than two percent per year"
        ],
        "model_ans": "10 times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 times </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did OPEC start to readjust oil prices?",
        "answers": [
            "After 1971",
            "1973\u20131974",
            "1971",
            "After 1971",
            "1971"
        ],
        "model_ans": "1973\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1973\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did oil finally returned to its Bretton Woods levels?",
        "answers": [
            "1973\u20131974",
            "1974",
            "1973\u20131974",
            "1973\u20131974",
            "1973\u20131974"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The price of oil is usually a stable commodity until when?",
        "answers": [
            "Until the oil shock",
            "the oil shock",
            "the oil shock",
            "Until the oil shock",
            "the oil shock"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Syria and Egypt launch a surprise attack on Israel?",
        "answers": [
            "On October 6, 1973",
            "October 6, 1973",
            "October 6, 1973",
            "October 6, 1973",
            "October 6, 1973"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the world's second largest oil producer?",
        "answers": [
            "Iran",
            "Iran",
            "Iran",
            "Iran",
            "Iran"
        ],
        "model_ans": "Saudi Arabia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saudi Arabia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many times more did the other nations have to pay for oil after the surprise attack?",
        "answers": [
            "ten times more",
            "ten",
            "a hundred",
            "ten"
        ],
        "model_ans": "5 times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 times </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which oil producer is a close ally of the United States?",
        "answers": [
            "Iran",
            "Iran",
            "Iran",
            "Iran",
            "Iran"
        ],
        "model_ans": "Saudi Arabia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saudi Arabia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did the Shah of Iran gave an interview?",
        "answers": [
            "renewal of hostilities in the Arab\u2013Israeli conflict",
            "renewal of hostilities",
            ".",
            "the Arab\u2013Israeli conflict released the underlying economic pressure on oil prices"
        ],
        "model_ans": "To promote his book",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To promote his book </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did OPEC raise the price of oil to $5.11?",
        "answers": [
            "In response to American aid to Israel",
            "In response to American aid to Israel",
            "In response to American aid to Israel",
            "In response to American aid to Israel",
            "American aid to Israel"
        ],
        "model_ans": "I am not aware of any information about OPEC raising the price of oil to $5.11",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not aware of any information about OPEC raising the price of oil to $5.11 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did they raise the price of oil to $5.11?",
        "answers": [
            "October 16, 1973,",
            "October 16, 1973",
            "October 16, 1973",
            "October 16, 1973",
            "October 16, 1973"
        ],
        "model_ans": "I am not aware of any specific date when the price of oil was raised to $5.11",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not aware of any specific date when the price of oil was raised to $5.11 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did the oil ministers agree to a cut in oil production?",
        "answers": [
            "until their economic and political objectives were met",
            "In response to American aid to Israel",
            "OPEC raised the posted price of oil",
            "until their economic and political objectives were met"
        ],
        "model_ans": "To stabilize the global oil market",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To stabilize the global oil market </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much was the emergency aid to Israel?",
        "answers": [
            "$2.2 billion",
            "$2.2 billion",
            "$2.2 billion",
            "$2.2 billion",
            "$2.2 billion"
        ],
        "model_ans": "$3.8 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $3.8 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did OPEC block oil deliveries to the United States?",
        "answers": [
            "American aid to Israel",
            "Nixon requested Congress to appropriate $2.2 billion in emergency aid to Israel",
            "OAPEC proclaimed the embargo that curbed exports to various countries and blocked all oil deliveries to the US as a \"principal hostile country",
            "OAPEC proclaimed the embargo that curbed exports to various countries",
            "American aid to Israel"
        ],
        "model_ans": "OPEC blocked oil deliveries to the United States in 1973 in response to the United States' support for Israel during the Yom Kippur War.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> OPEC blocked oil deliveries to the United States in 1973 in response to the United States' support for Israel during the Yom Kippur War. </answer>\n<confidence</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much did Saudi Arabia spend on spreading Wahhabism?",
        "answers": [
            "over 100 billion dollars",
            "over 100 billion dollars",
            "over 100 billion dollars",
            "over 100 billion dollars",
            "100 billion dollars"
        ],
        "model_ans": "$100 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $100 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which group benefited from the funds distributed by the religious charity, al-Haramain Foundation?",
        "answers": [
            "Al-Qaeda and the Taliban",
            "violent Sunni extremist groups such as Al-Qaeda and the Taliban",
            "Al-Qaeda and the Taliban",
            "Al-Qaeda and the Taliban",
            "Al-Qaeda and the Taliban"
        ],
        "model_ans": "Hamas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hamas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Some of the income went to the purchase of arms which exacerbated political tension especially in which area?",
        "answers": [
            "Middle East",
            "Middle East",
            "Middle East",
            "Middle East",
            "Middle East"
        ],
        "model_ans": "Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one of the reason that underdeveloped nations received aid from the oil income?",
        "answers": [
            "shrinking Western demand",
            "shrinking Western demand",
            "economies had been caught between higher oil prices and lower prices for their own export commodities",
            "economies had been caught between higher oil prices and lower prices for their own export commodities",
            "shrinking Western demand"
        ],
        "model_ans": "To compensate for the lack of natural resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To compensate for the lack of natural resources </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a fundamentalist interpretation of Islam called?",
        "answers": [
            "Wahhabism",
            "Wahhabism",
            "Wahhabism",
            "Wahhabism",
            "Wahhabism"
        ],
        "model_ans": "Salafism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Salafism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one of the reason that US production has been held responsible for recessions and lower economic growth?",
        "answers": [
            "distribution and price disruptions",
            "reduced productivity",
            "distribution and price disruptions",
            "distribution and price disruptions"
        ],
        "model_ans": "Outsourcing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Outsourcing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "US is concerned about confrontation of the Middle East with which other country?",
        "answers": [
            "USSR",
            "USSR",
            "USSR",
            "USSR",
            "USSR"
        ],
        "model_ans": "Iran",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iran </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Scholars stated that there was already an existing settlement between 2 parties prior to which date?",
        "answers": [
            "1973",
            "1973",
            "1973",
            "1973"
        ],
        "model_ans": "1000 BC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 BC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Interest groups and government agencies that were concerned with energy were no match for who?",
        "answers": [
            "Kissinger",
            "Kissinger",
            "Kissinger",
            "Kissinger's",
            "Kissinger"
        ],
        "model_ans": "Exxon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Exxon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has a negative influence over the US economy?",
        "answers": [
            "The embargo",
            "The embargo",
            "The embargo",
            "The embargo",
            "embargo"
        ],
        "model_ans": "China",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On an international level, which industry's competitive positions is affected? ",
        "answers": [
            "automobiles",
            "automobiles",
            "automobiles",
            "automobiles",
            "automobiles"
        ],
        "model_ans": "Tourism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tourism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which problem consists of both  inflationary and deflationary impacts?",
        "answers": [
            "Macroeconomic problems",
            "Macroeconomic",
            "Macroeconomic",
            "Macroeconomic",
            "Macroeconomic"
        ],
        "model_ans": "stagflation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> stagflation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The oil crisis caused oil companies to increase oil supplies in which area?",
        "answers": [
            "Arctic",
            "Arctic",
            "Arctic",
            "the Arctic",
            "the Arctic"
        ],
        "model_ans": "Middle East",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Middle East </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long does it take for new areas to have significant oil production?",
        "answers": [
            "five to ten years",
            "five to ten years",
            "five to ten years",
            "five to ten years",
            "five to ten years"
        ],
        "model_ans": "5-10 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5-10 years </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country faced a complete embargo in the EEC?",
        "answers": [
            "Netherlands",
            "Netherlands",
            "the Netherlands",
            "the Netherlands"
        ],
        "model_ans": "Greece",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The UK and France had non interruptions in their oil supply as they did not allow which country to use their airfield?",
        "answers": [
            "America",
            "America",
            "America",
            "America"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country is a traditional ally of Israel?",
        "answers": [
            "UK",
            "UK",
            "The UK",
            "The UK"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Harold WInston's supported which country's during its six day war?",
        "answers": [
            "Israel",
            "Israel",
            "Israelis",
            "the Israelis"
        ],
        "model_ans": "Israel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Israel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who wanted Israel to withdraw from its border?",
        "answers": [
            "Ted Heath",
            "Ted Heath",
            "Ted Heath",
            "Ted Heath"
        ],
        "model_ans": "Egypt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Egypt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country is not badly hit by the embargo?",
        "answers": [
            "UK",
            "UK",
            "UK",
            "the UK",
            "UK"
        ],
        "model_ans": "Cuba",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cuba </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What caused UK to have an oil crisis in its own country?",
        "answers": [
            "a series of strikes",
            "a series of strikes by coal miners and railroad workers",
            "a series of strikes by coal miners and railroad workers",
            "strikes by coal miners and railroad workers",
            "a series of strikes"
        ],
        "model_ans": "North Sea oil discovery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> North Sea oil discovery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the series of strikes happen?",
        "answers": [
            "winter of 1973\u201374",
            "over the winter of 1973\u201374",
            "1973\u201374",
            "winter of 1973\u201374",
            "the winter of 1973\u201374"
        ],
        "model_ans": "1970s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Name one country that banned boating, driving and flying on Sundays.",
        "answers": [
            "Germany",
            "Germany",
            "Italy",
            "Norway"
        ],
        "model_ans": "Singapore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Singapore </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country rationed gasoline and heating gas?",
        "answers": [
            "Sweden",
            "Sweden",
            "Sweden",
            "Sweden",
            "Sweden"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What made the oil crisis worse in the US?",
        "answers": [
            "Price controls",
            "Price controls",
            "Price controls",
            "Price controls",
            "Price controls"
        ],
        "model_ans": "OPEC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> OPEC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why are newly discovered oil sold at a higher price?",
        "answers": [
            "encourage investment",
            "to encourage investment",
            "to encourage investment",
            "to encourage investment",
            "The system limited the price of \"old oil\""
        ],
        "model_ans": "Supply and demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why was old oil withdrawn from the market?",
        "answers": [
            "Price controls",
            "Price controls",
            "promote oil exploration",
            "discouraged development of alternative energies",
            "The system limited the price of \"old oil\""
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How was scarcity managed in many countries?",
        "answers": [
            "rationing",
            "rationing",
            "rationing",
            "rationing",
            "rationing"
        ],
        "model_ans": "rationing",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> rationing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the first administrator of the Federal Energy Office?",
        "answers": [
            "William E. Simon",
            "William E. Simon",
            "William E. Simon",
            "William E. Simon",
            "William E. Simon"
        ],
        "model_ans": "John F. Campbell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John F. Campbell </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was he elected by Nixon?",
        "answers": [
            "In 1973",
            "1973",
            "1973",
            "1973",
            "1973"
        ],
        "model_ans": "1968",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1968 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why was this short termed organization created?",
        "answers": [
            "coordinate the response to the embargo",
            "to coordinate the response to the embargo",
            "to coordinate the response to the embargo",
            "to coordinate the response to the embargo",
            "to coordinate the response to the embargo"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to the AAA, what is the percentage of the gas stations that ran out of gasoline?",
        "answers": [
            "last week of February 1974,",
            "20%",
            "20",
            "20%",
            "20%"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the speed limit set to reduce consumption?",
        "answers": [
            "55 mph",
            "55 mph",
            "55 mph",
            "55 mph",
            "55 mph"
        ],
        "model_ans": "60 km/h",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60 km/h </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the law which imposed the speed limit?",
        "answers": [
            "Emergency Highway Energy Conservation Act",
            "Emergency Highway Energy Conservation Act",
            "Emergency Highway Energy Conservation Act",
            "Emergency Highway Energy Conservation Act",
            "Emergency Highway Energy Conservation Act"
        ],
        "model_ans": "Highway Code",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Highway Code </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which president ended the Emergency Energy Conservation Act?",
        "answers": [
            "Bill Clinton",
            "Bill Clinton",
            "Bill Clinton",
            "Bill Clinton",
            "Bill Clinton"
        ],
        "model_ans": "Jimmy Carter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jimmy Carter </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the National Highway Designated Act signed?",
        "answers": [
            "November 28, 1995",
            "November 28, 1995",
            "November 28, 1995",
            "November 28, 1995",
            "November 28, 1995"
        ],
        "model_ans": "1956",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1956 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the cabinet-level Energy Department created?",
        "answers": [
            "1977",
            "1977",
            "1977",
            "1977",
            "1977"
        ],
        "model_ans": "1977\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1977\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the catalyst that created greater interest in renewable resources?",
        "answers": [
            "energy crisis",
            "The energy crisis",
            "energy crisis",
            "energy crisis",
            "The energy crisis"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "There is criticism that the energy policies are expensive quick fixes that ignore which facts?",
        "answers": [
            "market and technology realities",
            "market and technology realities",
            "market and technology realities",
            "market and technology realities",
            "market and technology realities"
        ],
        "model_ans": "long-term",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> long-term </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who backed policies that have solutions that sound good but have poor prospects?",
        "answers": [
            "congresses and presidents",
            "congresses and presidents",
            "congresses and presidents",
            "congresses and presidents",
            "congresses and presidents"
        ],
        "model_ans": "politicians",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> politicians </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country was thinking about going to war to forcibly take Middle Eastern oil fields?",
        "answers": [
            "U.S",
            "U.S.",
            "U.S.",
            "U.S",
            "the U.S."
        ],
        "model_ans": "United States",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country was worried that the US would invade the Middle East?",
        "answers": [
            "British Prime Minister Edward Heath",
            "British",
            "British",
            "British"
        ],
        "model_ans": "France",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long would the invasion of the Middle East have to last in order to develop renewable resources?",
        "answers": [
            "10 years",
            "10 years",
            "10 years",
            "10 years",
            "10 years"
        ],
        "model_ans": "10 years",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who would the occupation alienate?",
        "answers": [
            "Arabs and much of the rest of the Third World",
            "the Arabs and much of the rest of the Third World",
            "Arabs",
            "Arabs and much of the rest of the Third World",
            "the Arabs and much of the rest of the Third World"
        ],
        "model_ans": "The Alien",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Alien </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country is the most dependent on Arab oil?",
        "answers": [
            "Japan",
            "Japan",
            "Japan",
            "Japan",
            "Japan"
        ],
        "model_ans": "Japan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Japan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much imported oil came from the Middle East?",
        "answers": [
            "71%",
            "71%",
            "71",
            "71%",
            "71%"
        ],
        "model_ans": "60%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To force Japan to be more involved in the crisis, what did Saudi and Kuwaiti government do?",
        "answers": [
            "5% production cut",
            "declared Japan a \"nonfriendly\" country",
            "declared Japan a \"nonfriendly\" country",
            "declared Japan a \"nonfriendly\" country",
            "declared Japan a \"nonfriendly\" country"
        ],
        "model_ans": "They cut oil production",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They cut oil production </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Japan release a statement to tell Israelis to withdraw from the Palestine?",
        "answers": [
            "November 22",
            "November 22",
            "November 22",
            "November 22,",
            "November 22"
        ],
        "model_ans": "1991",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1991 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Japan accepted as an Arab-friendly state?",
        "answers": [
            "December 25",
            "December 25",
            "December 25",
            "December 25",
            "December 25"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country's invasion show the insecurity of the Middle East?",
        "answers": [
            "USSR's invasion",
            "Afghanistan",
            "USSR's",
            "USSR",
            "Afghanistan"
        ],
        "model_ans": "Israel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Israel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which countries became dependent on US's security assurance to threats?",
        "answers": [
            "Saudi Arabia and Iran",
            "Saudi Arabia and Iran",
            "Saudi Arabia and Iran",
            "Saudi Arabia and Iran",
            "Saudi Arabia and Iran"
        ],
        "model_ans": "NATO",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NATO </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country's arms purchase from the US became 5 times more than Israel?",
        "answers": [
            "Saudi Arabia",
            "Saudi Arabia",
            "Saudi Arabia",
            "Saudi Arabia",
            "Saudi Arabia"
        ],
        "model_ans": "Saudi Arabia",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Saudi Arabia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Shah kingdom start to collapse?",
        "answers": [
            "January 1979",
            "1979",
            "1979",
            "1979",
            "January 1979"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Wahhabi seized the Grand Mosque in Mecca?",
        "answers": [
            "November 1979",
            "November 1979",
            "November 1979",
            "November 1979",
            "November 1979"
        ],
        "model_ans": "1979\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1979\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which sized cars were the least demanded cars in the crisis?",
        "answers": [
            "large cars",
            "large",
            "large",
            "large"
        ],
        "model_ans": "Small",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Small </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country's cars became more highly sought after as they were more fuel efficient?",
        "answers": [
            "Japanese imports",
            "Japan",
            "Japanese",
            "Japanese",
            "Japanese"
        ],
        "model_ans": "Japan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Japan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of engines does the American car typically have?",
        "answers": [
            "V8 and six cylinder engines",
            "V8 and six cylinder",
            "V8 and six cylinder",
            "V8 and six cylinder",
            "V8 and six cylinder"
        ],
        "model_ans": "V8",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> V8 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country's imports became the de facto mass market leaders?",
        "answers": [
            "Japan",
            "Japan",
            "Japanese",
            "Japanese",
            "Japanese"
        ],
        "model_ans": "Japan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Japan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Honda, Toyota and Nissan open US assembly plants?",
        "answers": [
            "A decade after the 1973",
            "1981",
            "1981",
            "A decade after the 1973 oil crisis",
            "1981"
        ],
        "model_ans": "1959",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1959 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Name a larger car that Toyota came up with as buyers lamented the small sized compacts?",
        "answers": [
            "Toyota Corona Mark II",
            "Corona Mark II",
            "Toyota Corona Mark II",
            "Corona Mark II"
        ],
        "model_ans": "Corolla",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Corolla </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Name an extra that was added to the production of the compacts.",
        "answers": [
            "power steering",
            "air conditioning",
            "air conditioning",
            "power windows"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Name a luxury division of Toyota.",
        "answers": [
            "Lexus",
            "Lexus",
            "Lexus",
            "Acura",
            "Lexus"
        ],
        "model_ans": "Lexus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lexus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Name a type of Toyota compact trucks?",
        "answers": [
            "Toyota Hilux",
            "Hilux",
            "Hilux",
            "Toyota Hilux",
            "Hilux"
        ],
        "model_ans": "Hilux",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hilux </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Mitsubishi rename its Forte to?",
        "answers": [
            "Dodge D-50",
            "Dodge D-50",
            "Dodge D-50",
            "Dodge D-50",
            "Dodge D-50"
        ],
        "model_ans": "Lancer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lancer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Mazda, Mitsubishi and Isuzu joined partnership with which American car company?",
        "answers": [
            "Ford, Chrysler, and GM",
            "Ford, Chrysler, and GM",
            "Ford, Chrysler, and GM, respectively",
            "Ford",
            "Ford, Chrysler, and GM"
        ],
        "model_ans": "Ford",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ford </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When American car companies rolled out with their domestic replacement cars, which policy ended?",
        "answers": [
            "captive import policy",
            "captive import",
            "captive import",
            "captive import",
            "captive import"
        ],
        "model_ans": "Protectionism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Protectionism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did GM, Ford and Chrysler introduced fuel-efficient and small cars to the US market?",
        "answers": [
            "An increase in imported cars",
            "An increase in imported cars into North America",
            "An increase in imported cars into North America",
            "An increase in imported cars",
            "An increase in imported cars"
        ],
        "model_ans": "To comply with government regulations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To comply with government regulations </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many passengers can the Ford Fiesta accommodate?",
        "answers": [
            "at least four passengers",
            "four",
            "at least four passengers",
            "at least four",
            "four"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By which year did the American cars mpg start to improve?",
        "answers": [
            "1985",
            "1985",
            "1985",
            "1985",
            "1985"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Name a luxury model that became popular in the mid-1970s.",
        "answers": [
            "Lincoln Continental,",
            "Cadillac DeVille",
            "Cadillac DeVille",
            "Cadillac DeVille"
        ],
        "model_ans": "Cadillac Seville",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cadillac Seville </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which full-sized model cars were not popular?",
        "answers": [
            "Chevrolet Bel Air",
            "lower price models such as the Chevrolet Bel Air, and Ford Galaxie 500",
            "lower price models",
            "Chevrolet Bel Air, and Ford Galaxie 500",
            "Chevrolet Bel Air, and Ford Galaxie 500"
        ],
        "model_ans": "Maisto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maisto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By which year did full sized American cars shrink to be smaller?",
        "answers": [
            "1979",
            "1979",
            "1979",
            "1979",
            "1979"
        ],
        "model_ans": "1970s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By which year did Chrysler ended its full sized luxury model?",
        "answers": [
            "1981",
            "1981",
            "1981",
            "1981",
            "1981"
        ],
        "model_ans": "1997",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1997 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which car shows the DOT's revision of categories?",
        "answers": [
            "Mustang I",
            "the 1974 Mustang I",
            "Mustang I",
            "1974 Mustang I",
            "1974 Mustang I"
        ],
        "model_ans": "Ford",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ford </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was OPEC production of oil being surpassed?",
        "answers": [
            "1981",
            "1981",
            "1981",
            "1981",
            "1981"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which year did the price of oil drop to $10 per barrel?",
        "answers": [
            "1980s",
            "during the 1980s",
            "1980s",
            "1980s",
            "1980s"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Saudi Arabia try to increase production, and reduce profits for high cost producers?",
        "answers": [
            "recover market share",
            "trying to recover market share",
            "recover market share",
            "to recover market share",
            "recover market share"
        ],
        "model_ans": "To increase market share and reduce prices",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To increase market share and reduce prices </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1979, during the oil crisis, what was the highest price of oil?",
        "answers": [
            "nearly $40 per barrel",
            "nearly $40 per barrel",
            "$40 per barrel",
            "$40 per barrel",
            "$40 per barrel"
        ],
        "model_ans": "$39.50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $39.50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is European Union Law?",
        "answers": [
            "a body of treaties and legislation",
            "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states",
            "a body of treaties and legislation, such as Regulations and Directives",
            "a body of treaties and legislation, such as Regulations and Directives"
        ],
        "model_ans": "EU law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the main sources of primary law?",
        "answers": [
            "Treaties establishing the European Union",
            "the Treaties establishing the European Union",
            "primary law, secondary law and supplementary law",
            "the Treaties establishing the European Union"
        ],
        "model_ans": "Statutes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Statutes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the secondary sources of primary law?",
        "answers": [
            "regulations and directives",
            "regulations and directives which are based on the Treaties",
            "regulations and directives which are based on the Treaties",
            "regulations and directives which are based on the Treaties"
        ],
        "model_ans": "secondary sources",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> secondary sources </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two bodies that make up the European Union's legislature?",
        "answers": [
            "European Parliament and the Council of the European Union",
            "the European Parliament and the Council of the European Union",
            "European Parliament and the Council of the European Union",
            "European Parliament and the Council of the European Union"
        ],
        "model_ans": "European Parliament and Council",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament and Council </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is European Union law?",
        "answers": [
            "a body of treaties and legislation",
            "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states",
            "a body of treaties and legislation, such as Regulations and Directives",
            "a body of treaties and legislation, such as Regulations and Directives"
        ],
        "model_ans": "EU law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What effect does European Union law have on laws of member states?",
        "answers": [
            "direct effect or indirect effect",
            "direct effect or indirect effect on the laws of European Union member states",
            "direct effect or indirect effect",
            "direct effect or indirect effect"
        ],
        "model_ans": "Supremacy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supremacy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the three sources of European Union law?",
        "answers": [
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law"
        ],
        "model_ans": "Treaties, Regulations, and Directives",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaties, Regulations, and Directives </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the main legislative bodies of the European Union?",
        "answers": [
            "European Parliament and the Council of the European Union",
            "the Treaties establishing the European Union",
            "European Parliament and the Council of the European Union",
            "European Parliament and the Council of the European Union"
        ],
        "model_ans": "European Parliament, Council of the European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament, Council of the European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the three main sources of European Union law?",
        "answers": [
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law",
            "primary law, secondary law and supplementary law"
        ],
        "model_ans": "Treaties, Regulations, and Directives",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaties, Regulations, and Directives </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the main sources of primary law?",
        "answers": [
            "the Treaties establishing the European Union",
            "the Treaties establishing the European Union",
            "the Treaties establishing the European Union",
            "the Treaties establishing the European Union"
        ],
        "model_ans": "Statutes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Statutes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the legislature of the European Union comprised of?",
        "answers": [
            "the European Parliament and the Council of the European Union",
            "the European Parliament and the Council of the European Union",
            "European Parliament and the Council of the European Union",
            "European Parliament and the Council of the European Union"
        ],
        "model_ans": "European Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many sources of European Union law are there?",
        "answers": [
            "three",
            "three",
            "three",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who applies European Union law?",
        "answers": [
            "courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who can enforce the European Union law when member states provide lesser rights?",
        "answers": [
            "courts of member states",
            "the courts of member states",
            "the courts of member states",
            "the courts of member states"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the highest court in the European Union?",
        "answers": [
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one of the supplementary sources of European Union law? ",
        "answers": [
            "international law",
            "case law by the Court of Justice",
            "case law by the Court of Justice",
            "case law by the Court of Justice"
        ],
        "model_ans": "Case law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Case law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which two courts apply European Union law?",
        "answers": [
            "courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union"
        ],
        "model_ans": "European Court of Justice and European Court of Human Rights",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice and European Court of Human Rights </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under what treaty can the European Commission take action against member states?",
        "answers": [
            "the Treaty on the Functioning of the European Union",
            "the Treaty on the Functioning of the European Union",
            "the Treaty on the Functioning of the European Union.",
            "the Treaty on the Functioning of the European Union"
        ],
        "model_ans": "Treaty on the Functioning of the European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty on the Functioning of the European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which court is the highest court in the European Union?",
        "answers": [
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one supplementary source of European Union law?",
        "answers": [
            "international law",
            "international law",
            "international law",
            "international law"
        ],
        "model_ans": "The European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By whom is European Law applied by?",
        "answers": [
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union",
            "the courts of member states and the Court of Justice of the European Union"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who can enforce European Union law?",
        "answers": [
            "the courts of member states",
            "the courts of member states",
            "the courts of member states",
            "the courts of member states"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the highest court in European Union law?",
        "answers": [
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some supplementary sources of European Union law?",
        "answers": [
            "case law by the Court of Justice, international law and general principles of European Union law",
            "general principles of European Union law",
            "case law by the Court of Justice",
            "case law by the Court of Justice"
        ],
        "model_ans": "The Official Journal of the European Union, the European Court of Justice, and the European Parliament",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Official Journal of the European Union, the European Court of Justice, and the European Parliament </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the two primary constitutional sources of the European Union?",
        "answers": [
            "Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)"
        ],
        "model_ans": "Treaty of Rome and the Treaty of Lisbon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Rome and the Treaty of Lisbon </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who has the power to initiate legislation within the European Union?",
        "answers": [
            "The European Commission",
            "The European Commission",
            "The European Commission",
            "The European Commission"
        ],
        "model_ans": "European Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who elects the members of the European Parliament?",
        "answers": [
            "citizens",
            "citizens",
            "citizens",
            "citizens"
        ],
        "model_ans": "European citizens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European citizens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What court is able to interpret European Union law?",
        "answers": [
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice",
            "The European Court of Justice"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What governing body appoints commissioners and the board of European Central Bank?",
        "answers": [
            "The \"European Council\"",
            "The \"European Council\"",
            "The \"European Council\"",
            "The \"European Council\""
        ],
        "model_ans": "European Parliament",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which treaty provides that the European Union law be applied to metropolitan territories of member states?",
        "answers": [
            "Treaty on European Union (TEU)",
            "Treaty on European Union (TEU)",
            "Treaty on European Union (TEU)",
            "Treaty on European Union (TEU)"
        ],
        "model_ans": "Treaty of Lisbon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Lisbon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Are there any regions where the Treaty of European Union excludes from jurisdiction?",
        "answers": [
            "the Faroe Islands",
            "the Faroe Islands",
            "the Faroe Islands",
            "the Faroe Islands"
        ],
        "model_ans": "Yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What powers does the Court of Justice of the European Union have in regards to treaties?",
        "answers": [
            "can interpret the Treaties, but it cannot rule on their validity",
            "The Court of Justice of the European Union can interpret the Treaties",
            "The Court of Justice of the European Union can interpret the Treaties",
            "The Court of Justice of the European Union can interpret the Treaties"
        ],
        "model_ans": "interpretive jurisdiction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> interpretive jurisdiction </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under what instances can individuals rely on primary law in the Court of Justice of European Union?",
        "answers": [
            "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional.",
            "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional",
            "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional",
            "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional"
        ],
        "model_ans": "Direct effect",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Direct effect </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When do treaties apply?",
        "answers": [
            "as soon as they enter into force, unless stated otherwise",
            "Treaties apply as soon as they enter into force",
            "as soon as they enter into force",
            "as soon as they enter into force"
        ],
        "model_ans": "When two or more countries agree to abide by the terms of the treaty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> When two or more countries agree to abide by the terms of the treaty </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the core treaties that the primary law of the EU consists of?",
        "answers": [
            "Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)",
            "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)"
        ],
        "model_ans": "Treaty on European Union, Treaty on the Functioning of the European Union",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Treaty on European Union, Treaty on the Functioning of the European Union </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are some examples of territories where a member state is responsible for external relations?",
        "answers": [
            "Gibraltar and the \u00c5land islands",
            "Gibraltar and the \u00c5land islands",
            "Gibraltar and the \u00c5land islands",
            "Gibraltar and the \u00c5land islands"
        ],
        "model_ans": "Greenland, French Polynesia, New Caledonia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greenland, French Polynesia, New Caledonia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When do the stated Treaties apply?",
        "answers": [
            "Treaties apply as soon as they enter into force, unless stated otherwise",
            "Treaties apply as soon as they enter into force, unless stated otherwise, and are generally concluded for an unlimited period",
            "as soon as they enter into force",
            "as soon as they enter into force"
        ],
        "model_ans": "1994",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1994 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is suited to interpret the Treaties?",
        "answers": [
            "The Court of Justice of the European Union can interpret the Treaties",
            "The Court of Justice of the European Union can interpret the Treaties",
            "The Court of Justice of the European Union",
            "The Court of Justice of the European Union"
        ],
        "model_ans": "The European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the principle treaties that form the European Union begin?",
        "answers": [
            "with common rules for coal and steel, and then atomic energy",
            "with common rules for coal and steel",
            "with common rules for coal and steel",
            "with common rules for coal and steel"
        ],
        "model_ans": "The Treaties of Rome",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Treaties of Rome </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which two treaties provided more formal institutions of the European Union?",
        "answers": [
            "Treaty of Rome 1957 and the Maastricht Treaty 1992",
            "the Treaty of Rome 1957 and the Maastricht Treaty 1992",
            "the Treaty of Rome 1957 and the Maastricht Treaty 1992 (now: TFEU)",
            "the Treaty of Rome 1957 and the Maastricht Treaty 1992 (now: TFEU)"
        ],
        "model_ans": "Maastricht Treaty and Lisbon Treaty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maastricht Treaty and Lisbon Treaty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what years did Spain and Portugal join the European Union?",
        "answers": [
            "1985",
            "1985",
            "1985",
            "1985"
        ],
        "model_ans": "1986 (Spain) and 1986 (Portugal)\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1986 (Spain) and 1986 (Portugal)\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In 1972, did Norway end up joining the European Union?",
        "answers": [
            "in 1972 (though Norway did not end up joining)",
            "not",
            "not",
            "not"
        ],
        "model_ans": "no",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> no </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country in 1985 signed a treaty to give it special status?",
        "answers": [
            "Greenland",
            "Greenland",
            "Greenland",
            "Greenland"
        ],
        "model_ans": "China",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What caused the need for principal Treaties that ended up forming the EU?",
        "answers": [
            "common rules for coal and steel, and then atomic energy",
            "common rules for coal and steel, and then atomic energy",
            "with common rules for coal and steel",
            "with common rules for coal and steel"
        ],
        "model_ans": "World War II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World War II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When year was the Maastrich Treaty signed?",
        "answers": [
            "1992",
            "1992",
            "1992",
            "1992"
        ],
        "model_ans": "1992\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1992\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": " When was the Single European Act made?",
        "answers": [
            "1986",
            "1986",
            "1986",
            "1986"
        ],
        "model_ans": "1986",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1986 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Denmark join the EU?",
        "answers": [
            "1972",
            "1972",
            "1972",
            "1972"
        ],
        "model_ans": "1973\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1973\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Greenland sign a Treaty granting them special status?",
        "answers": [
            "1985",
            "1985",
            "1985",
            "1985"
        ],
        "model_ans": "1953",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1953 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was there an attempt to reform the law of the EU?",
        "answers": [
            "Following the Nice Treaty",
            "2004",
            "Following the Nice Treaty",
            "Following the Nice Treaty"
        ],
        "model_ans": "1992",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What two country's referendums curtailed a constitution for Europe?",
        "answers": [
            "referendum in France and the referendum in the Netherlands",
            "the referendum in France and the referendum in the Netherlands",
            "referendum in France and the referendum in the Netherlands",
            "the referendum in France and the referendum in the Netherlands"
        ],
        "model_ans": "Ireland and Denmark",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ireland and Denmark </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How similar was the Lisbon Treaty to the constitutional treaty?",
        "answers": [
            "very similar",
            "very similar",
            "very similar",
            "very similar"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of treaty was the Lisbon Treaty?",
        "answers": [
            "an amending treaty",
            "an amending treaty",
            "an amending treaty",
            "an amending treaty"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Is the Lisbon Treaty one that would alter existing treaties or replace them?",
        "answers": [
            "altered the existing treaties",
            "it significantly altered the existing treaties",
            "significantly altered the existing treaties",
            "altered the existing treaties"
        ],
        "model_ans": "replace",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> replace </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What reform was attempted following the Nice Treaty?",
        "answers": [
            "there was an attempt to reform the constitutional law of the European Union and make it more transparent",
            "an attempt to reform the constitutional law of the European Union and make it more transparent",
            "there was an attempt to reform the constitutional law of the European Union and make it more transparent",
            "an attempt to reform the constitutional law of the European Union and make it more transparent"
        ],
        "model_ans": "Lisbon Treaty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lisbon Treaty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was an additional projected effect of the attempted reform?",
        "answers": [
            "this would have also produced a single constitutional document",
            "this would have also produced a single constitutional document",
            "would have also produced a single constitutional document",
            "this would have also produced a single constitutional document"
        ],
        "model_ans": "increased transparency",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> increased transparency </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which caused the reform to never come into force?",
        "answers": [
            "the referendum in France and the referendum in the Netherlands",
            "the referendum in France and the referendum in the Netherlands",
            "the referendum in France and the referendum in the Netherlands",
            "the referendum in France and the referendum in the Netherlands"
        ],
        "model_ans": "The Reform Act of 1832",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Reform Act of 1832 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What treaty took the place of constitutional treaty? ",
        "answers": [
            "the Lisbon Treaty",
            "the Lisbon Treaty",
            "the Lisbon Treaty",
            "the Lisbon Treaty"
        ],
        "model_ans": "Lisbon Treaty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lisbon Treaty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the main executive body of the EU?",
        "answers": [
            "The European Commission",
            "The European Commission",
            "The European Commission",
            "The European Commission"
        ],
        "model_ans": "European Commission",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Commission </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the sole governing authority capable of initiating legislative proposals?",
        "answers": [
            "the Commission",
            "The European Commission",
            "the Commission",
            "the Commission"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which authority figure is designated to schedule and set the work of the EU?",
        "answers": [
            "The Commission's President",
            "The Commission's President",
            "The Commission's President",
            "The Commission's President ("
        ],
        "model_ans": "European Commission",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Commission </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "For each of the 28 member states, how many Commissioner's are represented for each one?",
        "answers": [
            "one Commissioner for each of the 28 member states",
            "one",
            "one",
            "one"
        ],
        "model_ans": "1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the current President and the High Representative for Foreign and Security Policy?",
        "answers": [
            "Federica Mogherini",
            "Jean-Claude Juncker",
            "Jean-Claude Juncker",
            "Jean-Claude Juncker"
        ],
        "model_ans": "Ursula von der Leyen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ursula von der Leyen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which article of the Treaty on European Union states that Commissioners should be completely independent and not take instructions from any Government?",
        "answers": [
            "Article 17(3)",
            "Article 17(3)",
            "Article 17(3)",
            "Article 17(3)"
        ],
        "model_ans": "Article 17",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " Article 17 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who sets the agenda for the EU's work?",
        "answers": [
            "The Commission's President",
            "The Commission's President",
            "The Commission's President",
            "The Commission's President"
        ],
        "model_ans": "European Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are decisions made on behave of the EU made?",
        "answers": [
            "simple majority vote",
            "simple majority vote",
            "a simple majority vote",
            "a simple majority"
        ],
        "model_ans": "By the European Parliament, the European Council, and the European Commission",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By the European Parliament, the European Council, and the European Commission </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country refused to content to changes in the Treaty of Lisbon 2007?",
        "answers": [
            "Ireland",
            "Ireland",
            "Ireland",
            "Ireland"
        ],
        "model_ans": "Poland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Poland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who are the un-elected subordinates of member state governments?",
        "answers": [
            "Commissioners",
            "Commissioners",
            "Commissioners",
            "Commissioners"
        ],
        "model_ans": "EU officials",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> EU officials </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What commission was censured in 1999, and paved the way for Commissioners to abuse their power?",
        "answers": [
            "the Santer Commission",
            "the Santer Commission",
            "the Santer Commission",
            "the Santer Commission"
        ],
        "model_ans": "SEC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> SEC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Did the European Court of Justice rule the defendant in the case of Commission v. Edith Cresson broke any laws?",
        "answers": [
            "did in fact not break any law",
            "not",
            "not",
            "not"
        ],
        "model_ans": "No",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who found that there was a developed culture of Commissioner's who lacked responsibility?",
        "answers": [
            "Committee of Independent Experts",
            "a Committee of Independent Experts",
            "Committee of Independent Experts",
            "Committee of Independent Experts"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who appoints the board of the European Central Bank?",
        "answers": [
            "European Council",
            "the European Council",
            "the European Council",
            "the European Council"
        ],
        "model_ans": "European Council",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Council </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Can the President of the Council vote on important matters related to the European Central Bank?",
        "answers": [
            "do not have voting rights",
            "not",
            "not",
            "not"
        ],
        "model_ans": "No",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Santer Commission censured by Parliament?",
        "answers": [
            "1999",
            "1999",
            "1999",
            "1999"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The censuring of the Santer Commission  resulted in which main case?",
        "answers": [
            "Commission v Edith Cresson",
            "Commission v Edith Cresson",
            "Commission v Edith Cresson",
            "Commission v Edith Cresson"
        ],
        "model_ans": "The European Monetary System",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The European Monetary System </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who found that a culture had developed where few Commissioners had any sense of responsibility?",
        "answers": [
            "a Committee of Independent Experts",
            "a Committee of Independent Experts",
            "Committee of Independent Experts",
            "Committee of Independent Experts"
        ],
        "model_ans": "Lord Denning",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lord Denning </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The corruption found by the Committee of Independent Experts resulted to the creation of what office?",
        "answers": [
            "the European Anti-fraud Office",
            "the European Anti-fraud Office",
            "the European Anti-fraud Office",
            "the European Anti-fraud Office"
        ],
        "model_ans": "European Anti-Fraud Office",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Anti-Fraud Office </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the European Anti-Fraud Office investigate John Dalli?",
        "answers": [
            "2012",
            "2012",
            "2012",
            "2012"
        ],
        "model_ans": "2012\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2012\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The legislative body, the Council, are made up of what type of individuals?",
        "answers": [
            "different ministers of the member states",
            "ministers",
            "different ministers of the member states",
            "different ministers of the member states"
        ],
        "model_ans": "Members",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Members </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is currently the President of the Council?",
        "answers": [
            "Donald Tusk",
            "Poland Prime Minister Donald Tusk",
            "Donald Tusk",
            "Donald Tusk"
        ],
        "model_ans": "Michel Barnier",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michel Barnier </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are the votes weighted to ensure that smaller states aren't dominated by larger ones?",
        "answers": [
            "inversely",
            "it is weighted inversely to member state size",
            "it is weighted inversely to member state size",
            "weighted inversely to member state size"
        ],
        "model_ans": "Equal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Equal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the total number of votes to be counted during the voting process?",
        "answers": [
            "352",
            "352 votes",
            "352",
            "352"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Currently, how many votes out of the 352 total votes are needed for a majority?",
        "answers": [
            "260",
            "260",
            "260",
            "260"
        ],
        "model_ans": "176\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "176\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which entity is the secondary legislative body?",
        "answers": [
            "the Council",
            "the Council",
            "the Council",
            "the Council"
        ],
        "model_ans": "Senate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Senate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How often does the European Council meet?",
        "answers": [
            "each six months",
            "each six months",
            "each six months",
            "each six months"
        ],
        "model_ans": "twice a year",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> twice a year </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many votes in total does the Council have?",
        "answers": [
            "352",
            "352",
            "352",
            "352"
        ],
        "model_ans": "193",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 193 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is defined as the majority vote?",
        "answers": [
            "at least 55 per cent of the Council members (not votes) representing 65 per cent of the population of the EU",
            "74 per cent, or 260 of the 352 votes",
            "74 per cent, or 260 of the 352 votes",
            "74 per cent, or 260 of the 352 votes"
        ],
        "model_ans": "More than half",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> More than half </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of vote must the Parliament have to either block or suggest changes to the Commission's proposals?",
        "answers": [
            "a majority",
            "a Commission proposal",
            "a Commission proposal",
            "a Commission proposal"
        ],
        "model_ans": "qualified majority",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> qualified majority </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of vote must the Council pass in order to approve of any changes recommended by Parliament? ",
        "answers": [
            "qualified majority",
            "qualified majority",
            "a majority",
            "a majority"
        ],
        "model_ans": "Unanimous",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unanimous </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Is it easier or harder to change EU law than stay the same?",
        "answers": [
            "harder",
            "harder",
            "harder",
            "harder"
        ],
        "model_ans": "harder",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> harder </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What articles state that unless conferred, powers remain with member states?",
        "answers": [
            "TEU articles 4 and 5",
            "TEU articles 4 and 5",
            "TEU articles 4 and 5",
            "TEU articles 4 and 5"
        ],
        "model_ans": "Article 5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Article 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Within the EU, which court believes they have the final word deciding on EU's competence?",
        "answers": [
            "Court of Justice",
            "the Court of Justice",
            "the Court of Justice",
            "the Court of Justice"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which TFEU article defines the ordinary legislative procedure that applies for majority of EU acts?",
        "answers": [
            "TFEU article 294",
            "TFEU article 294",
            "TFEU article 294",
            "TFEU article 294"
        ],
        "model_ans": "Article 289",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Article 289 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can block a legislation?",
        "answers": [
            "legislation can be blocked by a majority in Parliament, a minority in the Council, and a majority in the Commission",
            "unanimity",
            "unanimity",
            "a majority in Parliament"
        ],
        "model_ans": "Veto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Veto </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which articles state that powers stay with member states unless they've been conferred?",
        "answers": [
            "TEU articles 4 and 5",
            "TEU articles 4 and 5",
            "TEU articles 4 and 5",
            "TEU articles 4 and 5"
        ],
        "model_ans": "Treaty on European Union",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Treaty on European Union </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What entity is created if the three different institutions cannot come to a consensus at any stage?",
        "answers": [
            "Conciliation Committee",
            "a \"Conciliation Committee\"",
            "a \"Conciliation Committee\"",
            "a \"Conciliation Committee\""
        ],
        "model_ans": "Arbitration",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arbitration </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which branch of the EU has had the most influence on the development of EU law?",
        "answers": [
            "judicial branch",
            "The judicial branch",
            "The judicial branch",
            "The judicial branch"
        ],
        "model_ans": "European Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the main judicial body of the EU?",
        "answers": [
            "Court of Justice of the European Union (CJEU)",
            "the Court of Justice of the European Union (CJEU)",
            "the Court of Justice of the European Union (CJEU)",
            "the Court of Justice of the European Union (CJEU)"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many total judges are there in the EU?",
        "answers": [
            "28",
            "28",
            "28",
            "28"
        ],
        "model_ans": "27",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 27 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under which courts is most EU law applied?",
        "answers": [
            "member state courts",
            "member state courts",
            "member state courts",
            "member state courts"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the CJEU's duty?",
        "answers": [
            "ensure that in the interpretation and application of the Treaties the law is observed",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\"",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\"",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\""
        ],
        "model_ans": "To interpret EU law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To interpret EU law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is the judicial branch of the EU an important factor in the development of EU law?",
        "answers": [
            "by assuming the task of interpreting the treaties, and accelerating economic and political integration",
            "assuming the task of interpreting the treaties, and accelerating economic and political integration",
            "has the ability to expand and develop the law according to the principles it deems to be appropriate",
            "has the ability to expand and develop the law according to the principles it deems to be appropriate"
        ],
        "model_ans": "The judicial branch of the EU plays a crucial role in interpreting EU law and ensuring its uniform application across member states.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The judicial branch of the EU plays a crucial role in interpreting EU law and ensuring its uniform application across member states. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the current main judicial body of the EU?",
        "answers": [
            "the Court of Justice of the European Union",
            "the Court of Justice of the European Union (CJEU)",
            "the Court of Justice of the European Union (CJEU)",
            "the Court of Justice of the European Union (CJEU)"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What entity deals with EU staff issues?",
        "answers": [
            "Civil Service Tribunal",
            "Civil Service Tribunal",
            "Civil Service Tribunal",
            "Civil Service Tribunal"
        ],
        "model_ans": "European Commission",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Commission </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long is one term for an elected president of the CJEU?",
        "answers": [
            "three years",
            "three years",
            "three years",
            "three years"
        ],
        "model_ans": "6 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the CJEU's duty?",
        "answers": [
            "to \"ensure that in the interpretation and application of the Treaties the law is observed\"",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\"",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\"",
            "\"ensure that in the interpretation and application of the Treaties the law is observed\""
        ],
        "model_ans": "To interpret EU law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To interpret EU law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If there is a conflict between EU law and national law, which law take precedence?",
        "answers": [
            "EU law",
            "EU law has primacy",
            "EU law has primacy",
            "EU law"
        ],
        "model_ans": "EU law",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU law </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the reason the Italian Constitutional court gave that resulted in Mr. Costa losing his his claim against ENEL?",
        "answers": [
            "nationalisation law was from 1962, and the treaty was in force from 1958",
            "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim",
            "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim",
            "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim"
        ],
        "model_ans": "lack of jurisdiction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> lack of jurisdiction </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the years two Regulations that conflicted with an Italian law originate in the Simmenthal SpA case? ",
        "answers": [
            "1964 and 1968",
            "1964 and 1968",
            "1964 and 1968",
            "1964 and 1968"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which entities have had to develop principles dedicated to conflict resolution between laws of different systems?",
        "answers": [
            "the European Court of Justice and the highest national courts",
            "the European Court of Justice and the highest national courts",
            "the European Court of Justice and the highest national courts",
            "the European Court of Justice and the highest national courts"
        ],
        "model_ans": "International Committee of the Red Cross",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> International Committee of the Red Cross </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Costa v ENEL take place?",
        "answers": [
            "1964",
            "1964",
            "1964",
            "1964"
        ],
        "model_ans": "1964\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1964\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which court argued that the Treaty of Rome did not prevent energy nationalism?",
        "answers": [
            "the Court of Justice",
            "the Court of Justice",
            "The Italian Constitutional Court",
            "The Italian Constitutional Court"
        ],
        "model_ans": "European Court of Justice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Court of Justice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do all member states agree takes precedence over national law?",
        "answers": [
            "EU law",
            "EU law",
            "EU law",
            "EU law"
        ],
        "model_ans": "EU law",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU law </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What issues do member states say the Court of Justice does not have the final say on?",
        "answers": [
            "foundational constitutional questions affecting democracy and human rights",
            "foundational constitutional questions affecting democracy and human rights",
            "foundational constitutional questions affecting democracy and human rights",
            "on foundational constitutional questions affecting democracy and human rights"
        ],
        "model_ans": "issues of national security",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> issues of national security </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the European Communities Act created?",
        "answers": [
            "1972",
            "1972",
            "1972",
            "1972"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what cases can the EU not override German law?",
        "answers": [
            "if the EU does not comply with its basic constitutional rights and principles",
            "if the EU does not comply with its basic constitutional rights and principles",
            "if the EU does not comply with its basic constitutional rights and principles"
        ],
        "model_ans": "In cases where the German constitution (Basic Law) explicitly prohibits it",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In cases where the German constitution (Basic Law) explicitly prohibits it </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the EU's legitimacy rest on?",
        "answers": [
            "the ultimate authority of member states, its factual commitment to human rights, and the democratic will of the people.",
            "the ultimate authority of member states, its factual commitment to human rights, and the democratic will of the people",
            "the ultimate authority of member states",
            "the ultimate authority of member states"
        ],
        "model_ans": "democratic principles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> democratic principles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which type of law makes EU institutions and its member states follow the law?",
        "answers": [
            "administrative law",
            "administrative law",
            "administrative law"
        ],
        "model_ans": "Supranational law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Supranational law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what year were citizens or corporations said to not be able to bring claims against other non state parties?",
        "answers": [
            "1986",
            "1986",
            "1986"
        ],
        "model_ans": "1976",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which actions by EU institutions can be subject to judicial review?",
        "answers": [
            "All actions",
            "All actions by EU institutions can be subject to judicial review",
            "All actions"
        ],
        "model_ans": "All actions",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> All actions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which type of law concerns the EU's governance structure?",
        "answers": [
            "constitutional law",
            "constitutional law",
            "constitutional law"
        ],
        "model_ans": "EU law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which case was it held that the provisions of the treaties are directly effective if they are clear, unconditional, and don't require further action by EU or national authorities?",
        "answers": [
            "Van Gend en Loos v Nederlandse Administratie der Belastingen",
            "Van Gend en Loos v Nederlandse Administratie der Belastingen",
            "Van Gend en Loos v Nederlandse Administratie der Belastingen"
        ],
        "model_ans": "Costa v ENEL",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Costa v ENEL </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which TEFU article states that no quantitative restrictions can be placed on trade?",
        "answers": [
            "article 30",
            "TFEU article 30",
            "TFEU article 30"
        ],
        "model_ans": "Article XI",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Article XI </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of company is Van Gend en Loos?",
        "answers": [
            "a postal company",
            "a postal company",
            "a postal company"
        ],
        "model_ans": "Law firm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Law firm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are EU Regulations essentially the same as in the case mentioned?",
        "answers": [
            "Treaty provisions",
            "EU Regulations are the same as Treaty provisions in this sense, because as TFEU article 288 states, they are \u2018directly applicable in all Member States\u2019",
            "they are \u2018directly applicable in all Member States\u2019"
        ],
        "model_ans": "US Regulations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> US Regulations </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What generally does not allow citizens to sue other citizens?",
        "answers": [
            "Directives",
            "Directives",
            "Directives"
        ],
        "model_ans": "Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many paid holiday days does the Working Time directive require workers to have each year?",
        "answers": [
            "4 weeks",
            "4 weeks paid holidays each year",
            "4 weeks paid"
        ],
        "model_ans": "20\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "20\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many paid holiday days do most member states require?",
        "answers": [
            "28 days",
            "more than 28 days",
            "more than 28 days"
        ],
        "model_ans": "20-30 days\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "20-30 days\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the three Advocate Generals argue that Directives should create rights and duties for all citizens?",
        "answers": [
            "early 1990s",
            "the early 1990s",
            "early 1990s"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens first if a Directive's deadline for implementation is not met?",
        "answers": [
            "the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action",
            "the member state cannot enforce conflicting laws",
            "the member state cannot enforce conflicting laws"
        ],
        "model_ans": "The Member State is sent a formal notice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Member State is sent a formal notice </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens secondly if a Directive's deadline is not met?",
        "answers": [
            "a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company",
            "a citizen may rely on the Directive in such an action (so called \"vertical\" direct effect)",
            "a citizen may rely on the Directive in such an action"
        ],
        "model_ans": "The Directive is repealed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Directive is repealed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long did Ms Kucukdeveci work for Swedex Gmbh & Co KG before she was dismissed?",
        "answers": [
            "10 years",
            "10 years",
            "10 years"
        ],
        "model_ans": "10 years",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which company did Mrs Foster work for?",
        "answers": [
            "British Gas plc",
            "British Gas plc",
            "British Gas plc"
        ],
        "model_ans": "Foster's Lager",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Foster's Lager </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what age did British Gas plc force their workers to retire?",
        "answers": [
            "women retire at age 60 and men at 65",
            "women retire at age 60 and men at 65",
            "women retire at age 60 and men at 65"
        ],
        "model_ans": "65\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "65\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which courts have a duty to interpret domestic law as far as possible?",
        "answers": [
            "national courts",
            "national courts",
            "national courts"
        ],
        "model_ans": "Courts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Courts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the First Company Law Directive article 11 require?",
        "answers": [
            "incorporations would only be nullified for a fixed list of reasons",
            "incorporations would only be nullified for a fixed list of reasons",
            "incorporations would only be nullified for a fixed list of reasons"
        ],
        "model_ans": "The First Company Law Directive article 11 requires that the annual accounts of a company must be drawn up in accordance with the provisions of the directive",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The First Company Law Directive article 11 requires that the annual accounts of a company must be drawn up in accordance with the provisions of the directive </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Italian government fail to do in Francovich v Italy?",
        "answers": [
            "failed to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent",
            "to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent, as the Insolvency Protection Directive required",
            "to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent, as the Insolvency Protection Directive required"
        ],
        "model_ans": "Implement a law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Implement a law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much money was Francovich allowed to claim from the Italian goverment in damages?",
        "answers": [
            "6 million Lira",
            "6 million Lira",
            "6 million Lira"
        ],
        "model_ans": "60 million euros",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60 million euros </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which entity developed the principles of European Union Law?",
        "answers": [
            "the European Court of Justice",
            "the European Court of Justice",
            "the European Court"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some of the accepted general principles of European Union law?",
        "answers": [
            "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity",
            "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity",
            "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity"
        ],
        "model_ans": "Direct effect, supremacy, state liability, and the principle of proportionality",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Direct effect, supremacy, state liability, and the principle of proportionality </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long has Proportionality been recognized as one of the general principles of EU law?",
        "answers": [
            "since the 1950s",
            "since the 1950s",
            "since the 1950s"
        ],
        "model_ans": "1969",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1969 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the principle of proportionality recognized in the EC treaty?",
        "answers": [
            "in Article 5",
            "the lawfulness of an action depends on whether it was appropriate and necessary to achieve the objectives legitimately pursued",
            "Article 5"
        ],
        "model_ans": "Article 5",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Article 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which measure must be adopted when there is a choice between several?",
        "answers": [
            "the least onerous",
            "the least onerous must be adopted",
            "the least onerous must be adopted"
        ],
        "model_ans": "Pareto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pareto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long has the concept of legal certainty been recognized as one of the general principles by the EU law?",
        "answers": [
            "since the 1960s",
            "since the 1960s",
            "since the 1960s"
        ],
        "model_ans": "1958",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1958 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which laws mentioned predate EU law?",
        "answers": [
            "international law and public law",
            "international law and public law",
            "international law and public law"
        ],
        "model_ans": "Roman Law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Roman Law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What must the adoption of laws which will have legal effect in the EU have?",
        "answers": [
            "a proper legal basis",
            "a proper legal basis",
            "a proper legal basis"
        ],
        "model_ans": "be approved by the European Parliament",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> be approved by the European Parliament </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what does the doctrine of legitimate expectations have roots?",
        "answers": [
            "the principles of legal certainty and good faith",
            "the principles of legal certainty and good faith",
            "the principles of legal certainty and good faith"
        ],
        "model_ans": "Administrative law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Administrative law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the European Court of justice likely to get inspiration from?",
        "answers": [
            "from the constitutional traditions common to the member states",
            "the constitutional traditions common to the member states",
            "the constitutional traditions common to the member states"
        ],
        "model_ans": "Roman Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Roman Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The European Court of Justice cannot uphold measures that are incompatible with what?",
        "answers": [
            "fundamental rights recognised and protected in the constitutions of member states",
            "fundamental rights recognised and protected in the constitutions of member states",
            "fundamental rights recognised and protected in the constitutions of member states"
        ],
        "model_ans": "the Treaty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the Treaty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many original treaties establishing the EU protected fundamental rights?",
        "answers": [
            "None",
            "None",
            "None"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which entities were originally concerned with preventing violation of human rights?",
        "answers": [
            "member states",
            "the European Convention on Human Rights",
            "the European Convention on Human Rights in 1950 and the establishment of the European Court of Human Rights"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the European Convention on Human Rights established?",
        "answers": [
            "1950",
            "1950",
            "1950"
        ],
        "model_ans": "1950\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1950\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What other entity was established at the same time as the European Convention on Human Rights?",
        "answers": [
            "European Court of Human Rights.",
            "the European Court of Human Rights",
            "European Court of Human Rights"
        ],
        "model_ans": "NATO",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NATO </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the European Council task an entity with drafting a European Charter of Human Rights?",
        "answers": [
            "1999",
            "1999",
            "1999"
        ],
        "model_ans": "1950",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Lisbon Treaty established?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2007\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What charter has become an important aspect of EU law?",
        "answers": [
            "the Charter of Fundamental Rights of the European Union",
            "the Charter of Fundamental Rights of the European Union of 7",
            "the Charter of Fundamental Rights of the European Union"
        ],
        "model_ans": "Charter of Fundamental Rights",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Charter of Fundamental Rights</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After the Lisbon treaty, the Charter and the Convention now co-exist under what?",
        "answers": [
            "European Union law",
            "European Union law",
            "European Union law"
        ],
        "model_ans": "EU Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> EU Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What entity enforces the Charter of Fundamental Rights of the European Union?",
        "answers": [
            "European Court of Justice",
            "European Court of Justice",
            "the European Court of Justice"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Social Chapter is a chapter of what treaty?",
        "answers": [
            "1997 Treaty of Amsterdam",
            "the 1997 Treaty of Amsterdam",
            "the 1997 Treaty of Amsterdam"
        ],
        "model_ans": "Treaty of Amsterdam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Amsterdam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year was the Treaty of Amsterdam created?",
        "answers": [
            "1997",
            "1997",
            "1997"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the basis for the Social Chapter developed?",
        "answers": [
            "1989",
            "1989",
            "1989"
        ],
        "model_ans": "1992",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many general principles does the Social Charter declare?",
        "answers": [
            "30",
            "30",
            "30"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many pieces of legislation has the Social Charter become the basis for?",
        "answers": [
            "40",
            "40",
            "40"
        ],
        "model_ans": "80",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many member states adopted the Social Charter in 1989?",
        "answers": [
            "11 of the then 12 member states",
            "11 of the then 12 member states",
            "11"
        ],
        "model_ans": "11\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "11\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which member state declined to sign the Social Charter?",
        "answers": [
            "The UK",
            "UK",
            "UK"
        ],
        "model_ans": "United States",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What title was the Social Charter set to be included into the Maastricht treaty under?",
        "answers": [
            "the \"Social Chapter\"",
            "the \"Social Chapter\"",
            "\"Social Chapter\""
        ],
        "model_ans": "Pillar III",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pillar III </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year was the Maastricht treaty signed?",
        "answers": [
            "1992",
            "1992",
            "1992"
        ],
        "model_ans": "1992\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1992\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What lead to the UK to subscribe to the agreement on Social Policy?",
        "answers": [
            "the election of the UK Labour Party to government",
            "the election of the UK Labour Party to government in 1997",
            "the election of the UK Labour Party to government"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the UK formally subscribe to the Agreement on Social Policy?",
        "answers": [
            "1997",
            "1997",
            "1997"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which directive mentioned was created in 1994?",
        "answers": [
            "Works Council Directive",
            "the 1994 Works Council Directive",
            "Works Council Directive"
        ],
        "model_ans": "94/46/EC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 94/46/EC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Parental Leave directive created?",
        "answers": [
            "1996",
            "1996",
            "1996"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Works Council Directive require?",
        "answers": [
            "workforce consultation in businesses",
            "workforce consultation in businesses",
            "workforce consultation in businesses"
        ],
        "model_ans": "employee involvement",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> employee involvement </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which countries were the European Coal and Steel Community agreement between?",
        "answers": [
            "France, Italy, Belgium, the Netherlands, Luxembourg and Germany",
            "France, Italy, Belgium, the Netherlands, Luxembourg and Germany",
            "France, Italy, Belgium, the Netherlands, Luxembourg and Germany"
        ],
        "model_ans": "France, Germany, Italy, Belgium, Netherlands, Luxembourg",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France, Germany, Italy, Belgium, Netherlands, Luxembourg </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year was the ECSC agreement established?",
        "answers": [
            "1951",
            "1951",
            "1951"
        ],
        "model_ans": "1952\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1952\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did article 65 of the ECSC ban?",
        "answers": [
            "cartels",
            "cartels",
            "cartels"
        ],
        "model_ans": "Coal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Coal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which article made provisions for concentrations or mergers and the abuse of a dominant position by companies?",
        "answers": [
            "article 66",
            "66",
            "66"
        ],
        "model_ans": "Treaty of Rome",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Rome </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were competition rules included in the Treaty of Rome?",
        "answers": [
            "1957",
            "1957",
            "1957"
        ],
        "model_ans": "1957",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1957 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which article does the Treaty of Lisbon prohibit anti-competitive agreements?",
        "answers": [
            "Article 101(1)",
            "Article 101(1)",
            "Article 101(1)"
        ],
        "model_ans": "Article 101",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Article 101 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Article 102 of the Treaty of Lisbon prohibit?",
        "answers": [
            "the abuse of dominant position",
            "the abuse of dominant position",
            "abuse of dominant position"
        ],
        "model_ans": "abuse of dominant position",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> abuse of dominant position </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which articles state that the member states' rights to deliver public services may not be obstructed?",
        "answers": [
            "Articles 106 and 107",
            "Articles 106 and 107",
            "Articles 106 and 107"
        ],
        "model_ans": "Treaty on the Functioning of the European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty on the Functioning of the European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which article allows the European Council to govern mergers between firms?",
        "answers": [
            "Article 102",
            "Article 102",
            "Article 102"
        ],
        "model_ans": "Merger Regulation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Merger Regulation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the concept of a social market economy introduced into EU law?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "1957",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1957 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long has free movement and trade been central to European development?",
        "answers": [
            "1957",
            "1957",
            "since the Treaty of Rome 1957"
        ],
        "model_ans": "1958",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1958 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Breaking down barriers to trade and enhancing the free movement of goods is meant to reduce what?",
        "answers": [
            "consumer prices",
            "consumer prices",
            "reduce consumer prices"
        ],
        "model_ans": "tariffs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> tariffs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the Treaties generally limit?",
        "answers": [
            "free trade",
            "free trade",
            "free trade"
        ],
        "model_ans": "Sovereignty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sovereignty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": " What entity has taken the view that the goals of free trade are underpinned by the aims to improve people's well being?",
        "answers": [
            "the Court of Justice",
            "the Court of Justice",
            "the Court of Justice"
        ],
        "model_ans": "World Trade Organization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World Trade Organization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What helps the process of free movement of goods?",
        "answers": [
            "a customs union, and the principle of non-discrimination",
            "a customs union",
            "a customs union"
        ],
        "model_ans": "Tariffs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tariffs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did did article 34 discriminate against in Procureur du Roi v Dassonville?",
        "answers": [
            "parallel importers like Mr Dassonville",
            "parallel importers",
            "parallel importers"
        ],
        "model_ans": "goods",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> goods </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Article 34 meant states could be responsible for what?",
        "answers": [
            "private actors",
            "private actors",
            "private actors"
        ],
        "model_ans": "Genocide",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Genocide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which case were French vigilantes sabotaging shipments of Spanish Strawberries?",
        "answers": [
            "Commission v France",
            "Commission v France French",
            "Commission v France French"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In Schmidberger v Austria, the Court of Justice came to the conclusion that Austria didn't infringe upon article 34 by failing to ban a what?",
        "answers": [
            "a protest that blocked heavy traffic",
            "a protest",
            "a protest"
        ],
        "model_ans": "film",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> film </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the minimum percent of alcohol content a German law requires all spirits and liqueurs to have?",
        "answers": [
            "25",
            "25 per cent",
            "25 per cent"
        ],
        "model_ans": "37%\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "37%\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country did Rewe-Zentrale AG wish to import from?",
        "answers": [
            "France",
            "France",
            "France"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which year was the case Commission v Italy that dealt with cocoa products?",
        "answers": [
            "2003",
            "2003",
            "2003"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "All Italian chocolate is made from what alone?",
        "answers": [
            "cocoa butter",
            "cocoa butter",
            "cocoa butter"
        ],
        "model_ans": "Cacao",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cacao </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": " In the 2009 Commission v Italy, case, the Court of Justice held that an Italian low prohibiting what infringed article 34?",
        "answers": [
            "motorcycles or mopeds pulling trailers",
            "motorcycles or mopeds pulling trailers",
            "motorcycles or mopeds pulling trailers"
        ],
        "model_ans": "the free movement of goods",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the free movement of goods </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which two importers claimed that under a French competition law, they were prevented from selling Picon beer under wholesale price?",
        "answers": [
            "Keck and Mithouard",
            "Keck and Mithouard",
            "Keck and Mithouard"
        ],
        "model_ans": "Heineken and Kronenbourg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Heineken and Kronenbourg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The aim of the French competition law was to do what?",
        "answers": [
            "cut throat competition",
            "prevent cut throat competition",
            "prevent cut throat competition"
        ],
        "model_ans": "regulate the economy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> regulate the economy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which case did the Court of Justice review Swedish bans on advertising to young children under 12?",
        "answers": [
            "Konsumentombudsmannen v De Agostini",
            "Konsumentombudsmannen v De Agostini",
            "Konsumentombudsmannen v De Agostini"
        ],
        "model_ans": "Pfleiderer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Pfleiderer</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under which Directive did the EU harmonize restrictions on restrictions on marketing and advertising?",
        "answers": [
            "the Unfair Commercial Practices Directive",
            "the Unfair Commercial Practices Directive",
            "the Unfair Commercial Practices Directive"
        ],
        "model_ans": "EU Tobacco Products Directive",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> EU Tobacco Products Directive </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What have the Treaties sought to enable since its foundation?",
        "answers": [
            "to enable people to pursue their life goals in any country through free movement",
            "people to pursue their life goals in any country through free movement",
            "Since its foundation"
        ],
        "model_ans": "International cooperation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> International cooperation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which entity focused upon the free movement of workers?",
        "answers": [
            "the European Community",
            "the European Community",
            "the European Community"
        ],
        "model_ans": "European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was free movement increasingly based on?",
        "answers": [
            "citizenship",
            "\"citizenship\"",
            "\"citizenship\""
        ],
        "model_ans": "Schengen Agreement",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Schengen Agreement </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which case did a German man claim the right to live in Netherlands where he was a volunteer plumber?",
        "answers": [
            "Steymann v Staatssecretaris van Justitie",
            "Steymann v Staatssecretaris van Justitie",
            "Steymann v Staatssecretaris van Justitie"
        ],
        "model_ans": "The Netherlands",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Netherlands </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Court of Justice say Steymann was entitled to?",
        "answers": [
            "to stay, so long as there was at least an \"indirect quid pro quo\" for the work he did",
            "stay",
            "stay"
        ],
        "model_ans": "a pension",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a pension </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which articles of the Free Movement of Workers Regulation set out the primary provisions on equal treatment of workers?",
        "answers": [
            "articles 1 to 7",
            "articles 1 to 7",
            "articles 1 to 7"
        ],
        "model_ans": "Articles 1-14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Articles 1-14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which Belgian footballer claimed that he should be allowed to transfer from one football club to another when his contract was fulfilled?",
        "answers": [
            "Jean-Marc Bosman",
            "the Belgian Football Association v Bosman",
            "Jean-Marc Bosman"
        ],
        "model_ans": "Romelu Lukaku",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Romelu Lukaku </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What language did the Court of Justice accept to be required to teach in a Dublin college in Groner v Minister for Education?",
        "answers": [
            "Gaelic",
            "Gaelic",
            "Gaelic"
        ],
        "model_ans": "Irish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Irish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which case was a Dutch national not entitled to continue receiving benefits when he moved to Belgium?",
        "answers": [
            "Hendrix v Employee",
            "Hendrix v Employee Insurance Institute",
            "Hendrix v Employee Insurance Institute"
        ],
        "model_ans": "Bosman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bosman</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the case Geven v Land Nordrhein-Westfalen, how many hours was the Dutch woman in question working in Germany?",
        "answers": [
            "between 3 and 14 hours a week",
            "3 and 14 hours a week",
            "between 3 and 14 hours a week"
        ],
        "model_ans": "40 hours",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40 hours </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has lately been being viewed as a fundamental status of member state nationals by the Court of Justice?",
        "answers": [
            "Citizenship of the EU",
            "Citizenship of the EU",
            "Citizenship of the EU"
        ],
        "model_ans": "Citizenship",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Citizenship </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has having an EU Citizenship increased?",
        "answers": [
            "the number of social services that people can access wherever they move",
            "the number of social services that people can access wherever they move",
            "the number of social services that people can access wherever they move"
        ],
        "model_ans": "mobility",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mobility </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which case did the Court state that Austria was not allowed to hold places in Austrian schools exclusively for Austrian students?",
        "answers": [
            "Commission v Austria",
            "Commission v Austria the Court",
            "Commission v Austria"
        ],
        "model_ans": "Bakke v. Regents of the University of California",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bakke v. Regents of the University of California</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the Court required to be more accessible?",
        "answers": [
            "higher education",
            "higher education",
            "higher education"
        ],
        "model_ans": "The internet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The internet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which Treaty protects the freedom of establishment and the freedom to provide services?",
        "answers": [
            "the Treaty on the Functioning of the European Union",
            "the Treaty on the Functioning of the European Union",
            "the Treaty on the Functioning of the European Union"
        ],
        "model_ans": "Treaty on the Functioning of the European Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty on the Functioning of the European Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In Gebhard v Consiglio...Milano, the requirements to be registered in Milan before being able to practice law would be allowed under what conditions?",
        "answers": [
            "if they were non-discriminatory",
            "if they were non-discriminatory, \"justified by imperative requirements in the general interest\" and proportionately applied",
            "participate in economic life \"on a stable and continuous basis\""
        ],
        "model_ans": "domicile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> domicile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which case did the Court of Justice state that refusal to admit a lawyer to the Belgian bar because he did not have Belgian heritage wasn't able to be justified?",
        "answers": [
            "Reyners v Belgium",
            "Reyners v Belgium the Court of Justice",
            "Reyners v Belgium"
        ],
        "model_ans": "Vanacker",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vanacker </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which TFEU article states that states are exempt from infringing on rights of establishment when they exercise official authority?",
        "answers": [
            "article 49",
            "TFEU article 49",
            "article 49"
        ],
        "model_ans": "Article 51",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Article 51 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which case did the Court of Justice hold that requiring Italian lawyers to comply with maximum tariffs unless there was an agreement with a client was not a restriction?",
        "answers": [
            "Commission v Italy",
            "Commission v Italy the Court of Justice",
            "Commission v Italy"
        ],
        "model_ans": "Werner Mangold",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Werner Mangold </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which year did a toxic waste spill from a European ship prompt the Commission to look into legislation against waste?",
        "answers": [
            "2006",
            "2006",
            "2006"
        ],
        "model_ans": "1991",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1991 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At the time, countries such as Spain didn't have a crime against what?",
        "answers": [
            "shipping toxic waste",
            "shipping toxic waste",
            "toxic waste"
        ],
        "model_ans": "humanity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> humanity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Court of Justice rule that the Commission could only propose that there must be some criminal sanctions?",
        "answers": [
            "October 2007",
            "2007",
            "2007"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the competence for the Union to create criminal sentences for ecological crimes contested?",
        "answers": [
            "2005",
            "2005",
            "2005"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The freedom to provide services under TFEU article 56 applies to who?",
        "answers": [
            "to people who give services \"for remuneration\"",
            "people who give services \"for remuneration\", especially commercial or professional activity",
            "people who give services \"for remuneration\""
        ],
        "model_ans": "All EU citizens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> All EU citizens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why was the Dutch lawyer who moved to Belgium while advising a client in a social society case told he couldn't continue?",
        "answers": [
            "because Dutch law said only people established in the Netherlands could give legal advice",
            "Dutch law said only people established in the Netherlands could give legal advice",
            "Dutch law said only people established in the Netherlands could give legal advice"
        ],
        "model_ans": "Conflict of interest",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Conflict of interest </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Court of Justice reason were controlled in all member states in Josemans v Burgemeester van Maastricht?",
        "answers": [
            "narcotic drugs",
            "narcotic drugs",
            "narcotic drugs"
        ],
        "model_ans": "Direct effect",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Direct effect </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Dutch health authorities regard as unnecessary in Geraets-Smits v Stichting Ziekenfonds?",
        "answers": [
            "the treatment",
            "treatment",
            "treatment"
        ],
        "model_ans": "euthanasia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> euthanasia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which newspaper's parent company could not evade tax by shifting its residence to the Netherlands?",
        "answers": [
            "the Daily Mail",
            "the Daily Mail",
            "Daily Mail"
        ],
        "model_ans": "De Telegraaf",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> De Telegraaf </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much capital did UK law require to start a company?",
        "answers": [
            "\u00a31",
            "\u00a31",
            "\u00a31"
        ],
        "model_ans": "\u00a350",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a350 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much capital did Danish law require to start a company?",
        "answers": [
            "200,000 Danish krone",
            "200,000 Danish krone",
            "200,000 Danish krone"
        ],
        "model_ans": "3000 DKK",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3000 DKK </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What could justify restrictions on freedom of establishment?",
        "answers": [
            "creditor protection, labour rights to participate in work, or the public interest in collecting taxes",
            "creditor protection, labour rights to participate in work, or the public interest in collecting taxes",
            "Denmark's minimum capital law"
        ],
        "model_ans": "Public health",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public health </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which case did the Court of Justice hold that a German court couldn't deny a Dutch building company the right to enforce a contract based in Germany?",
        "answers": [
            "\u00dcberseering BV v Nordic Construction GmbH",
            "\u00dcberseering BV v Nordic Construction GmbH",
            "\u00dcberseering BV v Nordic Construction GmbH"
        ],
        "model_ans": "Centros Ltd v Erhvervs- og Selskabsstyrelsen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Centros Ltd v Erhvervs- og Selskabsstyrelsen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which name is also used to describe the Amazon rainforest in English?",
        "answers": [
            "also known in English as Amazonia or the Amazon Jungle,",
            "Amazonia or the Amazon Jungle",
            "Amazonia"
        ],
        "model_ans": "Jungle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jungle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many square kilometers of rainforest is covered in the basin?",
        "answers": [
            "5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest.",
            "5,500,000",
            "5,500,000"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many nations control this region in total?",
        "answers": [
            "This region includes territory belonging to nine nations.",
            "nine",
            "nine"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many nations contain \"Amazonas\" in their names?",
        "answers": [
            "States or departments in four nations contain \"Amazonas\" in their names.",
            "four",
            "four"
        ],
        "model_ans": "8",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage does the Amazon represents in rainforests on the planet?",
        "answers": [
            "The Amazon represents over half of the planet's remaining rainforests",
            "over half"
        ],
        "model_ans": "40%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Dutch word for the Amazon rainforest?",
        "answers": [
            "Amazoneregenwoud",
            "Amazoneregenwoud",
            "Amazoneregenwoud"
        ],
        "model_ans": "Amazoneregenwoud",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Amazoneregenwoud </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What rainforest covers the majority of the Amazon basin in South America?",
        "answers": [
            "The Amazon rainforest",
            "Amazon rainforest",
            "The Amazon"
        ],
        "model_ans": "Amazon rainforest",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amazon rainforest </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what country can most of the Amazon rainforest be found?",
        "answers": [
            "Brazil",
            "Brazil",
            "Brazil"
        ],
        "model_ans": "Brazil",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Brazil</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Amazon rainforest makes up what amount of Earth's rainforests?",
        "answers": [
            "over half",
            "over half",
            "over half"
        ],
        "model_ans": "40%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many species of trees can be found in the Amazon rainforest?",
        "answers": [
            "16,000",
            "16,000",
            "16,000"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of forest is the Amazon rainforest?",
        "answers": [
            "moist broadleaf forest",
            "moist broadleaf forest",
            "tropical"
        ],
        "model_ans": "Tropical",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tropical </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many square kilometers is the Amazon Basin?",
        "answers": [
            "7,000,000 square kilometres (2,70",
            "7,000,000",
            "7,000,000 square kilometres"
        ],
        "model_ans": "5,500,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5,500,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many nations are within the Amazon Basin?",
        "answers": [
            "nine nations",
            "nine",
            "nine"
        ],
        "model_ans": "9",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which nation contains the majority of the amazon forest?",
        "answers": [
            "Brazil",
            "Brazil",
            "Brazil"
        ],
        "model_ans": "Brazil",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Brazil</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the estimate for the amount of tree species in the amazon tropical rain forest?",
        "answers": [
            "16,000 species",
            "16,000",
            "16,000"
        ],
        "model_ans": "16,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 16,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which type of climate may have allowed the rainforest to spread across the continent?",
        "answers": [
            "the wetter climate may have allowed the tropical rainforest to spread out across the continent.",
            "wetter",
            "wetter"
        ],
        "model_ans": "Tropical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tropical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has allowed for the Savanna region to expand into the tropics?",
        "answers": [
            "Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics.",
            "Climate fluctuations during the last 34 million years",
            "Climate fluctuations"
        ],
        "model_ans": "Climate change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Climate change </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what time did the rainforest spanned a narrow band? ",
        "answers": [
            "During the Oligocene, for example, the rainforest spanned a relatively narrow band.",
            "Oligocene",
            "Oligocene"
        ],
        "model_ans": "Paleozoic Era",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paleozoic Era </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did it retract to a inland formation?",
        "answers": [
            "It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum.",
            "Middle Miocene",
            "at the last glacial maximum"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Did the rainforest managed to thrive during the glacial periods? ",
        "answers": [
            "However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.",
            "still managed to thrive"
        ],
        "model_ans": "unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>unsure</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": " What may have caused rainforests to grow across South America?",
        "answers": [
            "the extinction of the dinosaurs and the wetter climate",
            "extinction of the dinosaurs and the wetter climate",
            "extinction of the dinosaurs"
        ],
        "model_ans": "Plate tectonics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Plate tectonics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many degrees south did the Amazon rainforest reach from 66-34 Mya?",
        "answers": [
            "45",
            "45\u00b0",
            "45\u00b0"
        ],
        "model_ans": "0 degrees",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0 degrees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has caused savanna regions to grow into the South American tropics in the last 34 million years?",
        "answers": [
            "Climate fluctuations",
            "Climate fluctuations",
            "Climate fluctuations"
        ],
        "model_ans": "Changes in Earth's orbit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Changes in Earth's orbit </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During which period in history was the Amazon rainforest a narrow band of forest?",
        "answers": [
            "Oligocene",
            "Oligocene",
            "Oligocene"
        ],
        "model_ans": "Paleozoic Era",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paleozoic Era </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Amazon rainforest do during the Middle Miocene?",
        "answers": [
            "It expanded",
            "expanded",
            "expanded"
        ],
        "model_ans": "It existed",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It existed </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What extinction event might have created some conditions allowing the expansion of the amazon rainforest?",
        "answers": [
            "Cretaceous\u2013Paleogene extinction event",
            "dinosaurs",
            "dinosaurs"
        ],
        "model_ans": "K-Pg extinction event",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> K-Pg extinction event </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Beginning how many years ago did the amazon rainforest extend 45 degrees south?",
        "answers": [
            "66\u201334 Mya",
            "66\u201334"
        ],
        "model_ans": "200 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After the Oligocene period, under what period did the amazon rainforest begin to expand?",
        "answers": [
            "Middle Miocene",
            "Middle Miocene",
            "Middle Miocene"
        ],
        "model_ans": "Miocene",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Miocene </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The amazon rainforest became a mostly inland forest around which global event?",
        "answers": [
            "last glacial maximum",
            "last glacial maximum",
            "last glacial maximum"
        ],
        "model_ans": "The breakup of the supercontinent Gondwana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The breakup of the supercontinent Gondwana </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Savannah areas expanded over the last how many years?",
        "answers": [
            "34 million years",
            "34 million",
            "34 million"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which point did the drainage basin of the Amazon split?",
        "answers": [
            "During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Purus Arch.",
            "During the mid-Eocene",
            "mid-Eocene"
        ],
        "model_ans": "The Amazon River splits into two main branches, the Solim\u00f5es River and the Negro River, at the city of Manaus, Brazil.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Amazon River splits into two main branches, the Solim\u00f5es River and the Negro River, at the city of Manaus, Brazil. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which direction did the water on the eastern side flow?",
        "answers": [
            "Water on the eastern side flowed toward the Atlantic,",
            "toward the Atlantic",
            "toward the Atlantic"
        ],
        "model_ans": "east",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> east </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the basin that was created from a enclosed lake?",
        "answers": [
            "Solim\u00f5es Basin",
            "Solim\u00f5es Basin",
            "Solim\u00f5es Basin"
        ],
        "model_ans": "Sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long ago was it when the water broke through the Purus Arch?",
        "answers": [
            "Within the last 5\u201310 million years",
            "Within the last 5\u201310 million years",
            "last 5\u201310 million years"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did it join in the direction of its flow?",
        "answers": [
            "joining the easterly flow toward the Atlantic.",
            "the easterly flow",
            "easterly"
        ],
        "model_ans": "river",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> river </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the drainage basin of the Amazon believed to have split in the middle of South America?",
        "answers": [
            "During the mid-Eocene",
            "During the mid-Eocene",
            "During the mid-Eocene"
        ],
        "model_ans": "10 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did water to the east of the Amazon drainage basin flow towards?",
        "answers": [
            "the Atlantic",
            "the Atlantic",
            "Atlantic"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where did water to the west of the Amazon drainage basin flow towards?",
        "answers": [
            "the Pacific",
            "the Pacific",
            "Pacific"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did water that flowed towards the Pacific have to flow across during the mid-Eocene?",
        "answers": [
            "Amazonas Basin",
            "Amazonas Basin",
            "Andes Mountains"
        ],
        "model_ans": "North America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What basin was formed when the Andes Mountains rose?",
        "answers": [
            "the Solim\u00f5es Basin",
            "Solim\u00f5es Basin",
            "Solim\u00f5es Basin"
        ],
        "model_ans": "Pacific",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pacific </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During what period the drainage basin of the Amazon likely split?",
        "answers": [
            "the mid-Eocene",
            "the mid-Eocene",
            "mid-Eocene"
        ],
        "model_ans": "10-15 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10-15 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Near where in the continent is it believed that the Amazon basin split?",
        "answers": [
            "Purus Arch",
            "along the middle",
            "Purus Arch"
        ],
        "model_ans": "Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did water on the eastern side of the amazon basin travel after the split?",
        "answers": [
            "the Atlantic",
            "the Atlantic",
            "Atlantic"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where did the water in the Amazon Basin flow towards when moving west?",
        "answers": [
            "the Pacific",
            "the Pacific",
            "Pacific"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the lake known as which was created by the rise of the Andes Mountains?",
        "answers": [
            "Solim\u00f5es Basin",
            "Solim\u00f5es Basin",
            "Solim\u00f5es Basin"
        ],
        "model_ans": "Lake Titicaca",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lake Titicaca </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does LGM stands for?",
        "answers": [
            "Last Glacial Maximum",
            "Last Glacial Maximum",
            "Last Glacial Maximum"
        ],
        "model_ans": "Little Green Men",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Little Green Men </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the analysis from the sediment deposits indicate? ",
        "answers": [
            "rainfall in the basin during the LGM was lower than for the present",
            "rainfall in the basin during the LGM was lower than for the present",
            "rainfall in the basin during the LGM was lower"
        ],
        "model_ans": "No information provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No information provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are some of scientists arguments? ",
        "answers": [
            "the rainforest was reduced to small, isolated refugia separated by open forest and grassland",
            "the rainforest was reduced to small, isolated refugia separated by open forest and grassland",
            "rainforest was reduced"
        ],
        "model_ans": "There are many arguments among scientists, but some of the most common ones include the debate over the origin of life, the existence of dark matter, and the impact of climate change </answer</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> There are many arguments among scientists, but some of the most common ones include the debate over the origin of life, the existence of dark matter, and the impact of climate change </answer</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How has this debate been proven?",
        "answers": [
            "This debate has proved difficult",
            "difficult to resolve"
        ],
        "model_ans": "I am not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not sure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are the explanations supported?",
        "answers": [
            "explanations are reasonably well supported",
            "by the available data",
            "reasonably well"
        ],
        "model_ans": "The explanations are supported by the provided information, but the accuracy of the information is uncertain.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The explanations are supported by the provided information, but the accuracy of the information is uncertain. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There have been major changes in Amazon rainforest vegetation over the last how many years?",
        "answers": [
            "21,000",
            "21,000",
            "21,000"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What caused changes in the Amazon rainforest vegetation?",
        "answers": [
            "the Last Glacial Maximum (LGM) and subsequent deglaciation",
            "rainfall in the basin during the LGM was lower than for the present",
            "rainfall"
        ],
        "model_ans": "Human activities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Human activities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has been analyzed to compare Amazon rainfall in the past and present?",
        "answers": [
            "sediment deposits",
            "sediment deposits",
            "sediment deposits"
        ],
        "model_ans": "Tree rings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tree rings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the lower rainfall in the Amazon during the LGM been attributed to?",
        "answers": [
            "reduced moist tropical vegetation cover in the basin",
            "reduced moist tropical vegetation cover in the basin",
            "reduced moist tropical vegetation cover"
        ],
        "model_ans": "Changes in atmospheric circulation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Changes in atmospheric circulation </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Many changes in the vegetation of the amazon rainforest took place since the  Last Glacial Maximum, which was how many years ago?",
        "answers": [
            "21,000",
            "21,000",
            "21,000"
        ],
        "model_ans": "12,000 years ago\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "12,000 years ago\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Analysis of what kind of deposits from the Amazon Fan indicates a change in rainfall in the Amazon basin?",
        "answers": [
            "sediment deposits",
            "sediment",
            "sediment"
        ],
        "model_ans": "Sediment",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sediment </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Changes in rainfall reduced what kind of vegetation cover in the Amazon basin?",
        "answers": [
            "moist tropical vegetation cover",
            "moist tropical",
            "tropical"
        ],
        "model_ans": "Forest",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Forest </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Scientists disagree with how the Amazon rainforest changed over time with some arguing that it was reduced to isolated refugia seperated by what?",
        "answers": [
            "open forest and grassland",
            "open forest and grassland",
            "open forest and grassland"
        ],
        "model_ans": "savannas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> savannas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is it difficult to resolve disagreements about the changes in the Amazon rainforest?",
        "answers": [
            "data sampling is biased away from the center of the Amazon basin",
            "practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin",
            "practical limitations of working in the rainforest"
        ],
        "model_ans": "Due to the complexity of the ecosystem and the lack of reliable data",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Due to the complexity of the ecosystem and the lack of reliable data </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the satellite that measured the amount of dust?",
        "answers": [
            "CALIPSO",
            "CALIPSO",
            "CALIPSO"
        ],
        "model_ans": "NASA's Terra satellite",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NASA's Terra satellite </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of dust are blown from the Sahara each year?",
        "answers": [
            "182 million tons",
            "182 million",
            "an average 182 million"
        ],
        "model_ans": "1,000,000,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000,000,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many miles does the dust travels over the Atlantic Ocean?",
        "answers": [
            "1,600 miles",
            "1,600",
            "1,600 miles"
        ],
        "model_ans": "1000 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which basin does the dust falls over into?",
        "answers": [
            "Amazon basin",
            "Amazon",
            "Amazon"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of dust remains in the air?",
        "answers": [
            "132 million tons",
            "132 million tons",
            "132 million"
        ],
        "model_ans": "1 ton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 ton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What tool has measured the amount of dust that travels from the Sahara to the Amazon?",
        "answers": [
            "NASA's CALIPSO satellite",
            "NASA's CALIPSO satellite",
            "satellite"
        ],
        "model_ans": "NASA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NASA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much dust is blown out of the Sahara each year?",
        "answers": [
            "182 million tons",
            "182 million tons",
            "182 million tons"
        ],
        "model_ans": "1.5 billion tons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5 billion tons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much Saharan dust falls over the Amazon basin each year?",
        "answers": [
            "27.7 million tons",
            "27.7 million tons",
            "27.7 million tons"
        ],
        "model_ans": "10 million tons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million tons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much Saharan dust remains in the air over the Amazon each year?",
        "answers": [
            "132 million tons",
            "132 million tons",
            "132 million tons"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much Saharan dust is blown and falls upon the Caribbean Sea each year?",
        "answers": [
            "43 million tons",
            "43 million tons",
            "43 million tons"
        ],
        "model_ans": "10 million tons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million tons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A satellite that measured the amount of dust going to the Amazon was named what?",
        "answers": [
            "CALIPSO",
            "CALIPSO",
            "CALIPSO"
        ],
        "model_ans": "Terra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Terra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What organization runs the satellite that measured dust that landed on the Amazon?",
        "answers": [
            "NASA",
            "NASA",
            "NASA's"
        ],
        "model_ans": "NASA",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NASA </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much windblown dust leaves the Sahara each year?",
        "answers": [
            "182 million tons",
            "182 million tons",
            "182 million tons"
        ],
        "model_ans": "1 billion tons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 billion tons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many miles across the Atlantic Ocean does Saharan dust travel?",
        "answers": [
            "1,600 miles",
            "1,600",
            "1,600"
        ],
        "model_ans": "3,000 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3,000 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of Saharan dust falls on the Amazon Basin each year?",
        "answers": [
            "27.7 million tons",
            "27.7 million",
            "27.7 million tons"
        ],
        "model_ans": "20 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the book written by Archeologist Betty Meggers?",
        "answers": [
            "Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise."
        ],
        "model_ans": "The Amazon and Her People",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Amazon and Her People </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the maximum square miles did Betty Meggers claim that can be sustained in the rainforest? ",
        "answers": [
            "0.52/sq mi",
            "0.52",
            "0.52/sq mi"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What would be needed to host a larger population?",
        "answers": [
            "agriculture",
            "agriculture",
            "agriculture"
        ],
        "model_ans": "Infrastructure",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Infrastructure </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which findings suggested that the region was densely populated? ",
        "answers": [
            "anthropological",
            "anthropological",
            "recent anthropological"
        ],
        "model_ans": "Archaeological findings",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Archaeological findings </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many people may have lived in the Amazon region during AD 1500?",
        "answers": [
            "5 million",
            "5 million",
            "5 million"
        ],
        "model_ans": "10 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What feature of the Amazon made people believe it couldn't have many inhabitants?",
        "answers": [
            "the poor soil",
            "poor soil",
            "poor soil."
        ],
        "model_ans": "The Amazon River's strong currents",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Amazon River's strong currents </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What well-known archeologist believed the Amazon didn't have many inhabitants?",
        "answers": [
            "Betty Meggers",
            "Betty Meggers",
            "Betty Meggers"
        ],
        "model_ans": "Percy Fawcett",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Percy Fawcett </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many inhabitants did Betty Meggers believe could occupy each square kilometre of the Amazon?",
        "answers": [
            "0.2",
            "0.2",
            "0.2"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what book did Betty Meggers describe the idea of the Amazon being sparsely populated?",
        "answers": [
            "Amazonia: Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise"
        ],
        "model_ans": "The Amazon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Amazon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which archaeologist proposed the idea that the Amazon rainforest couldn't sustain large populations? ",
        "answers": [
            "Betty Meggers",
            "Betty Meggers",
            "Betty Meggers"
        ],
        "model_ans": "Carl Linnaeus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carl Linnaeus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which book discussed the theory about low populations in the Amazon rainforest?",
        "answers": [
            "Amazonia: Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise",
            "Amazonia: Man and Culture in a Counterfeit Paradise"
        ],
        "model_ans": "The Sixth Extinction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Sixth Extinction </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the theorized maximum population density per square kilometre for the Amazon rainforest?",
        "answers": [
            "0.2 inhabitants per square kilometre",
            "0.2 inhabitants",
            "0.2 inhabitants per square kilometre"
        ],
        "model_ans": "0.5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1500 AD how many people were believed to have lived in the Amazon region?",
        "answers": [
            "5 million people",
            "5 million",
            "Some 5 million"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the 1980s what was the population of the amazon region?",
        "answers": [
            "200,000.",
            "less than 200,000",
            "less than 200,000"
        ],
        "model_ans": "20 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first European to travel the Amazon River?",
        "answers": [
            "Francisco de Orellana",
            "Francisco de Orellana",
            "Francisco de Orellana"
        ],
        "model_ans": "Francisco de Orellana",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Francisco de Orellana </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "During what time did civilization in the Amazon was flourishing when Orellana made his observations?",
        "answers": [
            "1540s",
            "1540s",
            "1540s"
        ],
        "model_ans": "1542",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1542 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was believed to be the cause of devastation to the civilization?",
        "answers": [
            "diseases from Europe",
            "the spread of diseases from Europe",
            "spread of diseases from Europe"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long since it's been that geoglyphs were first discovered on deforested land?",
        "answers": [
            "1970s",
            "Since the 1970s",
            "1970s"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What time period did the geoglyphs date back to?",
        "answers": [
            "AD 0\u20131250",
            "between AD 0\u20131250",
            "AD 0\u20131250"
        ],
        "model_ans": "500 BCE to 500 CE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 BCE to 500 CE </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first European to travel the entire length of the Amazon River?",
        "answers": [
            "Francisco de Orellana",
            "Francisco de Orellana",
            "Francisco de Orellana"
        ],
        "model_ans": "Francisco de Orellana",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Francisco de Orellana </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what year did the first European travel the entire length of the Amazon River?",
        "answers": [
            "1542",
            "1542",
            "1542"
        ],
        "model_ans": "1542\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1542\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Geoglyphs dating to what period were found in deforested land along the Amazon River?",
        "answers": [
            "AD 0\u20131250",
            "between AD 0\u20131250",
            "AD 0\u20131250"
        ],
        "model_ans": "1000 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is given credit for discovering geoglyphs along the Amazon River?",
        "answers": [
            "Ondemar Dias",
            "Ondemar Dias",
            "Ondemar Dias"
        ],
        "model_ans": "Maria Reiche",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maria Reiche </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For how many years was evidence shown that humans shaped the the Amazon?",
        "answers": [
            "11,000 years",
            "at least 11,000 years",
            "at least 11,000 years"
        ],
        "model_ans": "11,000 years",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 11,000 years </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is terra preta called?",
        "answers": [
            "black earth",
            "black earth",
            "black earth"
        ],
        "model_ans": "Amazonian Dark Earth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amazonian Dark Earth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much is terra preta distributed over the Amazon forest?",
        "answers": [
            "large areas",
            "over large areas",
            "over large areas"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the development of this fertile soil provide in hostile environment?",
        "answers": [
            "agriculture and silviculture",
            "allowed agriculture and silviculture",
            "agriculture and silviculture"
        ],
        "model_ans": "Life",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Life </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which region tribe were large settlements discovered?",
        "answers": [
            "Xingu tribe",
            "Xingu",
            "Xingu"
        ],
        "model_ans": "Mesopotamia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mesopotamia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who discovered this and where did they come from?",
        "answers": [
            "Michael Heckenberger and colleagues of the University of Florida",
            "Michael Heckenberger and colleagues of the University of Florida",
            "Michael Heckenberger and colleagues of the University of Florida"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of soil is considered a product of soil management by indigenous peoples in the Amazon Forest?",
        "answers": [
            "Terra preta (black earth)",
            "Terra preta",
            "black earth"
        ],
        "model_ans": "Terra Preta",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Terra Preta </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The development of Terra Preta allowed for what to happen in the Amazon Forest?",
        "answers": [
            "agriculture and silviculture",
            "agriculture and silviculture",
            "agriculture and silviculture"
        ],
        "model_ans": "sustainable agriculture",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> sustainable agriculture </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In lands attributed to what tribe are found remains of large settlements?",
        "answers": [
            "Xingu tribe",
            "Xingu",
            "Xingu"
        ],
        "model_ans": "Inca",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inca </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is credited with finding evidence of large settlements in the Amazon forest?",
        "answers": [
            "Michael Heckenberger and colleagues",
            "Michael Heckenberger and colleagues of the University of Florida",
            "Michael Heckenberger"
        ],
        "model_ans": "Betty Meggers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Betty Meggers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Evidence for what types of structures were found in 2003?",
        "answers": [
            "roads, bridges and large plazas",
            "roads, bridges and large plazas",
            "roads, bridges and large plazas"
        ],
        "model_ans": "ancient city",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ancient city </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many species of insects are known in the region?",
        "answers": [
            "2.5 million",
            "2.5 million",
            "2.5 million"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What portion of bird species make up the world's total live in the rainforest?",
        "answers": [
            "One in five",
            "One in five",
            "One in five"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many plant species make up the total in the rainforest?",
        "answers": [
            "40,000",
            "40,000",
            "40,000"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the total make up of fish species living in the Amazon?",
        "answers": [
            "one in five",
            "2,200",
            "2,200"
        ],
        "model_ans": "2,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many invertebrate species are known in Brazil alone? ",
        "answers": [
            "96,660 and 128,843",
            "between 96,660 and 128,843",
            "128,843"
        ],
        "model_ans": "1,500,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Amazon region is home to how many species of insect?",
        "answers": [
            "2.5 million",
            "about 2.5 million",
            "2.5 million"
        ],
        "model_ans": "2 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many species of bird and mammals are there in the Amazon region?",
        "answers": [
            "2,000",
            "some 2,000",
            "2,000"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many plant species are estimated to be in the Amazon region?",
        "answers": [
            "40,000",
            "tens of thousands",
            "tens of thousands"
        ],
        "model_ans": "40,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 40,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many reptiles have been discovered in the Amazon region?",
        "answers": [
            "378",
            "378",
            "378"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What amount of bird species on earth are found in the Amazon rainforest?",
        "answers": [
            "One in five",
            "1,294",
            "One in five of all the bird species in the world"
        ],
        "model_ans": "1,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many kilometers of acres of the Ecuadorian rainforest is supported?",
        "answers": [
            "62 acres",
            "quarter square",
            "quarter square",
            "62"
        ],
        "model_ans": "50,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tree species are in the rainforest?",
        "answers": [
            "1,100",
            "more than 1,100",
            "more than 1,100",
            "1,100"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of living plants are in the rainforest?",
        "answers": [
            "90,790",
            "about 90,790",
            "about 90,790",
            "90,790"
        ],
        "model_ans": "300 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 300 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the average plant biosmass?",
        "answers": [
            "356 \u00b1 47 tonnes per hectare",
            "356 \u00b1 47 tonnes per hectare",
            "356 \u00b1 47 tonnes per hectare",
            "356 \u00b1 47 tonnes per hectare"
        ],
        "model_ans": "0.5-1.5 g/m\u00b2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5-1.5 g/m\u00b2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the number of plant species in economics and social interest?",
        "answers": [
            "438,000",
            "438,000",
            "438,000",
            "438,000 species"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Amazon region rate among the entire earth for its amount of biodiversity?",
        "answers": [
            "highest on Earth",
            "the highest",
            "the highest",
            "highest"
        ],
        "model_ans": "1st",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1st </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many tree species were found in one square kilometer of Ecuadorian rainforest in 2001?",
        "answers": [
            "1,100",
            "more than 1,100",
            "more than 1,100",
            "1,100"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of live plants were found to live in one square kilometer of the Amazon rainforest in 1999?",
        "answers": [
            "90,790 tonnes",
            "about 90,790",
            "about 90,790",
            "90,790 tonnes"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the average weight of the biomass per hectare in the Amazon?",
        "answers": [
            "356 \u00b1 47 tonnes",
            "356 \u00b1 47 tonnes",
            "356 \u00b1 47 tonnes",
            "356 \u00b1 47 tonnes"
        ],
        "model_ans": "150-200 tons per hectare",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150-200 tons per hectare </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many plant species are of interest to society and manufacturers exist in the amazon rainforest?",
        "answers": [
            "438,000",
            "438,000",
            "438,000",
            "438,000"
        ],
        "model_ans": "40,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which animal that lives in the Amazon river may produce a deadly shock?",
        "answers": [
            "electric eels",
            "electric eels",
            "electric eels"
        ],
        "model_ans": "Electric Eel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric Eel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Large predators of the Amazon rainforest include the jaguar, cougar, and anaconda, what is one other example?",
        "answers": [
            "black caiman",
            "black caiman",
            "black caiman"
        ],
        "model_ans": "puma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> puma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What fish living in the Amazon river is known to bit humans?",
        "answers": [
            "piranha",
            "piranha",
            "piranha"
        ],
        "model_ans": "Piranha",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Piranha </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are dart frogs are known to secrete?",
        "answers": [
            "lipophilic alkaloid toxins",
            "lipophilic alkaloid toxins",
            "lipophilic alkaloid toxins"
        ],
        "model_ans": "poison",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poison </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of bat that lives in the Amazon rainforest can spread rabies?",
        "answers": [
            "Vampire bats",
            "Vampire",
            "Vampire"
        ],
        "model_ans": "Vampire bat",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vampire bat </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the process of removing trees from a forest known as?",
        "answers": [
            "Deforestation",
            "Deforestation",
            "Deforestation"
        ],
        "model_ans": "Logging",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Logging </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Acessing the Amazon rainforest was restricted before what era?",
        "answers": [
            "the early 1960s",
            "early 1960s",
            "1960s"
        ],
        "model_ans": "20th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What method was used to clear forest for crop cultivation in the amazon forest?",
        "answers": [
            "slash and burn method",
            "slash and burn",
            "slash and burn"
        ],
        "model_ans": "Slash and burn",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Slash and burn </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are two factors that made it difficult for colonists to the Amazon forest to survive?",
        "answers": [
            "loss of soil fertility and weed invasion",
            "loss of soil fertility and weed invasion",
            "soil fertility and weed invasion"
        ],
        "model_ans": "Malaria and Yellow Fever",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Malaria and Yellow Fever </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is notable about the Amazon forest when it is seen from space?",
        "answers": [
            "areas cleared of forest are visible to the naked eye",
            "areas cleared of forest",
            "areas cleared of forest are visible to the naked eye"
        ],
        "model_ans": "It appears as a green stripe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It appears as a green stripe </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many square kilometres of the Amazon forest was lost by 1991?",
        "answers": [
            "415,000",
            "415,000 to 587,000",
            "415,000"
        ],
        "model_ans": "400,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 400,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the year 2000 how many square kilometres of the Amazon forest had been lost?",
        "answers": [
            "587,000",
            "587,000",
            "587,000"
        ],
        "model_ans": "15%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 15% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is most of the cleared land in the Amazon region used for?",
        "answers": [
            "pasture for cattle",
            "pasture for cattle",
            "pasture for cattle"
        ],
        "model_ans": "Agriculture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Agriculture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is Brazil ranked globally in soybean production?",
        "answers": [
            "second-largest global producer",
            "second",
            "second-largest"
        ],
        "model_ans": "Brazil is the world's largest producer of soybeans, accounting for approximately 40% of global production.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brazil is the world's largest producer of soybeans, accounting for approximately 40% of global production.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of the land cleared in the Amazon is used for growing livestock?",
        "answers": [
            "91%",
            "91",
            "91%"
        ],
        "model_ans": "70%\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "70%\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Highways built in the Amazon rainforest were built primarily for what kind of farmers?",
        "answers": [
            "soy farmers",
            "soy",
            "soy"
        ],
        "model_ans": "Soybean",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Soybean </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did creating highways in the Amazon rainforest lead to?",
        "answers": [
            "increased settlement and deforestation",
            "increased settlement and deforestation",
            "increased settlement and deforestation"
        ],
        "model_ans": "Deforestation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deforestation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The rate of clearing of forest from 2000 to 2005 was how many square miles per year?",
        "answers": [
            "8,646 sq mi",
            "22,392 km2 or 8,646 sq mi",
            "8,646"
        ],
        "model_ans": "0.5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much higher was the rate of deforestation in 2000, to 2005 compared to 1995 to 2000?",
        "answers": [
            "18% higher",
            "18%",
            "18%"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened to the rate of deforestation in the Amazon region of Brazil between 2004 and 2014?",
        "answers": [
            "deforestation has declined",
            "declined significantly",
            "declined significantly"
        ],
        "model_ans": "The rate of deforestation increased by 15%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The rate of deforestation increased by 15% </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are environmentalists concerned about losing in the Amazon forest?",
        "answers": [
            "loss of biodiversity",
            "biodiversity",
            "biodiversity"
        ],
        "model_ans": "biodiversity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> biodiversity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The loss of biodiversity may be the result of what, according to environmentalists?",
        "answers": [
            "destruction of the forest",
            "destruction of the forest",
            "destruction of the forest"
        ],
        "model_ans": "human activities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> human activities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are environmentalists concerned about having released from the Amazon region?",
        "answers": [
            "carbon contained within the vegetation",
            "carbon contained within the vegetation",
            "carbon"
        ],
        "model_ans": "Carbon dioxide",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Carbon dioxide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What amount of the worlds carbon is stored in the Amazon forest?",
        "answers": [
            "10% of the carbon stores",
            "10%",
            "10%"
        ],
        "model_ans": "140 billion metric tons\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "140 billion metric tons\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many metric tons of carbon are believed to be stored in the Amazon forest?",
        "answers": [
            "1.1 \u00d7 1011 metric tonnes",
            "1.1 \u00d7 1011",
            "1.1 \u00d7 1011"
        ],
        "model_ans": "140 billion metric tons\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "140 billion metric tons\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What change in conditions may make the Amazon rainforest unsustainable?",
        "answers": [
            "reduced rainfall and increased temperatures",
            "severely reduced rainfall and increased temperatures",
            "severely reduced rainfall and increased temperatures"
        ],
        "model_ans": "Climate change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A complete loss of rainforest cover may be caused by what type of emissions?",
        "answers": [
            "greenhouse gas emissions",
            "greenhouse gas",
            "greenhouse gas"
        ],
        "model_ans": "Carbon dioxide",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carbon dioxide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If one computer model turns out correct, by what year would there be a nearly complete loss of rainforest in the Amazon basin?",
        "answers": [
            "2100",
            "by 2100",
            "2100"
        ],
        "model_ans": "2050",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2050 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long may the Amazon rainforest be threatened, according to some computer models?",
        "answers": [
            "though the 21st century",
            "though the 21st century",
            "though the 21st century"
        ],
        "model_ans": "100-200 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100-200 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the main threats facing the Amazon rainforest in the current century?",
        "answers": [
            "climate change in addition to deforestation",
            "climate change in addition to deforestation",
            "climate change in addition to deforestation"
        ],
        "model_ans": "Deforestation, climate change, and wildfires",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deforestation, climate change, and wildfires </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of territories are being destroyed by ecocide in the Amazon?",
        "answers": [
            "indigenous territories",
            "indigenous",
            "indigenous"
        ],
        "model_ans": "Rainforests",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rainforests </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of conservation effort is gaining attention in the Amazon?",
        "answers": [
            "community-based conservation",
            "community-based",
            "community-based"
        ],
        "model_ans": "reforestation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> reforestation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Indigenous territories are largely being destroyed in what two ways?",
        "answers": [
            "deforestation and ecocide",
            "deforestation and ecocide",
            "deforestation and ecocide"
        ],
        "model_ans": "deforestation and mining",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> deforestation and mining </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Peruvian Amazon indigienous people are one group struggling in the Amazon, what is another group?",
        "answers": [
            "Urarina",
            "Urarina",
            "Urarina"
        ],
        "model_ans": "Yanomami",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yanomami </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There is growing interest in what indigenous group in the Amazon?",
        "answers": [
            "lowland South American",
            "lowland South American peoples",
            "South American"
        ],
        "model_ans": "Yanomami",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yanomami </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of sending technology is being used to protect tribal lands in the Amazon?",
        "answers": [
            "remote sensing",
            "remote sensing",
            "remote sensing"
        ],
        "model_ans": "Satellite",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Satellite </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tribe uses GPS devices to map lands?",
        "answers": [
            "Trio Tribe",
            "Trio",
            "Trio"
        ],
        "model_ans": "Inuit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inuit </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Tribal members living in the rainforests of what region are using Google Earth?",
        "answers": [
            "southern Suriname",
            "southern Suriname",
            "southern Suriname"
        ],
        "model_ans": "Amazon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amazon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do tribes use Google Earth and GPS for?",
        "answers": [
            "to help strengthen their territorial claims",
            "map out their ancestral lands to help strengthen their territorial claims",
            "map out their ancestral lands"
        ],
        "model_ans": "Navigation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Navigation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why do some tribes use remote sensing technology?",
        "answers": [
            "to protect their tribal lands from commercial interests",
            "to protect their tribal lands from commercial interests",
            "protect their tribal lands from commercial interests"
        ],
        "model_ans": "For monitoring and tracking",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> For monitoring and tracking </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Classifying the stages of what is important to mapping aspects of the Amazon?",
        "answers": [
            "tree growth",
            "tree growth"
        ],
        "model_ans": "deforestation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> deforestation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The classification of aspects of the Amazon forest is important for mapping what type of emission?",
        "answers": [
            "carbon related emissions",
            "carbon related",
            "carbon related"
        ],
        "model_ans": "carbon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> carbon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who organized the trees of the Amazon into four categories?",
        "answers": [
            "Tatiana Kuplich",
            "Tatiana Kuplich",
            "Tatiana Kuplich"
        ],
        "model_ans": "Amazon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amazon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did one individual suggest classifying the trees of the Amazon into four categories?",
        "answers": [
            "2006",
            "2006",
            "2006"
        ],
        "model_ans": "1980",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1980 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of radar was used to classify trees into four categories?",
        "answers": [
            "Synthetic aperture radar (SAR)",
            "Synthetic aperture",
            "Synthetic aperture radar"
        ],
        "model_ans": "Synthetic Aperture Radar",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Synthetic Aperture Radar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did the Amazon experience its worst drought of recent history?",
        "answers": [
            "2005",
            "2005",
            "2005"
        ],
        "model_ans": "2010\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2010\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization predicted that the Amazon forest could survive only three years of drought?",
        "answers": [
            "Woods Hole Research Center",
            "Woods Hole Research Center",
            "Woods Hole Research Center"
        ],
        "model_ans": "NASA",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> NASA </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization argued that drought, among other effects, could cause the Amazon forest to reach a \"tipping point?\"",
        "answers": [
            "Brazilian National Institute of Amazonian Research",
            "Brazilian National Institute of Amazonian Research",
            "Brazilian National Institute of Amazonian Research"
        ],
        "model_ans": "IPCC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>IPCC</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with drought, what is one other factor that is pushing the Amazon rainforest towards a tipping point?",
        "answers": [
            "deforestation",
            "deforestation on regional climate",
            "deforestation"
        ],
        "model_ans": "Climate change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What might the Amazon forest become if it passes the tipping point and starts to die?",
        "answers": [
            "savanna or desert",
            "desert",
            "savanna or desert"
        ],
        "model_ans": "A desert",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> A desert </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did the Amazon experience a drought that may have been more extreme than in 2005?",
        "answers": [
            "2010",
            "2010",
            "2010"
        ],
        "model_ans": "2010\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2010\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many square miles large was the region impacted by the 2010 drought?",
        "answers": [
            "1,160,000",
            "1,160,000",
            "1,160,000"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many areas were impacted by the the death of vegetation in the 2010 drought?",
        "answers": [
            "three epicenters",
            "three epicenters",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The southern part of the Amazon forest was mainly impacted by drought in what year?",
        "answers": [
            "2005",
            "2005",
            "2005"
        ],
        "model_ans": "2010\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2010\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many tons of carbon are absorbed the Amazon in a typical year?",
        "answers": [
            "1.5 gigatons",
            "1.5 gigatons",
            "1.5 gigatons"
        ],
        "model_ans": "2.2 billion tons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2.2 billion tons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a ctenophora?",
        "answers": [
            "phylum of animals that live in marine waters",
            "a phylum of animals",
            "comb jellies"
        ],
        "model_ans": "jellyfish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> jellyfish </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the ctenophora use to swim?",
        "answers": [
            "\u2018combs\u2019 \u2013 groups of cilia",
            "cilia",
            "cilia"
        ],
        "model_ans": "cilia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cilia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does ctenophora use for digestion and respiration?",
        "answers": [
            "water flow through the body cavity",
            "water flow",
            "water flow through the body cavity"
        ],
        "model_ans": "cilia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cilia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How large can ctenophora grow?",
        "answers": [
            "1.5 m (4 ft 11 in)",
            "a few millimeters to 1.5 m"
        ],
        "model_ans": "up to 30 cm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> up to 30 cm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most distinctive feature of ctenophora?",
        "answers": [
            "\u2018combs\u2019 \u2013 groups of cilia",
            "combs",
            "the \u2018combs\u2019"
        ],
        "model_ans": "comb-like structure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> comb-like structure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are ctenophora commonly known as?",
        "answers": [
            "comb jellies",
            "comb jellies",
            "comb jellies"
        ],
        "model_ans": "comb jellies",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> comb jellies </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How big can ctenophora grow?",
        "answers": [
            "1.5 m (4 ft 11 in)",
            "1.5 m (4 ft 11 in)",
            "a few millimeters to 1.5 m"
        ],
        "model_ans": "up to 30 cm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> up to 30 cm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does ctenophora rely on for digestion and respiration?",
        "answers": [
            "water flow through the body cavity",
            "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'",
            "water flow through the body cavity"
        ],
        "model_ans": "water",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> water </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does ctenophora mean in Greek?",
        "answers": [
            "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'",
            "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'",
            "kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'"
        ],
        "model_ans": "hair-bearing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hair-bearing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do ctenophora live?",
        "answers": [
            "marine waters",
            "marine waters worldwide",
            "marine waters"
        ],
        "model_ans": "oceans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oceans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many species of Ctenophora have been validated?",
        "answers": [
            "100\u2013150 species",
            "100\u2013150",
            "100\u2013150"
        ],
        "model_ans": "200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the little tentacles that cydippids have called?",
        "answers": [
            "tentilla",
            "tentilla",
            "tentilla"
        ],
        "model_ans": "Cirri",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cirri </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much food does a ctenophora eat in a day?",
        "answers": [
            "ten times their own weight",
            "ten times their own weight",
            "ten times their own weight"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do coastal beroids not have that other ctenophora have?",
        "answers": [
            "tentacles",
            "tentacles",
            "tentacles"
        ],
        "model_ans": "tentacles",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> tentacles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does coastal beriods use as teeth?",
        "answers": [
            "groups of large, stiffened cilia",
            "stiffened cilia",
            "stiffened cilia"
        ],
        "model_ans": "Silica",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Silica </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much do ctenophore eat in a day?",
        "answers": [
            "ten times their own weight",
            "ten times their own weight",
            "ten times their own weight"
        ],
        "model_ans": "1-5% of their body weight",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1-5% of their body weight </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the small tentacles on Cydippids called?",
        "answers": [
            "tentilla",
            "tentilla",
            "tentilla"
        ],
        "model_ans": "Cirri",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cirri </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do Beriods use as teeth?",
        "answers": [
            "groups of large, stiffened cilia",
            "stiffened cilia",
            "stiffened cilia"
        ],
        "model_ans": "Phosphatic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Phosphatic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do Cydippids use to capture their prey?",
        "answers": [
            "colloblasts",
            "retractable tentacles fringed with tentilla",
            "colloblasts"
        ],
        "model_ans": "Tentacles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tentacles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many different species of ctenohore are there?",
        "answers": [
            "100\u2013150 species",
            "100\u2013150",
            "100\u2013150 species have been validated"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is unique about  a hermaphrodite?",
        "answers": [
            "can produce both eggs and sperm, meaning it can fertilize its own egg",
            "it can fertilize its own egg",
            "a single animal can produce both eggs and sperm"
        ],
        "model_ans": "It has both male and female reproductive organs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It has both male and female reproductive organs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can a simultaneous hermaphrodite do?",
        "answers": [
            "can produce both eggs and sperm at the same time",
            "produce both eggs and sperm at the same time",
            "produce both eggs and sperm at the same time"
        ],
        "model_ans": "Both male and female reproductive organs are present in the same individual",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Both male and female reproductive organs are present in the same individual </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of hermaphrodite produces egg and sperm at different times?",
        "answers": [
            "sequential",
            "sequential hermaphrodites",
            "simultaneous"
        ],
        "model_ans": "Sequential hermaphrodite",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sequential hermaphrodite </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which species eggs are fertilized and kept inside the parents body until hatched?",
        "answers": [
            "platyctenids",
            "platyctenids",
            "platyctenids"
        ],
        "model_ans": "Birds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Birds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What causes the population of ctenophora to grow at an explosive rate?",
        "answers": [
            "hermaphroditism and early reproduction",
            "hermaphroditism and early reproduction",
            "combination of hermaphroditism and early reproduction"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a hermaphrodite?",
        "answers": [
            "a single animal can produce both eggs and sperm",
            "a single animal can produce both eggs and sperm",
            "a single animal can produce both eggs and sperm"
        ],
        "model_ans": "An organism that has both male and female reproductive organs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> An organism that has both male and female reproductive organs </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is unique about  simultaneous hermaphrodites?",
        "answers": [
            "can produce both eggs and sperm at the same time.",
            "can produce both eggs and sperm",
            "produce both eggs and sperm at the same time"
        ],
        "model_ans": "They have both male and female reproductive organs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They have both male and female reproductive organs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a trait of sequential hermaphrodites?",
        "answers": [
            "the eggs and sperm mature at different times",
            "eggs and sperm mature at different times",
            "eggs and sperm mature at different times"
        ],
        "model_ans": "They can change sex",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They can change sex </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which group keep the eggs are fertilized and kept inside the parent's body until they hatch?",
        "answers": [
            "platyctenids",
            "platyctenids",
            "platyctenids"
        ],
        "model_ans": "Birds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Birds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which group has young that are born with no tentacles and a large mouth?",
        "answers": [
            "beroids",
            "beroids",
            "beroids"
        ],
        "model_ans": "Octopus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Octopus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Beroe eat? ",
        "answers": [
            "other ctenophores",
            "ctenophores",
            "other ctenophores"
        ],
        "model_ans": "small crustaceans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> small crustaceans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was introduces into the Black Sea?",
        "answers": [
            "Mnemiopsis",
            "Mnemiopsis",
            "Mnemiopsis"
        ],
        "model_ans": "The Danube River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Danube River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does  mnemiopsis eat?",
        "answers": [
            "fish larvae and organisms",
            "fish larvae and organisms that would otherwise have fed the fish",
            "fish larvae and organisms that would otherwise have fed the fish"
        ],
        "model_ans": "zooplankton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> zooplankton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do ctenophores be found in large numbers?",
        "answers": [
            "In bays",
            "bays",
            "bays"
        ],
        "model_ans": "Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where can ctenophores be found in large amounts?",
        "answers": [
            "In bays",
            "bays",
            "bays"
        ],
        "model_ans": "Oceans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oceans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are phytoplankton?",
        "answers": [
            "planktonic plants",
            "planktonic plants",
            "a vital part of marine food chains"
        ],
        "model_ans": "microscopic plants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> microscopic plants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What ctenophore was accidentally introduced into The Black Sea?",
        "answers": [
            "Mnemiopsis",
            "Mnemiopsis",
            "Mnemiopsis"
        ],
        "model_ans": "Mnemiopsis leidyi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mnemiopsis leidyi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What event was blamed on the introduction of mnemiopsis into The Black Sea?",
        "answers": [
            "causing fish stocks to collapse",
            "causing fish stocks to collapse",
            "causing fish stocks to collapse"
        ],
        "model_ans": "Overfishing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Overfishing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was done to counteract the overpopulation of mnemiopsis in The Black Sea?",
        "answers": [
            "introduction of Beroe",
            "accidental introduction of Beroe"
        ],
        "model_ans": "Biological control",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Biological control </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Cretaceous-Paleogene extinction happen?",
        "answers": [
            "66 million years ago",
            "515 million years ago",
            "66 million years ago"
        ],
        "model_ans": "65 million years ago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 65 million years ago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Evidence indicates that Cydippids are not what?",
        "answers": [
            "monophyletic",
            "monophyletic",
            "\"cydippids\" are not monophyletic"
        ],
        "model_ans": "jellyfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> jellyfish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How old are the fossils found that represent ctenophhores ?",
        "answers": [
            "515 million years",
            "66 million years ago",
            "515 million years"
        ],
        "model_ans": "580 million years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 580 million years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the fossils that were found to represent ctenphores missing that current ctenphora have?",
        "answers": [
            "tentacles",
            "tentacles",
            "tentacles"
        ],
        "model_ans": "Ctenophora fossils were found in the Burgess Shale, which dates back to the Cambrian period, around 505 million years ago.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ctenophora fossils were found in the Burgess Shale, which dates back to the Cambrian period, around 505 million years ago. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Fossils found that were believed to be ctenophores were how old?",
        "answers": [
            "515 million years",
            "66 million years",
            "515 million years"
        ],
        "model_ans": "580 million years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 580 million years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What event happened 66 million years ago?",
        "answers": [
            "Cretaceous\u2013Paleogene extinction",
            "the Cretaceous\u2013Paleogene extinction",
            "Cretaceous\u2013Paleogene extinction"
        ],
        "model_ans": "The Cretaceous-Paleogene extinction event",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Cretaceous-Paleogene extinction event </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cypiddids are not what?",
        "answers": [
            "monophyletic",
            "monophyletic",
            "monophyletic"
        ],
        "model_ans": "mammals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mammals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do current ctenophores have that fossils found did not have?",
        "answers": [
            "tentacles",
            "tentacles",
            "tentacles"
        ],
        "model_ans": "nervous system",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> nervous system </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Jellyfish ans sea anemones belong to what phylum?",
        "answers": [
            "cnidarians",
            "Ctenophores",
            "cnidarians"
        ],
        "model_ans": "Cnidaria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cnidaria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What makes ctenophores different from all other animals?",
        "answers": [
            "by having colloblasts",
            "having colloblasts",
            "colloblasts"
        ],
        "model_ans": "They have a unique body structure, with a gelatinous body and a network of nerve cells called a \"nerve net\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They have a unique body structure, with a gelatinous body and a network of nerve cells called a \"nerve net\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Ctenophora are less complex than which other phylum?",
        "answers": [
            "bilaterians",
            "bilaterians",
            "bilaterians"
        ],
        "model_ans": "Chordata",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chordata </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which phylum is more complex than sponges?",
        "answers": [
            "Ctenophores",
            "Ctenophores",
            "Ctenophores"
        ],
        "model_ans": "Cnidaria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cnidaria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does ctenophore use to capture prey?",
        "answers": [
            "colloblasts",
            "colloblasts",
            "colloblasts"
        ],
        "model_ans": "stinging cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> stinging cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Jellyfish and sea anemones belong to which group/",
        "answers": [
            "cnidarians",
            "cnidarians",
            "cnidarians"
        ],
        "model_ans": "Cnidaria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cnidaria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do ctenophores have that no other animals have?",
        "answers": [
            "colloblasts",
            "colloblasts",
            "colloblasts"
        ],
        "model_ans": "comb-like structures",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> comb-like structures </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do ctenophore use to capture their prey?",
        "answers": [
            "colloblasts",
            "colloblasts",
            "colloblasts"
        ],
        "model_ans": "stinging cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> stinging cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which two groups have cells bound by inter-cell connections and membranes, muscles, a nervous system and sensory organs?",
        "answers": [
            "ctenophores and cnidarians",
            "ctenophores and cnidarians",
            "ctenophores and cnidarians"
        ],
        "model_ans": "Animals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Animals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Ctenophores are less complex than what other group?",
        "answers": [
            "bilaterians",
            "bilaterians",
            "bilaterians"
        ],
        "model_ans": "Vertebrates",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vertebrates </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the jelly-like susbtance called?",
        "answers": [
            "mesoglea",
            "mesoglea",
            "mesoglea"
        ],
        "model_ans": "agar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> agar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Ctenophores and cnidarians are classified as what?",
        "answers": [
            "diploblastic",
            "ctenophores",
            "diploblastic"
        ],
        "model_ans": "animals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> animals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which group has two layers of cells with a middle layer of mesoglea?",
        "answers": [
            "sponges and cnidarians, ctenophores",
            "ctenophores",
            "cnidarians and ctenophores"
        ],
        "model_ans": "Jellyfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jellyfish</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Ctenophores, cnidarians and what other group are labelled diploblastic?",
        "answers": [
            "sponges",
            "sponges",
            "sponges"
        ],
        "model_ans": "Platyhelminthes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Platyhelminthes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the hairs on ctenophores called?",
        "answers": [
            "cilia",
            "cilia",
            "cilia"
        ],
        "model_ans": "cilia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cilia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are cilia used for?",
        "answers": [
            "method of locomotion",
            "their main method of locomotion",
            "locomotion"
        ],
        "model_ans": "Cilia are used for movement, sensing, and filtering",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cilia are used for movement, sensing, and filtering </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Comb like bands of cilia are called what?",
        "answers": [
            "ctenes",
            "ctenes",
            "ctenes"
        ],
        "model_ans": "Villi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Villi</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does ctenophore mean in Greek?",
        "answers": [
            "comb-bearing",
            "\"comb\" and the Greek suffix -\u03c6\u03bf\u03c1\u03bf\u03c2 meaning \"carrying\"",
            "comb-bearing"
        ],
        "model_ans": "hair-bearing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hair-bearing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which cidippid is used as a description on ctenophores in most textbooks?",
        "answers": [
            "Pleurobrachia",
            "Pleurobrachia",
            "Pleurobrachia"
        ],
        "model_ans": "comb-like",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> comb-like </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which group of ctenophore are are hardest to study?",
        "answers": [
            "oceanic species",
            "oceanic species",
            "oceanic species"
        ],
        "model_ans": "Pelagia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pelagia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are coastal species tough?",
        "answers": [
            "to withstand waves and swirling sediment particles",
            "to withstand waves and swirling sediment particles",
            "to withstand waves and swirling sediment particles"
        ],
        "model_ans": "They have adapted to survive in harsh marine environments",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They have adapted to survive in harsh marine environments </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which ctenophora have been studies the most?",
        "answers": [
            "Pleurobrachia, Beroe and Mnemiopsis",
            "Pleurobrachia, Beroe and Mnemiopsis",
            "Pleurobrachia, Beroe and Mnemiopsis"
        ],
        "model_ans": "Mnemiopsis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mnemiopsis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The inside of a ctenophore is lined with what?",
        "answers": [
            "epithelium",
            "epithelium",
            "epithelium"
        ],
        "model_ans": "mesoglea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mesoglea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do photocytes produce?",
        "answers": [
            "bioluminescence",
            "bioluminescence",
            "bioluminescence"
        ],
        "model_ans": "light",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> light </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the throat called?",
        "answers": [
            "pharynx",
            "pharynx",
            "pharynx"
        ],
        "model_ans": "Trachea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trachea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the internal cavity contain?",
        "answers": [
            "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals.",
            "a system of internal canals",
            "the gastrodermis"
        ],
        "model_ans": "organs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> organs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the most active parts of ctenophora?",
        "answers": [
            "the mouth and pharynx;",
            "the mouth and pharynx",
            "the mouth and pharynx"
        ],
        "model_ans": "comb rows",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> comb rows </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the eight comb rows on the outer surface called?",
        "answers": [
            "swimming-plates",
            "swimming-plates",
            "swimming-plates"
        ],
        "model_ans": "Heterocera",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Heterocera </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Combs are called what?",
        "answers": [
            "also called \"ctenes\" or \"comb plates",
            "\"ctenes\" or \"comb plates\"",
            "ctenes"
        ],
        "model_ans": "hair accessories",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hair accessories </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the 9 +3 pattern of cilia thought to do?",
        "answers": [
            "supporting function",
            "suspected to have a supporting function",
            "a supporting function"
        ],
        "model_ans": "move in a coordinated manner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> move in a coordinated manner </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What direction do ctenophore swim?",
        "answers": [
            "in the direction in which the mouth is pointing,",
            "the direction in which the mouth is pointing",
            "direction in which the mouth is pointing"
        ],
        "model_ans": "They swim in a direction that is perpendicular to the direction of the current",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They swim in a direction that is perpendicular to the direction of the current </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cilia can g ow up too what length?",
        "answers": [
            "2 millimeters (0.079 in)",
            "2 millimeters",
            "2 millimeters"
        ],
        "model_ans": "10 micrometers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 micrometers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do ctenophores control buoyancy?",
        "answers": [
            "osmotic pressure",
            "It is uncertain",
            "rely on osmotic pressure"
        ],
        "model_ans": "By controlling the amount of gas in their bodies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By controlling the amount of gas in their bodies </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Ciliary rosettes pump water into what to control buoyancy?",
        "answers": [
            "the mesoglea",
            "mesoglea",
            "mesoglea"
        ],
        "model_ans": "the cell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the cell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does pumping water into the mesoglea do?",
        "answers": [
            "increase its bulk and decrease its density",
            "increase its bulk and decrease its density",
            "increase its bulk and decrease its density"
        ],
        "model_ans": "It helps to maintain the jellyfish's buoyancy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It helps to maintain the jellyfish's buoyancy </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the ciliary rosettes do to decease bulk and increase density?",
        "answers": [
            "pump water out of the mesoglea",
            "pump",
            "pump water out of the mesoglea"
        ],
        "model_ans": "compact",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> compact </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the largest sensory feature of the ctenophora?",
        "answers": [
            "aboral organ",
            "aboral organ",
            "aboral organ"
        ],
        "model_ans": "Nerve net",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nerve net </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the aboral organ located?",
        "answers": [
            "at the opposite end from the mouth",
            "the opposite end from the mouth",
            "opposite end from the mouth"
        ],
        "model_ans": "mouth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> mouth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What protects the statocyst?",
        "answers": [
            "a transparent dome made of long, immobile cilia",
            "a transparent dome made of long, immobile cilia",
            "transparent dome made of long, immobile cilia"
        ],
        "model_ans": "otoliths",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> otoliths </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the main component of the aboral organ?",
        "answers": [
            "a statocyst",
            "statocyst",
            "statocyst"
        ],
        "model_ans": "Water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a statocyst?",
        "answers": [
            "a balance sensor",
            "a balance sensor consisting of a statolith",
            "a balance sensor consisting of a statolith"
        ],
        "model_ans": "a sensory organ found in some animals that helps them maintain balance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a sensory organ found in some animals that helps them maintain balance </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the common coastal pleurobrachia called?",
        "answers": [
            "sea gooseberry",
            "sea gooseberry",
            "sea gooseberry"
        ],
        "model_ans": "jellyfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> jellyfish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the pleurobrachia have on opposite sides of its body?",
        "answers": [
            "a pair of long, slender tentacles",
            "long, slender tentacles",
            "a pair of long, slender tentacles"
        ],
        "model_ans": "eyes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> eyes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cydippid are typically what shape?",
        "answers": [
            "more or less rounded",
            "egg-shaped",
            "more or less rounded"
        ],
        "model_ans": "cylindrical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cylindrical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The long tentacles on the pleurbrachia are protected by what?",
        "answers": [
            "a sheath",
            "a sheath",
            "a sheath into which it can be withdrawn"
        ],
        "model_ans": "chitinous rings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> chitinous rings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the mouth located on the pleuobrachia located?",
        "answers": [
            "at the narrow end",
            "the narrow end",
            "at the narrow end"
        ],
        "model_ans": "mouth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mouth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the tentacles of cydipped ctenophores are usually fringed with?",
        "answers": [
            "tentilla",
            "tentilla",
            "tentilla"
        ],
        "model_ans": "cilia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cilia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are colloblasts?",
        "answers": [
            "specialized mushroom-shaped cells in the outer layer of the epidermis",
            "specialized mushroom-shaped cells in the outer layer of the epidermis",
            "specialized mushroom-shaped cells in the outer layer of the epidermis"
        ],
        "model_ans": "Colloblasts are a type of cell found in the salivary glands of certain species of jellyfish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Colloblasts are a type of cell found in the salivary glands of certain species of jellyfish </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What makes the tentilla of euplokamis different from other cysippids?",
        "answers": [
            "they contain striated muscle,",
            "they contain striated muscle",
            "they contain striated muscle"
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many types of movements do euplokamis tentilla have?",
        "answers": [
            "three types of movement",
            "three",
            "three"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the euplokamis use the three types of movement for?",
        "answers": [
            "capturing prey",
            "capturing prey",
            "capturing prey"
        ],
        "model_ans": "swimming",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> swimming </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many rows of combs are there?",
        "answers": [
            "eight rows",
            "eight",
            "eight"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are the rows of combs located?",
        "answers": [
            "from near the mouth to the opposite end",
            "near the mouth to the opposite end",
            "near the mouth to the opposite end"
        ],
        "model_ans": "In the hive",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> In the hive </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are the combs spaced?",
        "answers": [
            "evenly round the body",
            "evenly",
            "evenly round the body"
        ],
        "model_ans": "evenly",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> evenly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What runs from the balancer in the statocyst to the comb rows?",
        "answers": [
            "ciliary groove",
            "a ciliary groove",
            "a ciliary groove"
        ],
        "model_ans": "otolith",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> otolith </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the lobata have pair of?",
        "answers": [
            "lobes",
            "lobes",
            "lobes"
        ],
        "model_ans": "antennae",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> antennae </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are auricles?",
        "answers": [
            "gelatinous projections edged with cilia that produce water currents",
            "gelatinous projections edged with cilia",
            "gelatinous projections edged with cilia"
        ],
        "model_ans": "Earlobes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Earlobes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many auricles do most species have?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "2\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the auricles do?",
        "answers": [
            "help direct microscopic prey toward the mouth",
            "produce water currents that help direct microscopic prey toward the mouth",
            "produce water currents that help direct microscopic prey toward the mouth"
        ],
        "model_ans": "They help to direct sound waves into the ear canal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They help to direct sound waves into the ear canal </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do lobates feed on?",
        "answers": [
            "suspended planktonic prey",
            "suspended planktonic prey",
            "planktonic prey"
        ],
        "model_ans": "algae",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> algae </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the bathocyroe and ocyropsis do to escape danger?",
        "answers": [
            "by clapping their lobes",
            "clapping their lobes",
            "clapping their lobes"
        ],
        "model_ans": "They release a cloud of ink to confuse predators",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They release a cloud of ink to confuse predators </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens when bathocyroe and ocyropsis clap their lobes together?",
        "answers": [
            "jet of expelled water drives them backwards very quickly.",
            "jet of expelled water drives them backwards very quickly",
            "expelled water drives them backwards very quickly"
        ],
        "model_ans": "Nothing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nothing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The movements of the lobates combs are controlled by what?",
        "answers": [
            "nerves",
            "nerves rather than by water disturbances created by the cilia",
            "nerves"
        ],
        "model_ans": "muscles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> muscles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Cydippids combs are controlled by what?",
        "answers": [
            "water disturbances created by the cilia",
            "water disturbances created by the cilia",
            "water disturbances created by the cilia"
        ],
        "model_ans": "muscles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> muscles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Beroida are known by what other name?",
        "answers": [
            "Nuda",
            "Nuda",
            "Nuda"
        ],
        "model_ans": "Beroida",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beroida </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What group has no feeding appendages?",
        "answers": [
            "The Beroida",
            "Beroida",
            "Beroida"
        ],
        "model_ans": "Jellyfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jellyfish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Some species of beroe have a pair of strips of adhesive cells on the stomach wall. What does it do?",
        "answers": [
            "zip\" the mouth shut when the animal is not feeding,",
            "\"zip\" the mouth shut when the animal is not feeding",
            "\"zip\" the mouth shut when the animal is not feeding"
        ],
        "model_ans": "captures prey",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> captures prey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the beroe do when pursuing prey?",
        "answers": [
            "\"zip\" the mouth shut",
            "streamlines the front of the animal",
            "tight closure streamlines the front of the animal"
        ],
        "model_ans": "swims",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> swims </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the beroida have instead of feeding appendages?",
        "answers": [
            "large pharynx",
            "large cilia",
            "\"macrocilia\""
        ],
        "model_ans": "tentacles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> tentacles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which species are ribbon-shaped planktonic animals?",
        "answers": [
            "The Cestida",
            "Cestida",
            "Cestida"
        ],
        "model_ans": "Radiolaria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Radiolaria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are cestida called?",
        "answers": [
            "belt animals",
            "belt animals",
            "\"belt animals\""
        ],
        "model_ans": "tapeworms",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> tapeworms </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How do cestids swim?",
        "answers": [
            "by undulating their bodies as well as by the beating of their comb-rows.",
            "undulating their bodies",
            "by undulating their bodies as well as by the beating of their comb-rows"
        ],
        "model_ans": "They use their setae",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They use their setae </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the largest ctenophore?",
        "answers": [
            "Cestum veneris",
            "Cestum veneris",
            "up to 1.5 meters (4.9 ft) long"
        ],
        "model_ans": "Mnemiopsis leidyi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mnemiopsis leidyi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which species moves by a darting motion?",
        "answers": [
            "Velamen parallelum",
            "Velamen parallelum",
            "Velamen parallelum"
        ],
        "model_ans": "Jellyfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jellyfish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do most platyctenida have on their aboral surface?",
        "answers": [
            "a pair of tentilla-bearing tentacles",
            "tentilla-bearing tentacles",
            "a pair of tentilla-bearing tentacles"
        ],
        "model_ans": "eyes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> eyes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do platyctenida use their pharynx for?",
        "answers": [
            "cling to and creep on surfaces",
            "as a muscular \"foot\"",
            "as a muscular \"foot\""
        ],
        "model_ans": "filter feeding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> filter feeding </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do all but one platycenida species lack?",
        "answers": [
            "comb-rows",
            "comb-rows",
            "comb-rows"
        ],
        "model_ans": "eyes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> eyes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do platycenida live?",
        "answers": [
            "on rocks, algae, or the body surfaces of other invertebrates",
            "rocks, algae, or the body surfaces of other invertebrates",
            "rocks, algae, or the body surfaces of other invertebrates"
        ],
        "model_ans": "Freshwater",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Freshwater </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are eggs and sperm released?",
        "answers": [
            "via pores in the epidermis",
            "pores in the epidermis",
            "via pores in the epidermis"
        ],
        "model_ans": "Eggs are released from the ovaries during ovulation, while sperm are released from the testes during ejaculation.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Eggs are released from the ovaries during ovulation, while sperm are released from the testes during ejaculation. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do platyctenids reproduce?",
        "answers": [
            "internal fertilization and keep the eggs in brood chambers until they hatch.",
            "internal fertilization",
            "internal fertilization"
        ],
        "model_ans": "Platyceratids reproduce through a process called viviparity, where the young develop inside the mother's body and are nourished by a yolk sac.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Platyceratids reproduce through a process called viviparity, where the young develop inside the mother's body and are nourished by a yolk sac.</answer>\n<confidence</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What genus has self-fertilization been seen?",
        "answers": [
            "Mnemiopsis",
            "Mnemiopsis",
            "Mnemiopsis"
        ],
        "model_ans": "Arabidopsis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arabidopsis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are the gonads located?",
        "answers": [
            "in the parts of the internal canal network under the comb rows",
            "the parts of the internal canal network under the comb rows",
            "internal canal network under the comb rows"
        ],
        "model_ans": "Abdomen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abdomen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Is fertilization  internal or exeternal in most species?",
        "answers": [
            "external",
            "external",
            "external"
        ],
        "model_ans": "internal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> internal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Juvenile and adult  beroe lack what?",
        "answers": [
            "tentacles and tentacle sheaths",
            "tentacles and tentacle sheaths",
            "tentacles and tentacle sheaths"
        ],
        "model_ans": "eyes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> eyes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do juvenile platyctenids live?",
        "answers": [
            "among the plankton",
            "among the plankton",
            "among the plankton"
        ],
        "model_ans": "Freshwater",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Freshwater </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When do juvenile develop into adults?",
        "answers": [
            "after dropping to the sea-floor",
            "after dropping to the sea-floor",
            "after dropping to the sea-floor"
        ],
        "model_ans": "around 18 years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 18 years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Juvenile platyctenids act like what?",
        "answers": [
            "more like true larvae",
            "true larvae",
            "like true larvae"
        ],
        "model_ans": "fish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which genus lack tentacles and sheaths?",
        "answers": [
            "Beroe",
            "Beroe",
            "Beroe"
        ],
        "model_ans": "Hydra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hydra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do bathyctena chuni, euplokamis stationis and eurhamphaea vexilligera have in common?",
        "answers": [
            "they produce secretions (ink) that luminesce",
            "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies",
            "they produce secretions (ink) that luminesce"
        ],
        "model_ans": "They are all species of jellyfish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They are all species of jellyfish </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When do bathyctena chuni, euplokamis stationis and eurhamphaea vexilligera  excrete secretions?",
        "answers": [
            "are disturbed,",
            "disturbed",
            "are disturbed"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the secretions commonly called?",
        "answers": [
            "ink",
            "ink",
            "ink"
        ],
        "model_ans": "Saliva",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saliva </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Do adults or juveniles secretions luminesce brighter?",
        "answers": [
            "Juveniles will luminesce more brightly",
            "Juveniles",
            "Juveniles"
        ],
        "model_ans": "adults",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> adults </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Are ctenophores predators, vegetarian or parasitic?",
        "answers": [
            "Almost all ctenophores are predators",
            "predators",
            "predators"
        ],
        "model_ans": "predators",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>predators</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Haeckelia prey mostly on what animal?",
        "answers": [
            "jellyfish",
            "jellyfish",
            "jellyfish"
        ],
        "model_ans": "fish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fish </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to the jellyfish nematocysts when they are eaten by the haeckelia?",
        "answers": [
            "incorporate their prey's nematocysts (stinging cells) into their own tentacles instead of colloblasts",
            "incorporate their prey's nematocysts (stinging cells) into their own tentacles",
            "incorporate their prey's nematocysts (stinging cells) into their own tentacles"
        ],
        "model_ans": "They are digested",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They are digested </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the bolinopsis generally eat?",
        "answers": [
            "smaller, weaker swimmers such as rotifers and mollusc and crustacean larvae.",
            "smaller, weaker swimmers such as rotifers and mollusc and crustacean larvae",
            "rotifers and mollusc and crustacean larvae"
        ],
        "model_ans": "plankton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> plankton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the two-tentacled cydippid that feedsentirely on salps called?",
        "answers": [
            "Lampea",
            "Lampea",
            "Lampea"
        ],
        "model_ans": "Mnemiopsis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mnemiopsis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why was it thought that  ctenophores were a poor diet for other animals?",
        "answers": [
            "their low ratio of organic matter to salt and water",
            "their low ratio of organic matter to salt and water",
            "low ratio of organic matter to salt and water"
        ],
        "model_ans": "Because they are low in nutrients",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they are low in nutrients </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the oncorhynchus also called?",
        "answers": [
            "chum salmon",
            "chum salmon",
            "chum salmon"
        ],
        "model_ans": "Salmon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Salmon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do beroids typically eat?",
        "answers": [
            "ctenophores",
            "other ctenophores",
            "other ctenophores"
        ],
        "model_ans": "insects",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> insects </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where have herbivorous fishes been seen feeding on gelatinous zooplankton?",
        "answers": [
            "the Red Sea",
            "the Red Sea",
            "blooms in the Red Sea"
        ],
        "model_ans": "coral reefs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> coral reefs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Turtles and jellyfish can eat large quantities of what?",
        "answers": [
            "ctenophores,",
            "ctenophores",
            "ctenophores"
        ],
        "model_ans": "plankton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> plankton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is blamed for causing the sharp drop in fish catches in the Black Sea and the Sea of Azov?",
        "answers": [
            "ctenophore Mnemiopsis leidyi",
            "Mnemiopsis leidyi",
            "the Western Atlantic ctenophore Mnemiopsis leidyi was accidentally introduced"
        ],
        "model_ans": "Overfishing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Overfishing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was the ctenophore mnemiopsis leidyi introduced into The Black Sea and the Sea of Azov?",
        "answers": [
            "via the ballast tanks of ships",
            "via the ballast tanks of ships",
            "the ballast tanks of ships"
        ],
        "model_ans": "Through ballast water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through ballast water </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was ctenophore mnemiopsis leidyi introduced into The Black Sea and the Sea of Azov?",
        "answers": [
            "in the late 1980s",
            "the late 1980s",
            "late 1980s"
        ],
        "model_ans": "1980s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1980s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How was the population of mnemiopsis in The black Sea and the Sea of Azov brought under control?",
        "answers": [
            "by the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata,",
            "the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata",
            "the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata, and by a cooling of the local climate from 1991 to 1993"
        ],
        "model_ans": "By introducing the ctenophore Mnemiopsis leidyi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By introducing the ctenophore Mnemiopsis leidyi </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How does cooling of the local environment affect the mnemiopsis?",
        "answers": [
            "significantly slowed the animal's metabolism",
            "slowed the animal's metabolism",
            "significantly slowed the animal's metabolism"
        ],
        "model_ans": "Cooling of the local environment can affect the mnemiopsis by slowing down its metabolism, reducing its feeding rate, and altering its behavior.",
        "model_confidence": "unsure</confidence",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cooling of the local environment can affect the mnemiopsis by slowing down its metabolism, reducing its feeding rate, and altering its behavior. </answer>\n<confidence>unsure</confidence</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are ctenophores extremely rare as fossils?",
        "answers": [
            "Because of their soft, gelatinous bodies",
            "their soft, gelatinous bodies",
            "their soft, gelatinous bodies"
        ],
        "model_ans": "Because they are soft-bodied animals and lack hard parts that can be preserved as fossils",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they are soft-bodied animals and lack hard parts that can be preserved as fossils </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Ediacaran eoandromeda can be regarded to represent what?",
        "answers": [
            "comb jelly.",
            "comb jelly",
            "a comb jelly"
        ],
        "model_ans": "a fossilized city",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a fossilized city </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the period called that was 505 million years ago?",
        "answers": [
            "Cambrian period.",
            "mid-Cambrian period",
            "mid-Cambrian period"
        ],
        "model_ans": "Ordovician",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ordovician </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many species were found in the Burgess Shale?",
        "answers": [
            "Three additional putative species",
            "Three",
            "Three"
        ],
        "model_ans": "143",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 143 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the  fossils found in the Burgess Shale lack?",
        "answers": [
            "lacked tentacles",
            "tentacles",
            "tentacles"
        ],
        "model_ans": "shells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> shells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How old were the fossils found in China?",
        "answers": [
            "515 million years",
            "about 515 million years",
            "515 million years"
        ],
        "model_ans": "4.4 billion years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4.4 billion years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of fossils were found in China?",
        "answers": [
            "Cambrian sessile frond-like fossil Stromatoveris",
            "Stromatoveris",
            "sessile frond-like"
        ],
        "model_ans": "Dinosaur fossils",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dinosaur fossils </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which genus is considered the \"aunt\" of ctenophores?",
        "answers": [
            "Stromatoveris",
            "Stromatoveris",
            "Stromatoveris"
        ],
        "model_ans": "Porifera",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Porifera </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Stromatoveris is similair to which genus?",
        "answers": [
            "Vendobionta",
            "ctenophores",
            "Vendobionta"
        ],
        "model_ans": "Stromatolite",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stromatolite </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Vendobionta lived during which period?",
        "answers": [
            "Ediacaran period",
            "Ediacaran period",
            "Ediacaran period"
        ],
        "model_ans": "Cambrian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cambrian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Recent studies believe  that ctenophores are the sister lineage to what?",
        "answers": [
            "all other animals",
            "Bilateria",
            "Bilateria"
        ],
        "model_ans": "cnidarians",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cnidarians </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do some researchers believe is the earliest-diverging animal phylum is?",
        "answers": [
            "Porifera",
            "Porifera",
            "Porifera"
        ],
        "model_ans": "Porifera",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Porifera </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which genus of ctenophores does not have cydipped-like larvae?",
        "answers": [
            "beroids",
            "beroids",
            "beroids"
        ],
        "model_ans": "Mnemiopsis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mnemiopsis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A molecular phylogeny analysis confirmed that cydippid are not what?",
        "answers": [
            "monophyletic",
            "monophyletic",
            "monophyletic"
        ],
        "model_ans": "jellyfish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> jellyfish </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Cretaceous-Paleogen extinction occur?",
        "answers": [
            "65.5 million years ago",
            "65.5 million years ago",
            "65.5 million years ago"
        ],
        "model_ans": "65 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 65 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did a morphologically analysis in 1985 that concluded cydippids are not monophyletic?",
        "answers": [
            "Richard Harbison",
            "Richard Harbison",
            "Richard Harbison"
        ],
        "model_ans": "J. R. V. Brockhurst",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> J. R. V. Brockhurst </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which city is the fifth-largest city in California?",
        "answers": [
            "Fresno",
            "Fresno",
            "Fresno"
        ],
        "model_ans": "San Diego",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Diego </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far is Fresno from Los Angeles?",
        "answers": [
            "220 miles (350 km)",
            "220 miles (350 km)",
            "220 miles (350 km)"
        ],
        "model_ans": "200 miles\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "200 miles\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the name Fresno mean in Spanish?",
        "answers": [
            "ash tree",
            "ash tree",
            "ash tree"
        ],
        "model_ans": "Ash tree",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ash tree </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is featured on the city of Fresno's city flag?",
        "answers": [
            "ash leaf",
            "ash leaf",
            "an ash leaf"
        ],
        "model_ans": "A coat of arms",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A coat of arms </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do you pronounce Fresno?",
        "answers": [
            "(/\u02c8fr\u025bzno\u028a/ FREZ-noh)",
            "FREZ-noh",
            "FREZ-noh"
        ],
        "model_ans": "FREZ-noh",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> FREZ-noh </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Central Pacific Railroad established a station for its new line in what year?",
        "answers": [
            "1872",
            "1872",
            "1872"
        ],
        "model_ans": "1869\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1869\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the reasons why residents moved to the town of Fresno Station?",
        "answers": [
            "the convenience of the railroad and worried about flooding",
            "drawn by the convenience of the railroad and worried about flooding",
            "the convenience of the railroad and worried about flooding"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Fresno become an incorporated city?",
        "answers": [
            "1885",
            "1885",
            "1885"
        ],
        "model_ans": "1874\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1874\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many streetcars did the Fresno Traction Company operate in 1931?",
        "answers": [
            "47 streetcars",
            "47",
            "47"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What entity sparked the growth of Fresno Station?",
        "answers": [
            "store",
            "store",
            "store"
        ],
        "model_ans": "Atchison, Topeka and Santa Fe Railway",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Atchison, Topeka and Santa Fe Railway </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1940, what percentage of the population in Fresno was Asian?",
        "answers": [
            "2.7%",
            "2.7%",
            "2.7%"
        ],
        "model_ans": "0.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What ethnic neighborhood in Fresno had primarily Japanese residents in 1940?",
        "answers": [
            "Chinatown",
            "Chinatown",
            "Chinatown"
        ],
        "model_ans": "Tower District",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tower District </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1942, what was North Fresno previously called?",
        "answers": [
            "Pinedale",
            "Pinedale",
            "Pinedale"
        ],
        "model_ans": "Fresno",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fresno </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the Pinedale Assembly Center?",
        "answers": [
            "an interim facility for the relocation of Fresno area Japanese Americans to internment camps",
            "an interim facility for the relocation of Fresno area Japanese Americans to internment camps",
            "an interim facility for the relocation of Fresno area Japanese Americans to internment camps"
        ],
        "model_ans": "Internment camp",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Internment camp </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the Fresno Fairgrounds used as?",
        "answers": [
            "an assembly center",
            "an assembly center",
            "an assembly center"
        ],
        "model_ans": "horse racing track",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> horse racing track </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What new product did Bank of America introduce in 1958?",
        "answers": [
            "BankAmericard",
            "BankAmericard",
            "BankAmericard"
        ],
        "model_ans": "BankAmericard",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> BankAmericard </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the name of the first successful credit card?",
        "answers": [
            "BankAmericard",
            "BankAmericard",
            "BankAmericard"
        ],
        "model_ans": "Diners Club",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Diners Club </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the BankAmericard allow customers do to that they couldn't do with previous financial instruments?",
        "answers": [
            "to revolve a balance",
            "a financial instrument that was usable across a large number of merchants and also allowed cardholders to revolve a balance",
            "revolve a balance"
        ],
        "model_ans": "pay bills online",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pay bills online </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did BankAmericard change its name?",
        "answers": [
            "1976",
            "1976",
            "1976"
        ],
        "model_ans": "1977",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1977 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What present-day company did BankAmericard turn into?",
        "answers": [
            "Visa Inc.",
            "Visa Inc.",
            "Visa Inc."
        ],
        "model_ans": "Visa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Visa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who wrote \"Walking in Fresno?\"",
        "answers": [
            "Bill Aken",
            "Bill Aken",
            "Bill Aken"
        ],
        "model_ans": "John Prine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Prine </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who recorded \"Walking in Fresno?\"",
        "answers": [
            "Bob Gallion",
            "Bob Gallion",
            "Bob Gallion"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what town did Bill Aiken grow up?",
        "answers": [
            "Madera",
            "Madera",
            "Madera"
        ],
        "model_ans": "Charleston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charleston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "On what show did Bill Aiken make is television debut?",
        "answers": [
            "The Fresno Barn",
            "The Fresno Barn",
            "the old country-western show at The Fresno Barn"
        ],
        "model_ans": "The Tonight Show",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Tonight Show </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Bill Aiken's adopted mother?",
        "answers": [
            "Lupe Mayorga",
            "Lupe Mayorga",
            "Lupe Mayorga"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many large public parks does Fresno have?",
        "answers": [
            "three",
            "three",
            "three"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which park is home to the Fresno Chafffee Zoo?",
        "answers": [
            "Roeding Park",
            "Roeding Park",
            "Roeding Park"
        ],
        "model_ans": "Woodward Park",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Woodward Park </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which park is home to the Kearney Mansion?",
        "answers": [
            "Kearney Park",
            "Kearney Park",
            "Kearney Park"
        ],
        "model_ans": "Kearney State Park",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kearney State Park </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which is one of the park features located in North Fresno?",
        "answers": [
            "Shinzen Japanese Gardens",
            "Shinzen Japanese Gardens"
        ],
        "model_ans": "Woodward Park",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Woodward Park </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which park hosts the largest Civil War reenactment on the west coast?",
        "answers": [
            "Kearney Park",
            "Kearney Park",
            "Kearney Park"
        ],
        "model_ans": "Antietam Battlefield",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Antietam Battlefield</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what period did downtown Fresno thrive?",
        "answers": [
            "Between the 1880s and World War II",
            "Between the 1880s and World War II",
            "Between the 1880s and World War II"
        ],
        "model_ans": "1950s-1970s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s-1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were two of Fresno's most beautiful architectural buildings that are now demolished?",
        "answers": [
            "Fresno County Courthouse (demolished), the Fresno Carnegie Public Library",
            "Fresno County Courthouse (demolished), the Fresno Carnegie Public Library",
            "the original Fresno County Courthouse (demolished), the Fresno Carnegie Public Library (demolished)"
        ],
        "model_ans": "The Fresno Theatre and the Fresno City Hall",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Fresno Theatre and the Fresno City Hall </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What former building is currently known as Grand 1401?",
        "answers": [
            "San Joaquin Light & Power Building",
            "San Joaquin Light & Power Building",
            "San Joaquin Light & Power Building"
        ],
        "model_ans": "The Grand Hotel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Grand Hotel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which one of Fresno's hotels burned down?",
        "answers": [
            "Hughes Hotel",
            "Hughes Hotel",
            "Hughes Hotel"
        ],
        "model_ans": "The Grand Hotel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Grand Hotel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Fresno get its first pedestrian mall?",
        "answers": [
            "1964",
            "1964",
            "1964"
        ],
        "model_ans": "1967",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1967 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the pedestrian mall renamed?",
        "answers": [
            "Fulton Mall",
            "Fulton Mall",
            "Fulton Mall"
        ],
        "model_ans": "Times Square",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Times Square </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which artist has a piece of his artwork located at the Fulton Mall?",
        "answers": [
            "Pierre-Auguste Renoir",
            "Pierre-Auguste Renoir",
            "Pierre-Auguste Renoir"
        ],
        "model_ans": "Jean-Michel Basquiat",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Michel Basquiat </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After reopening, where will the art pieces be located after restoration?",
        "answers": [
            "near their current locations",
            "near their current locations",
            "near their current locations"
        ],
        "model_ans": "The Louvre",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Louvre </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What feature will enrich the the pedestrian friendly environment after restoration?",
        "answers": [
            "wide sidewalks",
            "wide sidewalks",
            "wide sidewalks"
        ],
        "model_ans": "Greenery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greenery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the neighborhood of Sunnyside located in Fresno?",
        "answers": [
            "Fresno's far southeast side",
            "far southeast side",
            "far southeast side"
        ],
        "model_ans": "Fresno",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fresno </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two major thoroughfares of Sunnyside?",
        "answers": [
            "Kings Canyon Avenue and Clovis Avenue",
            "Kings Canyon Avenue and Clovis Avenue",
            "Kings Canyon Avenue and Clovis Avenue"
        ],
        "model_ans": "Queens Boulevard and Skillman Avenue",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Queens Boulevard and Skillman Avenue </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was most of Sunnside developed?",
        "answers": [
            "1950s through the 1970s",
            "1950s through the 1970s",
            "1950s through the 1970s"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the home of the Sunnyside Country Club?",
        "answers": [
            "Sunnyside",
            "Sunnyside",
            "Sunnyside"
        ],
        "model_ans": "Queens",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Queens </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who designed the golf course located at the Sunnyside Country Club?",
        "answers": [
            "William P. Bell",
            "William P. Bell",
            "William P. Bell"
        ],
        "model_ans": "Donald Ross",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Donald Ross </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Tower District is centered around which historic theatre?",
        "answers": [
            "Tower Theatre",
            "Tower Theatre",
            "Tower Theatre"
        ],
        "model_ans": "Tower Theatre",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tower Theatre </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the Tower Theatre built?",
        "answers": [
            "1939",
            "1939",
            "1939"
        ],
        "model_ans": "1884",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1884 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From what landmark within Fresno does the Tower Theatre get its name?",
        "answers": [
            "water tower",
            "water tower",
            "water tower"
        ],
        "model_ans": "Tower",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tower </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the original name of California State University at Fresno?",
        "answers": [
            "Fresno Normal School",
            "Fresno Normal School",
            "Fresno Normal School"
        ],
        "model_ans": "Fresno State College",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fresno State College </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How far is Fresno City College from the Tower District?",
        "answers": [
            "one-half mile",
            "one-half mile",
            "one-half mile"
        ],
        "model_ans": "1.5 miles\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1.5 miles\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what period did the Tower Theatre re-open?",
        "answers": [
            "late 1970s",
            "late 1970s",
            "late 1970s"
        ],
        "model_ans": "1990",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1990 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After its re-opening, which types of movies did the Tower Theatre show?",
        "answers": [
            "second and third run movies, along with classic films",
            "second and third run movies",
            "second and third run"
        ],
        "model_ans": "Independent films",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Independent films </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Roger Rocka's Dinner Theater & Good Company Players open?",
        "answers": [
            "1978",
            "1978",
            "1978"
        ],
        "model_ans": "1978\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1978\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is Audra McDonald from?",
        "answers": [
            "Fresno",
            "Fresno",
            "Fresno"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which two leading roles did Audra McDonald perform when she was in high school?",
        "answers": [
            "Evita and The Wiz",
            "Evita and The Wiz",
            "Evita and The Wiz"
        ],
        "model_ans": "She did not perform any leading roles in high school",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> She did not perform any leading roles in high school </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of theater do the neighborhoods feature?",
        "answers": [
            "live theater",
            "live",
            "live"
        ],
        "model_ans": "Off-Broadway",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Off-Broadway </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far apart are some of the neighborhood's features?",
        "answers": [
            "all within a few hundred feet of each other",
            "few hundred feet",
            "within a few hundred feet of each other"
        ],
        "model_ans": "1 mile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 mile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What area has become attractive for restaurants?",
        "answers": [
            "Tower District",
            "Tower District",
            "the Tower District"
        ],
        "model_ans": "Downtown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which Fresno district is the center for the LGBT community?",
        "answers": [
            "Tower District",
            "Tower District",
            "Tower District"
        ],
        "model_ans": "Tower District",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tower District </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which district in Fresno is known as the center for the heavy metal community?",
        "answers": [
            "Tower District",
            "Tower District",
            "Tower District"
        ],
        "model_ans": "Tower District",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tower District </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of homes is Fresno known for?",
        "answers": [
            "early twentieth century homes",
            "early twentieth century homes",
            "early twentieth century"
        ],
        "model_ans": "Spanish-style",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spanish-style </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of houses are designed by Fresno architects?",
        "answers": [
            "Storybook houses",
            "Storybook"
        ],
        "model_ans": "Residential",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Residential </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Does the residential architecture of the Tower District compare or contrast with other part of Fresno?",
        "answers": [
            "contrasts",
            "contrasts",
            "contrasts"
        ],
        "model_ans": "compare",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> compare </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How recently has the homes in Fresno been restored?",
        "answers": [
            "in recent decades",
            "recent decades",
            "recent decades"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which boulevard can you find many majestic homes in the area?",
        "answers": [
            "Huntington Boulevard",
            "Huntington Boulevard",
            "Huntington Boulevard"
        ],
        "model_ans": "Park Avenue",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Park Avenue </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who mapped the Alta Vista Tract?",
        "answers": [
            "William Stranahan",
            "William Stranahan",
            "William Stranahan"
        ],
        "model_ans": "Alta Vista",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alta Vista </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did developers Billings & Meyering acquire the Alta Vista Tract?",
        "answers": [
            "1914",
            "1914",
            "1914"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many homes did the Alta Vista Tract have five years after Billings & Meyering acquired it?",
        "answers": [
            "267",
            "267",
            "267"
        ],
        "model_ans": "1,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which company provided streetcar connections between downtown and the hospital?",
        "answers": [
            "Fresno Traction Company",
            "Fresno Traction Company",
            "Fresno Traction Company"
        ],
        "model_ans": "Streetcar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Streetcar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another name for the west side of Fresno?",
        "answers": [
            "\"Southwest Fresno\"",
            "Southwest Fresno",
            "Southwest Fresno"
        ],
        "model_ans": "Downtown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which direction does the west side of Fresno neighborhood lie to the 99 freeway?",
        "answers": [
            "southwest",
            "southwest",
            "southwest"
        ],
        "model_ans": "North",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> North </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The west side of Fresno is the center of which ethnic community?",
        "answers": [
            "African-American",
            "African-American",
            "African-American"
        ],
        "model_ans": "Hispanic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hispanic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two principal Asian-American groups living in the west side neighborhood of Fresno?",
        "answers": [
            "Hmong or Laotian",
            "Hmong or Laotian",
            "Hmong or Laotian"
        ],
        "model_ans": "Vietnamese and Filipino",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vietnamese and Filipino </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which neighborhood lies west of the 41 freeway?",
        "answers": [
            "\"West Side\"",
            "West Side",
            "West Side"
        ],
        "model_ans": "Downtown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is Kearney Boulevard named after?",
        "answers": [
            "M. Theo Kearney",
            "M. Theo Kearney",
            "M. Theo Kearney"
        ],
        "model_ans": "Kearney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kearney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kinds of trees is Kearney Boulevard lined with?",
        "answers": [
            "tall palm trees",
            "tall palm trees",
            "palm"
        ],
        "model_ans": "Palm trees",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Palm trees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Between which two streets along Kearney Boulevard were wealthy African-Americans at one time residing?",
        "answers": [
            "Fresno Street and Thorne Ave",
            "Fresno Street and Thorne Ave",
            "Fresno Street and Thorne Ave"
        ],
        "model_ans": "36th Street and 42nd Street",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 36th Street and 42nd Street </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name given to a section of Kearney Boulevard in efforts to change the areas image?",
        "answers": [
            "Brookhaven",
            "Brookhaven",
            "Brookhaven"
        ],
        "model_ans": "The Boulevard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Boulevard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What area of Brookhaven is still known for its high levels of crime?",
        "answers": [
            "The isolated subdivision",
            "Dogg Pound"
        ],
        "model_ans": "Downtown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Downtown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were the public housing developments built in the neighborhood?",
        "answers": [
            "between the 1960s and 1990s",
            "between the 1960s and 1990s",
            "between the 1960s and 1990s"
        ],
        "model_ans": "1930s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1930s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On which corner is the shopping center located?",
        "answers": [
            "Fresno and B streets",
            "Fresno and B streets",
            "Fresno and B streets"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the two processing facilities in the neighborhood?",
        "answers": [
            "Cargill Meat Solutions and Foster Farms",
            "Cargill Meat Solutions and Foster Farms",
            "Cargill Meat Solutions and Foster Farms"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the airport located?",
        "answers": [
            "the West Side",
            "West Side",
            "on the West Side"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much retail activity does the neighborhood have?",
        "answers": [
            "very little",
            "very little",
            "very little"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who founded Woodward Park?",
        "answers": [
            "Ralph Woodward",
            "Ralph Woodward",
            "Ralph Woodward"
        ],
        "model_ans": "City of Fresno",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> City of Fresno </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many total acres is Woodward Park?",
        "answers": [
            "300 acres",
            "300",
            "300"
        ],
        "model_ans": "150",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many seats does the amphitheatre at Woodward park have?",
        "answers": [
            "2,500",
            "2,500",
            "2,500"
        ],
        "model_ans": "500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many miles, once completed, will the the Lewis S. Eaton trail cover?",
        "answers": [
            "22 miles",
            "22",
            "22"
        ],
        "model_ans": "100 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What months out of the year is Woodward Park open?",
        "answers": [
            "April through October",
            "April through October",
            "April through October, 6am to 10pm and November through March, 6am to 7pm"
        ],
        "model_ans": "January to December",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> January to December </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Sierra Sky Park Airport formed?",
        "answers": [
            "1946",
            "1946",
            "1946"
        ],
        "model_ans": "1955",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1955 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who created the nation's first aviation community?",
        "answers": [
            "William Smilie",
            "William Smilie",
            "William Smilie"
        ],
        "model_ans": "Wright brothers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wright brothers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the first aviation community built?",
        "answers": [
            "Sierra Sky Park",
            "Sierra Sky Park",
            "Sierra Sky Park"
        ],
        "model_ans": "Wright",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wright </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The transportation law allows personal aircraft to share the roadways with what?",
        "answers": [
            "automobiles",
            "automobiles",
            "automobiles"
        ],
        "model_ans": "cars",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cars </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Are there any other aviation communities such as Sierra Sky Park in the United States?",
        "answers": [
            "there are now numerous such communities across the United States",
            "numerous"
        ],
        "model_ans": "Yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How would one describe the summers in Fresno?",
        "answers": [
            "hot and dry",
            "hot and dry",
            "hot and dry"
        ],
        "model_ans": "hot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What month is the warmest in Fresno?",
        "answers": [
            "July",
            "July",
            "July"
        ],
        "model_ans": "July",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> July </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much rain per year does Fresno get on average?",
        "answers": [
            "around 11.5 inches",
            "11.5 inches (292.1 mm)",
            "11.5 inches"
        ],
        "model_ans": "10.5 inches\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "10.5 inches\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which direction does most of the wind in Fresno originate from?",
        "answers": [
            "northwest",
            "northwest",
            "northwest"
        ],
        "model_ans": "West",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> West </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which months does Fresno experience increased wind coming from the southeastern direction?",
        "answers": [
            "December, January and February",
            "December, January and February",
            "December, January and February"
        ],
        "model_ans": "March and April",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March and April </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the hottest temperature record for Fresno?",
        "answers": [
            "115 \u00b0F",
            "115 \u00b0F (46.1 \u00b0C)",
            "115 \u00b0F"
        ],
        "model_ans": "118\u00b0F (48\u00b0C)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 118\u00b0F (48\u00b0C) </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what date was the record low temperature in Fresno?",
        "answers": [
            "January 6, 1913",
            "January 6, 1913",
            "January 6, 1913"
        ],
        "model_ans": "January 16, 1937",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 16, 1937 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Fresno experience the most rainfall?",
        "answers": [
            "1885",
            "July 1982 to June 1983"
        ],
        "model_ans": "1983",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1983 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most snow Fresno has ever had?",
        "answers": [
            "2.2 inches",
            "2.2 inches (0.06 m)",
            "2.2 inches"
        ],
        "model_ans": "6 inches",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 inches </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most rainfall recorded in a 24 hour period in Fresno?",
        "answers": [
            "3.55 inches",
            "3.55 inches (90.2 mm)",
            "3.55 inches"
        ],
        "model_ans": "2.5 inches",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2.5 inches </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was Fresno's population in 2010?",
        "answers": [
            "494,665",
            "494,665",
            "494,665"
        ],
        "model_ans": "520,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 520,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of whit people in Fresno in 2010?",
        "answers": [
            "49.6%",
            "49.6%",
            "49.6%"
        ],
        "model_ans": "44.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 44.5% </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Native American people resided in Fresno in 2010?",
        "answers": [
            "8,525",
            "62,528",
            "8,525"
        ],
        "model_ans": "2,444",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,444 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of Non-Hispanic Whites in 2010? ",
        "answers": [
            "30.0%",
            "30.0%",
            "30.0%"
        ],
        "model_ans": "72.4% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "72.4% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people per square mile lived in Fresno in 2010?",
        "answers": [
            "4,404.5 people",
            "4,404.5",
            "4,404.5"
        ],
        "model_ans": "4,345",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,345 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many households has kids under the age of 18 living in them?",
        "answers": [
            "68,511",
            "68,511",
            "68,511"
        ],
        "model_ans": "64.4 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 64.4 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of a female householder with no husband present?",
        "answers": [
            "19.3%",
            "19.3%",
            "19.3%"
        ],
        "model_ans": "12.6%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12.6% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many same-sex married couples or partnerships were there?",
        "answers": [
            "1,388",
            "1,388",
            "1,388"
        ],
        "model_ans": "1.2 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the average family size?",
        "answers": [
            "3.62",
            "3.62",
            "3.62"
        ],
        "model_ans": "3.14\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3.14\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the average household size?",
        "answers": [
            "3.07",
            "3.07",
            "3.07"
        ],
        "model_ans": "3.14\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3.14\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people lived in Fresno in 2000, according to the Census Bureau? ",
        "answers": [
            "427,652",
            "427,652",
            "427,652"
        ],
        "model_ans": "427,652",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 427,652 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many housing units were there in 2000?",
        "answers": [
            "149,025",
            "149,025",
            "149,025"
        ],
        "model_ans": "64,000,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 64,000,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of Black or African-Americans living in the city?",
        "answers": [
            "8.4%",
            "8.4%",
            "8.4%"
        ],
        "model_ans": "12.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "About how many of the Asian population was Hmong?",
        "answers": [
            "a third",
            "about a third",
            "a third"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the population density in 2000?",
        "answers": [
            "4,097.9 people per square mile",
            "4,097.9 people per square mile",
            "4,097.9"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why does Fresno only have UHF television stations?",
        "answers": [
            "To avoid interference with existing VHF television stations",
            "To avoid interference with existing VHF television stations",
            "To avoid interference with existing VHF television stations"
        ],
        "model_ans": "Due to the city's location in the San Joaquin Valley, which is a mountainous region, making it difficult to receive VHF signals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Due to the city's location in the San Joaquin Valley, which is a mountainous region, making it difficult to receive VHF signals </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the very first television station to broadcast in Fresno?",
        "answers": [
            "KMJ-TV",
            "KMJ-TV",
            "KMJ-TV"
        ],
        "model_ans": "KFRE-TV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> KFRE-TV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the KMJ-TV first broadcast?",
        "answers": [
            "June 1, 1953",
            "June 1, 1953",
            "June 1, 1953"
        ],
        "model_ans": "1953",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1953 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is KMJ now referred to?",
        "answers": [
            "NBC affiliate KSEE",
            "NBC affiliate KSEE",
            "KSEE"
        ],
        "model_ans": "KMB",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> KMB </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the CBS affiliate in Fresno?",
        "answers": [
            "KGPE",
            "KGPE",
            "KGPE"
        ],
        "model_ans": "KGPE",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> KGPE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What route connects Fresno with the California Central Valley?",
        "answers": [
            "State Route 99",
            "State Route 99",
            "State Route 99"
        ],
        "model_ans": "Highway 99",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Highway 99 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another name for State Route 168?",
        "answers": [
            "the Sierra Freeway",
            "Sierra Freeway",
            "Sierra Freeway"
        ],
        "model_ans": "SR 168",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SR 168 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another name for the Yosemite Freeway?",
        "answers": [
            "State Route 41",
            "State Route 41"
        ],
        "model_ans": "CA-120",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> CA-120 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "State Route 180 comes from which direction via Mendota?",
        "answers": [
            "west",
            "west",
            "west"
        ],
        "model_ans": "East",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> East </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which is the largest city not connected to an interstate highway?",
        "answers": [
            "Fresno",
            "Fresno",
            "Fresno"
        ],
        "model_ans": "Juneau",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Juneau </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the Interstate Highway System created?",
        "answers": [
            "1950s",
            "in the 1950s"
        ],
        "model_ans": "1956\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1956\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which State Route has been in discussion to upgrade to interstate standards?",
        "answers": [
            "99",
            "State Route 99",
            "State Route 99"
        ],
        "model_ans": "SR 99",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> SR 99 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the factors that are contributing to the desire to have SR 99 improved to be of interstate standards?",
        "answers": [
            "rapidly raising population and traffic in cities along SR 99",
            "rapidly raising population and traffic in cities along SR 99, as well as the desirability of Federal funding",
            "rapidly raising population and traffic in cities along SR 99, as well as the desirability of Federal funding"
        ],
        "model_ans": "traffic congestion, safety concerns, and economic growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> traffic congestion, safety concerns, and economic growth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which company provides train service in Fresno?",
        "answers": [
            "Amtrak San Joaquins",
            "Amtrak San Joaquins",
            "Amtrak San Joaquins"
        ],
        "model_ans": "Amtrak",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amtrak </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the Santa Fe Railroad Depot located?",
        "answers": [
            "Downtown Fresno",
            "Downtown Fresno",
            "Downtown Fresno"
        ],
        "model_ans": "Santa Fe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Santa Fe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What two railroads have railyards in the city of Fresno?",
        "answers": [
            "Burlington Northern Santa Fe Railway and Union Pacific Railroad",
            "Burlington Northern Santa Fe Railway and Union Pacific Railroad",
            "Burlington Northern Santa Fe Railway and Union Pacific Railroad"
        ],
        "model_ans": "BNSF Railway and Union Pacific Railroad",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> BNSF Railway and Union Pacific Railroad </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If you were to take a train west or south out of the city of Fresno, which railroad would you take?",
        "answers": [
            "San Joaquin Valley Railroad",
            "San Joaquin Valley Railroad",
            "San Joaquin Valley Railroad"
        ],
        "model_ans": "BNSF",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BNSF </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which city is planned to be a part of the California High Speed Rail?",
        "answers": [
            "Fresno",
            "Fresno",
            "Fresno"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Paul Baran develop ",
        "answers": [
            "Paul Baran developed the concept Distributed Adaptive Message Block Switching",
            "the concept Distributed Adaptive Message Block Switching",
            "Distributed Adaptive Message Block Switching"
        ],
        "model_ans": "packet switching",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> packet switching </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Distributed Adaptive Message Block Switching do",
        "answers": [
            "provide a fault-tolerant, efficient routing method for telecommunication messages",
            "provide a fault-tolerant, efficient routing method for telecommunication messages",
            "fault-tolerant, efficient routing method"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did this concept contradict ",
        "answers": [
            "This concept contrasted and contradicted the theretofore established principles of pre-allocation of network bandwidth",
            "theretofore established principles of pre-allocation of network bandwidth",
            "principles of pre-allocation of network bandwidth"
        ],
        "model_ans": "The concept of the concept",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The concept of the concept </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Donald Davies credited with ",
        "answers": [
            "Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe",
            "coining the modern name packet switching and inspiring numerous packet switching networks",
            "coining the modern name packet switching"
        ],
        "model_ans": "inventing packet switching",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inventing packet switching </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Paul Baran develop in the late 1950's",
        "answers": [
            "the concept Distributed Adaptive Message Block Switching",
            "the concept Distributed Adaptive Message Block Switching",
            "Distributed Adaptive Message Block Switching"
        ],
        "model_ans": "packet switching",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> packet switching </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the goal of the system ",
        "answers": [
            "to provide a fault-tolerant, efficient routing method for telecommunication messages",
            "provide a fault-tolerant, efficient routing method for telecommunication messages"
        ],
        "model_ans": "To provide a system that can answer questions with confidence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To provide a system that can answer questions with confidence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is credited with the modern name for this system ",
        "answers": [
            "Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe",
            "Donald Davies",
            "Donald Davies"
        ],
        "model_ans": "Carl Linnaeus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carl Linnaeus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Packet Switching contrast with what other principal ",
        "answers": [
            "circuit switching",
            "circuit switching",
            "circuit switching"
        ],
        "model_ans": "Circuit Switching",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Circuit Switching </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is circuit switching characterized by",
        "answers": [
            "circuit switching is characterized by a fee per unit of connection time",
            "a method which pre-allocates dedicated network bandwidth specifically for each communication session",
            "fee per unit of connection time"
        ],
        "model_ans": "Dedicated connection",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dedicated connection </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is packet switching charecterized",
        "answers": [
            "by a fee per unit of information transmitted",
            "a fee per unit of information transmitted",
            "fee per unit of information transmitted"
        ],
        "model_ans": "packet switching is a method of transmitting data in which data is broken into packets and transmitted independently",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> packet switching is a method of transmitting data in which data is broken into packets and transmitted independently </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does Packet switching contrast with ",
        "answers": [
            "circuit switching",
            "circuit switching",
            "circuit switching"
        ],
        "model_ans": "Circuit switching",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Circuit switching </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How is circuit switching allocated ",
        "answers": [
            "a method which pre-allocates dedicated network bandwidth",
            "pre-allocates dedicated network bandwidth specifically for each communication session",
            "pre-allocates"
        ],
        "model_ans": "dynamically",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> dynamically </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is circuit switching charecterized ",
        "answers": [
            "by a fee per unit of connection time, even when no data is transferred",
            "a fee per unit of connection time",
            "fee per unit of connection time"
        ],
        "model_ans": "Dedicated connection",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dedicated connection </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is packet switching characterized ",
        "answers": [
            "by a fee per unit of information transmitted, such as characters, packets, or messages",
            "a fee per unit of information transmitted",
            "fee per unit of information transmitted"
        ],
        "model_ans": "packet switching is a method of transmitting data in which data is broken up into packets and transmitted independently",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> packet switching is a method of transmitting data in which data is broken up into packets and transmitted independently </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In cases of shared physical medium how are they delivered ",
        "answers": [
            "the packets may be delivered according to a multiple access scheme",
            "according to a multiple access scheme",
            "multiple access scheme"
        ],
        "model_ans": "via email",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> via email </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is packet mode communication implemented ",
        "answers": [
            "with or without intermediate forwarding nodes",
            "with or without intermediate forwarding nodes",
            "with or without intermediate forwarding nodes"
        ],
        "model_ans": "using protocols such as TCP/IP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> using protocols such as TCP/IP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are packets normally forwarded",
        "answers": [
            "by intermediate network nodes asynchronously using first-in, first-out buffering, but may be forwarded according to some scheduling discipline for fair queuing",
            "intermediate network nodes asynchronously using first-in, first-out buffering",
            "asynchronously"
        ],
        "model_ans": "by routers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> by routers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In cases with shared medium how is it delivered ",
        "answers": [
            "the packets may be delivered according to a multiple access scheme",
            "according to a multiple access scheme",
            "multiple access scheme"
        ],
        "model_ans": "Digital",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Digital </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Baran develop during research at RAND ",
        "answers": [
            "the concept of distributed adaptive message block switching",
            "the concept of distributed adaptive message block switching",
            "concept of distributed adaptive message block switching"
        ],
        "model_ans": "the concept of the \"baran network\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the concept of the \"baran network\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was developed for the Air Force ",
        "answers": [
            "survivable communications networks",
            "the concept of distributed adaptive message block switching",
            "survivable communications networks"
        ],
        "model_ans": "Stealth Technology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stealth Technology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What 3 things does the Air Force work key on ",
        "answers": [
            "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks",
            "ideas"
        ],
        "model_ans": "Air, Force, Key",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Air, Force, Key </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are Air force messages delivered ",
        "answers": [
            "delivery of these messages by store and forward switching",
            "decentralized network with multiple paths between any two points",
            "store and forward switching"
        ],
        "model_ans": "via radio",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> via radio </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What concept was developed by Baran while researching at RAND",
        "answers": [
            "distributed adaptive message block switching",
            "distributed adaptive message block switching",
            "distributed adaptive message block switching"
        ],
        "model_ans": "packet switching",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> packet switching </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was report P-2626",
        "answers": [
            "a general architecture for a large-scale, distributed, survivable communications network",
            "a general architecture for a large-scale, distributed, survivable communications network",
            "briefing B-265"
        ],
        "model_ans": "Report P-2626 is a report on the effects of nuclear radiation on the human body",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Report P-2626 is a report on the effects of nuclear radiation on the human body </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What  things did the network concentrate on ",
        "answers": [
            "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets",
            "large-scale, distributed, survivable communications network",
            "multiple paths between any two points"
        ],
        "model_ans": "Television",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Television </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What delivery message was used ",
        "answers": [
            "by store and forward switching",
            "packets",
            "store and forward switching"
        ],
        "model_ans": "SMS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SMS </answer> \n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Donald Davies Develop",
        "answers": [
            "independently developed the same message routing methodology as developed by Baran",
            "the same message routing methodology as developed by Baran",
            "message routing methodology"
        ],
        "model_ans": "Packet switching",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Packet switching </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Davies call his system ",
        "answers": [
            "packet switching",
            "packet switching",
            "packet switching"
        ],
        "model_ans": "The Davies System",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Davies System </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Davies want to build ",
        "answers": [
            "proposed to build a nationwide network in the UK",
            "a nationwide network",
            "nationwide network"
        ],
        "model_ans": "a bridge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a bridge </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What use was suggested for the system ",
        "answers": [
            "use in the ARPANET",
            "ARPANET",
            "ARPANET"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who developed the same technology as Baran ",
        "answers": [
            "Donald Davies",
            "Donald Davies",
            "Donald Davies"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Davies call the System ",
        "answers": [
            "packet switching",
            "packet switching",
            "packet switching"
        ],
        "model_ans": "The System",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The System </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was suggested at the Symposium in 1967",
        "answers": [
            "suggested it for use in the ARPANET",
            "use in the ARPANET",
            "use in the ARPANET"
        ],
        "model_ans": "The Symposium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Symposium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does each packet includ in connectionless mode ",
        "answers": [
            "each packet includes complete addressing information",
            "complete addressing information",
            "complete addressing information"
        ],
        "model_ans": "header",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> header </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are the packets routed ",
        "answers": [
            "individually, sometimes resulting in different paths and out-of-order delivery",
            "individually",
            "individually"
        ],
        "model_ans": "IP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is included with each packet label",
        "answers": [
            "Each packet is labeled with a destination address, source address, and port numbers. It may also be labeled with the sequence number of the packet",
            "destination address, source address, and port numbers",
            "destination address, source address, and port numbers"
        ],
        "model_ans": "product name, product description, ingredients, instructions, and warnings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> product name, product description, ingredients, instructions, and warnings </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to the packet at the destination",
        "answers": [
            "the original message/data is reassembled in the correct order, based on the packet sequence number",
            "the original message/data is reassembled in the correct order",
            "reassembled"
        ],
        "model_ans": "It is processed by the destination device",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It is processed by the destination device </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does connection orientation require",
        "answers": [
            "a setup phase in each involved node before any packet is transferred to establish the parameters of communication",
            "a setup phase in each involved node",
            "setup phase"
        ],
        "model_ans": "Connection orientation requires a clear understanding of the relationship between the two entities being connected, as well as the context in which they are being connected.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Connection orientation requires a clear understanding of the relationship between the two entities being connected, as well as the context in which they are being connected. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a connection identifier ",
        "answers": [
            "a connection identifier rather than address information and are negotiated between endpoints so that they are delivered in order and with error checking",
            "negotiated between endpoints"
        ],
        "model_ans": "A unique identifier used to connect to a database",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A unique identifier used to connect to a database </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is the node requiered to look up ",
        "answers": [
            "Routing a packet requires the node to look up the connection id in a table",
            "the connection id in a table",
            "connection id"
        ],
        "model_ans": "to find the node's IP address",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> to find the node's IP address </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Is the packet header long ",
        "answers": [
            "The packet header can be small, as it only needs to contain this code and any information, such as length, timestamp, or sequence number",
            "The packet header can be small",
            "small"
        ],
        "model_ans": "yes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> yes </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "WHat do x.25 and Frame Relay both require",
        "answers": [
            "connection-oriented operations. But X.25 does it at the network layer of the OSI Model. Frame Relay does it at level two, the data link layer",
            "a handshake between the communicating parties before any user packets are transmitted",
            "connection-oriented operations"
        ],
        "model_ans": "a dedicated circuit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a dedicated circuit </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were X.25 and Frame relay used for ",
        "answers": [
            "Frame Relay was used to interconnect LANs across wide area networks. However, X.25 and well as Frame Relay have been supplanted",
            "provide connection-oriented operations",
            "standardized interface"
        ],
        "model_ans": "packet-switched networks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> packet-switched networks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What supplanted Frame Relay and X.25 ",
        "answers": [
            "supplanted by the Internet Protocol (IP) at the network layer, and the Asynchronous Transfer Mode (ATM) and or versions of Multi-Protocol Label Switching",
            "Internet Protocol (IP)",
            "Internet Protocol"
        ],
        "model_ans": "IP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a typical configuration",
        "answers": [
            "A typical configuration is to run IP over ATM or a version of MPLS",
            "run IP over ATM or a version of MPLS",
            "run IP over ATM or a version of MPLS"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "WHen did ARPNET and SITA become operational",
        "answers": [
            "1969",
            "1969",
            "1969"
        ],
        "model_ans": "ARPANET became operational in 1969, SITA became operational in 1947\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " ARPANET became operational in 1969, SITA became operational in 1947\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "2 differences betwen X.25 and ARPNET CITA technologies ",
        "answers": [
            "Two fundamental differences involved the division of functions and tasks between the hosts at the edge of the network and the network core",
            "the division of functions and tasks between the hosts at the edge of the network and the network core.",
            "division of functions and tasks between the hosts at the edge of the network and the network core"
        ],
        "model_ans": "1. X.25 is a packet-switching protocol, while ARPANET is a network protocol. 2. X.25 is a standardized protocol, while ARPANET</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1. X.25 is a packet-switching protocol, while ARPANET is a network protocol. 2. X.25 is a standardized protocol, while ARPANET</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "WHat does UserDatagram Protocol gaurentee",
        "answers": [
            "In the virtual call system, the network guarantees sequenced delivery of data to the host",
            "sequenced delivery of data to the host",
            "sequenced delivery of data"
        ],
        "model_ans": "Reliability",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Reliability </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "X.25 uses what type network type ",
        "answers": [
            "User Datagram Protocol",
            "the datagram model",
            "UDP"
        ],
        "model_ans": "packet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> packet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Apple Talk ",
        "answers": [
            "a proprietary suite of networking protocols developed by Apple Inc. in 1985",
            "a proprietary suite of networking protocols developed by Apple Inc",
            "proprietary suite of networking protocols"
        ],
        "model_ans": "AppleTalk",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> AppleTalk </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "WHat were features of Apple Talk ",
        "answers": [
            "that allowed local area networks to be established ad hoc without the requirement for a centralized router or server",
            "allowed local area networks to be established ad hoc without the requirement for a centralized router or server",
            "allowed local area networks to be established ad hoc without the requirement for a centralized router or server"
        ],
        "model_ans": "AppleTalk was a proprietary networking protocol developed by Apple Inc.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AppleTalk was a proprietary networking protocol developed by Apple Inc. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Apple system assign automatically ",
        "answers": [
            "automatically assigned addresses, updated the distributed namespace, and configured any required inter-network routing",
            "addresses",
            "addresses"
        ],
        "model_ans": "UUID",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UUID </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "This type of system is known as ",
        "answers": [
            "a plug-n-play system",
            "plug-n-play",
            "plug-n-play"
        ],
        "model_ans": "Expert System",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Expert System </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What network was designed by the french ",
        "answers": [
            "CYCLADES packet switching network",
            "CYCLADES",
            "CYCLADES"
        ],
        "model_ans": "Internet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Internet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was a first for this network ",
        "answers": [
            "to make the hosts responsible for reliable delivery of data, rather than the network itself",
            "the first network to make the hosts responsible for reliable delivery of data",
            "hosts responsible for reliable delivery of data"
        ],
        "model_ans": "MTV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MTV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was this possible ",
        "answers": [
            "using unreliable datagrams and associated end-to-end protocol mechanisms",
            "using unreliable datagrams and associated end-to-end protocol mechanisms",
            "unreliable datagrams and associated end-to-end protocol mechanisms"
        ],
        "model_ans": "I am not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not sure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "This network influenced  later models of ",
        "answers": [
            "later ARPANET architecture",
            "ARPANET",
            "ARPANET"
        ],
        "model_ans": "neural networks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> neural networks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is  DECnet",
        "answers": [
            "a suite of network protocols created by Digital Equipment Corporation",
            "a suite of network protocols created by Digital Equipment Corporation",
            "suite of network protocols created by Digital Equipment Corporation"
        ],
        "model_ans": "DEC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> DEC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did DECnet originally do ",
        "answers": [
            "connect two PDP-11 minicomputers",
            "connect two PDP-11 minicomputers",
            "connect two PDP-11 minicomputers"
        ],
        "model_ans": "DECnet was a proprietary networking protocol developed by Digital Equipment Corporation (DEC)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DECnet was a proprietary networking protocol developed by Digital Equipment Corporation (DEC) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "DEC originally had 3 layers but evolved into how many layers ",
        "answers": [
            "Initially built with three layers, it later (1982) evolved into a seven-layer OSI-compliant networking protocol",
            "seven",
            "seven"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did DECnet phase 2 become ",
        "answers": [
            "were open standards with published specifications, and several implementations were developed outside DEC, including one for Linux",
            "Linux",
            "open standards"
        ],
        "model_ans": "TCP/IP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> TCP/IP </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Warner Sinback",
        "answers": [
            "a data network based on this voice-phone network was designed to connect GE's four computer sales and service centers",
            "a data network",
            "a data network"
        ],
        "model_ans": "Warner Bros",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warner Bros </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The 4 sales and service centers are viewed as ",
        "answers": [
            "the world's first commercial online service",
            "the world's first commercial online service",
            "world's first commercial online service"
        ],
        "model_ans": "branches",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> branches </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Were the centers profitable",
        "answers": [
            "They lost money from the beginning, and Sinback, a high-level marketing manager, was given the job of turning the business around",
            "They lost money",
            "lost money"
        ],
        "model_ans": "No",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Warner Sinback decide ",
        "answers": [
            "that a time-sharing system, based on Kemney's work at Dartmouth\u2014which used a computer on loan from GE\u2014could be profitable",
            "a time-sharing system, based on Kemney's work at Dartmouth\u2014which used a computer on loan from GE\u2014could be profitable",
            "could be profitable"
        ],
        "model_ans": "I couldn't find any reliable source about Warner Sinback's decision",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I couldn't find any reliable source about Warner Sinback's decision </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "WHy was the Merit network formed in Michigan ",
        "answers": [
            "as a means to help the state's educational and economic development",
            "to explore computer networking between three of Michigan's public universities",
            "explore computer networking"
        ],
        "model_ans": "Merit was formed in 1977 as a non-profit organization to provide high-speed networking services to educational and research institutions in Michigan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Merit was formed in 1977 as a non-profit organization to provide high-speed networking services to educational and research institutions in Michigan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What completed the triad ",
        "answers": [
            "an interactive host to host connection was made between the IBM mainframe computer systems at the University of Michigan in Ann Arbor and Wayne State",
            "the CDC mainframe at Michigan State University in East Lansing",
            "1972 connections"
        ],
        "model_ans": "The Three Musketeers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Three Musketeers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What set the stage for Merits role in NSFNET",
        "answers": [
            "Ethernet attached hosts, and eventually TCP/IP and additional public universities in Michigan join the network",
            "the network was enhanced",
            "TCP/IP"
        ],
        "model_ans": "ARPANET",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ARPANET </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was telenet ",
        "answers": [
            "the first FCC-licensed public data network in the United States",
            "the first FCC-licensed public data network in the United States",
            "first FCC-licensed public data network"
        ],
        "model_ans": "Telenet was a pioneering online service provider that allowed users to access remote computers and servers over a dial-up modem connection.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Telenet was a pioneering online service provider that allowed users to access remote computers and servers over a dial-up modem connection. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who founded Telnet ",
        "answers": [
            "Larry Roberts",
            "ARPA IPTO director Larry Roberts",
            "Larry Roberts"
        ],
        "model_ans": "Bolt Beranek and Newman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bolt Beranek and Newman </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Purpose of Telnet ",
        "answers": [
            "making ARPANET technology public",
            "a means of making ARPANET technology public",
            "making ARPANET technology public"
        ],
        "model_ans": "Remote access to a computer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Remote access to a computer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Telnet Used what  Interface technology",
        "answers": [
            "host interface to X.25 and the terminal interface to X.29",
            "X.25",
            "ARPANET"
        ],
        "model_ans": "TCP/IP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> TCP/IP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Telnet was sold to ",
        "answers": [
            "Telenet was incorporated in 1973 and started operations in 1975. It went public in 1979 and was then sold to GTE",
            "GTE",
            "GTE"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Tymnet",
        "answers": [
            "an international data communications network headquartered in San Jose, CA",
            "an international data communications network",
            "international data communications network"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Tymnet connect ",
        "answers": [
            "connect host computers (servers)at thousands of large companies, educational institutions, and government agencies",
            "host computers (servers)at thousands of large companies, educational institutions, and government agencies",
            "host computers"
        ],
        "model_ans": "computers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> computers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did user of Tymnet connect ",
        "answers": [
            "connected via dial-up connections or dedicated async connections",
            "dial-up connections or dedicated async connections",
            "dial-up"
        ],
        "model_ans": "dial-up",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dial-up </answer> <confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The business allowed for private companies to do what ",
        "answers": [
            "government agencies and large companies (mostly banks and airlines) to build their own dedicated networks",
            "build their own dedicated networks",
            "build their own dedicated networks"
        ],
        "model_ans": "operate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> operate </answer> \n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Gateways allowed private companies to do what ",
        "answers": [
            "private networks were often connected via gateways to the public network to reach locations not on the private network",
            "reach locations not on the private network",
            "reach locations not on the private network"
        ],
        "model_ans": "operate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> operate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many types of X.25 networks were there originally ",
        "answers": [
            "There were two kinds of X.25 networks. Some such as DATAPAC and TRANSPAC",
            "two",
            "two"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who developed DATAPAC",
        "answers": [
            "DATAPAC was developed by Bell Northern Research",
            "Bell Northern Research",
            "Bell Northern Research"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "WHat did foreign clones of DATAPAC allow for ",
        "answers": [
            "A user or host could call a host on a foreign network by including the DNIC of the remote network as part of the destination address",
            "the interconnection of national X.25 networks",
            "interconnection of national X.25 networks"
        ],
        "model_ans": "Interoperability",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Interoperability </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was AUSTPAC",
        "answers": [
            "AUSTPAC was an Australian public X.25 network operated by Telstra",
            "an Australian public X.25 network operated by Telstra",
            "an Australian public X.25 network"
        ],
        "model_ans": "Australian Pacific",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Australian Pacific </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did AUSTPAC support ",
        "answers": [
            "supporting applications such as on-line betting, financial applications",
            "applications such as on-line betting, financial applications",
            "applications such as on-line betting, financial applications"
        ],
        "model_ans": "Australian Pacific",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Australian Pacific </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are AUSTPAC connections made ",
        "answers": [
            "Access can be via a dial-up terminal to a PAD, or, by linking a permanent X.25 node to the network",
            "dial-up terminal to a PAD, or, by linking a permanent X.25 node",
            "dial-up terminal"
        ],
        "model_ans": "AUSTPAC connections are made through a combination of mechanical and chemical bonding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AUSTPAC connections are made through a combination of mechanical and chemical bonding </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was DATANET 1 ",
        "answers": [
            "was the public switched data network operated by the Dutch PTT Telecom",
            "the public switched data network operated by the Dutch PTT Telecom",
            "public switched data network"
        ],
        "model_ans": "DATANET 1 was a packet switching network developed by the UK's Ministry of Defence in the 1970s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DATANET 1 was a packet switching network developed by the UK's Ministry of Defence in the 1970s </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Strictly speaking who was included in DATANET 1",
        "answers": [
            "Datanet 1 only referred to the network and the connected users via leased lines",
            "the network",
            "the network and the connected users"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who else did DATNET 1 refer to ",
        "answers": [
            "public PAD service Telepad (using the DNIC 2049",
            "the public PAD service Telepad",
            "public PAD service Telepad"
        ],
        "model_ans": "DATNET 2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DATNET 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Was the Use of the DATANET 1 name correct ",
        "answers": [
            "use of the name was incorrect all these services were managed by the same people within one department of KPN contributed to the confusion",
            "the name was incorrect",
            "Dutch PTT Telecom"
        ],
        "model_ans": "No",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is CSNET",
        "answers": [
            "The Computer Science Network",
            "a computer network funded by the U.S. National Science Foundation (NSF)",
            "Computer Science Network"
        ],
        "model_ans": "Computer Science Network",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Computer Science Network </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the purpose of CSNET",
        "answers": [
            "to extend networking benefits, for computer science departments at academic and research institutions that could not be directly connected to ARPANET",
            "to extend networking benefits",
            "extend networking benefits"
        ],
        "model_ans": "Computer Science Network",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Computer Science Network </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Funding limitations allowed CSNET to be what ",
        "answers": [
            "role in spreading awareness of, and access to, national networking and was a major milestone on the path to development of the global Internet",
            "not be directly connected to ARPANET",
            "not be directly connected to ARPANET"
        ],
        "model_ans": "a small network",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a small network </answer> \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": " what is Internet2",
        "answers": [
            "a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government",
            "a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government",
            "not-for-profit United States computer networking consortium"
        ],
        "model_ans": "Internet2 is a United States non-profit organization that develops and maintains an advanced network infrastructure to support research and education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Internet2 is a United States non-profit organization that develops and maintains an advanced network infrastructure to support research and education </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did internet2 partner with",
        "answers": [
            "The Internet2 community, in partnership with Qwest",
            "Qwest",
            "Qwest"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the first internet2 network named",
        "answers": [
            "Abilene",
            "Abilene",
            "Abilene"
        ],
        "model_ans": "Abilene",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abilene </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who did internet2 partner with ",
        "answers": [
            "a partnership with Level 3 Communications to launch a brand new nationwide network",
            "Level 3 Communications",
            "Qwest"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ableine was retired and the new platform is called ",
        "answers": [
            "Internet2 officially retired Abilene and now refers to its new, higher capacity network as the Internet2 Network",
            "Internet2 Network",
            "Internet2 Network"
        ],
        "model_ans": "Able",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Able </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is NSFNET",
        "answers": [
            "The National Science Foundation Network",
            "National Science Foundation Network",
            "National Science Foundation Network"
        ],
        "model_ans": "National Science Foundation Network",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> National Science Foundation Network </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did NSFNET promote",
        "answers": [
            "advanced research and education networking in the United States",
            "advanced research and education networking",
            "advanced research and education networking"
        ],
        "model_ans": "Internet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Internet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did NSFNET eventually provide",
        "answers": [
            "it developed into a major part of the Internet backbone",
            "a major part of the Internet backbone",
            "major part of the Internet backbone"
        ],
        "model_ans": "Internet connectivity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Internet connectivity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does vBNS stand for ",
        "answers": [
            "The Very high-speed Backbone Network Service",
            "Very high-speed Backbone Network Service",
            "Very high-speed Backbone Network Service"
        ],
        "model_ans": "Virtual Backbone Network Service",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Virtual Backbone Network Service </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did vBNS do ",
        "answers": [
            "provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States",
            "provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States",
            "high-speed interconnection"
        ],
        "model_ans": "vBNS was a high-speed network that was used for research and education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> vBNS was a high-speed network that was used for research and education </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who operated the vBSN network ",
        "answers": [
            "The network was engineered and operated by MCI Telecommunications under a cooperative agreement with the NSF",
            "MCI Telecommunications",
            "National Science Foundation"
        ],
        "model_ans": "vBSN",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> vBSN </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By 199 how many universities were connected ",
        "answers": [
            "By 1998, the vBNS had grown to connect more than 100 universities and research and engineering institutions via 12 national points of presence with DS-3",
            "more than 100 universities",
            "100"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 100 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the network install in 1999",
        "answers": [
            "vBNS installed one of the first ever production OC-48c (2.5 Gbit/s) IP links in February 1999 and went on to upgrade the entire backbone to OC-48c",
            "one of the first ever production OC-48c (2.5 Gbit/s) IP links",
            "OC-48c"
        ],
        "model_ans": "Internet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Internet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did the black death originate?",
        "answers": [
            "the arid plains of Central Asia",
            "Central Asia",
            "Central Asia"
        ],
        "model_ans": "Central Asia",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Central Asia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the black death make it to the Mediterranean and Europe?",
        "answers": [
            "merchant ships.",
            "merchant ships",
            "Silk Road"
        ],
        "model_ans": "Through trade routes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through trade routes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of the European population did the black death kill?",
        "answers": [
            "30\u201360% of Europe's total population",
            "30\u201360% of Europe's total population",
            "30\u201360%"
        ],
        "model_ans": "30-60%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30-60% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the world's population finally recover from the black death?",
        "answers": [
            "the 17th century",
            "17th century",
            "17th century"
        ],
        "model_ans": "1350",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1350 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For how long did the plague stick around?",
        "answers": [
            "until the 19th century",
            "until the 19th century",
            "19th century"
        ],
        "model_ans": "3-6 months",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3-6 months </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does it mean for a disease to be enzootic?",
        "answers": [
            "commonly present",
            "commonly present",
            "commonly present"
        ],
        "model_ans": "Enzootic refers to a disease that is native to a particular animal species or group of species, and is typically maintained within that population through a cycle of transmission",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enzootic refers to a disease that is native to a particular animal species or group of species, and is typically maintained within that population through a cycle of transmission </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How old are the gravestones that reference the plague?",
        "answers": [
            "dating to 1338\u201339",
            "1338\u201339",
            "1338\u201339"
        ],
        "model_ans": "700 years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 700 years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do scientists think all of the plagues originated from?",
        "answers": [
            "China",
            "China",
            "China"
        ],
        "model_ans": "Egypt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Egypt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Chinese famine begin?",
        "answers": [
            "1331",
            "1331",
            "1331"
        ],
        "model_ans": "1959\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1959\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many did this epidemic in China kill?",
        "answers": [
            "an estimated 25 million",
            "25 million",
            "25 million"
        ],
        "model_ans": "3,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who introduced plague to Europe?",
        "answers": [
            "Genoese traders",
            "Genoese traders",
            "Genoese traders"
        ],
        "model_ans": "Mongols",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did the army siege belong to?",
        "answers": [
            "Jani Beg",
            "Jani Beg",
            "Jani Beg"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Mongol army throw in their catapults?",
        "answers": [
            "infected corpses",
            "infected corpses",
            "infected corpses"
        ],
        "model_ans": "Stones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did the genoese traders bring the plague?",
        "answers": [
            "Sicily",
            "Sicily and the south of Europe",
            "Sicily"
        ],
        "model_ans": "Constantinople",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Constantinople </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What contributed to the severity of the plague?",
        "answers": [
            "war, famine, and weather",
            "war, famine, and weather",
            "war, famine, and weather"
        ],
        "model_ans": "Poor sanitation and hygiene",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poor sanitation and hygiene </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which direction did the disease first move in?",
        "answers": [
            "northwest across Europe",
            "northwest",
            "northwest"
        ],
        "model_ans": "North",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> North </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country was the last to receive the disease?",
        "answers": [
            "northwestern Russia",
            "Russia",
            "Russia"
        ],
        "model_ans": "South Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> South Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of European groups were able to avoid the plague?",
        "answers": [
            "parts of Europe that had smaller trade relations with their neighbours",
            "smaller trade relations with their neighbours",
            "smaller trade relations with their neighbours"
        ],
        "model_ans": "Monastic communities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Monastic communities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the disease spreading between 1348 and 1350?",
        "answers": [
            "Germany and Scandinavia",
            "Germany and Scandinavia",
            "Germany and Scandinavia"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did a plague-ridden ship land in Norway?",
        "answers": [
            "1349",
            "1349",
            "1349"
        ],
        "model_ans": "1348\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1348\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What effect did the plague have on the Middle East?",
        "answers": [
            "serious depopulation and permanent change in both economic and social structures",
            "depopulation and permanent change in both economic and social structures",
            "depopulation and permanent change in both economic and social structures"
        ],
        "model_ans": "The plague had a significant impact on the Middle East, causing widespread death and economic disruption.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The plague had a significant impact on the Middle East, causing widespread death and economic disruption. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When had the plague reached Alexandria?",
        "answers": [
            "autumn 1347",
            "1347",
            "1347"
        ],
        "model_ans": "541 AD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 541 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the plague infiltrate Alexandria?",
        "answers": [
            "y through the port's trade with Constantinople, and ports on the Black Sea",
            "port's trade",
            "trade with Constantinople"
        ],
        "model_ans": "Through trade and commerce",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through trade and commerce </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the residents of Antioch flee to?",
        "answers": [
            "The city's residents fled to the north",
            "the north",
            "north"
        ],
        "model_ans": "Jerusalem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jerusalem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who claimed that the name Black Death first appeared in 1631?",
        "answers": [
            "Gasquet",
            "Gasquet",
            "Gasquet"
        ],
        "model_ans": "John Aubrey",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Aubrey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Latin name for Black Death?",
        "answers": [
            "atra mors",
            "atra mors",
            "atra mors"
        ],
        "model_ans": "Yersinia pestis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yersinia pestis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who allegedly coined the name Black Death?",
        "answers": [
            "J.I. Pontanus",
            "J.I. Pontanus",
            "J.I. Pontanus"
        ],
        "model_ans": "Giovanni Boccaccio",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Giovanni Boccaccio </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the name black death officially take root in England?",
        "answers": [
            "1823",
            "1823",
            "1823"
        ],
        "model_ans": "1348\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1348\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Did the plague spread in Scandinavia or Germany first?",
        "answers": [
            "Scandinavia",
            "Scandinavia",
            "Scandinavia"
        ],
        "model_ans": "Scandinavia",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Scandinavia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the black death originally blamed on?",
        "answers": [
            "the heavens",
            "the heavens",
            "the heavens"
        ],
        "model_ans": "Jews",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jews</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the medical report written for?",
        "answers": [
            "the king of France",
            "king of France",
            "king of France"
        ],
        "model_ans": "Dr. Lee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dr. Lee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the newer, more widely accepted theory behind the spread of the plague?",
        "answers": [
            "That the plague was caused by bad air",
            "bad air",
            "great pestilence in the air"
        ],
        "model_ans": "The Black Death was caused by the bacterium Yersinia pestis, which was transmitted to humans through the bites of infected fleas living on rats and other rodents.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Black Death was caused by the bacterium Yersinia pestis, which was transmitted to humans through the bites of infected fleas living on rats and other rodents. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the bad air theory officially known as?",
        "answers": [
            "Miasma theory",
            "Miasma theory.",
            "Miasma theory"
        ],
        "model_ans": "Miasma theory",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miasma theory </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was considered responsible for the black death as well as the epidemic in southern China?",
        "answers": [
            "Yersinia pestis",
            "Yersinia pestis",
            "Yersinia pestis"
        ],
        "model_ans": "Bubonic plague",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bubonic plague</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where and when did the investigation of the plague pathogen begin?",
        "answers": [
            "Hong Kong in 1894",
            "Hong Kong",
            "Hong Kong in 1894"
        ],
        "model_ans": "France, 1894",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France, 1894 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was yersinia pestis named for?",
        "answers": [
            "French-Swiss bacteriologist Alexandre Yersin",
            "Alexandre Yersin",
            "Alexandre Yersin"
        ],
        "model_ans": "Yersin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yersin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Paul-Louis Simond establish in 1898?",
        "answers": [
            "The mechanism by which Y. pestis was usually transmitted",
            "mechanism by which Y. pestis was usually transmitted",
            "The mechanism by which Y. pestis was usually transmitted"
        ],
        "model_ans": "Pasteur Institute",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pasteur Institute </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the bubonic plague mechanism reliant on?",
        "answers": [
            "two populations of rodents",
            "two populations of rodents",
            "two populations of rodents"
        ],
        "model_ans": "Fleas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fleas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who wrote about the great pestilence in 1893?",
        "answers": [
            "Francis Aidan Gasquet",
            "Francis Aidan Gasquet",
            "Francis Aidan Gasquet"
        ],
        "model_ans": "Albert Camus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Albert Camus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Gasquet think the plague was?",
        "answers": [
            "some form of the ordinary Eastern or bubonic plague",
            "bubonic plague",
            "ordinary Eastern or bubonic plague"
        ],
        "model_ans": "The Black Death",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Black Death </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the second edition of Gasquet's book come out?",
        "answers": [
            "1908",
            "1908",
            "1908"
        ],
        "model_ans": "1903",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1903 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Gasquet's book blame the plague on?",
        "answers": [
            "rats and fleas",
            "rats and fleas",
            "rats and fleas"
        ],
        "model_ans": "The Jews",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Jews </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another plague thought to have spread the same way?",
        "answers": [
            "the Justinian plague that was prevalent in the Eastern Roman Empire from 541 to 700 CE.",
            "Justinian plague",
            "Justinian plague"
        ],
        "model_ans": "The Black Death",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Black Death </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the mortality rate of the modern bubonic plague?",
        "answers": [
            "30\u201375%",
            "30\u201375%",
            "30\u201375%"
        ],
        "model_ans": "50-60%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50-60% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How high do plague fevers run?",
        "answers": [
            "100\u2013106 \u00b0F",
            "38\u201341 \u00b0C",
            "41 \u00b0C"
        ],
        "model_ans": "103\u00b0F (39.4\u00b0C)\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "103\u00b0F (39.4\u00b0C)\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percent of untreated victims of the plague die within 8 days?",
        "answers": [
            "80 percent",
            "80",
            "80"
        ],
        "model_ans": "90%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 90% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the mortality rate of pneumonic plague?",
        "answers": [
            "90 to 95 percent",
            "90 to 95",
            "90 to 95 percent"
        ],
        "model_ans": "50-60% if left untreated\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "50-60% if left untreated\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What skin-related symptom appears from the pneumonic plague?",
        "answers": [
            "purple skin patches",
            "purple skin patches",
            "purple skin patches"
        ],
        "model_ans": "Bubonic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bubonic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Plos Pathogens paper come out?",
        "answers": [
            "In October 2010",
            "October 2010",
            "October 2010"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Plos Pathogens paper about?",
        "answers": [
            "a new investigation into the role of Yersinia pestis in the Black Death",
            "role of Yersinia pestis in the Black Death",
            "the role of Yersinia pestis in the Black Death"
        ],
        "model_ans": "The paper was about the discovery of a new species of bacteria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The paper was about the discovery of a new species of bacteria </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did scientists assess the DNA/RNA of yersinia pestis? ",
        "answers": [
            "with Polymerase Chain Reaction (PCR)",
            "Polymerase Chain Reaction (PCR) techniques",
            "Polymerase Chain Reaction (PCR) techniques"
        ],
        "model_ans": "PCR",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> PCR </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did scientists find their Y. pestis sample? ",
        "answers": [
            "from the tooth sockets in human skeletons",
            "mass graves in northern, central and southern Europe",
            "tooth sockets in human skeletons"
        ],
        "model_ans": "Mongolia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongolia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the plos pathogen paper claim?",
        "answers": [
            "unambiguously demonstrates that Y. pestis was the causative agent of the epidemic plague",
            "Y. pestis was the causative agent of the epidemic plague",
            "Y. pestis was the causative agent of the epidemic plague that devastated Europe during the Middle Ages"
        ],
        "model_ans": "The paper claims that the plos pathogen is a new genus of bacteria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The paper claims that the plos pathogen is a new genus of bacteria </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are clades?",
        "answers": [
            "genetic branches",
            "genetic branches",
            "genetic branches"
        ],
        "model_ans": "Clades are groups of organisms that share a common ancestor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Clades are groups of organisms that share a common ancestor </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What strains of y. pestis were found in the mass graves?",
        "answers": [
            "Y. p. orientalis and Y. p. medievalis",
            "Y. pestis",
            "Y. p. orientalis and Y. p. medievalis"
        ],
        "model_ans": "Orientalis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Orientalis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do the strains of y. pestis suggest abut the plague?",
        "answers": [
            "the plague may have entered Europe in two waves",
            "the plague may have entered Europe in two waves",
            "may have entered Europe in two waves"
        ],
        "model_ans": "The strains of Y. pestis suggest that the plague has been present in human populations for thousands of years, and that it has evolved over time through genetic drift and natural selection. </</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The strains of Y. pestis suggest that the plague has been present in human populations for thousands of years, and that it has evolved over time through genetic drift and natural selection. </</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How and when did the first variant of y. pestis enter Europe?",
        "answers": [
            "through the port of Marseille around November 1347",
            "the port of Marseille around November 1347",
            "1347"
        ],
        "model_ans": "The first recorded outbreak of the plague in Europe was in 1347, when the Black Death arrived in Sicily, Italy, via trade routes from Asia.",
        "model_confidence": "",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The first recorded outbreak of the plague in Europe was in 1347, when the Black Death arrived in Sicily, Italy, via trade routes from Asia. </answer>\n<confidence</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the y. pestis reach England?",
        "answers": [
            "spring of 1349",
            "1349",
            "1349"
        ],
        "model_ans": "1348\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1348\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the current status of the Haensch study?",
        "answers": [
            "confirmed and amended",
            "confirmed and amended",
            "confirmed and amended"
        ],
        "model_ans": "The Haensch study is a historical study that was conducted in the 19th century, so it is no longer current.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Haensch study is a historical study that was conducted in the 19th century, so it is no longer current. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the burial site used for testing located?",
        "answers": [
            "East Smithfield",
            "England",
            "East Smithfield"
        ],
        "model_ans": "Oak Ridge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oak Ridge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is thought to have happened to the y. pestis that caused the black death?",
        "answers": [
            "may no longer exist",
            "may no longer exist",
            "may no longer exist"
        ],
        "model_ans": "It is believed that the plague bacterium, Yersinia pestis, was transmitted to humans through the bites of infected fleas that lived on rats and other rodents.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It is believed that the plague bacterium, Yersinia pestis, was transmitted to humans through the bites of infected fleas that lived on rats and other rodents. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the study on sequenced Y genomes published?",
        "answers": [
            "October 2011",
            "October 2011",
            "October 2011"
        ],
        "model_ans": "2015\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2015\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who challenged the plague theory first?",
        "answers": [
            "British bacteriologist J. F. D. Shrewsbury",
            "J. F. D. Shrewsbury",
            "J. F. D. Shrewsbury"
        ],
        "model_ans": "Ignaz Semmelweis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ignaz Semmelweis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Shrewsbury note about the plague?",
        "answers": [
            "rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague",
            "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague",
            "reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague"
        ],
        "model_ans": "Shrewsbury noted that the plague was caused by bad air",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shrewsbury noted that the plague was caused by bad air </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Shrewsbury's conclusion?",
        "answers": [
            "contemporary accounts were exaggerations",
            "contemporary accounts were exaggerations",
            "contemporary accounts were exaggerations"
        ],
        "model_ans": "Shrewsbury's conclusion is not recorded",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shrewsbury's conclusion is not recorded </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Graham Twigg publish in 1984?",
        "answers": [
            "the first major work to challenge the bubonic plague theory directly",
            "the first major work to challenge the bubonic plague theory directly",
            "first major work to challenge the bubonic plague theory directly,"
        ],
        "model_ans": "Inventing Ireland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inventing Ireland</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who discussed Twigg's study in 2002?",
        "answers": [
            "Samuel K. Cohn, Jr.",
            "Samuel K. Cohn, Jr.",
            "Samuel K. Cohn, Jr."
        ],
        "model_ans": "BBC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BBC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is as important as identifying plague symptoms?",
        "answers": [
            "epidemiological account of the plague",
            "an epidemiological account",
            "epidemiological account of the plague"
        ],
        "model_ans": "Identifying the source of the plague",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Identifying the source of the plague </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are researchers struggling to identify the history of the plague?",
        "answers": [
            "the lack of reliable statistics from this period",
            "the lack of reliable statistics",
            "lack of reliable statistics"
        ],
        "model_ans": "Because the plague has been around for so long, and records from that time period are scarce and often unreliable",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because the plague has been around for so long, and records from that time period are scarce and often unreliable </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much do estimations of the population during the plague vary?",
        "answers": [
            "by over 100%",
            "by over 100%",
            "over 100%"
        ],
        "model_ans": "75-200 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 75-200 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where can population estimates be extrapolated from?",
        "answers": [
            "the clergy",
            "figures from the clergy",
            "figures from the clergy"
        ],
        "model_ans": "Census",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Census </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During which years was no census taken?",
        "answers": [
            "between the time of publication of the Domesday Book and the year 1377",
            "1377",
            "between the time of publication of the Domesday Book and the year 1377"
        ],
        "model_ans": "1943",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1943 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why might rats not be responsible for the plague?",
        "answers": [
            "the rat population was insufficient",
            "rat population was insufficient",
            "rat population was insufficient to account for a bubonic plague pandemic"
        ],
        "model_ans": "Because the plague is caused by the bacterium Yersinia pestis, which is transmitted through the bites of infected fleas, not through rat bites or contact.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Because the plague is caused by the bacterium Yersinia pestis, which is transmitted through the bites of infected fleas, not through rat bites or contact. </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How significant was the transfer of disease through fleas?",
        "answers": [
            "of marginal significance",
            "marginal",
            "marginal"
        ],
        "model_ans": "significant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> significant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why  might the temperature affect the theory of plague spreading?",
        "answers": [
            "temperatures that are too cold in northern Europe for the survival of fleas",
            "too cold in northern Europe for the survival of fleas",
            "too cold in northern Europe for the survival of fleas"
        ],
        "model_ans": "Temperature affects the survival rate of bacteria and viruses, which could impact the spread of the plague.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Temperature affects the survival rate of bacteria and viruses, which could impact the spread of the plague.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Was the bubonic plague spread faster or slower than modern bubonic plague?",
        "answers": [
            "the Black Death was much faster than that of modern bubonic plague",
            "faster",
            "faster"
        ],
        "model_ans": "slower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> slower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many years could separate outbreaks of the black death?",
        "answers": [
            "5 to 15 years",
            "5 to 15",
            "5 to 15"
        ],
        "model_ans": "200-300 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200-300 years </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does Graham Twigg propose about the spread of disease?",
        "answers": [
            "a form of anthrax",
            "was a form of anthrax",
            "the cause was a form of anthrax"
        ],
        "model_ans": "He proposes that the spread of disease is influenced by the social and economic conditions of the population",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He proposes that the spread of disease is influenced by the social and economic conditions of the population </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Norman Cantor's theory about the plague?",
        "answers": [
            "a combination of anthrax and other pandemics",
            "a combination of anthrax and other pandemics",
            "a combination of anthrax and other pandemics"
        ],
        "model_ans": "He believed that the plague was caused by a combination of factors, including poor sanitation, malnutrition, and the lack of effective medical treatment.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He believed that the plague was caused by a combination of factors, including poor sanitation, malnutrition, and the lack of effective medical treatment. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which diseases do many scientists believe contributed to plague pandemic?",
        "answers": [
            "typhus, smallpox and respiratory infections",
            "typhus, smallpox and respiratory infections",
            "typhus, smallpox and respiratory infections"
        ],
        "model_ans": "Bubonic plague",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bubonic plague </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is septicemia? ",
        "answers": [
            "(a type of \"blood poisoning\"",
            "a type of \"blood poisoning\"",
            "a type of \"blood poisoning\""
        ],
        "model_ans": "Blood poisoning",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Blood poisoning </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many bodies did Public Health England exhume? ",
        "answers": [
            "25",
            "25",
            "25"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of the population in the Middle East died of the plague?",
        "answers": [
            "about a third.",
            "about a third",
            "about a third"
        ],
        "model_ans": "75%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 75% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of Paris' population was killed by the plague?",
        "answers": [
            "Half of Paris's population of 100,000 people",
            "100,000",
            "Half"
        ],
        "model_ans": "200,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do isolated, spaced out graves of plague victims indicate?",
        "answers": [
            "at least some pre-planning and Christian burials",
            "some pre-planning and Christian burials",
            "some pre-planning and Christian burials"
        ],
        "model_ans": "Quarantine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quarantine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people would die of plague in largely populated cities?",
        "answers": [
            "as much as 50%",
            "50%",
            "50%"
        ],
        "model_ans": "60% of the population",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60% of the population </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which areas were least vulnerable to disease?",
        "answers": [
            "most isolated areas",
            "isolated areas",
            "isolated"
        ],
        "model_ans": "The areas that were least vulnerable to disease were the ones that were well-ventilated, had good sanitation, and were far from the source of the disease.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The areas that were least vulnerable to disease were the ones that were well-ventilated, had good sanitation, and were far from the source of the disease.</answer>\n<confidence></confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the plague return to Europe?",
        "answers": [
            "throughout the 14th to 17th centuries",
            "14th to 17th centuries",
            "14th to 17th centuries"
        ],
        "model_ans": "1347-1353\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1347-1353\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Biraben say about the plague in Europe?",
        "answers": [
            "the plague was present somewhere in Europe in every year between 1346 and 1671.",
            "was present somewhere in Europe in every year between 1346 and 1671",
            "the plague was present somewhere in Europe in every year between 1346 and 1671"
        ],
        "model_ans": "The plague in Europe was caused by the bacterium Yersinia pestis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The plague in Europe was caused by the bacterium Yersinia pestis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many French people were lost to plague between 1628-31?",
        "answers": [
            "almost a million people",
            "almost a million people",
            "a million"
        ],
        "model_ans": "150,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150,000 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did historians do in the absence of census figures?",
        "answers": [
            "propose a range of preincident population figures from as high as 7 million to as low as 4 million",
            "propose a range of preincident population figures from as high as 7 million to as low as 4 million",
            "propose a range of preincident population figures"
        ],
        "model_ans": "They used other sources such as tax records, land surveys, and church records",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They used other sources such as tax records, land surveys, and church records </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the black death technically subside?",
        "answers": [
            "By the end of 1350",
            "1350",
            "By the end of 1350"
        ],
        "model_ans": "1353\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1353\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people died in the outbreak of 1471?",
        "answers": [
            "10\u201315% of the population",
            "10\u201315% of the population",
            "10\u201315% of the population"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the great plague of London?",
        "answers": [
            "1665",
            "1665",
            "1665"
        ],
        "model_ans": "1665\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1665\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people died of plague in Paris in 1466?",
        "answers": [
            "40,000",
            "40,000",
            "40,000"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The black plague ravaged Europe for three years followed by what country?",
        "answers": [
            "Russia",
            "Russia",
            "Russia"
        ],
        "model_ans": "England",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many times did plague occur in Venice?",
        "answers": [
            "22 times between 1361 and 1528",
            "22",
            "22"
        ],
        "model_ans": "57 times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 57 times </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which outbreak was associated with troops in the thirty years war?",
        "answers": [
            "the Italian Plague of 1629\u20131631",
            "Italian Plague",
            "Italian Plague"
        ],
        "model_ans": "The Black Death",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Black Death </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the last plague outbreak?",
        "answers": [
            "The last plague outbreak ravaged Oslo in 1654.",
            "1654",
            "1654"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many were killed by plague in Italy in the 17th century?",
        "answers": [
            "some 1.7 million victims",
            "1.7 million",
            "1.7 million"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many were killed by plague in Naples in 1656?",
        "answers": [
            "about half of Naples' 300,000 inhabitants",
            "half of Naples' 300,000 inhabitants",
            "half of Naples' 300,000 inhabitants"
        ],
        "model_ans": "10,000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "10,000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many residents of Seville died of plague in 1649?",
        "answers": [
            "reduced the population of Seville by half",
            "half",
            "half"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who fought in the great Northern war?",
        "answers": [
            "Sweden v. Russia and allies",
            "Sweden v. Russia and allies",
            "Sweden v. Russia and allies"
        ],
        "model_ans": "Sweden, Russia, Poland, Saxony, Denmark-Norway, Hanover, Prussia, Austria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sweden, Russia, Poland, Saxony, Denmark-Norway, Hanover, Prussia, Austria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Europe's last major epidemic?",
        "answers": [
            "1720 in Marseille.",
            "1720",
            "1720"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During which years was the plague present in Islamic countries?",
        "answers": [
            "between 1500 and 1850",
            "1500 and 1850",
            "1500 and 1850"
        ],
        "model_ans": "1347-1351",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1347-1351 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people were lost in Algiers during 1620-21?",
        "answers": [
            "30 to 50 thousand inhabitants",
            "30 to 50 thousand",
            "30 to 50 thousand"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long did plague last in the Ottoman empire?",
        "answers": [
            "until the second quarter of the 19th century.",
            "until the second quarter of the 19th century",
            "until the second quarter of the 19th century"
        ],
        "model_ans": "5 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people, at most, have died of plague in Baghdad? ",
        "answers": [
            "two-thirds of its population",
            "two-thirds of its population",
            "two-thirds of its population"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "An igneous rock is a rock that crystallizes from what?",
        "answers": [
            "melt (magma and/or lava)",
            "melt",
            "rock crystallizes from melt (magma and/or lava)",
            "melt (magma and/or lava)"
        ],
        "model_ans": "magma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> magma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Sedimentary rock can be turned into which of the three types of rock?",
        "answers": [
            "metamorphic rock",
            "metamorphic",
            "metamorphic rock",
            "metamorphic"
        ],
        "model_ans": "metamorphic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> metamorphic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When the three types of rock are re-melted what is formed? ",
        "answers": [
            "new magma",
            "igneous",
            "new magma",
            "magma"
        ],
        "model_ans": "magma",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> magma </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the three major types of rock? ",
        "answers": [
            "igneous, sedimentary, and metamorphic",
            "igneous, sedimentary, and metamorphic",
            "igneous, sedimentary, and metamorphic",
            "igneous, sedimentary, and metamorphic"
        ],
        "model_ans": "Igneous, sedimentary, metamorphic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Igneous, sedimentary, metamorphic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What changes the mineral content of a rock?",
        "answers": [
            "heat and pressure",
            "heat and pressure",
            "heat and pressure",
            "heat and pressure"
        ],
        "model_ans": "Weathering",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Weathering </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the most important discovery that led to the understanding that Earth's lithosphere is separated into tectonic plates?",
        "answers": [
            "seafloor spreading",
            "seafloor spreading",
            "seafloor spreading",
            "seafloor spreading"
        ],
        "model_ans": "Wegener's theory of continental drift",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wegener's theory of continental drift </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which parts of the Earth are included in the lithosphere? ",
        "answers": [
            "the crust and rigid uppermost portion of the upper mantle",
            "crust and rigid uppermost portion of the upper mantle",
            "crust and rigid uppermost portion of the upper mantle",
            "crust and rigid uppermost portion of the upper mantle"
        ],
        "model_ans": "Crust and uppermost part of the mantle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Crust and uppermost part of the mantle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another word for the Earth's upper mantle?",
        "answers": [
            "asthenosphere",
            "asthenosphere",
            "asthenosphere",
            "asthenosphere"
        ],
        "model_ans": "Lithosphere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lithosphere </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Plate tectonics can be seen as the intimate coupling between rigid plates on the surface of the Earth and what? ",
        "answers": [
            "the convecting mantle",
            "convection of the mantle",
            "convection of the mantle",
            "the convecting mantle"
        ],
        "model_ans": "the mantle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the mantle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what decade was seafloor spreading discovered? ",
        "answers": [
            "the 1960s",
            "1960s",
            "1960s",
            "1960s"
        ],
        "model_ans": "1960s",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the area called where two plates move apart?",
        "answers": [
            "divergent boundaries",
            "divergent boundaries",
            "divergent boundaries",
            "divergent boundaries"
        ],
        "model_ans": "Rift zone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rift zone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the area called where one plate subducts under another?",
        "answers": [
            "convergent boundaries",
            "convergent boundaries",
            "convergent boundaries",
            "convergent boundaries"
        ],
        "model_ans": "Subduction zone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Subduction zone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of fault boundary is defined by having widespread powerful earthquakes, as in the state of California?",
        "answers": [
            "Transform boundaries",
            "Transform",
            "Transform boundaries",
            "Transform boundaries"
        ],
        "model_ans": "Strike-slip fault",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Strike-slip fault </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose theory was the theory of continental drift?",
        "answers": [
            "Alfred Wegener",
            "Alfred Wegener",
            "Alfred Wegener",
            "Alfred Wegener"
        ],
        "model_ans": "Alfred Wegener",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alfred Wegener </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The lithosphere moves over which mantle n the theory of plate tectonics?",
        "answers": [
            "the convecting mantle",
            "convecting mantle",
            "convecting",
            "convecting"
        ],
        "model_ans": "asthenosphere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> asthenosphere </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of waves do seismologists use to image the interior of the Earth?",
        "answers": [
            "seismic waves",
            "seismic",
            "seismic",
            "seismic"
        ],
        "model_ans": "seismic waves",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> seismic waves </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In the layered model of the Earth, the outermost layer is what? ",
        "answers": [
            "crust",
            "crust",
            "lithosphere",
            "crust and lithosphere"
        ],
        "model_ans": "Crust",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Crust </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In the layered model of the Earth, the mantle has two layers below it. What are they? ",
        "answers": [
            "the outer core and inner core",
            "outer core and inner core",
            "outer core and inner core",
            "outer core and inner core"
        ],
        "model_ans": "outer core and inner core",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> outer core and inner core </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the layered model of the Earth there are seismic discontinuities in which layer? ",
        "answers": [
            "the mantle",
            "mantle",
            "mantle",
            "mantle"
        ],
        "model_ans": "Mohorovi\u010di\u0107 discontinuity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mohorovi\u010di\u0107 discontinuity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Recently a more detailed model of the Earth was developed. Seismologists were able to create this using images of what from the interior of the Earth? ",
        "answers": [
            "wave speeds",
            "wave speeds",
            "wave speeds"
        ],
        "model_ans": "seismic waves",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> seismic waves </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is the second timeline needed? ",
        "answers": [
            "second scale shows the most recent eon with an expanded scale",
            "compresses the most recent era",
            "compresses the most recent era"
        ],
        "model_ans": "To provide a backup in case the primary timeline fails",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To provide a backup in case the primary timeline fails </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which timeline is further expanded in the fourth scale?",
        "answers": [
            "Quaternary",
            "Quaternary",
            "Quaternary"
        ],
        "model_ans": "The fourth scale",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The fourth scale </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the latest epoch?",
        "answers": [
            "The Holocene",
            "Holocene",
            "The Holocene",
            "Holocene"
        ],
        "model_ans": "Holocene",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Holocene </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Pleistocene epoch takes place during which period?",
        "answers": [
            "the Quaternary period",
            "Quaternary period",
            "Quaternary",
            "Quaternary"
        ],
        "model_ans": "Cenozoic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cenozoic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What principle relates to the formation of faults and the age of the sequences through which they cut? ",
        "answers": [
            "The principle of cross-cutting relationships",
            "cross-cutting relationships",
            "cross-cutting relationships"
        ],
        "model_ans": "Principle of cross-cutting relationships",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Principle of cross-cutting relationships </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When rock formations are found on top of a fault that have not been cut, then they must be older or younger than the fault?",
        "answers": [
            "younger than the fault",
            "younger",
            "younger"
        ],
        "model_ans": "older",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> older </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Finding what helps to determine if a fault is a normal fault or a thrust fault? ",
        "answers": [
            "the key bed",
            "key bed",
            "key bed"
        ],
        "model_ans": "The dip of the fault",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The dip of the fault </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Rocks on top of a fault that are cut are always older or younger than the fault itself?",
        "answers": [
            "older than the fault",
            "older",
            "younger"
        ],
        "model_ans": "older",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> older </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What foreign bodies, which are older than the rocks themselves, occur igneous rocks?",
        "answers": [
            "xenoliths",
            "xenoliths",
            "inclusions",
            "xenoliths"
        ],
        "model_ans": "Meteorites",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Meteorites </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Xenoliths are picked up by what and deposited into the matrix of igneous rocks? ",
        "answers": [
            "magma or lava flows",
            "magma or lava flows",
            "magma or lava",
            "magma or lava flows"
        ],
        "model_ans": "magma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> magma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another word for inclusions in sedimentary rocks? ",
        "answers": [
            "clasts",
            "clasts",
            "clasts",
            "clasts"
        ],
        "model_ans": "fossils",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fossils </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the principle that states that with sedimentary rocks, inclusions must be older than the formation that contains them?",
        "answers": [
            "The principle of inclusions and components",
            "principle of inclusions and components",
            "The principle of inclusions and components",
            "inclusions and components"
        ],
        "model_ans": "Law of Inclusions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Law of Inclusions</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is something that is often torn up and included in sedimentary rock?",
        "answers": [
            "gravel",
            "gravel",
            "gravel",
            "gravel"
        ],
        "model_ans": "Plant material",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plant material </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which principle is based on the appearance of fossils in sedimentary rocks?",
        "answers": [
            "The principle of faunal succession",
            "principle of faunal succession",
            "The principle of faunal succession",
            "faunal succession"
        ],
        "model_ans": "Law of Superposition",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Law of Superposition </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose principles were the principle of faunal succession built upon?",
        "answers": [
            "William Smith",
            "William Smith",
            "William Smith",
            "William Smith"
        ],
        "model_ans": "Jean-Baptiste Lamarck",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Baptiste Lamarck </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The fact that not all fossils may be found globally at the same time causes the principle to become what?",
        "answers": [
            "complex",
            "complex",
            "complex",
            "quite complex"
        ],
        "model_ans": "incomplete",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> incomplete </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The presence or absence of what can be used to determine the relative age of the formations in which they are found? ",
        "answers": [
            "organisms",
            "organisms",
            "organisms",
            "organisms"
        ],
        "model_ans": "Fossils",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fossils </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The principle of faunal succession was developed 100 years before whose theory of evolution?",
        "answers": [
            "Charles Darwin",
            "Charles Darwin",
            "Charles Darwin",
            "Charles Darwin"
        ],
        "model_ans": "Charles Darwin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Darwin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the ability to use radioactive isotopes to date rock formations developed?",
        "answers": [
            "At the beginning of the 20th century",
            "20th century",
            "At the beginning of the 20th century",
            "beginning of the 20th century"
        ],
        "model_ans": "1940s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1940s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of correlation was used previously to help date rock formations?",
        "answers": [
            "stratigraphic correlation",
            "stratigraphic",
            "stratigraphic",
            "stratigraphic"
        ],
        "model_ans": "Biostratigraphy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Biostratigraphy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "It is now possible to convert old relative ages into what type of ages using isotopic dating?",
        "answers": [
            "absolute ages",
            "rock units",
            "new absolute"
        ],
        "model_ans": "absolute",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> absolute </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Previous to isotopic dating sections of rocks had to be dated using fossils and stratigraphic correlation relative to what? ",
        "answers": [
            "to one another",
            "one another",
            "one another"
        ],
        "model_ans": "other rocks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> other rocks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When dating rocks, what is the absolute isotopic date applied to?",
        "answers": [
            "fossil sequences",
            "fossil sequences",
            "fossil sequences",
            "fossil sequences"
        ],
        "model_ans": "minerals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> minerals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What techniques can be used to determine paleotopography?",
        "answers": [
            "Thermochemical techniques",
            "Thermochemical",
            "Thermochemical",
            "Thermochemical"
        ],
        "model_ans": "geomorphology, sedimentology, and geophysics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> geomorphology, sedimentology, and geophysics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The point at which different radiometric isotopes stop diffusing into and out of the crystal lattice is called what?",
        "answers": [
            "particular closure temperature",
            "closure temperature",
            "closure temperature"
        ],
        "model_ans": "Closure temperature",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Closure temperature </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of ratios are used in geochronologic and thermochronologic studies?",
        "answers": [
            "isotope ratios of radioactive elements",
            "isotope",
            "isotope",
            "isotope"
        ],
        "model_ans": "isotopic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> isotopic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How can you find the absolute age of sedimentary rock units which do not contain radioactive isotopes?",
        "answers": [
            "Dating of lava and volcanic ash layers found within a stratigraphic sequence",
            "Dating of lava and volcanic ash layers",
            "stratigraphic sequence",
            "Dating of lava and volcanic ash layers found within a stratigraphic sequence"
        ],
        "model_ans": "By using the principle of cross-cutting relationships, superposition, and faunal succession",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By using the principle of cross-cutting relationships, superposition, and faunal succession </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Rock units become thicker and shorten when placed under this type of compression. ",
        "answers": [
            "horizontal compression",
            "horizontal",
            "horizontal"
        ],
        "model_ans": "horizontal",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> horizontal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do thrust faults form?",
        "answers": [
            "In the shallow crust",
            "shallow crust",
            "shallow crust"
        ],
        "model_ans": "At the boundary between two tectonic plates",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> At the boundary between two tectonic plates </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When rock folds deep in the Earth it can fold one of two ways, when it buckles upwards it creates what? ",
        "answers": [
            "antiforms",
            "antiforms",
            "antiforms"
        ],
        "model_ans": "anticline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> anticline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When rock folds deep in the Earth it can fold one of two ways, when it buckles downwards it creates what? ",
        "answers": [
            "synforms",
            "synforms",
            "synforms"
        ],
        "model_ans": "syncline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> syncline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If the tops of the rock units within the folds remain pointing upwards, they are called what? ",
        "answers": [
            "anticlines and synclines",
            "overturned anticline",
            "anticlines and synclines"
        ],
        "model_ans": "synclines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> synclines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "This causes the rock unit as a whole to become longer and thinner. ",
        "answers": [
            "Extension",
            "Extension",
            "Extension"
        ],
        "model_ans": "Tectonic stretching",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tectonic stretching </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Stretched rocks that pinch into lenses are known by what word? ",
        "answers": [
            "boudins",
            "boudins",
            "boudins"
        ],
        "model_ans": "Sills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where can the entire sedimentary sequence of the Grand Canyon be seen in less than the length of a meter?",
        "answers": [
            "within the Maria Fold and Thrust Belt",
            "Maria Fold and Thrust Belt",
            "Maria Fold and Thrust Belt"
        ],
        "model_ans": "The Grand Canyon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Grand Canyon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Rocks that are a depth where they are ductilely stretched are also often what?",
        "answers": [
            "metamorphosed",
            "metamorphosed",
            "metamorphosed"
        ],
        "model_ans": "metamorphic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> metamorphic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What causes rock extension?",
        "answers": [
            "normal faulting and through the ductile stretching and thinning",
            "normal faulting",
            "normal faulting and through the ductile stretching and thinning"
        ],
        "model_ans": "Tectonic forces",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tectonic forces </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another word for long, planar igneous intrusions?",
        "answers": [
            "Dikes",
            "Dikes",
            "Dikes"
        ],
        "model_ans": "Sills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where do dikes form?",
        "answers": [
            "in areas that are being actively deformed",
            "areas that are being actively deformed",
            "in areas that are being actively deformed"
        ],
        "model_ans": "Rivers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rivers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of gradients are formed by faulting and other deformational processes?",
        "answers": [
            "topographic gradients",
            "topographic",
            "topographic"
        ],
        "model_ans": "Structural",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Structural </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What activity maintains topographic gradients?",
        "answers": [
            "Continual motion along the fault",
            "Continual motion",
            "Continual motion along the fault"
        ],
        "model_ans": "erosion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> erosion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What events are often associated with volcanism and igneous activity?",
        "answers": [
            "Deformational events",
            "Deformational",
            "Deformational"
        ],
        "model_ans": "earthquakes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> earthquakes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Hawaiian Islands are made up almost entirely of what?",
        "answers": [
            "layered basaltic lava flows",
            "layered basaltic lava flows",
            "layered basaltic lava flows"
        ],
        "model_ans": "Volcanic rock",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Volcanic rock </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the oldest known rock in the world?",
        "answers": [
            "Acasta gneiss",
            "Acasta gneiss",
            "Acasta gneiss of the Slave craton in northwestern Canada"
        ],
        "model_ans": "The Acasta Gneiss",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Acasta Gneiss </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of rock is found at the Grand Canyon?",
        "answers": [
            "sedimentary rocks",
            "sedimentary",
            "sedimentary"
        ],
        "model_ans": "Sedimentary",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sedimentary </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The rocks at the Grand Canyon have been in place since when?",
        "answers": [
            "Cambrian time",
            "Cambrian time",
            "Cambrian time"
        ],
        "model_ans": "1.8 billion years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.8 billion years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the oldest known rock in the world located?",
        "answers": [
            "Slave craton in northwestern Canada",
            "Canada",
            "northwestern Canada"
        ],
        "model_ans": "Jack Hills",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jack Hills </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is petrology?",
        "answers": [
            "the study of rocks",
            "study of rocks",
            "the study of rocks"
        ],
        "model_ans": "the study of the origin, composition, distribution, and alteration of rocks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the study of the origin, composition, distribution, and alteration of rocks </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is stratigraphy?",
        "answers": [
            "the study of sedimentary layers",
            "study of sedimentary layers",
            "the study of sedimentary layers"
        ],
        "model_ans": "the study of rock layers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the study of rock layers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is structural geology?",
        "answers": [
            "the study of positions of rock units and their deformation",
            "study of positions of rock units and their deformation",
            "the study of positions of rock units and their deformation"
        ],
        "model_ans": "The study of the three-dimensional distribution of rocks and their deformation within the Earth's crust",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The study of the three-dimensional distribution of rocks and their deformation within the Earth's crust </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": " What modern formations do geologists study?",
        "answers": [
            "modern soils",
            "soils, rivers, landscapes, and glaciers",
            "soils, rivers, landscapes, and glaciers"
        ],
        "model_ans": "plate tectonics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> plate tectonics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do petrologists use electron microprobes in the laboratory for?",
        "answers": [
            "identifying rocks",
            "identifying rocks",
            "identifying rocks"
        ],
        "model_ans": "to analyze the chemical composition of rocks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to analyze the chemical composition of rocks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What properties are analyzed with a conoscopic lens by petrologists? ",
        "answers": [
            "birefringence, pleochroism, twinning, and interference properties",
            "birefringence, pleochroism, twinning, and interference",
            "birefringence, pleochroism, twinning, and interference"
        ],
        "model_ans": "optical properties",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> optical properties </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Stable and radioactive isotope studies provide insight into what?",
        "answers": [
            "geochemical evolution of rock units",
            "geochemical evolution of rock units",
            "the geochemical evolution of rock units"
        ],
        "model_ans": "the Earth's climate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the Earth's climate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Petrologists identify rock samples in the field and where else? ",
        "answers": [
            "the laboratory",
            "laboratory",
            "laboratory"
        ],
        "model_ans": "laboratory",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> laboratory </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of microscope is used by petrologists?",
        "answers": [
            "petrographic microscope",
            "petrographic",
            "petrographic"
        ],
        "model_ans": "polarizing microscope",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> polarizing microscope </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How else can petrologists understand the pressures at which different mineral phases appear?",
        "answers": [
            "pressure physical experiments",
            "fluid inclusion data",
            "fluid inclusion data"
        ],
        "model_ans": "By studying the mineral assemblages in metamorphic rocks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By studying the mineral assemblages in metamorphic rocks </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How else can petrologists understand the temperature at which different mineral phases appear?",
        "answers": [
            "physical experiments",
            "high temperature and pressure physical experiments",
            "pressure physical experiments"
        ],
        "model_ans": "By studying the mineral assemblages and their relationships",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By studying the mineral assemblages and their relationships </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Data from physical experiments can be extrapolated to the field to understand what processes? ",
        "answers": [
            "metamorphic processes",
            "metamorphic",
            "metamorphic"
        ],
        "model_ans": "natural phenomena",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> natural phenomena </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of geologists give information about strain within the crystalline structure of the rocks?",
        "answers": [
            "Structural geologists",
            "Structural",
            "Structural"
        ],
        "model_ans": "Structural geologists",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Structural geologists </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How do structural geologists observe the fabric within the rocks?",
        "answers": [
            "microscopic analysis of oriented thin sections",
            "microscopic analysis",
            "use microscopic analysis of oriented thin sections of geologic samples"
        ],
        "model_ans": "By studying the orientation of minerals, rock textures, and structures",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By studying the orientation of minerals, rock textures, and structures </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In order to better understand the orientations of faults and folds, structural geologists do what with measurements of geological structures?",
        "answers": [
            "plot and combine",
            "plot and combine",
            "plot and combine"
        ],
        "model_ans": "plot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> plot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of experiments of rock deformation do structural geologists perform?",
        "answers": [
            "analog and numerical experiments",
            "analog and numerical",
            "analog and numerical"
        ],
        "model_ans": "Triaxial testing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Triaxial testing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Zones in which mountains are built along convergent tectonic plate boundaries are called what?",
        "answers": [
            "orogenic wedges",
            "orogenic wedges",
            "orogenic wedges"
        ],
        "model_ans": "Subduction zones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Subduction zones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are among the most well known experiments in structural geology? ",
        "answers": [
            "those involving orogenic wedges",
            "orogenic wedges",
            "involving orogenic wedges"
        ],
        "model_ans": "The experiments of the 1960s and 1970s on the deformation of rocks under different conditions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The experiments of the 1960s and 1970s on the deformation of rocks under different conditions </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Horizontal layers of what are pulled along a surface into a back stop in analog versions of orogenic wedge experiments?",
        "answers": [
            "sand",
            "sand",
            "sand"
        ],
        "model_ans": "Sediment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sediment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does critically tapered mean? ",
        "answers": [
            "all angles remain the same",
            "all angles remain the same",
            "all angles remain the same"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which is more sophisticated, numericals model or an analog models of orogenic wedges? ",
        "answers": [
            "Numerical models",
            "Numerical",
            "Numerical models"
        ],
        "model_ans": "numerical models",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> numerical models </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The analysis of stratigraphic sections such as drill cores is done by who?",
        "answers": [
            "stratigraphers",
            "stratigraphers",
            "stratigraphers"
        ],
        "model_ans": "Geologists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geologists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of surveys show the location of stratigraphic units in the subsurface?",
        "answers": [
            "geophysical surveys",
            "geophysical",
            "geophysical"
        ],
        "model_ans": "Geophysical surveys",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geophysical surveys </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What can be combined with geophysical data to produce a better view of the subsurface?",
        "answers": [
            "well logs",
            "well logs",
            "well logs"
        ],
        "model_ans": "seismic data",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> seismic data </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tool do stratigraphers use to see their data in three dimensions?",
        "answers": [
            "computer programs",
            "computer programs",
            "computer programs"
        ],
        "model_ans": "3D visualization software",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 3D visualization software </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Stratigraphers try to locate areas for what types of extraction? ",
        "answers": [
            "water, coal, and hydrocarbon extraction",
            "hydrocarbon",
            "hydrocarbon"
        ],
        "model_ans": "oil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> oil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who analyzes rock samples from drill cores in the lab? ",
        "answers": [
            "biostratigraphers",
            "biostratigraphers",
            "biostratigraphers"
        ],
        "model_ans": "Geologists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geologists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who dates rocks, precisely, within the stratigraphic section?",
        "answers": [
            "Geochronologists",
            "Geochronologists",
            "Geochronologists"
        ],
        "model_ans": "Geologists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geologists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is it important to precisely date rocks within the stratigraphic section? ",
        "answers": [
            "provide better absolute bounds on the timing and rates of deposition",
            "gain information about past climate",
            "provide better absolute bounds on the timing and rates of deposition"
        ],
        "model_ans": "To reconstruct the Earth's history",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To reconstruct the Earth's history </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of scientists looks for signs of magnetic reversals in igneous rocks within the drill cores?",
        "answers": [
            "Magnetic stratigraphers",
            "Magnetic stratigraphers",
            "Magnetic stratigraphers"
        ],
        "model_ans": "Geophysicists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Geophysicists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Fielding H. Garrison believes that the science of geology can be traced to where?",
        "answers": [
            "Persia",
            "Persia",
            "Persia after the Muslim conquests had come to an end"
        ],
        "model_ans": "Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Living from 973\u20131048 CE he was one of the earliest Persian geologists, what was his name?",
        "answers": [
            "Abu al-Rayhan al-Biruni",
            "Abu al-Rayhan al-Biruni",
            "Abu al-Rayhan al-Biruni"
        ],
        "model_ans": "Abd al-Rahman al-Sufi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abd al-Rahman al-Sufi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In China, this person inferred that the land was formed by erosion of the mountains and by silt deposition, what was his name?",
        "answers": [
            "Shen Kuo",
            "Shen Kuo",
            "Shen Kuo"
        ],
        "model_ans": "Chang Heng",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chang Heng </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "This person proposed explanations for the origins of earthquakes and the formation of mountains, what was his name?",
        "answers": [
            "Ibn Sina",
            "Ibn Sina",
            "Ibn Sina"
        ],
        "model_ans": "James Hutton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Hutton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What prompted Shen Kuo to believe the land was formed by erosion of the mountains?",
        "answers": [
            "his observation of fossil animal shells",
            "fossil animal shells",
            "based on his observation of fossil animal shells in a geological stratum in a mountain hundreds of miles from the ocean"
        ],
        "model_ans": "He observed the layers of rock and soil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He observed the layers of rock and soil </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is viewed as the first modern geologist?",
        "answers": [
            "James Hutton",
            "James Hutton",
            "James Hutton"
        ],
        "model_ans": "Jean-Andr\u00e9 Deluc",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Andr\u00e9 Deluc</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1785 James Hutton presented what paper to the Royal Society of Edinburgh?",
        "answers": [
            "Theory of the Earth",
            "Theory of the Earth",
            "Theory of the Earth"
        ],
        "model_ans": "Theory of the Earth",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Theory of the Earth </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "James Hutton published a 2 volume version of his theories in what year?",
        "answers": [
            "1795",
            "1795",
            "1795"
        ],
        "model_ans": "1795\n<confidence> unsure </confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1795\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the main idea of James Hutton's paper?",
        "answers": [
            "Earth must be much older than had previously been supposed",
            "Earth must be much older than had previously been supposed",
            "the Earth must be much older than had previously been supposed"
        ],
        "model_ans": "The concept of uniformitarianism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The concept of uniformitarianism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who produced the first geological map of the U.S.?",
        "answers": [
            "William Maclure",
            "William Maclure",
            "William Maclure"
        ],
        "model_ans": "Ferdinand Vandeveer Hayden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ferdinand Vandeveer Hayden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the first geological map of the U.S. produced?",
        "answers": [
            "1809",
            "1809",
            "1809"
        ],
        "model_ans": "1876\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1876\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did William Maclure begin the process of creating the first geological map of the U.S.?",
        "answers": [
            "1807",
            "1807",
            "1807"
        ],
        "model_ans": "1807\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1807\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To whom did William Maclure submit the map?",
        "answers": [
            "the American Philosophical Society",
            "American Philosophical Society",
            "American Philosophical Society"
        ],
        "model_ans": "Thomas Jefferson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Jefferson </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the memoir entitled which was submitted to the American Philosophical Society?",
        "answers": [
            "Observations on the Geology of the United States explanatory of a Geological Map",
            "Observations on the Geology of the United States explanatory of a Geological Map",
            "Observations on the Geology of the United States"
        ],
        "model_ans": "Observations on the Natural History of the Insect World",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Observations on the Natural History of the Insect World </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "First published by Sir Charles Lyell in 1830 this book was called what? ",
        "answers": [
            "Principles of Geology",
            "Principles of Geology",
            "Principles of Geology"
        ],
        "model_ans": "Principles of Geology",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Principles of Geology </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What doctrine did the doctrine of the Principles of Geology successfully promote?",
        "answers": [
            "uniformitarianism",
            "uniformitarianism",
            "uniformitarianism"
        ],
        "model_ans": "Uniformitarianism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uniformitarianism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which theory states that slow geological processes are still occurring today, and have occurred throughout Earth's history?",
        "answers": [
            "uniformitarianism",
            "uniformitarianism",
            "uniformitarianism"
        ],
        "model_ans": "Plate Tectonics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plate Tectonics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which theory states that Earth's features remained unchanged after forming in one single catastrophic event?",
        "answers": [
            "catastrophism",
            "catastrophism",
            "catastrophism"
        ],
        "model_ans": "Flood Geology",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Flood Geology </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which famous evolutionist was influenced by the book Principles of Geology?",
        "answers": [
            "Charles Darwin",
            "Charles Darwin",
            "Charles Darwin"
        ],
        "model_ans": "Charles Darwin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Darwin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What word is the word pharmacy taken from?",
        "answers": [
            "its root word pharma",
            "pharma",
            "pharma",
            "pharma"
        ],
        "model_ans": "Greek",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greek </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What goods were sold in a pharma?",
        "answers": [
            "ingredients for medicines, sold tobacco and patent medicines",
            "ingredients for medicines, sold tobacco and patent medicines",
            "ingredients for medicines, sold tobacco and patent medicines",
            "medicines"
        ],
        "model_ans": "medicines",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medicines </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did the Greek root pharmakos imply?",
        "answers": [
            "sorcery or even poison",
            "sorcery or even poison",
            "sorcery",
            "sorcery"
        ],
        "model_ans": "medicine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medicine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How would the word apothecary be viewed by contemporary English speakers?",
        "answers": [
            "outdated or only approproriate if herbal remedies were on offer to a large extent",
            "outdated",
            "outdated",
            "outdated"
        ],
        "model_ans": "As a noun referring to a person who prepares and sells medicines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> As a noun referring to a person who prepares and sells medicines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What else was used by pharmas?",
        "answers": [
            "many other herbs not listed",
            "many other herbs",
            "other herbs not listed",
            "other herbs"
        ],
        "model_ans": "APIs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> APIs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of professionals are pharmacists?",
        "answers": [
            "healthcare professionals",
            "healthcare",
            "healthcare professionals with specialised education"
        ],
        "model_ans": "healthcare professionals",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> healthcare professionals </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What types of health outcomes do pharmacists aim for with their patients?",
        "answers": [
            "optimal health outcomes",
            "optimal",
            "optimal health outcomes"
        ],
        "model_ans": "optimal health outcomes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> optimal health outcomes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of treatment are pharmacists important for?",
        "answers": [
            "optimisation of a drug treatment for an individual",
            "optimisation of a drug treatment",
            "optimisation of a drug treatment for an individual"
        ],
        "model_ans": "Medication",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medication </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other role do many pharmacists play?",
        "answers": [
            "small-business proprietors",
            "small-business proprietors",
            "small-business proprietors"
        ],
        "model_ans": "healthcare professionals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> healthcare professionals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of preparation do pharmacists have?",
        "answers": [
            "specialised education and training",
            "specialised education and training",
            "specialised education and training"
        ],
        "model_ans": "Doctor of Pharmacy (PharmD)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doctor of Pharmacy (PharmD) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who oversees a Pharmacy Technician in the UK?",
        "answers": [
            "other senior pharmacy technicians",
            "senior pharmacy technicians",
            "other senior pharmacy technicians"
        ],
        "model_ans": "General Pharmaceutical Council",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Pharmaceutical Council </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "With what body must a pharmacy technician register?",
        "answers": [
            "the General Pharmaceutical Council (GPhC) register",
            "General Pharmaceutical Council (GPhC)",
            "General Pharmaceutical Council (GPhC) register"
        ],
        "model_ans": "State",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> State </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a main duty of the GPhC?",
        "answers": [
            "regulates the practice of pharmacists and pharmacy technicians",
            "governing body for pharmacy health care professionals",
            "regulates the practice of pharmacists and pharmacy technicians"
        ],
        "model_ans": "Regulating pharmacy professionals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Regulating pharmacy professionals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of professional is a Pharmacy Technician considered to be?",
        "answers": [
            "health care professional",
            "pharmacy health care",
            "health care professional"
        ],
        "model_ans": "Healthcare",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Healthcare </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of responsibilities might a pharmacy technician have?",
        "answers": [
            "manage the pharmacy department and specialised areas in pharmacy practice",
            "manage the pharmacy department and specialised areas",
            "manage the pharmacy department"
        ],
        "model_ans": "dispensing medication, processing prescriptions, handling patient records, and assisting pharmacists",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> dispensing medication, processing prescriptions, handling patient records, and assisting pharmacists </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was a man studying medicinal applicants of plants in Ancient Greece?",
        "answers": [
            "Diocles of Carystus",
            "Diocles of Carystus",
            "Diocles of Carystus"
        ],
        "model_ans": "Dioscorides",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dioscorides </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is Pedanius Dioscorides known for?",
        "answers": [
            "writing a five volume book in his native Greek",
            "writing a five volume book",
            "five volume book in his native Greek"
        ],
        "model_ans": "He is known for his book De Materia Medica",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He is known for his book De Materia Medica </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the Latin translation of Dioscorides' book?",
        "answers": [
            "De Materia Medica",
            "De Materia Medica",
            "De Materia Medica"
        ],
        "model_ans": "De Materia Medica",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> De Materia Medica </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What term resulted from Dioscorides' book?",
        "answers": [
            "materia medica",
            "materia medica",
            "materia medica"
        ],
        "model_ans": "Materia Medica",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Materia Medica </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who added to Dioscorides' book in the Islamic Golden Age?",
        "answers": [
            "many middle eastern scientists",
            "middle eastern scientists",
            "many middle eastern scientists"
        ],
        "model_ans": "Ibn al-Baytar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ibn al-Baytar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How were the men who did tasks like those of today's pharmacists viewed in Japan in the Asuka and Nara periods?",
        "answers": [
            "highly respected",
            "highly respected",
            "highly respected"
        ],
        "model_ans": "They were viewed as spiritual leaders",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They were viewed as spiritual leaders </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which two codes were the roles of pharmacists codified?",
        "answers": [
            "the Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code (718)",
            "Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code",
            "Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code"
        ],
        "model_ans": "HIPAA and ICH",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> HIPAA and ICH </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What put a hierarchical structure in place?",
        "answers": [
            "the pre-Heian Imperial court",
            "Taih\u014d Code",
            "pre-Heian Imperial court"
        ],
        "model_ans": "Hierarchy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hierarchy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What stature did pharmacists have in the pre-Heian Imperial court?",
        "answers": [
            "status superior to all others in health-related fields such as physicians and acupuncturists",
            "Ranked positions",
            "status superior to all others in health-related fields"
        ],
        "model_ans": "5th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the pharmacist stand in relation to the Emperor's personal physicians?",
        "answers": [
            "ranked above",
            "ranked above",
            "ranked above the two personal physicians of the Emperor"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Developments in which scientists influenced the creation of pharmacology in medieval Islam?",
        "answers": [
            "botany and chemistry",
            "botany and chemistry",
            "advances made in the Middle East in botany and chemistry"
        ],
        "model_ans": "Ibn Sina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ibn Sina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was influential in promoting the use of chemical compounds as medicines?",
        "answers": [
            "Muhammad ibn Zakar\u012bya R\u0101zi",
            "Muhammad ibn Zakar\u012bya R\u0101zi",
            "Muhammad ibn Zakar\u012bya R\u0101zi"
        ],
        "model_ans": "Paracelsus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paracelsus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who authored the Liber servitoris?",
        "answers": [
            "Abu al-Qasim al-Zahrawi",
            "Abu al-Qasim al-Zahrawi",
            "Abu al-Qasim al-Zahrawi"
        ],
        "model_ans": "Anonymous",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anonymous </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which two compounds did Al-Muwaffaq differentiate between?",
        "answers": [
            "sodium carbonate and potassium carbonate",
            "sodium carbonate and potassium carbonate",
            "sodium carbonate and potassium carbonate"
        ],
        "model_ans": "Mercury and silver",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mercury and silver </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote about the distillation of drinking water from sea water?",
        "answers": [
            "Al-Muwaffaq",
            "Al-Muwaffaq",
            "Al-Muwaffaq"
        ],
        "model_ans": "Denis Papin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Denis Papin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far does one pharmacy in Croatia date back to?",
        "answers": [
            "1317",
            "1317",
            "1317"
        ],
        "model_ans": "1000 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 years </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the oldest pharmacy stated to be located?",
        "answers": [
            "Church of Santa Maria Novella in Florence, Italy",
            "Church of Santa Maria Novella in Florence, Italy",
            "Florence, Italy"
        ],
        "model_ans": "Alexandria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alexandria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the medieval Esteve Pharmacy used as at present?",
        "answers": [
            "museum",
            "a museum",
            "museum"
        ],
        "model_ans": "Museum",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Museum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What sorts of items are displayed in the Esteve Pharmacy museum?",
        "answers": [
            "albarellos from the 16th and 17th centuries, old prescription books and antique drugs",
            "albarellos from the 16th and 17th centuries, old prescription books and antique drugs",
            "old prescription books and antique drugs"
        ],
        "model_ans": "pharmaceutical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pharmaceutical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year is the oldest pharmacy said to have been established?",
        "answers": [
            "1221",
            "1221",
            "1221"
        ],
        "model_ans": "1231",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1231 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the dispensary subject to in a majority of countries?",
        "answers": [
            "pharmacy legislation",
            "pharmacy legislation",
            "pharmacy legislation"
        ],
        "model_ans": "Pharmacy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pharmacy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What responsibilities were pharmacy technicians formerly limited to?",
        "answers": [
            "within the dispensary compounding/dispensing medications",
            "communicating with patients",
            "compounding/dispensing medications"
        ],
        "model_ans": "dispensing medication",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> dispensing medication </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do pharmacy technicians depend on more and more?",
        "answers": [
            "automation",
            "automation",
            "automation"
        ],
        "model_ans": "Technology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Technology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are new responsibilities pharmacy technicians now deal with?",
        "answers": [
            "patients' prescriptions and patient safety issues",
            "patients' prescriptions and patient safety issues",
            "dealing with patients' prescriptions and patient safety issues"
        ],
        "model_ans": "prescription processing, patient counseling, and medication therapy management",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>prescription processing, patient counseling, and medication therapy management</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does pharmacy legislation mandate?",
        "answers": [
            "storage conditions, compulsory texts, equipment, etc.",
            "storage conditions, compulsory texts, equipment, etc.",
            "storage conditions, compulsory texts, equipment"
        ],
        "model_ans": "Prescription",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Prescription </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do pharmacists acquire more preparation following pharmacy school?",
        "answers": [
            "a pharmacy practice residency",
            "pharmacy practice residency",
            "pharmacy practice residency"
        ],
        "model_ans": "Residency",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Residency </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do clinical pharmacists specialize in?",
        "answers": [
            "various disciplines of pharmacy",
            "various disciplines of pharmacy",
            "various disciplines of pharmacy"
        ],
        "model_ans": "Medication therapy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medication therapy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one issue that adds to the complexity of a pharmacist's job?",
        "answers": [
            "effectiveness of treatment regimens",
            "effectiveness of treatment regimens",
            "effectiveness of treatment regimens"
        ],
        "model_ans": "Medication interactions",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medication interactions </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which pharmacists are likely to seek additional education following pharmacy school?",
        "answers": [
            "pharmacists practicing in hospitals",
            "pharmacists practicing in hospitals",
            "clinical pharmacists"
        ],
        "model_ans": "Many",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Many </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are many hospital pharmacies located?",
        "answers": [
            "within the premises of the hospital",
            "premises of the hospital",
            "within the premises of the hospital"
        ],
        "model_ans": "hospitals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hospitals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what form are most hospital medications?",
        "answers": [
            "unit-dose, or a single dose of medicine",
            "unit-dose",
            "unit-dose, or a single dose of medicine"
        ],
        "model_ans": "pills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of pharmacy functions have begun to be outsourced?",
        "answers": [
            "high risk preparations and some other compounding functions",
            "high risk preparations and some other compounding functions",
            "high risk preparations and some other compounding functions"
        ],
        "model_ans": "dispensing, compounding, and packaging",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> dispensing, compounding, and packaging </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one factor that increases the importance of the pharmacy performing at a high level?",
        "answers": [
            "The high cost of medications and drug-related technology",
            "high cost of medications",
            "high cost of medications and drug-related technology"
        ],
        "model_ans": "Patient safety",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Patient safety </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some advantages of hospital pharmacies?",
        "answers": [
            "Hospital pharmacies usually stock a larger range of medications, including more specialized medications",
            "more specialized medications",
            "stock a larger range of medications, including more specialized medications"
        ],
        "model_ans": "1. Convenience, 2. Quality control, 3. Patient safety",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1. Convenience, 2. Quality control, 3. Patient safety </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do the services given by pharmacists provide?",
        "answers": [
            "optimizes the use of medication and promotes health, wellness, and disease prevention",
            "optimizes the use of medication and promotes health, wellness, and disease prevention",
            "direct patient care services that optimizes the use of medication and promotes health, wellness, and disease prevention"
        ],
        "model_ans": "medication",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medication </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the origin of clinical pharmacy?",
        "answers": [
            "inside hospitals and clinics",
            "inside hospitals and clinics",
            "the clinical pharmacy movement initially began inside hospitals and clinics"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who do clinical pharmacists work with much of the time?",
        "answers": [
            "physicians and other healthcare professionals",
            "physicians",
            "physicians and other healthcare professionals"
        ],
        "model_ans": "Physicians",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physicians </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do clinical pharmacists often participate in?",
        "answers": [
            "patient care rounds drug product selection",
            "interdisciplinary approach",
            "patient care rounds drug product selection"
        ],
        "model_ans": "medication therapy management",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medication therapy management </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where do clinical pharmacists work with patients?",
        "answers": [
            "all health care settings",
            "drug product selection",
            "all health care settings"
        ],
        "model_ans": "hospitals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hospitals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one example of what a clinical pharmacist's duties entail?",
        "answers": [
            "creating a comprehensive drug therapy plan for patient-specific problems",
            "identifying goals of therapy",
            "creating a comprehensive drug therapy plan for patient-specific problems"
        ],
        "model_ans": "Dispensing medication",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dispensing medication </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is involved in a review of prescribed medications?",
        "answers": [
            "an evaluation of the appropriateness of the drug therapy",
            "an evaluation of the appropriateness of the drug therapy",
            "evaluation of the appropriateness of the drug therapy"
        ],
        "model_ans": "Review of medication regimen, dosage, and potential interactions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Review of medication regimen, dosage, and potential interactions </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the components of drug therapy?",
        "answers": [
            "drug choice, dose, route, frequency, and duration of therapy",
            "drug choice, dose, route, frequency, and duration of therapy",
            "drug choice, dose, route, frequency, and duration of therapy"
        ],
        "model_ans": "medication, dosage, frequency, duration",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> medication, dosage, frequency, duration </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are some other factors a pharmacist must monitor?",
        "answers": [
            "potential drug interactions, adverse drug reactions",
            "potential drug interactions",
            "potential drug interactions, adverse drug reactions, and assess patient drug allergies"
        ],
        "model_ans": "patient's medical history, allergies, and medication interactions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> patient's medical history, allergies, and medication interactions </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of authority are ambulatory care pharmacists given in the U.S. federal health care system?",
        "answers": [
            "full independent prescribing authority",
            "full independent prescribing authority",
            "full independent prescribing authority"
        ],
        "model_ans": "prescriptive authority",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> prescriptive authority </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what states are pharmacist clinicians given prescriptive and diagnostic authority?",
        "answers": [
            "North Carolina and New Mexico",
            "North Carolina and New Mexico",
            "North Carolina and New Mexico"
        ],
        "model_ans": "California",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was ambulatory care pharmacy approved as its own certification?",
        "answers": [
            "2011",
            "2011",
            "2011"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What will a pharmacist who passes the ambulatory pharmacist exam be called?",
        "answers": [
            "Board Certified Ambulatory Care Pharmacist",
            "Board Certified Ambulatory Care Pharmacist",
            "Board Certified Ambulatory Care Pharmacist"
        ],
        "model_ans": "Board Certified Ambulatory Care Pharmacist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Board Certified Ambulatory Care Pharmacist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What entities are included in the federal health care system?",
        "answers": [
            "the VA, the Indian Health Service, and NIH",
            "the VA, the Indian Health Service, and NIH",
            "VA, the Indian Health Service, and NIH"
        ],
        "model_ans": "Medicare, Medicaid, and the Veterans Health Administration",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Medicare, Medicaid, and the Veterans Health Administration </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is consultant pharmacy mainly concerned with?",
        "answers": [
            "medication regimen review",
            "medication regimen review",
            "medication regimen review"
        ],
        "model_ans": "patient care",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> patient care </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where do a majority of consultant pharmacists tend to work?",
        "answers": [
            "nursing homes",
            "nursing homes",
            "nursing homes"
        ],
        "model_ans": "hospitals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hospitals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some large pharmacy management companies?",
        "answers": [
            "Omnicare, Kindred Healthcare and PharMerica",
            "Omnicare, Kindred Healthcare and PharMerica",
            "Omnicare, Kindred Healthcare and PharMerica"
        ],
        "model_ans": "CVS Health, Walgreens Boots Alliance, Express Scripts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CVS Health, Walgreens Boots Alliance, Express Scripts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the main reason consulting pharmacists are increasingly working directly with patients?",
        "answers": [
            "because many elderly people are now taking numerous medications but continue to live outside of institutional settings",
            "many elderly people are now taking numerous medications but continue to live outside of institutional settings",
            "many elderly people are now taking numerous medications but continue to live outside of institutional settings"
        ],
        "model_ans": "To provide personalized care and improve patient outcomes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To provide personalized care and improve patient outcomes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do some community pharmacies do?",
        "answers": [
            "employ consultant pharmacists and/or provide consulting services",
            "employ consultant pharmacists",
            "employ consultant pharmacists and/or provide consulting services"
        ],
        "model_ans": "dispense prescription medications",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dispense prescription medications </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did internet pharmacies begin to come into being?",
        "answers": [
            "about the year 2000",
            "2000",
            "2000"
        ],
        "model_ans": "1990s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1990s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who often operates internet pharmacies?",
        "answers": [
            "brick-and-mortar community pharmacies that serve consumers online and those that walk in their door",
            "brick-and-mortar community pharmacies",
            "brick-and-mortar community pharmacies"
        ],
        "model_ans": "Pharmacies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pharmacies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are internet pharmacies also called?",
        "answers": [
            "online pharmacies",
            "online pharmacies",
            "online pharmacies"
        ],
        "model_ans": "Online pharmacies",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Online pharmacies </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is one reason a patient might choose an internet pharmacy?",
        "answers": [
            "another customer might overhear about the drugs that they take",
            "homebound",
            "more convenient and private method"
        ],
        "model_ans": "Convenience",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Convenience </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the main difference between online pharmacies and community pharmacies?",
        "answers": [
            "the method by which the medications are requested and received",
            "method by which the medications are requested and received",
            "the method by which the medications are requested and received"
        ],
        "model_ans": "Online pharmacies operate remotely, while community pharmacies have a physical storefront",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Online pharmacies operate remotely, while community pharmacies have a physical storefront </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why might customers order from internet pharmacies?",
        "answers": [
            "to avoid the \"inconvenience\" of visiting a doctor or to obtain medications which their doctors were unwilling to prescribe",
            "avoid the \"inconvenience\" of visiting a doctor",
            "avoid the \"inconvenience\" of visiting a doctor or to obtain medications which their doctors were unwilling to prescribe"
        ],
        "model_ans": "Convenience, lower prices, and anonymity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Convenience, lower prices, and anonymity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who has criticized ordering from online pharmacies that don't require prescriptions?",
        "answers": [
            "those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication.",
            "by those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication",
            "those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication"
        ],
        "model_ans": "FDA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> FDA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a criticism of online pharmacies that issue drugs without a prescription?",
        "answers": [
            "dispensing substandard products",
            "potentially dangerous",
            "reports of such pharmacies dispensing substandard products"
        ],
        "model_ans": "Lack of medical expertise",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lack of medical expertise </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What practice do some internet pharmacies engage in?",
        "answers": [
            "sell prescription drugs without requiring a prescription",
            "sell prescription drugs without requiring a prescription",
            "some Internet pharmacies sell prescription drugs without requiring a prescription"
        ],
        "model_ans": "selling counterfeit drugs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> selling counterfeit drugs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do most online pharmacies do?",
        "answers": [
            "sell prescription drugs and require a valid prescription",
            "sell prescription drugs",
            "sell prescription drugs and require a valid prescription"
        ],
        "model_ans": "sell prescription drugs",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sell prescription drugs </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What conditions must be met for a prescription for a controlled substance to be valid?",
        "answers": [
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship"
        ],
        "model_ans": "A valid prescription must be written by a licensed medical professional, contain the patient's name, the name of the controlled substance, the dosage, and the duration of treatment.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A valid prescription must be written by a licensed medical professional, contain the patient's name, the name of the controlled substance, the dosage, and the duration of treatment. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one problem with internet pharmacies?",
        "answers": [
            "the ease with which people, youth in particular, can obtain controlled substances",
            "ease with which people, youth in particular, can obtain controlled substances",
            "the ease with which people, youth in particular, can obtain controlled substances"
        ],
        "model_ans": "Counterfeit drugs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Counterfeit drugs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What conditions must be met to prescribe a controlled substance?",
        "answers": [
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
            "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship"
        ],
        "model_ans": "A valid prescription from a licensed medical professional, a legitimate medical purpose, and a patient-physician relationship",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A valid prescription from a licensed medical professional, a legitimate medical purpose, and a patient-physician relationship </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the obligation of a pharmacy filling a prescription?",
        "answers": [
            "to ensure that the prescription is valid",
            "ensure that the prescription is valid",
            "The filling pharmacy has a corresponding responsibility to ensure that the prescription is valid"
        ],
        "model_ans": "Fill the prescription accurately and in a timely manner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fill the prescription accurately and in a timely manner </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who defines what constitutes a patient-doctor relationship?",
        "answers": [
            "individual state laws",
            "individual state laws",
            "Often, individual state laws outline what defines a valid patient-doctor relationship"
        ],
        "model_ans": "American Medical Association",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> American Medical Association </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an example of a controlled substance?",
        "answers": [
            "Vicodin, generically known as hydrocodone",
            "Vicodin",
            "Vicodin"
        ],
        "model_ans": "cocaine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cocaine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a reason for the movement to legalize importing medicines from other countries?",
        "answers": [
            "to reduce consumer costs",
            "reduce consumer costs",
            "in order to reduce consumer costs"
        ],
        "model_ans": "Cost savings",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cost savings </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one country that has been suggested for importation of medicines?",
        "answers": [
            "Canada",
            "Canada",
            "Canada"
        ],
        "model_ans": "Canada",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Canada </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who are FDA laws against importing medications aimed at?",
        "answers": [
            "international drug suppliers, rather than consumers",
            "international drug suppliers",
            "international drug suppliers"
        ],
        "model_ans": "consumers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> consumers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Has there ever been anyone charged with importing drugs from Canada for personal medicinal use?",
        "answers": [
            "There is no known case",
            "no known case",
            "no"
        ],
        "model_ans": "Yes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is there a push for in the U.S. to reduce consumer drug costs?",
        "answers": [
            "to legalize importation of medications from Canada and other countries",
            "legalize importation of medications",
            "legalize importation of medications from Canada and other countries"
        ],
        "model_ans": "price",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> price </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What two things does pharmacy informatics bring together?",
        "answers": [
            "pharmacy practice science and applied information science",
            "pharmacy practice science and applied information science",
            "pharmacy practice science and applied information science"
        ],
        "model_ans": "pharmacy and informatics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pharmacy and informatics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What fields may pharmacy informatics also work in?",
        "answers": [
            "information technology departments or for healthcare information technology vendor companies",
            "information technology departments or for healthcare information technology vendor companies",
            "information technology departments or for healthcare information technology vendor companies"
        ],
        "model_ans": "healthcare, medicine, IT",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> healthcare, medicine, IT </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose needs will the growth in pharmacy informatics meet?",
        "answers": [
            "major national and international patient information projects and health system interoperability goals",
            "major national and international patient information projects",
            "major national and international patient information projects"
        ],
        "model_ans": "Pharmacists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pharmacists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What areas are pharmacy informatics prepared to work in?",
        "answers": [
            "medication management system development, deployment and optimization",
            "medication management system development, deployment and optimization",
            "medication management system development, deployment and optimization"
        ],
        "model_ans": "healthcare, pharmaceutical industry",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> healthcare, pharmaceutical industry </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How fast is pharmacy informatics growing?",
        "answers": [
            "quickly",
            "growing quickly",
            "quickly"
        ],
        "model_ans": "10% annually",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% annually </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the fastest growing area in the pharmaceutical industry?",
        "answers": [
            "specialty pharmacies",
            "specialty pharmacies",
            "specialty pharmacies"
        ],
        "model_ans": "Digital Health",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Digital Health </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many drugs approved by the FDA in 2013 were specialty drugs?",
        "answers": [
            "19",
            "19",
            "19 of 28 newly FDA approved medications"
        ],
        "model_ans": "24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of diseases are specialty drugs often used against?",
        "answers": [
            "cancer, hepatitis, and rheumatoid arthritis",
            "chronic and complex disease states",
            "chronic and complex disease states such as cancer, hepatitis, and rheumatoid arthritis"
        ],
        "model_ans": "Rare and chronic diseases",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rare and chronic diseases </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of medications do specialty pharmacies stock?",
        "answers": [
            "novel medications that need to be properly stored, administered, carefully monitored, and clinically managed",
            "novel medications",
            "novel medications that need to be properly stored, administered, carefully monitored, and clinically managed"
        ],
        "model_ans": "Specialty pharmacies stock medications that are not typically found in retail pharmacies, such as injectable medications, biologics, and orphan drugs.",
        "model_confidence": "unsure</confidence",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Specialty pharmacies stock medications that are not typically found in retail pharmacies, such as injectable medications, biologics, and orphan drugs. </answer>\n<confidence>unsure</confidence</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides drugs, what else do specialty pharmacies provide?",
        "answers": [
            "lab monitoring, adherence counseling, and assist patients with cost-containment strategies needed to obtain their expensive specialty drugs",
            "lab monitoring, adherence counseling, and assist patients with cost-containment strategies",
            "lab monitoring, adherence counseling, and assist patients with cost-containment strategies needed to obtain their expensive specialty drugs"
        ],
        "model_ans": "Compounded medications",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Compounded medications </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are pharmacists regulated in most jurisdictions?",
        "answers": [
            "separately from physicians",
            "separately from physicians",
            "separately from physicians"
        ],
        "model_ans": "By a professional regulatory body",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> By a professional regulatory body </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who do most jurisdictions say can give scheduled drugs to the public?",
        "answers": [
            "only pharmacists",
            "only pharmacists",
            "only pharmacists may supply scheduled pharmaceuticals to the public"
        ],
        "model_ans": "Doctors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doctors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What body has stated that physicians can also dispense drugs under specific conditions?",
        "answers": [
            "the American Medical Association (AMA)",
            "American Medical Association",
            "American Medical Association (AMA)"
        ],
        "model_ans": "World Health Organization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World Health Organization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the estimate of how many physicians give out drugs on their own?",
        "answers": [
            "7 to 10 percent",
            "7 to 10 percent",
            "7 to 10 percent of American physicians"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are pharmacists forbidden to do?",
        "answers": [
            "form business partnerships with physicians or give them \"kickback\" payments",
            "form business partnerships with physicians",
            "pharmacists cannot form business partnerships with physicians or give them \"kickback\" payments"
        ],
        "model_ans": "Dispense controlled substances without a prescription",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dispense controlled substances without a prescription </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are some physicians permitted to prescribe and give out medications within their practices?",
        "answers": [
            "In some rural areas in the United Kingdom",
            "rural areas in the United Kingdom",
            "prescribe and dispense prescription-only medicines to their patients from within their practices"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another country that permits physicians to give out drugs from within their practice?",
        "answers": [
            "Austria",
            "Austria",
            "Austria"
        ],
        "model_ans": "Canada",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Canada </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the minimum distance between a patient's home and the nearest pharmacy that allows a physician to give out medication?",
        "answers": [
            "1.6 kilometres",
            "1.6 kilometres",
            "1.6 kilometres"
        ],
        "model_ans": "1 mile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 mile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the minimum distance between a patient's home and the nearest pharmacy that allows a physician in Austria to give out medicine?",
        "answers": [
            "more than 4 kilometers",
            "4 kilometers",
            "more than 4 kilometers"
        ],
        "model_ans": "500 meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 meters </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is majority rule used?",
        "answers": [
            "the high risk of a conflict of interest and/or the avoidance of absolute powers",
            "high risk of a conflict of interest",
            "high risk of a conflict of interest and/or the avoidance of absolute powers"
        ],
        "model_ans": "To ensure that the majority of people have a say in the decision-making process",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To ensure that the majority of people have a say in the decision-making process </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why might a physician diagnose a large number of conditions?",
        "answers": [
            "because he or she can then sell more medications to the patient",
            "sell more medications to the patient",
            "sell more medications to the patient"
        ],
        "model_ans": "Overdiagnosis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Overdiagnosis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do rules about conflict of interest involving doctors diagnosing patients resemble?",
        "answers": [
            "the checks and balances system of the U.S. and many other governments.",
            "checks and balances system of the U.S. and many other governments",
            "similarity to the checks and balances system of the U.S. and many other governments"
        ],
        "model_ans": "rules about judges presiding over cases involving friends or family members",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> rules about judges presiding over cases involving friends or family members </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where might the doctor's self-interest be at odds with the patient's self-interest?",
        "answers": [
            "in obtaining cost-effective medication and avoiding the unnecessary use of medication that may have side-effects",
            "obtaining cost-effective medication",
            "the physician has a financial self-interest in \"diagnosing\" as many conditions as possible"
        ],
        "model_ans": "In a situation where the doctor is incentivized to prescribe expensive treatments or procedures",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In a situation where the doctor is incentivized to prescribe expensive treatments or procedures </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How else might a physician take advantage of self-interest?",
        "answers": [
            "exaggerating their seriousness",
            "avoiding the unnecessary use of medication that may have side-effects",
            "because he or she can then sell more medications to the patient"
        ],
        "model_ans": "By taking advantage of the financial incentives offered by insurance companies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By taking advantage of the financial incentives offered by insurance companies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What will be the importance of the pharmacist in coming decades?",
        "answers": [
            "expected to become more integral within the health care system",
            "patient care skills",
            "pharmacists are expected to become more integral within the health care system"
        ],
        "model_ans": "To play a crucial role in the healthcare system",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To play a crucial role in the healthcare system </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What responsibilities are pharmacists believed to be taking on more in the future?",
        "answers": [
            "increasingly expected to be compensated for their patient care skills",
            "patient care skills",
            "pharmacists are increasingly expected to be compensated for their patient care skills"
        ],
        "model_ans": "patient care",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> patient care </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is included in Medication Therapy Management?",
        "answers": [
            "clinical services that pharmacists can provide for their patients",
            "clinical services that pharmacists can provide for their patients",
            "the clinical services that pharmacists can provide for their patients"
        ],
        "model_ans": "Medication therapy management includes medication therapy, patient education, and monitoring of medication adherence.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Medication therapy management includes medication therapy, patient education, and monitoring of medication adherence.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are examples of clinical services that pharmacists can provide?",
        "answers": [
            "thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual",
            "thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual.",
            "the thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual"
        ],
        "model_ans": "immunizations, medication therapy management, point-of-care testing, and patient counseling",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> immunizations, medication therapy management, point-of-care testing, and patient counseling </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are outcomes expected with Medication Therapy Management?",
        "answers": [
            "a reconciliation of medication and patient education resulting in increased patient health outcomes and decreased costs to the health care system",
            "increased patient health outcomes and decreased costs",
            "a reconciliation of medication and patient education resulting in increased patient health outcomes and decreased costs to the health care system"
        ],
        "model_ans": "Improved medication adherence, reduced hospitalizations, improved health outcomes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Improved medication adherence, reduced hospitalizations, improved health outcomes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which provinces in Canada limit the rights of pharmacists in prescribing?",
        "answers": [
            "Alberta and British Columbia",
            "Alberta and British Columbia",
            "Alberta and British Columbia"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who pays Australian pharmacists for doing Home Medicines Reviews?",
        "answers": [
            "the Australian Government",
            "Australian Government",
            "the Australian Government"
        ],
        "model_ans": "Medicare Australia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medicare Australia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are pharmacists in the United Kingdom being increasingly paid for?",
        "answers": [
            "medicine use reviews",
            "medicine use reviews",
            "medicine use reviews"
        ],
        "model_ans": "dispensing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dispensing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What fields have increased in influence on pharmacy in the United States?",
        "answers": [
            "pharmaceutical care or clinical pharmacy",
            "pharmaceutical care or clinical pharmacy",
            "pharmaceutical care or clinical pharmacy"
        ],
        "model_ans": "Public health, health informatics, and pharmaceutical industry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public health, health informatics, and pharmaceutical industry </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What degree is now mandatory in the U.S. in order to be a licensed pharmacist?",
        "answers": [
            "Doctor of Pharmacy (Pharm. D.)",
            "Doctor of Pharmacy",
            "the Doctor of Pharmacy (Pharm. D.) degree"
        ],
        "model_ans": "Doctor of Pharmacy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doctor of Pharmacy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the two symbols that signify pharmacy in English-speaking countries?",
        "answers": [
            "the mortar and pestle and the \u211e (recipere) character",
            "mortar and pestle and the \u211e (recipere) character",
            "the mortar and pestle and the \u211e (recipere) character"
        ],
        "model_ans": "Rx",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rx </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What symbol was employed until early in the 20th century?",
        "answers": [
            "The show globe",
            "show globe",
            "show globe"
        ],
        "model_ans": "ampersand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ampersand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What country uses the Bowl of Hygieia as a symbol of pharmacy?",
        "answers": [
            "the Netherlands",
            "the Netherlands",
            "the Netherlands"
        ],
        "model_ans": "Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What countries use a red stylized A to signify pharmacy?",
        "answers": [
            "Germany and Austria",
            "Germany and Austria",
            "Germany and Austria"
        ],
        "model_ans": "Australia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Australia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which countries use the green Greek cross as a symbol of pharmacy?",
        "answers": [
            "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India",
            "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India",
            "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India"
        ],
        "model_ans": "Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is it called when people in society rebel against laws they think are unfair?",
        "answers": [
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience"
        ],
        "model_ans": "Civil Disobedience",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civil Disobedience </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an example of major civil disobedience in South Africa?",
        "answers": [
            "apartheid",
            "fight against apartheid",
            "the fight against apartheid",
            "the fight against apartheid",
            "Singing Revolution to bring independence to the Baltic countries"
        ],
        "model_ans": "The Defiance Campaign",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Defiance Campaign </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the the movement called that brought Baltic countries independence from the Soviet Union?",
        "answers": [
            "Singing Revolution",
            "Singing Revolution",
            "the Singing Revolution",
            "Singing Revolution",
            "Singing Revolution"
        ],
        "model_ans": "Singing Revolution",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Singing Revolution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 2004 the Orange revolution occurred in what country?",
        "answers": [
            "Ukraine",
            "Ukraine",
            "Ukraine",
            "Ukraine",
            "Ukraine"
        ],
        "model_ans": "Ukraine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ukraine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where was the location of the 2003 Rose revolution?",
        "answers": [
            "Georgia",
            "Georgia",
            "Georgia",
            "Georgia",
            "Georgia"
        ],
        "model_ans": "Georgia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Georgia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which people brought forward one of the earliest examples of Civil Disobedience?",
        "answers": [
            "Egyptians",
            "Egyptians",
            "Egyptians",
            "Egyptians",
            "India"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was one of the earliest examples of Civil Disobedience against?",
        "answers": [
            "the British",
            "British",
            "Egyptians against the British occupation in the 1919 Revolution.",
            "British occupation",
            "communist governments"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why do people chose civil disobedience to protest?",
        "answers": [
            "nonviolent resistance",
            "unfair laws",
            "nonviolent resistance movements",
            "rebelled against what they deem to be unfair"
        ],
        "model_ans": "To draw attention to their cause and to challenge unjust laws",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To draw attention to their cause and to challenge unjust laws </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does civil disobedience protest against?",
        "answers": [
            "unfair laws",
            "unfair laws",
            "unfair laws.",
            "unfair laws",
            "what they deem to be unfair"
        ],
        "model_ans": "unjust laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unjust laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What civil rights movement in the US was known for it's disobedience?",
        "answers": [
            "American Civil Rights Movement",
            "American Civil Rights Movement",
            "American Civil Rights Movement",
            "Civil Rights Movement",
            "American Civil Rights Movement"
        ],
        "model_ans": "Civil Rights Movement",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civil Rights Movement </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Sophocles demonstrated civil disobedience in a play that was called?",
        "answers": [
            "Antigone",
            "Antigone",
            "Antigone",
            "Antigone",
            "Antigone"
        ],
        "model_ans": "Antigone",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antigone </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is Antigone's father in the play?",
        "answers": [
            "former King of Thebes",
            "Oedipus",
            "Oedipus",
            "Oedipus",
            "King of Thebes"
        ],
        "model_ans": "Oedipus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oedipus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the current King of Thebes in the play?",
        "answers": [
            "Creon",
            "Creon",
            "Creon",
            "Creon",
            "Creon"
        ],
        "model_ans": "Oedipus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oedipus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What character in the play portrays civil disobedience?",
        "answers": [
            "Oedipus",
            "Antigone",
            "Antigone",
            "Antigone",
            "Antigone"
        ],
        "model_ans": "Gandhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is Creon trying to stop Antigone from doing in the play? ",
        "answers": [
            "giving her brother Polynices a proper burial",
            "trying to stop her from giving her brother Polynices a proper burial",
            "giving her brother Polynices a proper burial",
            "giving her brother Polynices a proper burial.",
            "from giving her brother Polynices a proper burial"
        ],
        "model_ans": "burying her brother",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> burying her brother </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What play showed an early depiction of civil disobedience?",
        "answers": [
            "Antigone",
            "Antigone",
            "Antigone",
            "Antigone",
            "Antigone"
        ],
        "model_ans": "The Crucible",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Crucible </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Antigone was a play made by whom?",
        "answers": [
            "Sophocles",
            "Sophocles",
            "Sophocles",
            "Sophocles",
            "Sophocles"
        ],
        "model_ans": "Sophocles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sophocles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In Antigone, who was the target of civil disobedience?",
        "answers": [
            "Creon, the current King of Thebes",
            "Creon",
            "Creon, the current King of Thebes",
            "Creon",
            "Creon"
        ],
        "model_ans": "Creon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Creon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the protest in Antigone about?",
        "answers": [
            "giving her brother Polynices a proper burial",
            "giving her brother Polynices a proper burial",
            "the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial",
            "Creon, the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial",
            "giving her brother Polynices a proper burial"
        ],
        "model_ans": "Antigone's defiance of the law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antigone's defiance of the law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was the civil disobedience shown in Antigone?",
        "answers": [
            "obey her conscience rather than human law",
            "She gives a stirring speech",
            "She gives a stirring speech in which she tells him that she must obey her conscience rather than human law",
            "a stirring speech",
            "She gives a stirring speech in which she tells him that she must obey her conscience rather than human law"
        ],
        "model_ans": "Antigone's defiance of the law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antigone's defiance of the law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After the Peterloo massacre what poet wrote The Massacre of Anarchy?",
        "answers": [
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley"
        ],
        "model_ans": "Percy Bysshe Shelley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Percy Bysshe Shelley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "His poem is considered the first kind of what type of protest?",
        "answers": [
            "nonviolent",
            "political poem",
            "nonviolent",
            "nonviolent",
            "nonviolent"
        ],
        "model_ans": "sonnet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> sonnet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What famous author used similarity and likeness of Percy Shelly in his writing?",
        "answers": [
            "Henry David Thoreau",
            "Gandhi",
            "Henry David Thoreau",
            "Henry David Thoreau",
            "Gandhi"
        ],
        "model_ans": "Jorge Luis Borges",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jorge Luis Borges </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Inspired by Shelley what was the name of Gandhi's doctrine?",
        "answers": [
            "Satyagraha",
            "Satyagraha",
            "Satyagraha",
            "Satyagraha",
            "Satyagraha"
        ],
        "model_ans": "Ahimsa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ahimsa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Gandhi often referenced Shelley's poem in his efforts to do what? ",
        "answers": [
            "free India",
            "free India",
            "campaign for a free India",
            "protest and political action",
            "during the campaign for a free India"
        ],
        "model_ans": "promote non-violent resistance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> promote non-violent resistance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote the poem The Mark of Anarchy?",
        "answers": [
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley",
            "Percy Shelley"
        ],
        "model_ans": "Percy Bysshe Shelley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Percy Bysshe Shelley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Mark of Anarchy was written to protest against what?",
        "answers": [
            "unjust forms of authority",
            "Peterloo massacre",
            "unjust forms of authority",
            "the unjust forms of authority",
            "Peterloo massacre"
        ],
        "model_ans": "the Vietnam War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the Vietnam War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the principle shown in The Mark of Anarchy?",
        "answers": [
            "principle of nonviolent protest",
            "nonviolent protest",
            "nonviolent protest",
            "nonviolent protest",
            "nonviolent protest"
        ],
        "model_ans": "The Mark of Anarchy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Mark of Anarchy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which famous Indian practiced civil disobedience?",
        "answers": [
            "Gandhi",
            "Gandhi",
            "Gandhi",
            "Gandhi",
            "Gandhi"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was Ghandi's work called?",
        "answers": [
            "doctrine of Satyagraha",
            "Satyagraha",
            "Satyagraha",
            "Satyagraha",
            "Satyagraha"
        ],
        "model_ans": "Hind Swaraj",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hind Swaraj </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Vice President Agnew describes Civil disobedience in what activities?",
        "answers": [
            "muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins",
            "civil disobedience",
            "muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins",
            "muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins",
            "activities of muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins"
        ],
        "model_ans": "protests",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> protests </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Civil disobedience has been argued in more recent times to have suffered from what?",
        "answers": [
            "ambiguity",
            "debased",
            "ambiguity",
            "ambiguity",
            "ambiguity"
        ],
        "model_ans": "co-optation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> co-optation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "More in the present prevalence of civil disobedience has turned and said to be?",
        "answers": [
            "utterly debased",
            "debased",
            "everything from bringing a test-case in the federal courts to taking aim at a federal official",
            "utterly debased"
        ],
        "model_ans": "Martin Luther King Jr.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Martin Luther King Jr. </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What person argues that civil disobedience is used to describe everything?",
        "answers": [
            "Marshall Cohen",
            "Marshall Cohen",
            "Marshall Cohen",
            "Marshall Cohen",
            "Marshall Cohen"
        ],
        "model_ans": "Henry David Thoreau",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry David Thoreau </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In modern times, what is said about civil disobedience?",
        "answers": [
            "become utterly debased",
            "utterly debased",
            "in modern times, become utterly debased",
            "become utterly debased",
            "become utterly debased"
        ],
        "model_ans": "It is a non-violent resistance movement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It is a non-violent resistance movement </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who noted the different current uses of civil disobedience?",
        "answers": [
            "Marshall Cohen",
            "Marshall Cohen",
            "Marshall Cohen",
            "Marshall Cohen",
            "President Agnew"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How has civil disobedience evolved in current times?",
        "answers": [
            "code-word describing the activities of muggers, arsonists, draft evaders",
            "utterly debased",
            "become utterly debased",
            "become utterly debased",
            "become utterly debased"
        ],
        "model_ans": "Civil disobedience has evolved in current times by incorporating new technologies, such as social media, to spread awareness and mobilize people. It has also become more diverse, with people from different</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civil disobedience has evolved in current times by incorporating new technologies, such as social media, to spread awareness and mobilize people. It has also become more diverse, with people from different</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who gave a negative connotation to civil disobedience in recent history?",
        "answers": [
            "Vice President Agnew",
            "Vice President Agnew",
            "Vice President Agnew",
            "Vice President Agnew",
            "Marshall Cohen"
        ],
        "model_ans": "Martin Luther King Jr.",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Martin Luther King Jr. </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What issue has been plaguing the civil disobedience movement.",
        "answers": [
            "ambiguity",
            "ambiguity",
            "ambiguity",
            "ambiguity"
        ],
        "model_ans": "Racism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Racism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote that it is difficult to produce an all inclusive definition of civil disobedience?",
        "answers": [
            "LeGrande",
            "LeGrande",
            "LeGrande",
            "LeGrande",
            "LeGrande"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Le Grande also wrote that defining the term civil disobedience so difficult it could be described as? ",
        "answers": [
            "impossible",
            "a maze of semantical problems and grammatical niceties",
            "impossible",
            "impossible"
        ],
        "model_ans": "impossible",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> impossible </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Le grand asks for a variance of what three terms?",
        "answers": [
            "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience",
            "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience",
            "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience",
            "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience",
            "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience"
        ],
        "model_ans": "1.5, 2.5, 3.5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5, 2.5, 3.5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Le grand states that students studying civil disobedience will often run into grammatical niceties and what other problem? ",
        "answers": [
            "semantical",
            "semantical",
            "a maze of semantical problems",
            "semantical",
            "semantical problems"
        ],
        "model_ans": "logical fallacies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> logical fallacies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Le grand concludes that an author's words offer only what they intended for them to imply regarding this type of terminology?",
        "answers": [
            "specific",
            "civil disobedience",
            "specific",
            "specific"
        ],
        "model_ans": "ambiguity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ambiguity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who said that writing a good description of civil disobedience is hard?",
        "answers": [
            "LeGrande",
            "LeGrande",
            "LeGrande",
            "LeGrande",
            "LeGrande"
        ],
        "model_ans": "Henry David Thoreau",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry David Thoreau </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much literature has been written regarding civil disobedience?",
        "answers": [
            "voluminous literature",
            "voluminous",
            "voluminous",
            "voluminous"
        ],
        "model_ans": "numerous",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> numerous </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What issue plagues the literature about civil disobedience?",
        "answers": [
            "semantical problems and grammatical niceties",
            "maze of semantical problems and grammatical niceties",
            "semantical problems and grammatical niceties",
            "semantical problems and grammatical niceties"
        ],
        "model_ans": "The lack of clear definitions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The lack of clear definitions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of protest falls under civil disobedience without aggression?",
        "answers": [
            "nonviolent civil disobedience",
            "nonviolent civil disobedience",
            "nonviolent",
            "nonviolent",
            "nonviolent"
        ],
        "model_ans": "Nonviolent resistance",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nonviolent resistance </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of civil disobedience is accompanied by aggression?",
        "answers": [
            "violent civil disobedience",
            "violent civil disobedience",
            "violent",
            "violent",
            "violent"
        ],
        "model_ans": "Violent civil disobedience",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Violent civil disobedience </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If the head of government refuses to enforce a decision of the highest court what terminology could be used?",
        "answers": [
            "constitutional impasse",
            "her or his capacity as public official",
            "capacity as public official",
            "constitutional impasse"
        ],
        "model_ans": "Judicial Supremacy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judicial Supremacy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Constitutional impasse is different from civil disobedience because does not include what type of person?",
        "answers": [
            "citizen's",
            "head of government",
            "private citizen",
            "private citizen",
            "private"
        ],
        "model_ans": "violent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> violent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is civil disobedience typically defined in connection of the citizen's?",
        "answers": [
            "to the state and its laws",
            "relation to the state and its laws",
            "a citizen's relation to the state and its laws,",
            "pertaining to a citizen's relation to the state and its laws",
            "as pertaining to a citizen's relation to the state and its laws"
        ],
        "model_ans": "as the intentional act of breaking a law in order to bring attention to a social injustice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> as the intentional act of breaking a law in order to bring attention to a social injustice </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When would a person be considered to be excising a constitutional impasse?",
        "answers": [
            "the head of government would be acting in her or his capacity as public official",
            "two public agencies, especially two equally sovereign branches of government, conflict",
            "two public agencies, especially two equally sovereign branches of government, conflict",
            "if the head of government of a country were to refuse to enforce a decision of that country's highest court",
            "two public agencies, especially two equally sovereign branches of government, conflict"
        ],
        "model_ans": "When a person is in a situation where they are unable to make a decision due to conflicting opinions or values",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> When a person is in a situation where they are unable to make a decision due to conflicting opinions or values </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Constitutional impasse is distinct from what key term? ",
        "answers": [
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience",
            "Civil disobedience"
        ],
        "model_ans": "political crisis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> political crisis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does civil disobedience relate to?",
        "answers": [
            "the state and its laws",
            "a citizen's relation to the state and its laws",
            "a citizen's relation to the state and its laws",
            "a citizen's relation to the state and its laws",
            "a citizen's relation to the state and its laws"
        ],
        "model_ans": "Nonviolent resistance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nonviolent resistance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does not constitute as civil disobedience?",
        "answers": [
            "refuse to enforce a decision",
            "constitutional impasse",
            "two public agencies, especially two equally sovereign branches of government, conflict.",
            "a constitutional impasse in which two public agencies",
            "constitutional impasse"
        ],
        "model_ans": "Violent acts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Violent acts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of person can not be attributed civil disobedience?",
        "answers": [
            "head of government",
            "public official",
            "public official",
            "public"
        ],
        "model_ans": "A judge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A judge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Civil Disobedience is mainly performed by what population group?",
        "answers": [
            "private citizen",
            "private citizen",
            "private citizen",
            "private"
        ],
        "model_ans": "Students",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Students </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What group of people cannot be part of civil disobedience?",
        "answers": [
            "sovereign branches of government",
            "public official",
            "public agencies",
            "public"
        ],
        "model_ans": "Military personnel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Military personnel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What author argues pitching the conscience versus the collective?",
        "answers": [
            "Thoreau",
            "Thoreau",
            "Thoreau",
            "Thoreau",
            "Thoreau's"
        ],
        "model_ans": "Friedrich Nietzsche",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Friedrich Nietzsche </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Thoreau's punishment for not paying his taxes?",
        "answers": [
            "imprisonment",
            "imprisonment",
            "imprisonment",
            "imprisonment",
            "imprisonment"
        ],
        "model_ans": "Jail",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jail </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Thoreau argues that usually majority rules but their views collectively are sometimes?",
        "answers": [
            "not necessarily right",
            "not necessarily right",
            "the will of elite politicians",
            "the will of elite politicians",
            "not necessarily right"
        ],
        "model_ans": "wrong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> wrong </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Thoreau ask a public figure the taxman to do?",
        "answers": [
            "Resign",
            "refusal to pay",
            "Resign",
            "Resign",
            "Resign"
        ],
        "model_ans": "pay his taxes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pay his taxes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Thoreau mentions what type of person could corrupt a government system?",
        "answers": [
            "elite politicians",
            "elite politicians",
            "individuals",
            "elite politicians",
            "individuals"
        ],
        "model_ans": "the masses",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the masses </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the final judge of right and wrong?",
        "answers": [
            "The individual",
            "individuals",
            "The individual",
            "The individual",
            "individual"
        ],
        "model_ans": "God",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> God </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is to blame for acting unjustly?",
        "answers": [
            "individuals",
            "individuals",
            "an individual",
            "individuals",
            "individuals"
        ],
        "model_ans": "No one",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No one </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was famous for disobedience against a tax collector?",
        "answers": [
            "Thoreau",
            "Thoreau",
            "Thoreau",
            "Thoreau",
            "Thoreau"
        ],
        "model_ans": "Jesus Christ",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jesus Christ </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What advise did Thoreau give the tax collector when unable to perform his duty?",
        "answers": [
            "Resign",
            "Resign",
            "Resign",
            "Resign",
            "Resign"
        ],
        "model_ans": "Pay your taxes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pay your taxes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Thoreau claim about the majority?",
        "answers": [
            "not necessarily right",
            "may be powerful but it is not necessarily right",
            "The majority may be powerful but it is not necessarily right",
            "The majority may be powerful but it is not necessarily right",
            "may be powerful but it is not necessarily right"
        ],
        "model_ans": "He claimed that the majority is often wrong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He claimed that the majority is often wrong </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Some theories argue that civil disobedience is justified in regard to?",
        "answers": [
            "governmental entities",
            "against governmental entities",
            "governmental entities",
            "governmental entities",
            "governmental entities"
        ],
        "model_ans": "unjust laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unjust laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Brownlee argues disobedience can be justified toward what institutions?",
        "answers": [
            "trade unions, banks, and private universities",
            "non-governmental agencies",
            "decisions of non-governmental agencies",
            "non-governmental agencies",
            "non-governmental agencies"
        ],
        "model_ans": "unjust",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unjust </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Brownlee justifies civil disobedience toward what branch of the government?",
        "answers": [
            "legal system",
            "foreign",
            "legal system",
            "international organizations and foreign governments"
        ],
        "model_ans": "government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Browlee also applies that civil disobedience is okay regarding?",
        "answers": [
            "international organizations and foreign governments",
            "a larger challenge to the legal system that permits those decisions to be taken",
            "international organizations and foreign governments",
            "breaches of law in protest against international organizations and foreign governments",
            "opposition to the decisions of non-governmental agencies such as trade unions, banks, and private universities"
        ],
        "model_ans": "unjust laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unjust laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do some theories claim about civil disobedience?",
        "answers": [
            "only justified against governmental entities",
            "civil disobedience is only justified against governmental entities",
            "civil disobedience is only justified against governmental entities.",
            "civil disobedience is only justified against governmental entities",
            "that civil disobedience is only justified against governmental entities"
        ],
        "model_ans": "It can be an effective means of achieving social change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It can be an effective means of achieving social change </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who claims that public companies can also be part of civil disobedience?",
        "answers": [
            "Brownlee",
            "Brownlee",
            "Brownlee",
            "Brownlee",
            "Brownlee"
        ],
        "model_ans": "Naomi Klein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Naomi Klein </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What reason is given that you should also protest public companies?",
        "answers": [
            "a larger challenge to the legal system",
            "challenge to the legal system that permits those decisions to be taken",
            "it reflects \"a larger challenge to the legal system that permits those decisions to be taken",
            "a larger challenge to the legal system"
        ],
        "model_ans": "Because they are also responsible for the environment",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they are also responsible for the environment </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What public entity of learning is often target of civil disobedience?",
        "answers": [
            "universities",
            "private universities",
            "private universities",
            "private universities",
            "private universities"
        ],
        "model_ans": "University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If law breaking is not done in a public manor it is not considered what term?",
        "answers": [
            "civil disobedience",
            "lawbreaking",
            "civil disobedience",
            "civil disobedience",
            "civil disobedience"
        ],
        "model_ans": "private",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> private </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Stephen Eilmann asks why show public civil disobedience instead what is a better idea?",
        "answers": [
            "covert lawbreaking",
            "lawbreaking",
            "covert lawbreaking",
            "covert lawbreaking",
            "covert lawbreaking"
        ],
        "model_ans": "Non-violent direct action",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Non-violent direct action </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Stephen Eilmann demonstrates covert law breaking in Nazi Germany.   Citizen's illegally had been doing what? ",
        "answers": [
            "hiding a Jew in their house",
            "hiding a Jew",
            "hiding a Jew in their house",
            "hiding a Jew in their house",
            "hiding a Jew"
        ],
        "model_ans": "hiding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hiding </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Stephen Eildmann cites the oldest known example of civil disobedience in what part of the bible? ",
        "answers": [
            "(Exodus 1: 15-19)",
            "Book of Exodus",
            "the Book of Exodus",
            "Shiphrah and Puah refused a direct order of Pharaoh but misrepresented how they did it",
            "Book of Exodus,"
        ],
        "model_ans": "Exodus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exodus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What two women were defying the pharaoh in the story from the book of Exodus? ",
        "answers": [
            "Shiphrah and Puah",
            "Shiphrah and Puah",
            "Shiphrah and Puah",
            "Shiphrah and Puah",
            "Shiphrah and Puah"
        ],
        "model_ans": "Shiphrah and Puah",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Shiphrah and Puah </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What must be done to make non public lawbreaking acknowledged as civil disobedience?",
        "answers": [
            "must be publicly announced",
            "publicly announced",
            "must be publicly announced",
            "publicly announced",
            "civil disobedience"
        ],
        "model_ans": "Public recognition",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public recognition </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is necessary to disobey?",
        "answers": [
            "rules that conflict with morality",
            "rules that conflict with morality",
            "rules that conflict with morality",
            "rules that conflict with morality"
        ],
        "model_ans": "A reason",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A reason </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is sometimes more effective than civil disobedience at times?",
        "answers": [
            "fabricating evidence or committing perjury",
            "fabricating evidence or committing perjury",
            "covert lawbreaking",
            "assisting in fabricating evidence or committing perjury",
            "covert lawbreaking"
        ],
        "model_ans": "Nonviolent resistance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nonviolent resistance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What dilemma is a good example of moral civil disobedience?",
        "answers": [
            "the dilemma faced by German citizens",
            "German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house",
            "the dilemma faced by German citizens",
            "the dilemma faced by German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house"
        ],
        "model_ans": "Rosa Parks' refusal to give up her seat on a Montgomery, Alabama bus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rosa Parks' refusal to give up her seat on a Montgomery, Alabama bus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What book of the Bible discusses civil disobedience?",
        "answers": [
            "Book of Exodus",
            "Exodus",
            "Exodus",
            "Exodus",
            "Exodus"
        ],
        "model_ans": "Hebrews",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hebrews </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cristian Bay's encyclopedia concludes that civil disobedience does not only include what behavior?",
        "answers": [
            "non-violence",
            "non-violent",
            "non-violent",
            "non-violent",
            "non-violent"
        ],
        "model_ans": "non-violent",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> non-violent </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What dictionary contains a non- violent definition?",
        "answers": [
            "Black's Law",
            "Black's Law Dictionary",
            "Black's Law Dictionary",
            "Black's Law Dictionary",
            "Black's Law Dictionary"
        ],
        "model_ans": "Merriam-Webster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Merriam-Webster </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other terminology is considered much more destructive?",
        "answers": [
            "civil rebellion",
            "rebellion",
            "civil rebellion are justified by appeal to constitutional defects, rebellion is much more",
            "rebellion",
            "rebellion"
        ],
        "model_ans": "Nuclear",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nuclear </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "People behaving with civil disobedience that is not-violent is said to make society have more of what?",
        "answers": [
            "tolerance",
            "tolerance of civil disobedience",
            "tolerance of civil disobedience",
            "tolerance of civil disobedience",
            "tolerance"
        ],
        "model_ans": "change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Debates about civil disobedience include or exclude what major practice? ",
        "answers": [
            "violence",
            "non-violent",
            "appeal to constitutional defects",
            "violence",
            "civil disobedience"
        ],
        "model_ans": "civil disobedience",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> civil disobedience </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of civil disobedience is commonly accepted?",
        "answers": [
            "non-violent",
            "non-violent",
            "non-violent",
            "non-violent",
            "non-violence"
        ],
        "model_ans": "Nonviolent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nonviolent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When violence is used, what is civil disobedience sometimes called?",
        "answers": [
            "civil rebellion",
            "civil rebellion",
            "civil rebellion",
            "rebellion",
            "rebellion"
        ],
        "model_ans": "Riot",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Riot </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one result of civil rebellion?",
        "answers": [
            "destructive",
            "use of force and violence and refusal to submit to arrest",
            "rebellion is much more destructive",
            "rebellion is much more destructive",
            "force and violence and refusal to submit to arrest"
        ],
        "model_ans": "Overthrow of the government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Overthrow of the government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is it preferred that civil disobedience is non violent?",
        "answers": [
            "help preserve society's tolerance of civil disobedience",
            "preserve society's tolerance of civil disobedience",
            "rebellion is much more destructive",
            "Civil disobedients' refraining from violence is also said to help preserve society's tolerance of civil disobedience",
            "help preserve society's tolerance"
        ],
        "model_ans": "To avoid harming innocent people and to show that the cause is just",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To avoid harming innocent people and to show that the cause is just </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is it called when there is an active attempt to overthrow a government or belief system?",
        "answers": [
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience"
        ],
        "model_ans": "Coup",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coup </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What group of people performed revolutionary civil disobedience toward the Austrian government?",
        "answers": [
            "Hungarians",
            "Hungarians",
            "the Hungarians under Ferenc De\u00e1k",
            "Hungarians",
            "Hungarians"
        ],
        "model_ans": "The Habsburgs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Habsburgs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Hungarians performed this civil disobedience under the direction of what person?",
        "answers": [
            "Ferenc De\u00e1k",
            "Ferenc De\u00e1k",
            "Ferenc De\u00e1k",
            "Ferenc De\u00e1k",
            "Ferenc De\u00e1k"
        ],
        "model_ans": "Imre Nagy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Imre Nagy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Revolutionary civil disobedience towards culture is highlighted by example of who? ",
        "answers": [
            "Gandhi's",
            "Gandhi",
            "Gandhi",
            "Gandhi's"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What other topics can Civil disobedience pertain to?",
        "answers": [
            "cultural traditions, social customs, religious beliefs",
            "revolutionary civil disobedience",
            "change cultural traditions, social customs, religious beliefs, etc",
            "cultural traditions, social customs, religious beliefs",
            "peaceable revolution"
        ],
        "model_ans": "Racism, sexism, homophobia, and other forms of discrimination",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Racism, sexism, homophobia, and other forms of discrimination </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a simple form of civil disobedience?",
        "answers": [
            "disobedience of laws",
            "Non-revolutionary civil disobedience",
            "Non-revolutionary civil disobedience",
            "Non-revolutionary",
            "cultural revolution"
        ],
        "model_ans": "Refusal to pay taxes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Refusal to pay taxes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why would a person chose civil disobedience against specific laws?",
        "answers": [
            "judged \"wrong\" by an individual conscience",
            "they are judged \"wrong\" by an individual conscience",
            "they are judged \"wrong\" by an individual conscience",
            "to cause their repeal",
            "they are judged \"wrong\" by an individual conscience"
        ],
        "model_ans": "To protest unjust laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To protest unjust laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the goal of individual civil disobedience?",
        "answers": [
            "render certain laws ineffective",
            "to render certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue",
            "render certain laws ineffective, to cause their repeal",
            "t to render certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue",
            "to render certain laws ineffective,"
        ],
        "model_ans": "To challenge unjust laws or policies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To challenge unjust laws or policies </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of civil disobedience is larger scale?",
        "answers": [
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience",
            "Revolutionary civil disobedience",
            "Revolutionary",
            "Revolutionary"
        ],
        "model_ans": "Mass protest",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mass protest </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What famous Indian's actions were considered civil disobedience?",
        "answers": [
            "Gandhi",
            "Gandhi's",
            "Gandhi's",
            "Gandhi",
            "Gandhi's"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the earliest examples of civil disobedience as a whole occur?",
        "answers": [
            "during the Roman Empire",
            "Roman Empire",
            "during the Roman Empire",
            "the Roman Empire",
            "during the Roman Empire"
        ],
        "model_ans": "Ancient Greece",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ancient Greece </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Jewish people do so pagan items wouldn't be in the temple of Jerusalem?",
        "answers": [
            "gathered in the streets",
            "gathered in the streets",
            "gathered in the streets",
            "gathered in the streets",
            "gathered in the streets"
        ],
        "model_ans": "They removed them",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They removed them </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Since Thoreau was not a well known writer what happened when he was arrested?",
        "answers": [
            "was not covered in any newspapers",
            "was not covered in any newspapers in the days, weeks and months after it happened.",
            "his arrest was not covered in any newspapers",
            "his arrest was not covered in any newspapers in the days, weeks and months after it happened",
            "his arrest was not covered in any newspapers"
        ],
        "model_ans": "He was arrested for refusing to pay taxes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He was arrested for refusing to pay taxes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What position did the tax collector that arrested Thoreau get?",
        "answers": [
            "rose to higher political office",
            "higher political office",
            "higher political office",
            "rose to higher political office",
            "higher political office"
        ],
        "model_ans": "Collector",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Collector </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Thoreau's essay published?",
        "answers": [
            "after the end of the Mexican War",
            "end of the Mexican War",
            "after the end of the Mexican War.",
            "after the end of the Mexican War",
            "after the end of the Mexican War"
        ],
        "model_ans": "1862\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1862\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is the oldest recorded incident of civil disobedience?",
        "answers": [
            "during the Roman Empire",
            "during the Roman Empire",
            "during the Roman Empire",
            "during the Roman Empire",
            "during the Roman Empire"
        ],
        "model_ans": "1905",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1905 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the goal of this Roman disobedience?",
        "answers": [
            "prevent the installation of pagan images",
            "prevent the installation of pagan images in the Temple in Jerusalem",
            "prevent the installation of pagan images in the Temple in Jerusalem",
            "to prevent the installation of pagan images in the Temple in Jerusalem",
            "prevent the installation of pagan images"
        ],
        "model_ans": "To overthrow the Roman Empire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To overthrow the Roman Empire </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a recent civil disobedience done in a group form?",
        "answers": [
            "refuse to sign bail",
            "collectively refuse to sign bail until certain demands are met",
            "some activists who commit civil disobedience as a group collectively refuse to sign bail until certain demands are met",
            "jail solidarity"
        ],
        "model_ans": "The Extinction Rebellion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Extinction Rebellion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the civil disobedience called where people refuse to be released?",
        "answers": [
            "jail solidarity",
            "solitary civil disobedience",
            "jail solidarity",
            "jail solidarity",
            "jail solidarity"
        ],
        "model_ans": "Hunger strike",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hunger strike </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long did it take for Thoreau's disobedience to be known?",
        "answers": [
            "until after the end of the Mexican War",
            "months",
            "months after it happened",
            "Thoreau's essay was not published until after the end of the Mexican War",
            "after the end of the Mexican War"
        ],
        "model_ans": "150 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Civil disobedients have chosen many different kinds of what type of behaviors?",
        "answers": [
            "illegal",
            "illegal acts",
            "illegal acts",
            "illegal acts",
            "illegal acts"
        ],
        "model_ans": "protests",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> protests </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Bedau notes that illegal protests towards public policy may serve as what purpose?",
        "answers": [
            "propaganda",
            "propaganda",
            "propaganda",
            "propaganda",
            "just a harassment"
        ],
        "model_ans": "political expression",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> political expression </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What group of civil disobedients brought medicine to Iraq without the permission of the government?",
        "answers": [
            "Voice in the Wilderness",
            "Voice in the Wilderness",
            "Voice in the Wilderness",
            "Voice in the Wilderness",
            "Voice in the Wilderness"
        ],
        "model_ans": "Doctors Without Borders",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doctors Without Borders </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long did Julia Butterfly Hill live in a tree?",
        "answers": [
            "738 days",
            "738 days",
            "738 days",
            "738 days",
            "738 days"
        ],
        "model_ans": "738 days\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "738 days\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the outcome of living in the California Redwood tree?",
        "answers": [
            "successfully preventing it from being cut down",
            "successfully preventing it from being cut down",
            "successfully preventing it from being cut down",
            "successfully preventing it from being cut down",
            "preventing it from being cut down"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of actions are taken sometimes in civil disobedience?",
        "answers": [
            "illegal acts",
            "symbolic illegal protests",
            "symbolic illegal protests",
            "a variety of different illegal acts",
            "illegal"
        ],
        "model_ans": "protests",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> protests </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an example of illegal disobedience?",
        "answers": [
            "trespassing at a nuclear-missile installation",
            "symbolic illegal protests",
            "trespassing at a nuclear-missile installation",
            "the proprietors of illegal medical cannabis dispensaries",
            "trespassing at a nuclear-missile installation"
        ],
        "model_ans": "Refusal to comply with a court order",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Refusal to comply with a court order </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Such protests are usually considered to be what type?",
        "answers": [
            "entirely symbolic",
            "symbolic illegal protests",
            "harassment",
            "symbolic",
            "inane"
        ],
        "model_ans": "peaceful",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> peaceful </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of goals are usually done skirting the law?",
        "answers": [
            "social goal",
            "social goal",
            "protests toward public policy",
            "propaganda",
            "social"
        ],
        "model_ans": "Illegal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Illegal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who lived in a tree to prevent it from being cut down as a form of civil disobedience?",
        "answers": [
            "Julia Butterfly Hill",
            "Julia Butterfly Hill",
            "Julia Butterfly Hill",
            "Julia Butterfly Hill",
            "Julia Butterfly Hill"
        ],
        "model_ans": "Julia Butterfly Hill",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Julia Butterfly Hill </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was Joseph Haas arrested for?",
        "answers": [
            "sending an email to the Lebanon, New Hampshire city councilors",
            "sending an email",
            "sending an email to the Lebanon, New Hampshire city councilors",
            "sending an email",
            "sending an email to the Lebanon"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Joseph Haas say in his email?",
        "answers": [
            "\"Wise up or die.\"",
            "Wise up or die",
            "\"Wise up or die.\"",
            "Wise up or die",
            "Wise up or die"
        ],
        "model_ans": "No answer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No answer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Civil disobedience can occur when people speak about a certain topic that is deemed as?",
        "answers": [
            "criminalized behavior",
            "forbidden speech",
            "criminalized behavior",
            "forbidden",
            "forbidden"
        ],
        "model_ans": "taboo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> taboo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "WBAI's broadcasting Some of George Carlin's comedy eventually led to what?",
        "answers": [
            "Supreme Court case of FCC v. Pacifica Foundation",
            "1978 Supreme Court case of FCC v. Pacifica Foundation",
            "Supreme Court case of FCC v. Pacifica Foundation",
            "FCC v. Pacifica Foundation",
            "the 1978 Supreme Court case of FCC v. Pacifica Foundation"
        ],
        "model_ans": "FCC fines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> FCC fines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did the the case go before the supreme court?",
        "answers": [
            "1978",
            "1978",
            "1978",
            "1978",
            "1978"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one criminal behavior that is hard to stop by authorities?",
        "answers": [
            "pure speech",
            "forbidden speech",
            "pure speech",
            "engaging in the forbidden speech"
        ],
        "model_ans": "Money laundering",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Money laundering </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one way to use pure speech to reach as much people as possible to protest?",
        "answers": [
            "broadcasting",
            "engaging in the forbidden speech",
            "broadcasting",
            "broadcasting"
        ],
        "model_ans": "Social media",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social media </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How can you protest against the government in an individual way?",
        "answers": [
            "Threatening government officials",
            "forbidden speech",
            "engaging in the forbidden speech",
            "speech",
            "Threatening government officials"
        ],
        "model_ans": "Write letters to your representatives, participate in peaceful protests, boycott products from companies that support policies you disagree with, and engage in civil disobedience",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Write letters to your representatives, participate in peaceful protests, boycott products from companies that support policies you disagree with, and engage in civil disobedience </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one way of digital civil disobedience that can have far reaching consequences?",
        "answers": [
            "sending an email",
            "email",
            "Supreme Court case",
            "broadcasting"
        ],
        "model_ans": "DDoS attacks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DDoS attacks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Boycotting, refusing to pay taxes, sit ins, and draft dodging all make what harder?",
        "answers": [
            "system to function",
            "system to function",
            "for a system to function",
            "for a system to function",
            "for a system to function"
        ],
        "model_ans": "change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> change </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Name one way the Plowshares organization temporarily close GCSB Waihopai?",
        "answers": [
            "by padlocking the gates",
            "padlocking the gates",
            "padlocking the gates",
            "padlocking the gates",
            "padlocking the gates"
        ],
        "model_ans": "By painting the satellite dish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By painting the satellite dish </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Name the other way that the Plowshares organization temporarily closed?",
        "answers": [
            "using sickles to deflate one of the large domes covering two satellite dishes",
            "using sickles to deflate one of the large domes covering two satellite dishes",
            "using sickles to deflate one of the large domes covering two satellite dishes",
            "using sickles to deflate one of the large domes covering two satellite dishes",
            "using sickles to deflate one of the large domes"
        ],
        "model_ans": "The Plowshares organization temporarily closed the",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Plowshares organization temporarily closed the </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Brownlee argues that sometimes people behave in what way to have their issue heard?",
        "answers": [
            "limited coercion",
            "civil disobedience",
            "employ limited coercion",
            "limited coercion",
            "employ limited coercion"
        ],
        "model_ans": "loudly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> loudly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When large groups of people all boycott a system or don't pay taxes it can be considered?",
        "answers": [
            "coercive",
            "civil disobedience",
            "coercive",
            "coercive",
            "civil disobedience"
        ],
        "model_ans": "civil disobedience",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> civil disobedience </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a type of disobedience against the federal government?",
        "answers": [
            "refusals to pay taxes",
            "civil disobedience",
            "refusals to pay taxes",
            "refusals to pay taxes",
            "refusals to pay taxes"
        ],
        "model_ans": "Rebellion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rebellion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What side effect of these type of protests is unfortunate?",
        "answers": [
            "coercion",
            "make it more difficult for a system to function",
            "make it more difficult for a system to function",
            "make it more difficult for a system to function"
        ],
        "model_ans": "Injuries and property damage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Injuries and property damage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What goal do many of these protests have?",
        "answers": [
            "engage in moral dialogue",
            "get their issue onto the table",
            "get their issue onto the table",
            ", make it more difficult for a system to function"
        ],
        "model_ans": "Change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How can you protest against big companies in a non violent way?",
        "answers": [
            "padlocking the gates",
            "illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins",
            "boycotts",
            "illegal boycotts",
            "sit-ins"
        ],
        "model_ans": "Boycott their products, sign petitions, participate in peaceful demonstrations, write letters to the editor, and use social media to raise awareness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Boycott their products, sign petitions, participate in peaceful demonstrations, write letters to the editor, and use social media to raise awareness </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of government investigations apply to civil disobedience?",
        "answers": [
            "criminal investigations",
            "grant a consent search",
            "grant a consent search",
            "criminal investigations",
            "Many of the same decisions and principles that apply in other criminal investigations",
            "criminal"
        ],
        "model_ans": "Federal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Federal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a way you can show police officers civil disobedience ?",
        "answers": [
            "not to grant a consent search",
            "not to talk to police officers",
            "not to talk to police officers",
            "not to talk",
            "resist responding to investigators' questions",
            "grant a consent search"
        ],
        "model_ans": "Refusing to obey a law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Refusing to obey a law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What should be avoided when talking to authorities?",
        "answers": [
            "suspect's talking to criminal investigators",
            "responding to investigators' questions",
            "responding to investigators' questions",
            "grant a consent search of his property,",
            "talking to criminal investigators",
            "responding to investigators' questions"
        ],
        "model_ans": "lying",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lying </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What reasons cause failure of the disobedience with authorities?",
        "answers": [
            "lack of understanding of the legal ramifications,",
            "a suspect's talking to criminal investigators",
            "lack of understanding",
            "lack of understanding of the legal ramifications, or due to a fear of seeming rude."
        ],
        "model_ans": "disobedience",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> disobedience </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why do some people purposely resist officers of the law?",
        "answers": [
            "use the arrest as an opportunity",
            "civil disobedience",
            "civil disobedience",
            "civil disobedience",
            "civil disobedience",
            "to make an impression"
        ],
        "model_ans": "Various reasons, including political beliefs, personal vendetta, or a desire to challenge authority",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Various reasons, including political beliefs, personal vendetta, or a desire to challenge authority </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do some civil disobedient people feel the need to acknowledge.",
        "answers": [
            "accept punishment",
            "accept punishment",
            "punishment",
            "punishment",
            "punishment"
        ],
        "model_ans": "their rights",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> their rights </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is the need for acceptance of punishment needed?",
        "answers": [
            "validity of the social contract",
            "their belief in the validity of the social contract",
            "because of their belief in the validity of the social contract",
            "belief in the validity of the social contract",
            "their belief in the validity of the social contract"
        ],
        "model_ans": "To maintain social order and respect for the law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To maintain social order and respect for the law </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do some people protest against?",
        "answers": [
            "legitimacy of a particular law",
            "law",
            "laws",
            "the legitimacy of any government"
        ],
        "model_ans": "injustice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> injustice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the group called that does not agree with government at all?",
        "answers": [
            "anarchists",
            "anarchists",
            "anarchists",
            "anarchists",
            "anarchists"
        ],
        "model_ans": "Anarchist",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anarchist </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Anarchists do not want to accept punishment for what reason?",
        "answers": [
            "does not infringe the rights of others",
            "don't believe in the legitimacy of any government",
            "a violation of criminal law that does not infringe the rights of others",
            "see no need to accept punishment for a violation of criminal law that does not infringe the rights of others",
            "a violation of criminal law that does not infringe the rights of others."
        ],
        "model_ans": "Because they reject the concept of authority",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they reject the concept of authority </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an important personal decision for civil disobedients?",
        "answers": [
            "whether or not to plead guilty",
            "whether or not to plead guilty",
            "whether or not to plead guilty",
            "whether or not to plead guilty",
            "whether or not to plead guilty.",
            "whether or not to plead guilty."
        ],
        "model_ans": "Whether to use non-violent resistance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Whether to use non-violent resistance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which duty do some people believe civil disobedients have?",
        "answers": [
            "submit to the punishment prescribed by law",
            "to submit to the punishment prescribed by law",
            "submit to the punishment",
            "to submit to the punishment prescribed by law",
            "to submit to the punishment prescribed by law",
            "to submit to the punishment prescribed by law"
        ],
        "model_ans": "to disobey unjust laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to disobey unjust laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why would one plead guilty to a crime involving civil disobedience?",
        "answers": [
            "I feel I did the right thing by violating this particular law",
            "I feel I did the right thing by violating this particular law",
            "proud of it",
            "proud of it",
            "have violated some specific laws, but I am guilty of doing no w",
            "have violated some specific laws, but I am guilty of doing no w"
        ],
        "model_ans": "To avoid a harsher sentence",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To avoid a harsher sentence </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which reason is given sometimes to plead not guilty involving these matters?",
        "answers": [
            "Guilt implies wrong-doing",
            "Guilt implies wrong-doing",
            "guilty of doing no wrong",
            "Guilt implies wrong-doing",
            "I may have violated some specific laws, but I am guilty of doing no wrong",
            "I may have violated some specific laws, but I am guilty of doing no wrong"
        ],
        "model_ans": "Insanity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Insanity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What third type of plea uses creative words?",
        "answers": [
            "creative plea",
            "no contest",
            "creative plea",
            "creative plea",
            "creative plea",
            "creative plea"
        ],
        "model_ans": "Nolo Contendere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nolo Contendere </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where in Las Vegas did a famous protest take place?",
        "answers": [
            "Camp Mercury nuclear test site",
            "Camp Mercury nuclear test site",
            "Camp Mercury nuclear test site",
            "Camp Mercury nuclear test site",
            "Camp Mercury nuclear test site"
        ],
        "model_ans": "Freedom Corner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Freedom Corner </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the civil disobedience performed at the test site?",
        "answers": [
            "tempted to enter the test site",
            "protesters attempted to enter the test site",
            "attempted to enter the test site",
            "13 of the protesters attempted to enter the test site",
            "protest"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the result of the disobedience protesting the nuclear site?",
        "answers": [
            "arrested",
            "arrest",
            "were immediately arrested",
            "one at a time they stepped across the \"line\" and were immediately arrested",
            "put on a bus and taken to the Nye County seat of Tonopah, Nevada, and arraigned for trial before the local Justice of the Peace"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did their lawyer suggest they would plea?",
        "answers": [
            "nolo contendere",
            "nolo contendere",
            "nolo contendere",
            "nolo contendere",
            "nolo contendere"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of sentences were the protesters given?",
        "answers": [
            "suspended sentences",
            "suspended sentences",
            "suspended",
            "suspended",
            "suspended"
        ],
        "model_ans": "Sentences",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sentences </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why do some people chose to go to jail for their disobedience?",
        "answers": [
            "a way of continuing their protest",
            "continuing their protest",
            "a way of continuing their protest",
            "a way of continuing their protest",
            "a way of continuing their protest"
        ],
        "model_ans": "For political or social reasons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> For political or social reasons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Going to jail accomplished what goal of civil disobedience?",
        "answers": [
            "reminding their countrymen of injustice",
            "reminding their countrymen of injustice",
            "reminding their countrymen of injustice",
            "reminding their countrymen of injustice",
            "reminding their countrymen of injustice"
        ],
        "model_ans": "Martin Luther King Jr.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Martin Luther King Jr. </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most important item for civil disobedience to follow through?",
        "answers": [
            "protest should be maintained all the way",
            "spirit of protest",
            "the spirit of protest should be maintained all the way",
            "the spirit of protest should be maintained all the way",
            "spirit of protest"
        ],
        "model_ans": "Non-violence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Non-violence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why should one not go to jail?",
        "answers": [
            "accept jail penitently",
            "is to switch suddenly to a spirit of subservience",
            "To accept jail penitently as an accession to 'the rules' is to switch suddenly to a spirit of subservience",
            "To accept jail penitently as an accession to 'the rules' is to switch suddenly to a spirit of subservience"
        ],
        "model_ans": "Because it is a place of confinement and punishment",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because it is a place of confinement and punishment </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of punishment is sometimes offered to civil disobedients?",
        "answers": [
            "plea bargain",
            "plead guilty to one misdemeanor count and receive no jail time",
            "plea bargain",
            "plea bargain",
            "plea bargain"
        ],
        "model_ans": "Jail",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jail </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is usually the goal of taking a plea bargain?",
        "answers": [
            "no jail time",
            "plead guilty to one misdemeanor count and receive no jail time",
            "receive no jail time",
            "no jail time",
            "receive no jail time"
        ],
        "model_ans": "To avoid a trial",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To avoid a trial </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When many people are arrested, what is a common tactic negotiating?",
        "answers": [
            "solidarity tactics",
            "solidarity tactics",
            "solidarity",
            "solidarity",
            "solidarity"
        ],
        "model_ans": "Plea bargaining",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plea bargaining </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of plea is sometimes taken as an act of disobedience?",
        "answers": [
            "blind plea",
            "blind plea",
            "blind plea",
            "blind plea",
            "blind plea"
        ],
        "model_ans": "Nolo contendere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nolo contendere </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which famous Indian took a plea and put himself at the mercy of the courts?",
        "answers": [
            "Mohandas Gandhi",
            "Mohandas Gandhi",
            "Mohandas Gandhi",
            "Mohandas Gandhi",
            "Gan"
        ],
        "model_ans": "Rajiv Gandhi",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Rajiv Gandhi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What way do some people perform civil disobedience in a constructive way?",
        "answers": [
            "defiant speech",
            "defiant speech",
            "allocution",
            "defiant speech",
            "defiant speech",
            "defiant speech"
        ],
        "model_ans": "nonviolent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nonviolent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why would one want to give a speech?",
        "answers": [
            "explaining their actions",
            "explaining their actions",
            "make a defiant speech, or a speech explaining their actions,",
            "explaining their actions",
            "explaining their actions",
            "explaining their actions"
        ],
        "model_ans": "To communicate ideas, persuade, or entertain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To communicate ideas, persuade, or entertain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is giving a defiant speech sometimes more harmful for the individual?",
        "answers": [
            "lack of remorse",
            "lack of remorse",
            "the judge increased her sentence",
            "statement suggested a lack of remorse"
        ],
        "model_ans": "Because it can lead to further isolation, ridicule, or even persecution",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because it can lead to further isolation, ridicule, or even persecution </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why would one want to give more punishment?",
        "answers": [
            "likelihood of repeating",
            "likelihood of repeating her illegal actions",
            "a lack of remorse",
            "lack of remorse",
            "lack of remorse"
        ],
        "model_ans": "To deter others from committing the same crime",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To deter others from committing the same crime </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of treatment do civil disobedients usually receive?",
        "answers": [
            "mistreatment from government officials",
            "mistreatment",
            "mistreatment from government officials",
            "sentence",
            "mistreatment",
            "mistreatment"
        ],
        "model_ans": "Jail time",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jail time </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the primary goal of pleading not guilty when arrested for Civil Disobedience?",
        "answers": [
            "acquittal and avoid imprisonment",
            "win an acquittal and avoid imprisonment or a fine",
            "to use the proceedings as a forum",
            "win an acquittal",
            "to win an acquittal and avoid imprisonment or a fine"
        ],
        "model_ans": "To contest the charges",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To contest the charges </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a secondary goal of pleading not guilty?",
        "answers": [
            "use the proceedings as a forum",
            "use the proceedings as a forum to inform the jury and the public of the political circumstances",
            "win an acquittal and avoid imprisonment",
            "use the proceedings as a forum to inform the jury and the public of the political circumstances",
            "use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case"
        ],
        "model_ans": "To delay the trial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To delay the trial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What would someone who is civilly disobedient do in court?",
        "answers": [
            "inform the jury and the public of the political circumstances",
            "plead not guilty",
            "plead not guilty",
            "inform the jury and the public",
            "plead not guilty"
        ],
        "model_ans": "Refuse to comply with the court's orders",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Refuse to comply with the court's orders </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What US war has a large amount of Civil Disobedients?",
        "answers": [
            "Vietnam War",
            "Vietnam War",
            "Vietnam War",
            "Vietnam War",
            "Vietnam War"
        ],
        "model_ans": "Vietnam War",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vietnam War </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What can sympathetic Jurors in cases with civil disobedients?",
        "answers": [
            "jury nullification",
            "jury nullification",
            "jury nullification",
            "nullification",
            "nullification"
        ],
        "model_ans": "Acquit",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Acquit </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What needs to be avoided with civil disobedience?",
        "answers": [
            "general disobedience",
            "undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit",
            "great amount of it",
            "general disobedience",
            "conscientious lawbreakers"
        ],
        "model_ans": "violence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> violence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why should disobedience by the general public be avoided?",
        "answers": [
            "neither conscientious nor of social benefit",
            "neither conscientious nor of social benefit",
            "any great amount of it would undermine the law",
            "conscientious lawbreakers"
        ],
        "model_ans": "Because it can lead to chaos and disorder",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because it can lead to chaos and disorder </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one main reason that civil disobedience is not recognized?",
        "answers": [
            "breaking the law for self-gratification",
            "breaking the law for self-gratification",
            "it would undermine the law by encouraging general disobedience",
            "breaking the law for self-gratification"
        ],
        "model_ans": "Lack of recognition by the government",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lack of recognition by the government </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why should someone not commit a crime when they are protesting?",
        "answers": [
            "not being a civil disobedient",
            "viewed as not being a civil disobedient",
            "conscientious lawbreakers must be punished",
            "it would undermine the law by encouraging general disobedience",
            "constitute civil disobedience"
        ],
        "model_ans": "Because it is illegal and can lead to serious consequences",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Because it is illegal and can lead to serious consequences </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "For what reason would someone avoid crimes while protesting?",
        "answers": [
            "avoiding attribution",
            "viewed as not being a civil disobedient",
            "it would undermine the law by encouraging general disobedience",
            "constitute civil disobedience"
        ],
        "model_ans": "To avoid punishment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To avoid punishment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is violating a law which is not the goal of the protest called?",
        "answers": [
            "Indirect civil disobedience",
            "Indirect civil disobedience",
            "Indirect civil disobedience",
            "Indirect civil disobedience",
            "Indirect civil disobedience"
        ],
        "model_ans": "Civil disobedience",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civil disobedience </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When the law is a direct target of the protest, what is this called?",
        "answers": [
            "direct civil disobedience",
            "direct civil disobedience",
            "direct civil disobedience",
            "direct civil disobedience",
            "direct civil disobedience"
        ],
        "model_ans": "Direct Action",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Direct Action </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What US war caused a high amount of civil disobedience?",
        "answers": [
            "Vietnam War",
            "Vietnam War",
            "Vietnam War",
            "Vietnam War",
            "Vietnam"
        ],
        "model_ans": "Vietnam War",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vietnam War </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of defense is sometimes used in court by protestors?",
        "answers": [
            "competing harms defense",
            "necessity defense",
            "necessity defense",
            "necessity"
        ],
        "model_ans": "Necessity",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Necessity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are people who distribute leaflets inside courthouses not been arrested?",
        "answers": [
            "the leaflets will have to be given to the leafleter's own jury as evidence",
            "if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence",
            "the leaflets will have to be given to the leafleter's own jury as evidence",
            "the leaflets will have to be given to the leafleter's own jury as evidence",
            "the leaflets will have to be given to the leafleter's own jury as evidence"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the main goal of criminal punishment of civil disobedients?",
        "answers": [
            "incapacitation",
            "achieving crime control via incapacitation and deterrence",
            "achieving crime control via incapacitation and deterrence",
            "achieving crime control",
            "achieving crime control"
        ],
        "model_ans": "To deter others from engaging in similar acts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To deter others from engaging in similar acts </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What should be the main goal of not using punishment in a just system?",
        "answers": [
            "would do more harm than good",
            "whether it would do more harm than good",
            "it focuses attention on the threat of punishment and not the moral reasons to follow this law",
            "whether it would do more harm than good",
            "whether it would do more harm than good."
        ],
        "model_ans": "Rehabilitation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rehabilitation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who decides the fate of protesters most of the time?",
        "answers": [
            "the state",
            "judges",
            "the state (including the judges)",
            "the judges",
            "judges"
        ],
        "model_ans": "Police",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Police </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What should the punishment rely on instead in a just society?",
        "answers": [
            "moral reasons to follow this law",
            "whether it would do more harm than good",
            "whether it would do more harm than good",
            "whether it would do more harm than good",
            "whether it would do more harm than good"
        ],
        "model_ans": "rehabilitation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> rehabilitation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the process of constructing a building or infrastructure?",
        "answers": [
            "Construction",
            "Construction",
            "Construction"
        ],
        "model_ans": "Construction",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Construction </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What typically involves mass production of similar items without a designated purchaser?",
        "answers": [
            "manufacturing",
            "manufacturing",
            "manufacturing"
        ],
        "model_ans": "Manufacturing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manufacturing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What percentile of gross domestic product is construction comprised of?",
        "answers": [
            "six to nine percent",
            "six to nine percent",
            "six to nine percent"
        ],
        "model_ans": "10-15%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10-15% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What three things are needed for construction to take place?",
        "answers": [
            "planning,[citation needed] design, and financing",
            "planning,[citation needed] design, and financing",
            "planning,[citation needed] design, and financing and continues until the project is built"
        ],
        "model_ans": "land, materials, and labor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> land, materials, and labor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Construction takes place on location for who?",
        "answers": [
            "a known client",
            "client",
            "known client"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who normally manages a construction job?",
        "answers": [
            "An architect",
            "architect",
            "architect"
        ],
        "model_ans": "Construction Manager",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Construction Manager </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who normally supervises a construction job?",
        "answers": [
            "a construction manager, design engineer, construction engineer or project manager",
            "construction engineer or project manager",
            "construction manager, design engineer, construction engineer or project manager"
        ],
        "model_ans": "General Contractor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Contractor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is essential for the successful execution of a project?",
        "answers": [
            "effective planning",
            "effective planning",
            "effective planning"
        ],
        "model_ans": "Planning",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Planning </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The largest construction projects are known as what?",
        "answers": [
            "megaprojects",
            "megaprojects",
            "megaprojects"
        ],
        "model_ans": "megaprojects",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> megaprojects </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Zoning requirements, environmental impact, budgeting, and logistics are things who should consider?",
        "answers": [
            "Those involved with the design and execution of the infrastructure",
            "Those involved with the design and execution of the infrastructure",
            "Those involved with the design and execution of the infrastructure in question"
        ],
        "model_ans": "Developers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Developers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the three sectors of construction?",
        "answers": [
            "buildings, infrastructure and industrial",
            "buildings, infrastructure and industrial",
            "buildings, infrastructure and industrial"
        ],
        "model_ans": "Building, Infrastructure, and Industrial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Building, Infrastructure, and Industrial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Building construction is usually further divided into what categories?",
        "answers": [
            "residential and non-residential",
            "residential and non-residential (commercial/institutional)",
            "residential and non-residential (commercial/institutional)"
        ],
        "model_ans": "residential, commercial, industrial",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> residential, commercial, industrial </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Infrastructure is often called what?",
        "answers": [
            "heavy/highway, heavy civil or heavy engineering",
            "heavy/highway, heavy civil or heavy engineering",
            "heavy/highway, heavy civil or heavy engineering"
        ],
        "model_ans": "backbone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> backbone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Large public works, dams, bridges, highways, water/wastewater and utility distribution are under what construction sector?",
        "answers": [
            "Infrastructure",
            "Infrastructure",
            "Infrastructure"
        ],
        "model_ans": "Heavy Civil Construction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heavy Civil Construction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Refineries, process chemical, power generation, mills and manufacturing plants are under what sector of construction?",
        "answers": [
            "Industrial",
            "heavy civil or heavy engineering",
            "Industrial"
        ],
        "model_ans": "Industrial",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Industrial </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is Engineering News-Record?",
        "answers": [
            "a trade magazine for the construction industry",
            "a trade magazine for the construction industry",
            "trade magazine for the construction industry"
        ],
        "model_ans": "A magazine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A magazine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What compiles and reports on data about the size of design and construction companies?",
        "answers": [
            "ENR",
            "Engineering News-Record (ENR)",
            "Engineering News-Record (ENR)"
        ],
        "model_ans": "ENR",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ENR </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what year did ENR compile data in nine market segments?",
        "answers": [
            "2014",
            "2014",
            "2014"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ENR used data on what to rank Top 400 firms as heavy contractors?",
        "answers": [
            "transportation, sewer, hazardous waste and water",
            "data on transportation, sewer, hazardous waste and water",
            "transportation, sewer, hazardous waste and water"
        ],
        "model_ans": "construction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> construction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the three construction subsectors?",
        "answers": [
            "building construction, heavy and civil engineering construction, and specialty trade contractors",
            "building construction, heavy and civil engineering construction, and specialty trade contractors",
            "building construction, heavy and civil engineering construction, and specialty trade contractors"
        ],
        "model_ans": "Buildings, Infrastructure, and Industrial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Buildings, Infrastructure, and Industrial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There are other categories for what?",
        "answers": [
            "construction service firms (e.g., engineering, architecture) and construction managers",
            "service firms",
            "construction service firms (e.g., engineering, architecture) and construction managers"
        ],
        "model_ans": "other",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> other </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has a classification system for construction companies?",
        "answers": [
            "The Standard Industrial Classification and the newer North American Industry Classification System",
            "Standard Industrial Classification",
            "The Standard Industrial Classification and the newer North American Industry Classification System"
        ],
        "model_ans": "NAICS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NAICS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are construction managers?",
        "answers": [
            "firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project",
            "firms engaged in managing construction projects",
            "(firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project)"
        ],
        "model_ans": "Professionals who oversee the planning, coordination, and execution of construction projects",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Professionals who oversee the planning, coordination, and execution of construction projects </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the process of adding structure to real property or construction of buildings?",
        "answers": [
            "Building construction",
            "Building construction",
            "Building construction"
        ],
        "model_ans": "Construction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Construction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The majority of building construction jobs are what?",
        "answers": [
            "small renovations",
            "small renovations",
            "small renovations"
        ],
        "model_ans": "residential",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> residential </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who acts as laborer, paymaster, and design team for a renovation project?",
        "answers": [
            "the owner of the property",
            "the owner",
            "owner of the property"
        ],
        "model_ans": "Contractor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Contractor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some examples of undesirable end results of a project?",
        "answers": [
            "structural collapse, cost overruns, and/or litigation",
            "structural collapse, cost overruns, and/or litigation",
            "structural collapse, cost overruns, and/or litigation"
        ],
        "model_ans": "failure, delay, cost overruns, poor quality, scope creep",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> failure, delay, cost overruns, poor quality, scope creep </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do those in the field do to ensure a positive outcome?",
        "answers": [
            "make detailed plans and maintain careful oversight",
            "make detailed plans and maintain careful oversight",
            "make detailed plans and maintain careful oversight during the project"
        ],
        "model_ans": "They follow established protocols and guidelines, and continuously monitor and adapt to changing circumstances",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They follow established protocols and guidelines, and continuously monitor and adapt to changing circumstances </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Residential construction practices, technologies, and resources must conform to what?",
        "answers": [
            "local building authority regulations and codes of practice",
            "local building authority regulations and codes of practice",
            "local building authority regulations and codes of practice"
        ],
        "model_ans": "local building codes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> local building codes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What generally dictates the construction materials used?",
        "answers": [
            "Materials readily available in the area",
            "Materials readily available in the area",
            "Materials readily available in the area"
        ],
        "model_ans": "Budget",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Budget </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Residential construction can generate what is not carefully planned?",
        "answers": [
            "a lot of waste",
            "waste",
            "waste"
        ],
        "model_ans": "waste",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> waste </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Site conditions, local regulations, economies of scale and the availability of skilled tradespeople all affect what?",
        "answers": [
            "Cost of construction",
            "Cost of construction",
            "Cost of construction"
        ],
        "model_ans": "construction costs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> construction costs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "New techniques of building construction are being researched, made possible by advances in what?",
        "answers": [
            "3D printing technology",
            "3D printing technology",
            "advances in 3D printing technology"
        ],
        "model_ans": "technology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> technology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Building printing is making it possible to flexibly construct small commercial buildings and private habitations in what amount of time?",
        "answers": [
            "around 20 hours",
            "around 20 hours",
            "20 hours"
        ],
        "model_ans": "1-3 days",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1-3 days </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Dutch architect Janjaap Ruijssenaars's performative architecture 3D-printed building is scheduled to be built when?",
        "answers": [
            "Working versions of 3D-printing building technology are already printing",
            "2014",
            "2014"
        ],
        "model_ans": "2013\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2013\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Working versions of 3D-printing building technology are already printing how much building material per hour?",
        "answers": [
            "2 metres (6 ft 7 in)",
            "2 metres (6 ft 7 in)",
            "2 metres (6 ft 7 in)"
        ],
        "model_ans": "100-200 cubic meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100-200 cubic meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Construction involves the translation of what?",
        "answers": [
            "designs into reality",
            "designs into reality",
            "designs into reality"
        ],
        "model_ans": "design",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> design </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A formal design team may be assembled to do what?",
        "answers": [
            "plan the physical proceedings, and to integrate those proceedings with the other parts",
            "plan the physical proceedings, and to integrate those proceedings with the other parts",
            "plan the physical proceedings, and to integrate those proceedings with the other parts"
        ],
        "model_ans": "design",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> design </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The design team is most commonly employed by who?",
        "answers": [
            "the property owner",
            "the property owner",
            "property owner"
        ],
        "model_ans": "Architects",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Architects </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who provides the bill of quantities?",
        "answers": [
            "a quantity surveyor",
            "quantity surveyor",
            "quantity surveyor"
        ],
        "model_ans": "Quantity Surveyor",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantity Surveyor </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The owner typically awards a contract to who?",
        "answers": [
            "the most cost efficient bidder",
            "the most cost efficient bidder",
            "most cost efficient bidder"
        ],
        "model_ans": "the lowest bidder",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the lowest bidder </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The modern trend in design is toward integration of what?",
        "answers": [
            "previously separated specialties",
            "previously separated specialties",
            "previously separated specialties, especially among large firms"
        ],
        "model_ans": "technology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> technology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Even in large firms, architects, interior designers, engineers, developers, construction managers, and general contractors were more likely to be what?",
        "answers": [
            "entirely separate companies",
            "entirely separate companies",
            "entirely separate companies"
        ],
        "model_ans": "independent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> independent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In modern times, firms may offer themselves as what for a construction project?",
        "answers": [
            "\"one-stop shopping\"",
            "one-stop shopping",
            "\"one-stop shopping\""
        ],
        "model_ans": "contractors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> contractors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of contract is given when the contractor is given a performance specification and must undertake the project from design to construction, while adhering to the performance specifications?",
        "answers": [
            "\"design build\" contract",
            "design build",
            "\"design build\" contract"
        ],
        "model_ans": "Lump Sum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lump Sum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What project structures assist the owner in integration?",
        "answers": [
            "design-build, partnering and construction management",
            "design-build, partnering and construction management",
            "design-build, partnering and construction management"
        ],
        "model_ans": "RUP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> RUP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "These project structures allow the owner to integrate the services of who throughout the design and construction?",
        "answers": [
            "architects, interior designers, engineers and constructors",
            "architects, interior designers, engineers and constructors",
            "architects, interior designers, engineers and constructors"
        ],
        "model_ans": "Architect",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Architect </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Many construction companies are now placing more emphasis on what?",
        "answers": [
            "establishing relationships with other necessary participants through the design-build process",
            "establishing relationships with other necessary participants",
            "establishing relationships with other necessary participants"
        ],
        "model_ans": "sustainability",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sustainability </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can construction projects suffer from?",
        "answers": [
            "preventable financial problems",
            "preventable financial problems",
            "preventable financial problems"
        ],
        "model_ans": "delays",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> delays </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an underbid?",
        "answers": [
            "when builders ask for too little money to complete the project",
            "when builders ask for too little money to complete the project",
            "builders ask for too little money to complete the project"
        ],
        "model_ans": "An underbid is a bid that is lower than the actual value of the item being auctioned",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> An underbid is a bid that is lower than the actual value of the item being auctioned </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When do cash flow problems exist?",
        "answers": [
            "when the present amount of funding cannot cover the current costs for labour and materials",
            "when the present amount of funding cannot cover the current costs for labour and materials",
            "present amount of funding cannot cover the current costs for labour and materials"
        ],
        "model_ans": "When a company's cash inflows are less than its cash outflows",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> When a company's cash inflows are less than its cash outflows </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What financial issue is notoriously prevalent in the construction field?",
        "answers": [
            "Fraud",
            "Fraud",
            "Fraud"
        ],
        "model_ans": "Cash flow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cash flow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who are likely participants in creating an overall plan for the financial management of the building construction project?",
        "answers": [
            "Mortgage bankers, accountants, and cost engineers",
            "Mortgage bankers, accountants, and cost engineers",
            "Mortgage bankers, accountants, and cost engineers"
        ],
        "model_ans": "Architects, Engineers, Contractors, Project Managers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Architects, Engineers, Contractors, Project Managers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The presence of who is highly likely even in small projects?",
        "answers": [
            "the mortgage banker",
            "mortgage banker",
            "mortgage banker"
        ],
        "model_ans": "a manager",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a manager </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who studies the expected monetary flow over the life of the project and to monitor the payouts throughout the process?",
        "answers": [
            "Accountants",
            "Accountants",
            "Accountants"
        ],
        "model_ans": "Financial Analyst",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Financial Analyst </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who applies expertise to relate the work and materials involved to a proper valuation?",
        "answers": [
            "Cost engineers and estimators",
            "Cost engineers and estimators",
            "Cost engineers and estimators"
        ],
        "model_ans": "Appraiser",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Appraiser </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Cost overruns with government projects have occurred when the contractor did what?",
        "answers": [
            "identified change orders or project changes that increased costs",
            "identified change orders or project changes that increased costs",
            "contractor identified change orders or project changes that increased costs"
        ],
        "model_ans": "underestimated the cost",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> underestimated the cost </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What must a project adhere to?",
        "answers": [
            "zoning and building code requirements",
            "zoning and building code requirements",
            "zoning and building code requirements"
        ],
        "model_ans": "standards",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> standards </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Constructing a project that fails to adhere to codes does not benefit whom?",
        "answers": [
            "the owner",
            "owner",
            "the owner"
        ],
        "model_ans": "society",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> society </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is malum in se considerations?",
        "answers": [
            "the desire to prevent things that are indisputably bad",
            "desire to prevent things that are indisputably bad",
            "the desire to prevent things that are indisputably bad"
        ],
        "model_ans": "moral evil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> moral evil </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are malum prohibitum considerations?",
        "answers": [
            "things that are a matter of custom or expectation",
            "things that are a matter of custom or expectation",
            "things that are a matter of custom or expectation"
        ],
        "model_ans": "illegal but not necessarily morally wrong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> illegal but not necessarily morally wrong </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who may seek changes or exemptions in the law that governs the land where the building will be built?",
        "answers": [
            "An attorney",
            "attorney",
            "An attorney"
        ],
        "model_ans": "Developers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Developers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a complex net of contracts and other legal obligations?",
        "answers": [
            "A construction project",
            "A construction project",
            "A construction project"
        ],
        "model_ans": "web",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> web </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the exchange of a set of obligations between two or more parties?",
        "answers": [
            "A contract",
            "A contract",
            "A contract"
        ],
        "model_ans": "Contract",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Contract </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the time element in construction mean?",
        "answers": [
            "that a delay costs money, and in cases of bottlenecks, the delay can be extremely expensive",
            "a delay costs money",
            "that a delay costs money, and in cases of bottlenecks, the delay can be extremely expensive"
        ],
        "model_ans": "Time element refers to the duration of a construction project, including the time required for planning, design, procurement, construction, testing, and commissioning.",
        "model_confidence": "uns",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Time element refers to the duration of a construction project, including the time required for planning, design, procurement, construction, testing, and commissioning. </answer>\n<confidence>uns</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Contracts must be designed to ensure what?",
        "answers": [
            "that each side is capable of performing the obligations set out",
            "that each side is capable of performing the obligations set out",
            "each side is capable of performing the obligations set out"
        ],
        "model_ans": "fairness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fairness </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What leads to confusion and collapse?",
        "answers": [
            "poorly drafted contracts",
            "poorly drafted contracts",
            "poorly drafted contracts"
        ],
        "model_ans": "hyperventilation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hyperventilation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A growing number of new forms of procurement involves what?",
        "answers": [
            "relationship contracting where the emphasis is on a co-operative relationship",
            "relationship contracting",
            "relationship contracting"
        ],
        "model_ans": "digital",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> digital </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is PPP?",
        "answers": [
            "Public-Private Partnering",
            "Public-Private Partnering",
            "Public-Private Partnering"
        ],
        "model_ans": "Public Private Partnership",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public Private Partnership </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a PPP also known as?",
        "answers": [
            "private finance initiatives (PFIs)",
            "private finance initiatives (PFIs)",
            "private finance initiatives (PFIs)"
        ],
        "model_ans": "Public Private Partnership",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Public Private Partnership </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Focus on what is to ameliorate the many problems that arise from the often highly competitive and adversarial practices within the construction industry.",
        "answers": [
            "co-operation",
            "co-operation",
            "co-operation"
        ],
        "model_ans": "collaboration",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> collaboration </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In the most common construction procurement, who acts as the project coordinator?",
        "answers": [
            "the architect or engineer",
            "the architect or engineer",
            "the architect or engineer"
        ],
        "model_ans": "Architect",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Architect </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Whose role is to design the works, prepare the specifications and produce construction drawings, administer the contract, tender the works, and manage the works from inception to completion",
        "answers": [
            "the project coordinator",
            "project coordinator",
            "the architect or engineer"
        ],
        "model_ans": "Architect",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Architect </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "There are direct contractual links between who?",
        "answers": [
            "the architect's client and the main contractor",
            "the architect's client and the main contractor",
            "architect's client and the main contractor"
        ],
        "model_ans": "The Stranglers and EMI",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers and EMI </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Any subcontractor has a direct contractual relationship with who?",
        "answers": [
            "the main contractor",
            "the main contractor",
            "main contractor"
        ],
        "model_ans": "the prime contractor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the prime contractor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The procedure continues until what?",
        "answers": [
            "the building is ready to occupy.",
            "the building is ready to occupy",
            "building is ready to occupy"
        ],
        "model_ans": "the end",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the end </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who produces a list of requirements for a project, giving an overall view of the project's goals?",
        "answers": [
            "The owner",
            "The owner",
            "The owner"
        ],
        "model_ans": "Project Manager",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Project Manager </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who presents different ideas about how to accomplish goals?",
        "answers": [
            "D&B contractors",
            "D&B contractors",
            "Several D&B contractors"
        ],
        "model_ans": "Consultants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Consultants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who selects and hires the best ideas and appropriate contractors?",
        "answers": [
            "The owner",
            "The owner",
            "The owner"
        ],
        "model_ans": "Project Manager",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Project Manager </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is usually working together?",
        "answers": [
            "a consortium of several contractors",
            "a consortium of several contractors",
            "a consortium of several contractors"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What happens as they build phase 1?",
        "answers": [
            "they design phase 2",
            "they design phase 2",
            "they design phase 2"
        ],
        "model_ans": "The construction of the first phase of a project",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The construction of the first phase of a project </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is required to verify and have existing utility lines marked?",
        "answers": [
            "contractors",
            "contractors",
            "contractors"
        ],
        "model_ans": "Excavator",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Excavator </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Having existing utility lines marked lessens the likelihood of what?",
        "answers": [
            "damage",
            "the likelihood of damage",
            "the likelihood of damage to the existing electrical, water, sewage, phone, and cable facilities"
        ],
        "model_ans": "damage",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> damage </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are some existing facilities?",
        "answers": [
            "electrical, water, sewage, phone, and cable facilities",
            "electrical, water, sewage, phone, and cable",
            "electrical, water, sewage, phone, and cable facilities"
        ],
        "model_ans": "hospital, school, library",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hospital, school, library </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who inspects the building periodically to ensure that the construction adheres to the approved plans and the local building code?",
        "answers": [
            "the municipal building inspector",
            "municipal building inspector",
            "the municipal building inspector"
        ],
        "model_ans": "Building Inspector",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Building Inspector </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is issued once construction is complete and a final inspection has been passed?",
        "answers": [
            "an occupancy permit",
            "occupancy permit",
            "an occupancy permit"
        ],
        "model_ans": "Certificate of Occupancy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Certificate of Occupancy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the annual construction industry revenue in 2014?",
        "answers": [
            "$960 billion",
            "$960 billion",
            "$960 billion"
        ],
        "model_ans": "$1.3 trillion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $1.3 trillion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much revenue is private?",
        "answers": [
            "$680 billion",
            "$680 billion",
            "$680 billion"
        ],
        "model_ans": "private",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> private </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many firms were existing in 2005?",
        "answers": [
            "667,000 firms",
            "667,000 firms",
            "667,000 firms"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The average contractor hired how many employees?",
        "answers": [
            "fewer than 10 employees",
            "fewer than 10",
            "fewer than 10"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many women were employed in construction in 2011?",
        "answers": [
            "828,000",
            "828,000 women",
            "828,000"
        ],
        "model_ans": "1.3 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.3 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the average construction salary in the Middle East?",
        "answers": [
            "\u00a342,090",
            "\u00a342,090",
            "\u00a342,090"
        ],
        "model_ans": "$60,000 - $80,000 per year",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $60,000 - $80,000 per year </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the average construction salary in the UK?",
        "answers": [
            "\u00a326,719",
            "\u00a326,719",
            "\u00a326,719"
        ],
        "model_ans": "\u00a335,000-\u00a350,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a335,000-\u00a350,000 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where have some workers made more than $100,000?",
        "answers": [
            "US/Canada",
            "US/Canada",
            "US/Canada"
        ],
        "model_ans": "Silicon Valley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Silicon Valley </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one of the most dangerous occupations in the world?",
        "answers": [
            "Construction",
            "Construction",
            "Construction"
        ],
        "model_ans": "Logging",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Logging </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most common cause of injury on site?",
        "answers": [
            "Falls",
            "Falls",
            "Falls"
        ],
        "model_ans": "falls",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> falls </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are other major fatality causes?",
        "answers": [
            "electrocution, transportation accidents, and trench cave-ins",
            "electrocution, transportation accidents, and trench cave-ins",
            "electrocution, transportation accidents, and trench cave-ins"
        ],
        "model_ans": "heart disease, stroke, chronic lower respiratory diseases, accidents, diabetes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> heart disease, stroke, chronic lower respiratory diseases, accidents, diabetes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can curtail the risk of occupational injuries in the construction industry?",
        "answers": [
            "Proper safety equipment such as harnesses and guardrails and procedures such as securing ladders and inspecting scaffolding",
            "Proper safety equipment",
            "Proper safety equipment"
        ],
        "model_ans": "Personal Protective Equipment (PPE)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Personal Protective Equipment (PPE) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with non-governmental and nonstate schools, what is another name for private schools?",
        "answers": [
            "independent",
            "independent schools",
            "independent schools"
        ],
        "model_ans": "Independent schools",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Independent schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with sport and art, what is a type of talent scholarship?",
        "answers": [
            "academic",
            "academic",
            "academic"
        ],
        "model_ans": "music",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> music </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Rather than taxation, what are private schools largely funded by?",
        "answers": [
            "tuition",
            "charging their students tuition",
            "tuition"
        ],
        "model_ans": "tuition fees",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> tuition fees </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What right do private schools have that public schools don't?",
        "answers": [
            "to select their students",
            "select their students",
            "select their students"
        ],
        "model_ans": "autonomy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> autonomy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the yearly cost of some notable prep schools in New England?",
        "answers": [
            "$45,000",
            "more than $45,000",
            "$45,000"
        ],
        "model_ans": "$50,000 to $70,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $50,000 to $70,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are private schools that charge no tuition called?",
        "answers": [
            "'tuition-free",
            "tuition-free",
            "tuition-free"
        ],
        "model_ans": "Free schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Free schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with Canada and the United Kingdom, what country generally doesn't refer to universities as private schools?",
        "answers": [
            "Australia",
            "Australia",
            "Australia"
        ],
        "model_ans": "Australia",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Australia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What region does use the term 'private schools' to refer to universities?",
        "answers": [
            "North America",
            "North America",
            "North America"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another term for year 12 of education?",
        "answers": [
            "lower sixth",
            "lower sixth",
            "lower sixth"
        ],
        "model_ans": "Senior year",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Senior year </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another term used for year 13?",
        "answers": [
            "upper sixth",
            "upper sixth",
            "upper sixth"
        ],
        "model_ans": "Sixth form",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sixth form </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another term for university-preparatory schools?",
        "answers": [
            "prep schools",
            "prep schools",
            "prep schools"
        ],
        "model_ans": "Preparatory schools",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Preparatory schools </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with location, endowment and the willingness of parents to pay, what factor influences private school tuition?",
        "answers": [
            "peer tuitions",
            "peer tuitions",
            "peer tuitions and the school's financial endowment"
        ],
        "model_ans": "demand",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> demand </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who receives higher salaries at private schools that charge higher tuition?",
        "answers": [
            "teachers",
            "teachers",
            "best teachers"
        ],
        "model_ans": "Teachers",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Teachers </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What religion's schools does the term 'parochial schools' generally refer to?",
        "answers": [
            "Roman Catholic",
            "Roman Catholic"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with Muslims, Jews and Protestant Christians, what religious group notably operates private schools?",
        "answers": [
            "Orthodox Christians",
            "Roman Catholic",
            "Orthodox Christians"
        ],
        "model_ans": "Catholics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Catholics</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of education is sometimes present at religious schools in addition to the secular curriculum?",
        "answers": [
            "religious",
            "religious",
            "the usual academic subjects"
        ],
        "model_ans": "religious education",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> religious education </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What power is available to Australian private schools but generally not present in public schools?",
        "answers": [
            "expulsion",
            "expulsion",
            "offer a higher quality of education"
        ],
        "model_ans": "Fee-based funding",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fee-based funding </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an example of an article of uniform clothing typically present in Australian private schools?",
        "answers": [
            "blazer",
            "blazer",
            "blazer"
        ],
        "model_ans": "blazer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> blazer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the comparison in price between Australian private schools versus public?",
        "answers": [
            "more expensive",
            "more expensive",
            "more expensive"
        ],
        "model_ans": "The average annual fee for private schools in Australia is around $10,000-$20,000, while public schools are free or low-cost.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The average annual fee for private schools in Australia is around $10,000-$20,000, while public schools are free or low-cost. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with the Anglican Church and Uniting Church, what religious denomination operates private schools in Australia?",
        "answers": [
            "Presbyterian",
            "Presbyterian Church",
            "Presbyterian Church"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What denomination operates St Joseph's College?",
        "answers": [
            "Catholic",
            "Catholic",
            "Catholic"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Catholic</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is St Aloysius' College located?",
        "answers": [
            "Sydney",
            "Sydney",
            "Sydney"
        ],
        "model_ans": "Mumbai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mumbai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who attends Loreto Normanhurst?",
        "answers": [
            "girls",
            "girls",
            "girls"
        ],
        "model_ans": "Loreto Normanhurst",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Loreto Normanhurst </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What article of the Grundgesetz grants the right to make private schools?",
        "answers": [
            "7",
            "7",
            "7"
        ],
        "model_ans": "Article 7",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Article 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The prospect of what event compelled the protection of German private schools?",
        "answers": [
            "second Gleichschaltung",
            "a second Gleichschaltung",
            "a second Gleichschaltung"
        ],
        "model_ans": "Nazi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nazi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of German students attended private schools in 2008?",
        "answers": [
            "7.8",
            "7.8%",
            "7.8"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the percentage of Germans attending private high schools in 2008?",
        "answers": [
            "11.1",
            "11.1%",
            "11.1"
        ],
        "model_ans": "15%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 15% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1992, what percentage of East German students attended private schools?",
        "answers": [
            "0.5",
            "0.5%",
            "6.1"
        ],
        "model_ans": "0% (East Germany had a state-run education system, so there were no private schools)\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "0% (East Germany had a state-run education system, so there were no private schools)\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the German term for segregating students based on their parents' wealth?",
        "answers": [
            "Sonderungsverbot",
            "Sonderungsverbot",
            "Sonderungsverbot"
        ],
        "model_ans": "Schulzweigung",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Schulzweigung </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do Germans call private schools?",
        "answers": [
            "Ersatzschulen",
            "Ersatzschulen",
            "Ersatzschulen"
        ],
        "model_ans": "Privatschule",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Privatschule </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How does the level of tuition in German private schools compare to private schools in other Western European countries?",
        "answers": [
            "very low",
            "very low",
            "very low tuition fees"
        ],
        "model_ans": "Generally, German private schools are considered to be more affordable compared to private schools in other Western European countries",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Generally, German private schools are considered to be more affordable compared to private schools in other Western European countries </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are private secondary schools in Germany called?",
        "answers": [
            "Erg\u00e4nzungsschulen",
            "Erg\u00e4nzungsschulen",
            "Erg\u00e4nzungsschulen"
        ],
        "model_ans": "Gymnasium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gymnasium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of schools are most erg\u00e4nzungsschulen?",
        "answers": [
            "vocational",
            "secondary or post-secondary",
            "vocational schools"
        ],
        "model_ans": "secondary schools",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> secondary schools </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are erg\u00e4nzungsschulen funded?",
        "answers": [
            "tuition",
            "tuition",
            "tuition fees"
        ],
        "model_ans": "Publicly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Publicly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with private individuals and organizations, what groups sometimes runs erg\u00e4nzungsschulen?",
        "answers": [
            "religious",
            "religious groups",
            "religious"
        ],
        "model_ans": "Municipalities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Municipalities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for an Indian private school?",
        "answers": [
            "independent",
            "independent schools",
            "independent schools"
        ],
        "model_ans": "Gurukul",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gurukul </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with the CISCE and NENBSE, what is a notable Examination Board in multiple Indian states?",
        "answers": [
            "CBSE",
            "CBSE",
            "CBSE"
        ],
        "model_ans": "CBSE",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CBSE </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many Examination Boards exist in India?",
        "answers": [
            "30",
            "30",
            "30"
        ],
        "model_ans": "34",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 34 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What body in India provides policy directions to schools?",
        "answers": [
            "union government",
            "the union government",
            "union government"
        ],
        "model_ans": "Ministry of Human Resource Development",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ministry of Human Resource Development </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with trusts, what other non-profits are allowed to run schools in India?",
        "answers": [
            "societies",
            "societies",
            "societies"
        ],
        "model_ans": "Societies",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Societies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What country has the most illiterate adults in the world?",
        "answers": [
            "India",
            "India",
            "India"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the full name of the ASER?",
        "answers": [
            "Annual Status of Education Report",
            "Annual Status of Education Report",
            "Annual Status of Education Report"
        ],
        "model_ans": "Association for Strengthening Agricultural Research",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Association for Strengthening Agricultural Research </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the purpose of the ASER?",
        "answers": [
            "evaluates learning levels in rural India",
            "evaluates learning levels in rural India",
            "evaluates learning levels in rural India"
        ],
        "model_ans": "Assessing School Readiness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Assessing School Readiness </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In private schools, what language are classes taught in?",
        "answers": [
            "English",
            "English",
            "English"
        ],
        "model_ans": "English",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> English </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the Irish term for private schools?",
        "answers": [
            "scoil phr\u00edobh\u00e1ideach",
            "scoil phr\u00edobh\u00e1ideach",
            "scoil phr\u00edobh\u00e1ideach"
        ],
        "model_ans": "Gaelscoileanna",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gaelscoileanna </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do private schools in Ireland differ from most?",
        "answers": [
            "teacher's salaries are paid by the State",
            "a certain number of teacher's salaries are paid by the State",
            "certain number of teacher's salaries are paid by the State"
        ],
        "model_ans": "They are mostly fee-paying",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They are mostly fee-paying </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the typical annual cost for an Irish private school?",
        "answers": [
            "\u20ac5,000",
            "\u20ac5,000",
            "\u20ac5,000"
        ],
        "model_ans": "\u20ac5,000 to \u20ac10,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> \u20ac5,000 to \u20ac10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with the Congregation of Christian Brothers, what is a notable religious group that runs fee-paying schools in Ireland?",
        "answers": [
            "Society of Jesus",
            "the Society of Jesus",
            "Society of Jesus"
        ],
        "model_ans": "Jesuits",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jesuits </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What might the fees to attend an Irish boarding school rise to?",
        "answers": [
            "\u20ac25,000 per year",
            "\u20ac25,000",
            "\u20ac25,000 per year"
        ],
        "model_ans": "\u20ac20,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u20ac20,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Malaysia receive its independence?",
        "answers": [
            "1957",
            "1957",
            "1957"
        ],
        "model_ans": "1957\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1957\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What language is used in Chinese primary schools in Malaysia?",
        "answers": [
            "Chinese",
            "Chinese",
            "Chinese"
        ],
        "model_ans": "Malay",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Malay </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What language is used in Chinese secondary schools in Malaysia?",
        "answers": [
            "English",
            "English",
            "English"
        ],
        "model_ans": "Malay",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Malay </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the post-independence government school system in Malaysia?",
        "answers": [
            "National School",
            "National Type",
            "National School"
        ],
        "model_ans": "Sekolah Menengah Kebangsaan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sekolah Menengah Kebangsaan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "As a result of a compromise, about how many Chinese schools became National Type schools?",
        "answers": [
            "60",
            "60",
            "all"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a term for schools that receive government assistance?",
        "answers": [
            "aided",
            "aided",
            "aided"
        ],
        "model_ans": "Public",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Public </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are 'un-aided' schools different from 'aided' schools?",
        "answers": [
            "fully funded by private parties",
            "fully funded by private parties",
            "fully funded by private parties"
        ],
        "model_ans": "Un-aided schools are private schools that receive no financial assistance from the government, whereas aided schools receive financial assistance from the government.",
        "model_confidence": "unsure</confidence",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Un-aided schools are private schools that receive no financial assistance from the government, whereas aided schools receive financial assistance from the government. </answer>\n<confidence>unsure</confidence</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is Galaxy Public School located?",
        "answers": [
            "Kathmandu",
            "Kathmandu",
            "Kathmandu"
        ],
        "model_ans": "Delhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Delhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In Nepalese private schools, what is the primary language of instruction?",
        "answers": [
            "English",
            "English",
            "English"
        ],
        "model_ans": "English",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> English </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In addition to English, what language is also often taught in Nepalese private schools?",
        "answers": [
            "Nepali",
            "Nepali",
            "Nepali"
        ],
        "model_ans": "Hindi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hindi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many private schools existed in New Zealand in April 2014?",
        "answers": [
            "88",
            "88",
            "88"
        ],
        "model_ans": "1,400",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,400 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In April 2014, how many New Zealand students attended private schools?",
        "answers": [
            "28,000",
            "28,000",
            "28,000"
        ],
        "model_ans": "120,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 120,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of New Zealand students attended private schools in April 2014?",
        "answers": [
            "3.7",
            "3.7%",
            "3.7"
        ],
        "model_ans": "12%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What religion's schools were integrated into New Zealand public schools between 1979 and 1984?",
        "answers": [
            "Catholic",
            "Catholic",
            "Catholic"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What city, along with Hamilton, Wellington and Christchurch, is one of the largest in New Zealand?",
        "answers": [
            "Auckland",
            "Auckland",
            "Auckland"
        ],
        "model_ans": "Auckland",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Auckland</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What denomination is the Diocesan School for Girls in Auckland affiliated with?",
        "answers": [
            "Anglican",
            "Anglican",
            "Anglican"
        ],
        "model_ans": "Catholic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Catholic</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is Samuel Marsden Collegiate School located?",
        "answers": [
            "Wellington",
            "Wellington",
            "Wellington"
        ],
        "model_ans": "Wellington",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wellington </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What denomination is associated with Saint Kentigern College?",
        "answers": [
            "Presbyterian",
            "Presbyterian",
            "Presbyterian"
        ],
        "model_ans": "Presbyterian",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Presbyterian </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what city is Rangi Ruru Girls' School?",
        "answers": [
            "Christchurch",
            "Christchurch",
            "Christchurch"
        ],
        "model_ans": "Christchurch",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christchurch </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What group operates St Dominic's College in Wanganui?",
        "answers": [
            "Society of St Pius X",
            "the Society of St Pius X",
            "Catholic schismatic"
        ],
        "model_ans": "Dominican Order",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dominican Order </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of Filipino primary school students are in private schools?",
        "answers": [
            "7.5",
            "7.5%",
            "7.5"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the Philippines, what percentage of secondary school students attend private schools?",
        "answers": [
            "32",
            "32%",
            "32"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of Filipino tertiary education takes place in private schools?",
        "answers": [
            "80",
            "80%",
            "80"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what month and year was the revised Manual of Regulations for Private Schools released?",
        "answers": [
            "August 1992",
            "August 1992",
            "August 1992"
        ],
        "model_ans": "May 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with English and mathematics, what subject replaced values education for fourth year students?",
        "answers": [
            "natural science",
            "natural science",
            "English, mathematics and natural science"
        ],
        "model_ans": "Business Studies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Business Studies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the scheme that provides tuition and fee assistance to students due to excess enrollment?",
        "answers": [
            "Education Service Contracting",
            "Education Service Contracting",
            "Education Service Contracting"
        ],
        "model_ans": "Tuition Fee Assistance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tuition Fee Assistance </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What stipend do students enrolled in priority courses receive?",
        "answers": [
            "Tuition Fee Supplement",
            "Tuition Fee Supplement",
            "Tuition Fee Supplement"
        ],
        "model_ans": "$500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What aid is available to underprivileged students seeking to attend a private university?",
        "answers": [
            "Private Education Student Financial Assistance",
            "Private Education Student Financial Assistance",
            "Private Education Student Financial Assistance"
        ],
        "model_ans": "Scholarships",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scholarships </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What South African law recognized two types of schools?",
        "answers": [
            "South African Schools Act",
            "South African Schools Act",
            "South African Schools Act"
        ],
        "model_ans": "Model C schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Model C schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the South African Schools Act passed?",
        "answers": [
            "1996",
            "1996",
            "1996"
        ],
        "model_ans": "1996",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1996 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along with public schools, what type of school was recognized under the South African Schools Act?",
        "answers": [
            "independent",
            "independent",
            "independent"
        ],
        "model_ans": "Private schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Private schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In South Africa, along with privately governed schools, what schools are classified as independent?",
        "answers": [
            "traditional private",
            "traditional private schools",
            "traditional private schools and schools which are privately governed"
        ],
        "model_ans": "Public schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what century did missionaries notably establish church schools in South Africa?",
        "answers": [
            "nineteenth",
            "nineteenth",
            "nineteenth century"
        ],
        "model_ans": "19th",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 19th </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After apartheid, what types of schools are referred to as \"Model C\" schools?",
        "answers": [
            "government schools formerly reserved for white children",
            "government schools formerly reserved for white children",
            "semi-private"
        ],
        "model_ans": "formerly white schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> formerly white schools </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do academic results in former Model C schools compare to other schools?",
        "answers": [
            "better",
            "better",
            "produce better academic results"
        ],
        "model_ans": "better",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> better </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do the fees at former Model C schools compare to those at other schools?",
        "answers": [
            "higher",
            "much higher",
            "much higher"
        ],
        "model_ans": "The fees at former Model C schools are generally lower compared to other schools",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The fees at former Model C schools are generally lower compared to other schools </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "As of 2008, about what percentage of Swedish students attended private schools?",
        "answers": [
            "10",
            "10%",
            "10"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "About many students attend Kunskapsskolan schools?",
        "answers": [
            "10,000",
            "10,000",
            "nearly 10,000"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people work for Kunskapsskolan schools?",
        "answers": [
            "700",
            "700",
            "700"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the English translation of Kunskapsskolan?",
        "answers": [
            "The Knowledge School",
            "The Knowledge School",
            "The Knowledge School"
        ],
        "model_ans": "School of Knowledge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> School of Knowledge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What school model is Sweden notable for?",
        "answers": [
            "voucher",
            "voucher",
            "pupils are free to choose a private school"
        ],
        "model_ans": "Free school",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Free school </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Up to what age do students in the United Kingdom attend preparatory schools?",
        "answers": [
            "13",
            "13",
            "13"
        ],
        "model_ans": "11\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "11\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What schools do preparatory schools prepare British children to attend?",
        "answers": [
            "public",
            "public",
            "public"
        ],
        "model_ans": "Public schools",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Public schools </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What percentage of British children are educated at GSCE level in fee-paying schools?",
        "answers": [
            "9",
            "9",
            "9"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At A-level, what percentage of British students attend fee-paying schools?",
        "answers": [
            "13",
            "13",
            "13"
        ],
        "model_ans": "7%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the upper range of annual fees for non-boarding students in British public schools?",
        "answers": [
            "\u00a321,000",
            "\u00a321,000",
            "\u00a321,000"
        ],
        "model_ans": "\u00a310,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u00a310,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What court case desegregated schools in the United States?",
        "answers": [
            "Brown v. Board of Education of Topeka",
            "Brown v. Board of Education of Topeka",
            "Brown v. Board of Education of Topeka"
        ],
        "model_ans": "Brown v. Board of Education",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brown v. Board of Education </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a derogatory term for the Christian academies that arose in the wake of school desegregation?",
        "answers": [
            "segregation academies",
            "segregation academies"
        ],
        "model_ans": "Bible Belt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bible Belt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what part of the United States did many students migrate to Christian academies during the desegregation period?",
        "answers": [
            "South",
            "South",
            "U.S. South"
        ],
        "model_ans": "South",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the primary race of students attending Christian academies after the Brown decision?",
        "answers": [
            "white",
            "white",
            "African-American"
        ],
        "model_ans": "White",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> White </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "School desegregation in the United States led to an increased number of students of what ethnicity in public schools?",
        "answers": [
            "African-American",
            "African-American",
            "African-American"
        ],
        "model_ans": "African American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> African American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Along with tuition, scholarships, vouchers, donations and grants, where does funding for private schools come from?",
        "answers": [
            "endowments",
            "endowments",
            "endowments"
        ],
        "model_ans": "Endowments",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Endowments </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What amendment to the United States Constitution governs government funding of religious schools?",
        "answers": [
            "First",
            "First",
            "First Amendment"
        ],
        "model_ans": "First Amendment",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> First Amendment </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What state constitutional amendments make reference to the government funding religious schools?",
        "answers": [
            "Blaine",
            "Blaine Amendments",
            "Blaine Amendments"
        ],
        "model_ans": "Louisiana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louisiana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Granting what status would allow private non-religious schools in the US to receive public funds?",
        "answers": [
            "charter",
            "charter",
            "charter"
        ],
        "model_ans": "Charter school",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charter school </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the first US state to have compulsory education?",
        "answers": [
            "Massachusetts",
            "Massachusetts",
            "Massachusetts"
        ],
        "model_ans": "Massachusetts",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Massachusetts </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what year did Massachusetts first require children to be educated in schools?",
        "answers": [
            "1852",
            "1852",
            "1852"
        ],
        "model_ans": "1647\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1647\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was Wisconsin v. Yoder decided at the Supreme Court?",
        "answers": [
            "1972",
            "1972",
            "1972"
        ],
        "model_ans": "1972\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1972\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the citation for the Pierce v. Society of Sisters case?",
        "answers": [
            "268 U.S. 510",
            "268 U.S. 510",
            "268 U.S. 510 (1925)"
        ],
        "model_ans": "268 U.S. 510 (1925)\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "268 U.S. 510 (1925)\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the opposing party in the Runyon case?",
        "answers": [
            "McCrary",
            "McCrary",
            "McCrary"
        ],
        "model_ans": "The City of New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The City of New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "About how much did a New York City day school cost annually in 2012?",
        "answers": [
            "$40,000",
            "$40,000",
            "$40,000"
        ],
        "model_ans": "$20,000 to $50,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $20,000 to $50,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What would a parent have to pay to send their child to a boarding school in 2012?",
        "answers": [
            "$50,000",
            "$50,000",
            "$50,000"
        ],
        "model_ans": "$10,000 to $50,000 per year",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> $10,000 to $50,000 per year </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What notable private school has an endowment of several hundred million dollars?",
        "answers": [
            "Groton School",
            "Groton School",
            "Groton School"
        ],
        "model_ans": "Phillips Exeter Academy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Phillips Exeter Academy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In addition to endowments and tuition, how do boarding schools cover their operating costs?",
        "answers": [
            "fundraising",
            "fundraising drives",
            "fundraising drives"
        ],
        "model_ans": "fundraising",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> fundraising </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What individual is the school named after?",
        "answers": [
            "John Harvard",
            "John Harvard",
            "John Harvard"
        ],
        "model_ans": "John",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the undergraduate program become coeducational?",
        "answers": [
            "1977",
            "1977",
            "1977"
        ],
        "model_ans": "1969\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1969\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the leader through the Great Depression and World War II?",
        "answers": [
            "James Bryant Conant",
            "James Bryant Conant",
            "James Bryant Conant"
        ],
        "model_ans": "Franklin D. Roosevelt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Franklin D. Roosevelt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What organization did Harvard found in 1900?",
        "answers": [
            "Association of American Universities",
            "Association of American Universities",
            "Association of American Universities"
        ],
        "model_ans": "Harvard University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What president of the university transformed it into a modern research university?",
        "answers": [
            "Charles W. Eliot",
            "Charles W. Eliot",
            "Charles W. Eliot"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the worlds largest academic and private library system?",
        "answers": [
            "Harvard Library",
            "Harvard Library",
            "Harvard"
        ],
        "model_ans": "Harvard University",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard University </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many individual libraries make up the main school library?",
        "answers": [
            "79 individual libraries",
            "79",
            "79"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many volumes are contained in the library?",
        "answers": [
            "18 million volumes",
            "18 million",
            "over 18 million"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many US presidents are alumni of the school?",
        "answers": [
            "eight U.S. presidents",
            "eight",
            "eight"
        ],
        "model_ans": "7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Nobel Laureates are among the school alumni?",
        "answers": [
            "150 Nobel laureates",
            "150",
            "150"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the major US city that the is the university located?",
        "answers": [
            "Boston metropolitan area",
            "Boston",
            "Boston"
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the size of the school's endowment?",
        "answers": [
            "$37.6 billion",
            "$37.6 billion",
            "$37.6 billion"
        ],
        "model_ans": "$1.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $1.5 billion </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river is located in the vicinity of the school?",
        "answers": [
            "Charles River",
            "Charles",
            "Charles"
        ],
        "model_ans": "River Thames",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> River Thames </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many academic units make up the school?",
        "answers": [
            "eleven separate academic units",
            "eleven",
            "eleven"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the area that the main campus is centered in Cambridge?",
        "answers": [
            "Harvard Yard",
            "Harvard Yard",
            "Harvard Yard"
        ],
        "model_ans": "Cambridge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cambridge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the school formed?",
        "answers": [
            "1636",
            "1636",
            "1636"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization arranged to founding of school?",
        "answers": [
            "Massachusetts Bay Colony",
            "Great and General Court of the Massachusetts Bay Colony",
            "Great and General Court of the Massachusetts Bay Colony"
        ],
        "model_ans": "University",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year was North America's first printing press started?",
        "answers": [
            "1638",
            "1638",
            "1638"
        ],
        "model_ans": "1476\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1476\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the school renamed as Harvard College?",
        "answers": [
            "1639",
            "1639",
            "1639"
        ],
        "model_ans": "1636\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1636\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the charter granted for Harvard Corporation?",
        "answers": [
            "1650",
            "1650",
            "1650"
        ],
        "model_ans": "1650\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1650\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Ministers of what faith were trained by the university in early years?",
        "answers": [
            "Puritan ministers",
            "Puritan",
            "Puritan"
        ],
        "model_ans": "Anglican",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anglican </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After what higher learning model was the school designed?",
        "answers": [
            "English university model",
            "English university",
            "English university"
        ],
        "model_ans": "Harvard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harvard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Was the school officially associated with any denomination?",
        "answers": [
            "It was never affiliated with any particular denomination",
            "never",
            "never"
        ],
        "model_ans": "No",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did Harvard President Joseph Willard die?",
        "answers": [
            "1804",
            "1804",
            "1804"
        ],
        "model_ans": "1804\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1804\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What liberal succeeded Joseph Willard as president?",
        "answers": [
            "Samuel Webber",
            "Samuel Webber",
            "Samuel Webber"
        ],
        "model_ans": "Charles Sumner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Sumner </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was Henry Ware elected to chair?",
        "answers": [
            "1805",
            "1805",
            "1805"
        ],
        "model_ans": "1843",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1843 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in 1846 who's natural history lectures were acclaimed in New York and Harvard?",
        "answers": [
            "Louis Agassiz",
            "Louis Agassiz",
            "Louis Agassiz"
        ],
        "model_ans": "Louis Agassiz",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis Agassiz </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Agassiz's approach to science combined observation and what?",
        "answers": [
            "intuition",
            "intuition",
            "intuition"
        ],
        "model_ans": "experimentation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> experimentation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Common Sense Realism of what Scottish philosophers did Agassiz incorporate in his dual view of knowedge?",
        "answers": [
            "Thomas Reid and Dugald Stewart",
            "Thomas Reid and Dugald Stewart",
            "Thomas Reid and Dugald Stewart"
        ],
        "model_ans": "Reid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Reid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What president eliminated the Christian position in the curriculum?",
        "answers": [
            "Charles W. Eliot",
            "Charles W. Eliot",
            "Charles W. Eliot"
        ],
        "model_ans": "Barack Obama",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Barack Obama </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What conviction motivated Eliot to move towards secularization?",
        "answers": [
            "Transcendentalist Unitarian",
            "Transcendentalist Unitarian",
            "Transcendentalist Unitarian"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "From whom were the movement that Eliot followed derived?",
        "answers": [
            "William Ellery Channing and Ralph Waldo Emerson",
            "William Ellery Channing and Ralph Waldo Emerson",
            "William Ellery Channing and Ralph Waldo Emerson"
        ],
        "model_ans": "Plato",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Plato </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who lead the school back to leading research institution in 2oth century?",
        "answers": [
            "James Bryant Conant",
            "James Bryant Conant",
            "James Bryant Conant"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How was the school able to bring aboard the best talented students?",
        "answers": [
            "identify, recruit",
            "Conant devised programs",
            "programs to identify, recruit, and support talented youth"
        ],
        "model_ans": "By offering scholarships and competitive programs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By offering scholarships and competitive programs </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year of 20th century, did Harvard release an important document about education in America?",
        "answers": [
            "1945",
            "1945",
            "1945"
        ],
        "model_ans": "1920",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the ratio of men to women at Harvard/Radcliffe?",
        "answers": [
            "about four men attending Harvard College for every woman studying at Radcliffe",
            "four men attending Harvard College for every woman studying at Radcliffe",
            "four men attending Harvard College for every woman"
        ],
        "model_ans": "3:1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3:1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Harvard and Radcliffe admissions merge?",
        "answers": [
            "1977",
            "1977",
            "1977"
        ],
        "model_ans": "1977\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1977\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the trend of female student population from 1970s and deyond?",
        "answers": [
            "the proportion of female undergraduates steadily increased, mirroring a trend throughout higher education in the United States",
            "steadily increased",
            "increased"
        ],
        "model_ans": "Increased",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Increased </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far from state house in downtown Boston is Harvard Yard?",
        "answers": [
            "3 miles",
            "3 miles",
            "about 3 miles"
        ],
        "model_ans": "0.5 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many residential dorms house upper class, sophomore, Jr, and Sr students?",
        "answers": [
            "twelve residential Houses",
            "twelve",
            "twelve"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Along what geographic feature are nine residential houses located?",
        "answers": [
            "Charles River",
            "Charles River",
            "Charles River"
        ],
        "model_ans": "river",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> river </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far from the Yard is the Quad located?",
        "answers": [
            "half a mile northwest of the Yard",
            "half a mile",
            "half a mile"
        ],
        "model_ans": "0.5 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is Harvard stadium located?",
        "answers": [
            "Allston",
            "Allston",
            "on a 358-acre (145 ha) campus"
        ],
        "model_ans": "Boston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Boston</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the bridge that joins parts of the campus of the Charles River?",
        "answers": [
            "The John W. Weeks Bridge",
            "John W. Weeks Bridge",
            "John W. Weeks Bridge"
        ],
        "model_ans": "Harvard Bridge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard Bridge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are the Harvard medical, Dental and school of Public Health located?",
        "answers": [
            "Longwood Medical and Academic Area",
            "Longwood Medical and Academic Area",
            "Longwood Medical and Academic Area"
        ],
        "model_ans": "Boston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much more land does the school own in Allston than Cambridge?",
        "answers": [
            "approximately fifty percent",
            "fifty percent",
            "fifty percent more"
        ],
        "model_ans": "0",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 0 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are some proposals to connect campuses?",
        "answers": [
            "new and enlarged bridges, a shuttle service and/or a tram.",
            "new and enlarged bridges, a shuttle service and/or a tram",
            "new and enlarged bridges, a shuttle service and/or a tram"
        ],
        "model_ans": "pedestrian bridges, tunnels, shuttle buses, and bike paths",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pedestrian bridges, tunnels, shuttle buses, and bike paths </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What additional benefits are there to surrounding community of expansion?",
        "answers": [
            "enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible.",
            "enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible",
            "enhanced transit infrastructure, possible shuttles open to the public, and park space"
        ],
        "model_ans": "Economic growth, job creation, and increased property values",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic growth, job creation, and increased property values </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the total number of professors, instructors, and lecturers at Harvard?",
        "answers": [
            "2,400",
            "2,400",
            "2,400"
        ],
        "model_ans": "2,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the enrollment of undergraduates at Harvard?",
        "answers": [
            "7,200",
            "7,200",
            "7,200"
        ],
        "model_ans": "around 6,700",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 6,700 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many graduate students does Harvard have?",
        "answers": [
            "14,000",
            "14,000",
            "14,000"
        ],
        "model_ans": "8,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the color crimson adopted at Harvard as official color?",
        "answers": [
            "1875",
            "1875",
            "1875"
        ],
        "model_ans": "1875",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1875 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year is the earliest traces of the color Crimson at Harvard?",
        "answers": [
            "1858",
            "1858",
            "1858"
        ],
        "model_ans": "1636",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1636 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Harvard endowment total in 2011?",
        "answers": [
            "$32 billion",
            "$32 billion",
            "$32 billion"
        ],
        "model_ans": "$29.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $29.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How great were the losses suffered in the the financial crisis of 2008-09 to Harvard endowment?",
        "answers": [
            "30% loss",
            "$12 billion",
            "30% loss"
        ],
        "model_ans": "Harvard's endowment lost around 27% of its value",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harvard's endowment lost around 27% of its value </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What project did Harvard halt due to the financial crisis?",
        "answers": [
            "Allston Science Complex",
            "Allston Science Complex",
            "construction of the $1.2 billion Allston Science Complex"
        ],
        "model_ans": "Harvard's endowment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard's endowment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are Harvard's Pell grant reserves?",
        "answers": [
            "$4.093 million",
            "$4.093 million",
            "$4.093 million"
        ],
        "model_ans": "$1.4 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $1.4 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Harvard's total financial aid reserves?",
        "answers": [
            "$159 million",
            "$159 million",
            "$159 million"
        ],
        "model_ans": "$40 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $40 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the divestment from South Africa movement? ",
        "answers": [
            "late 1980s",
            "late 1980s",
            "1980s"
        ],
        "model_ans": "1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What South African Vice Consul did Harvard students blockade the speech of? ",
        "answers": [
            "South African Vice Consul Duke Kent-Brown.",
            "Duke Kent-Brown",
            "Duke Kent-Brown"
        ],
        "model_ans": "Hendrik Verwoerd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hendrik Verwoerd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By how much did Harvard management reduce its South Africa holdings in response to pressure?",
        "answers": [
            "$230 million",
            "$230 million",
            "$230 million"
        ],
        "model_ans": "40%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the applicant admission rate for class of 2019?",
        "answers": [
            "accepted 5.3% of applicants",
            "5.3%",
            "5.3%"
        ],
        "model_ans": "12.9%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12.9% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Harvard end its early admission program?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Harvard end its early admission program?",
        "answers": [
            "disadvantage low-income and under-represented minority applicants",
            "believed to disadvantage low-income and under-represented minority applicants",
            "believed to disadvantage low-income and under-represented minority applicants"
        ],
        "model_ans": "Harvard ended its early admission program in 2020 due to concerns about fairness and equity, as well as the potential for students to be disadvantaged by the early decision process.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard ended its early admission program in 2020 due to concerns about fairness and equity, as well as the potential for students to be disadvantaged by the early decision process. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was an early admission program reintroduced?",
        "answers": [
            "2016",
            "2016",
            "2016"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Between 1978 an d2008 four year full time undergraduate students were required to complete how many classes outside of their concentration?",
        "answers": [
            "core curriculum of seven classes",
            "seven",
            "seven"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Post 2008 undergraduate students are required to complete how many general education classes towards degree?",
        "answers": [
            "eight General Education categories",
            "eight",
            "eight"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What criticism in NY times article that impacts the quality of Education at Harvard?",
        "answers": [
            "reliance on teaching fellows",
            "reliance on teaching fellows",
            "reliance on teaching fellows"
        ],
        "model_ans": "The criticism is that Harvard is too focused on research and not enough on teaching",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The criticism is that Harvard is too focused on research and not enough on teaching </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the duration of Harvard Academic year?",
        "answers": [
            "beginning in early September and ending in mid-May",
            "beginning in early September and ending in mid-May",
            "beginning in early September and ending in mid-May"
        ],
        "model_ans": "9 months",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 months </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many courses must undergraduates maintain for full time status?",
        "answers": [
            "four-course rate average",
            "four",
            "four"
        ],
        "model_ans": "12\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "12\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the top 4-5% graduating students honored with?",
        "answers": [
            "summa cum laude",
            "summa cum laude",
            "summa cum laude"
        ],
        "model_ans": "Summa Cum Laude",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Summa Cum Laude </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "From 2004 to 2005 Harvard reduced the number of students earning Latin honors from 90% to what?",
        "answers": [
            "60%",
            "60%",
            "60%"
        ],
        "model_ans": "70%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 70% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is tuition for 2012 - 13 year at Harvard? ",
        "answers": [
            "$38,000",
            "$38,000",
            "$38,000"
        ],
        "model_ans": "$60,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $60,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the total cost of attendance in 2012-13?",
        "answers": [
            "$57,000",
            "$57,000",
            "$57,000"
        ],
        "model_ans": "$43,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $43,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After 2007 how much do student from families earning less than $60,000 pay for school?",
        "answers": [
            "nothing for their children to attend, including room and board",
            "nothing",
            "nothing"
        ],
        "model_ans": "$0",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $0 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 2009 what was the total of Grants awarded from Harvard?",
        "answers": [
            "$414 million",
            "$414 million",
            "$414 million"
        ],
        "model_ans": "$1.5 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $1.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of total financial aid for undergraduates from Harvard was in the form of grants?",
        "answers": [
            "88%",
            "88%",
            "88%"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the center library in the Harvard library system?",
        "answers": [
            "Widener Library",
            "Widener",
            "Widener Library"
        ],
        "model_ans": "Widener Library",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Widener Library </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many total volumes are in the Harvard library system?",
        "answers": [
            "18 million volumes",
            "18 million",
            "over 18 million"
        ],
        "model_ans": "18 million",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 18 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the 3 post popular libraries for undergraduates in the Harvard system?",
        "answers": [
            "Cabot Science Library, Lamont Library, and Widener Library",
            "Cabot Science Library, Lamont Library, and Widener Library",
            "Cabot Science Library, Lamont Library, and Widener Library"
        ],
        "model_ans": "Baker, Widener, and Lamont",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Baker, Widener, and Lamont</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are America's oldest collection of maps, gazettes, and atlases housed?",
        "answers": [
            "Pusey Library",
            "Pusey Library",
            "Pusey Library"
        ],
        "model_ans": "Library of Congress",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Library of Congress </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many museums comprise Harvard Art Museums?",
        "answers": [
            "three museums.",
            "three",
            "three"
        ],
        "model_ans": "3\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "3\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Fogg Museum of Art cover?",
        "answers": [
            "Western art from the Middle Ages to the present",
            "Western art from the Middle Ages to the present",
            "Western art from the Middle Ages to the present"
        ],
        "model_ans": "Art",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Art </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What museum specializes in cultural history and civilizations of the Western Hemisphere?",
        "answers": [
            "Peabody Museum of Archaeology and Ethnology",
            "Peabody Museum of Archaeology and Ethnology",
            "Peabody Museum of Archaeology and Ethnology"
        ],
        "model_ans": "American Museum of Natural History",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> American Museum of Natural History </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Starting in what year has Harvard topped the Academic Rankings of World Universities?",
        "answers": [
            "2003",
            "2003",
            "2003"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Beginning in what year was Harvard on top of the World Reputation Rankings?",
        "answers": [
            "2011",
            "2011",
            "2011"
        ],
        "model_ans": "2003",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2003 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to the Princeton Review where has Harvard ranked as a \"Dream College\" in 2013",
        "answers": [
            "second most commonly",
            "second",
            "second"
        ],
        "model_ans": "Harvard University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many intercollegiate sports does Harvard compete in NCAA division I",
        "answers": [
            "42",
            "42",
            "42"
        ],
        "model_ans": "42\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "42\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Harvard's most intense rival?",
        "answers": [
            "Yale University",
            "Yale",
            "Yale University"
        ],
        "model_ans": "Yale",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yale </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "At what time is the Harvard-Yale rivalry set aside?",
        "answers": [
            "every two years when the Harvard and Yale Track and Field teams come together to compete against a combined Oxford University and Cambridge University team",
            "every two years",
            "every two years"
        ],
        "model_ans": "Thanksgiving",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thanksgiving </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the first year that Yale and Harvard played football?",
        "answers": [
            "1875",
            "1875",
            "1875"
        ],
        "model_ans": "1875\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1875\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Harvard Stadium become the first ever concrete reinforced stadium in the country?",
        "answers": [
            "1903",
            "1903",
            "1903"
        ],
        "model_ans": "1905",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1905 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was a set of significant rule changes introduced including the forward pass?",
        "answers": [
            "1906",
            "1906",
            "1906"
        ],
        "model_ans": "1895\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1895\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What school was Walter Camp a captain for the football team?",
        "answers": [
            "former captain of the Yale football team",
            "Yale",
            "Yale"
        ],
        "model_ans": "Yale",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yale </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of Harvard's basketball facility?",
        "answers": [
            "Lavietes Pavilion",
            "Lavietes Pavilion",
            "Lavietes Pavilion"
        ],
        "model_ans": "Lavietes Pavilion",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lavietes Pavilion </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of Harvard's primary recreational sports facility?",
        "answers": [
            "Malkin Athletic Center",
            "Malkin Athletic Center",
            "Malkin Athletic Center"
        ],
        "model_ans": "Malkin Athletic Center",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Malkin Athletic Center </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many weight rooms are in the Malkin Athletic Center",
        "answers": [
            "three weight rooms",
            "three",
            "three"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Harvard - Yale Regatta predates \"The Game\" by how many years?",
        "answers": [
            "23 years",
            "23",
            "23"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what body of water is the Harvard - Yale Regatta held?",
        "answers": [
            "Thames River",
            "Thames River",
            "Thames River"
        ],
        "model_ans": "Connecticut River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Connecticut River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the primary rival of the Harvard Crimson hockey team?",
        "answers": [
            "strong rivalry against Cornell",
            "Cornell",
            "Cornell"
        ],
        "model_ans": "Brown University",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brown University</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Harvard win an Intercolleiate Sailing Association National Championship?",
        "answers": [
            "2003",
            "2003",
            "2003"
        ],
        "model_ans": "2019\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2019\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What UN secretary went to Harvard?",
        "answers": [
            "General Ban Ki-moon",
            "Ban Ki-moon",
            "Ban Ki-moon"
        ],
        "model_ans": "Ban Ki-moon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ban Ki-moon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What Columbia President went to Harvard?",
        "answers": [
            "Juan Manuel Santos",
            "Juan Manuel Santos",
            "Juan Manuel Santos"
        ],
        "model_ans": "Barack Obama",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Barack Obama </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the Costa Rican President that went to Harvard?",
        "answers": [
            "Jos\u00e9 Mar\u00eda Figueres",
            "Jos\u00e9 Mar\u00eda Figueres",
            "Jos\u00e9 Mar\u00eda Figueres"
        ],
        "model_ans": "Luis Guillermo Sol\u00eds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Luis Guillermo Sol\u00eds </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Harvard Alumni was the Palestine Prime Minister?",
        "answers": [
            "Benjamin Netanyahu",
            "Benazir Bhutto"
        ],
        "model_ans": "Mahmoud Abbas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahmoud Abbas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tv host and writer went to Harvard?",
        "answers": [
            "Conan O'Brien",
            "Conan O'Brien",
            "Conan O'Brien"
        ],
        "model_ans": "Conan O'Brien",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Conan O'Brien </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What famous conductor went to Harvard?",
        "answers": [
            "Leonard Bernstein",
            "Leonard Bernstein",
            "Leonard Bernstein"
        ],
        "model_ans": "Bernstein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bernstein</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of world renowned cellist is a former Harvard student?",
        "answers": [
            "Yo Yo Ma",
            "Yo Yo Ma",
            "Yo Yo Ma"
        ],
        "model_ans": "Juanita Kurland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Juanita Kurland</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What famous civil rights leader called Harvard home?",
        "answers": [
            "W. E. B. Du Bois",
            "W. E. B. Du Bois",
            "W. E. B. Du Bois"
        ],
        "model_ans": "W.E.B. Du Bois",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> W.E.B. Du Bois </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Fields Medal winning Mathematician is a faculty member at Harvard?",
        "answers": [
            "Shing-Tung Yau",
            "Shing-Tung Yau",
            "Shing-Tung Yau"
        ],
        "model_ans": "David Donoho",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Donoho </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What prestigious legal scholars are faculty members at Harvard?",
        "answers": [
            "Alan Dershowitz and Lawrence Lessig",
            "Alan Dershowitz and Lawrence Lessig",
            "Alan Dershowitz and Lawrence Lessig"
        ],
        "model_ans": "Alan Dershowitz, Laurence Tribe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alan Dershowitz, Laurence Tribe </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Shakespeare Scholar is a faculty member at Harvard?",
        "answers": [
            "Stephen Greenblatt",
            "Stephen Greenblatt",
            "Stephen Greenblatt"
        ],
        "model_ans": "Stephen Greenblatt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stephen Greenblatt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which Florida city has the biggest population?",
        "answers": [
            "Jacksonville",
            "Jacksonville",
            "Jacksonville"
        ],
        "model_ans": "Jacksonville",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jacksonville </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the population Jacksonville city as of 2010?",
        "answers": [
            "1,345,596",
            "1,345,596",
            "1,345,596"
        ],
        "model_ans": "821,784\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "821,784\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Based on population alone, what is Jacksonville's ranking in the United States?",
        "answers": [
            "12th",
            "12th",
            "12th"
        ],
        "model_ans": "12th\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "12th\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In which county does Jacksonville reside?",
        "answers": [
            "Duval",
            "Duval County",
            "Duval County"
        ],
        "model_ans": "Duval",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Duval </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What year did consolidation cause Jacksonville to become part of Duval County?",
        "answers": [
            "1968",
            "1968",
            "1968"
        ],
        "model_ans": "1901",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1901 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river runs alongside Jacksonville?",
        "answers": [
            "St. Johns",
            "St. Johns River",
            "St. Johns River"
        ],
        "model_ans": "Jacksonville River",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville River</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far is Jacksonville from Miami?",
        "answers": [
            "340 miles",
            "340 miles",
            "340 miles"
        ],
        "model_ans": "345 miles\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "345 miles\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the French colony established in 1564?",
        "answers": [
            "Fort Caroline",
            "Fort Caroline",
            "Fort Caroline"
        ],
        "model_ans": "Quebec",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Prior to the arrival of the French, the area now known as Jacksonville was previously inhabited by what people?",
        "answers": [
            "the Timucua",
            "Timucua",
            "the Timucua people"
        ],
        "model_ans": "Timucua",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Timucua </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What historical figure was Jacksonville named after?",
        "answers": [
            "Andrew Jackson",
            "Andrew Jackson",
            "Andrew Jackson"
        ],
        "model_ans": "Andrew Jackson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Jackson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the ranking of the military forces in Jacksonville?",
        "answers": [
            "third largest",
            "third largest military presence",
            "third largest"
        ],
        "model_ans": "Jacksonville",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jacksonville </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What sport attracts most tourists to Jacksonville?",
        "answers": [
            "golf",
            "golf",
            "golf"
        ],
        "model_ans": "Jacksonville Jaguars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville Jaguars</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many naval bases are located in Jacksonville?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are those from Jacksonville sometimes called?",
        "answers": [
            "\"Jacksonvillians\" or \"Jaxsons\"",
            "\"Jacksonvillians\"",
            "\"Jacksonvillians\" or \"Jaxsons\""
        ],
        "model_ans": "Jags",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jags</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The area where Jacksonville currently sits has been inhabited for how many years?",
        "answers": [
            "thousands",
            "thousands of years",
            "thousands of years"
        ],
        "model_ans": "12,000 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12,000 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who discovered pottery found on Black Hammock Island?",
        "answers": [
            "a University of North Florida team",
            "University of North Florida",
            "University of North Florida"
        ],
        "model_ans": "University of Florida",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University of Florida </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What civilization did the pottery belong to?",
        "answers": [
            "Timucua",
            "Timucua people",
            "Mocama"
        ],
        "model_ans": "Greek",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greek </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the 16th century known as the start of?",
        "answers": [
            "the historical era",
            "historical era",
            "beginning of the historical era"
        ],
        "model_ans": "The Renaissance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Renaissance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the village that once existed in what is now downtown Jacksonville?",
        "answers": [
            "Ossachite",
            "Ossachite",
            "Ossachite"
        ],
        "model_ans": "LaVilla",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> LaVilla </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who mapped the St. Johns River in 1562?",
        "answers": [
            "Jean Ribault",
            "Jean Ribault",
            "Jean Ribault"
        ],
        "model_ans": "Spanish explorers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish explorers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "For what nation did Ribault initially claim what is now Jacksonville?",
        "answers": [
            "France",
            "France",
            "France"
        ],
        "model_ans": "France\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " France\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who led the attack of the French colony in 1565?",
        "answers": [
            "Pedro Men\u00e9ndez de Avil\u00e9s",
            "Pedro Men\u00e9ndez de Avil\u00e9s",
            "Pedro Men\u00e9ndez de Avil\u00e9s"
        ],
        "model_ans": "Jean Ribault",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean Ribault </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Fort Caroline renamed to after the Spanish attack?",
        "answers": [
            "San Mateo",
            "fort San Mateo",
            "San Mateo"
        ],
        "model_ans": "Fort Caroline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fort Caroline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which fort was rebuilt in 1964?",
        "answers": [
            "Fort Caroline",
            "Fort Caroline",
            "Fort Caroline"
        ],
        "model_ans": "Fort Knox",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fort Knox </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After what event did the Spanish concede Florida to Britain?",
        "answers": [
            "French and Indian War",
            "French and Indian War",
            "French and Indian War"
        ],
        "model_ans": "Treaty of Paris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Paris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Soon after gaining Florida, what did the English do?",
        "answers": [
            "constructed the King's Road",
            "constructed the King's Road",
            "constructed the King's Road"
        ],
        "model_ans": "Established colonies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Established colonies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why the narrow part of St. John's River called Cowford?",
        "answers": [
            "cattle were brought across the river there.",
            "cattle were brought across",
            "cattle were brought across the river there"
        ],
        "model_ans": "Jacksonville",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who gained control of Florida after the conclusion of the Revolutionary War?",
        "answers": [
            "Spain",
            "Spain",
            "Spain"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the Jacksonville town charter approved?",
        "answers": [
            "February 9, 1832",
            "1832.",
            "February 9, 1832"
        ],
        "model_ans": "1832",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1832 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Supplies from Jacksonville were in support of which faction in the Civil War?",
        "answers": [
            "Confederate",
            "Confederate",
            "the Confederate cause"
        ],
        "model_ans": "Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the battle that marked the first Confederate win in Florida?",
        "answers": [
            "The Skirmish of the Brick Church",
            "Skirmish of the Brick Church",
            "Skirmish of the Brick Church"
        ],
        "model_ans": "Battle of Olustee",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Battle of Olustee </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After what battle did Union forces return to and occupy Jacksonville for the rest of the war?",
        "answers": [
            "Battle of Olustee",
            "Battle of Olustee",
            "Battle of Olustee"
        ],
        "model_ans": "Battle of Olustee",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Battle of Olustee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What factors negatively impacted Jacksonville following the war?",
        "answers": [
            "Warfare and the long occupation",
            "Warfare and the long occupation",
            "Warfare and the long occupation"
        ],
        "model_ans": "The war led to a decline in the city's economy, and the city struggled to recover",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The war led to a decline in the city's economy, and the city struggled to recover </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the battle that resulted from a Confederate cavalry unit attacking a Union expedition?",
        "answers": [
            "Battle of Cedar Creek",
            "Battle of Cedar Creek",
            "1864"
        ],
        "model_ans": "1863\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1863\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During which period did Jacksonville become a popular destination for the rich?",
        "answers": [
            "Gilded Age",
            "Reconstruction",
            "Reconstruction and the Gilded Age"
        ],
        "model_ans": "1920s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which US President visited Jacksonville in 1888?",
        "answers": [
            "Grover Cleveland",
            "Grover Cleveland",
            "President Grover Cleveland"
        ],
        "model_ans": "Grover Cleveland",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Grover Cleveland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What caused Jacksonville's tourism to become less desirable at the latter half of the 19th century?",
        "answers": [
            "yellow fever outbreaks",
            "yellow fever outbreaks",
            "yellow fever outbreaks"
        ],
        "model_ans": "Yellow fever",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yellow fever </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What drew would-be Jacksonville tourists to other Florida destinations?",
        "answers": [
            "extension of the Florida East Coast Railway further south",
            "Florida East Coast Railway",
            "the Florida East Coast Railway"
        ],
        "model_ans": "Hurricane Irma",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hurricane Irma </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Other than the steamboat, what modern form of travel brought visitors to Florida?",
        "answers": [
            "railroad",
            "railroad",
            "railroad"
        ],
        "model_ans": "Airplane",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Airplane </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What caused the spread of the Jacksonville fire in 1901?",
        "answers": [
            "Spanish moss",
            "kitchen fire",
            "Spanish moss"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many buildings were razed by the Jacksonville fire?",
        "answers": [
            "over 2,000",
            "2,000 buildings",
            "over 2,"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the wake of the Jacksonville fire, what did the Florida Governor do?",
        "answers": [
            "declare martial law",
            "declare martial law",
            "declare martial law and sent the state militia to maintain order"
        ],
        "model_ans": "Ron DeSantis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ron DeSantis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the Jacksonville fire later known as?",
        "answers": [
            "Great Fire of 1901",
            "Great Fire of 1901",
            "Great Fire of 1901"
        ],
        "model_ans": "Jacksonville Fire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville Fire</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was drawn to Jacksonville in the 1910s?",
        "answers": [
            "New York\u2013based filmmakers",
            "filmmakers",
            "New York\u2013based filmmakers"
        ],
        "model_ans": "Jacksonville Jaguars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville Jaguars</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of movies were produced in Jacksonville's 30 studios?",
        "answers": [
            "silent film",
            "silent film",
            "silent"
        ],
        "model_ans": "Film",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Film </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Jacksonville's popularity for films earned it what title?",
        "answers": [
            "Winter Film Capital of the World",
            "Winter Film Capital of the World",
            "Winter Film Capital of the World"
        ],
        "model_ans": "Film City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Film City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What brought the downfall of Jacksonville filmmaking?",
        "answers": [
            "Hollywood",
            "Hollywood",
            "the emergence of Hollywood"
        ],
        "model_ans": "The decline of the film industry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The decline of the film industry </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What drove residents to quieter suburban housing?",
        "answers": [
            "highways",
            "construction of highways",
            "The construction of highways"
        ],
        "model_ans": "Urbanization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Urbanization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the white population of Jacksonville as of 2010?",
        "answers": [
            "55.1%",
            "55.1%",
            "55.1%"
        ],
        "model_ans": "59.6%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 59.6% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What term referred to middle class citizens leaving the suburbs?",
        "answers": [
            "\"white flight\"",
            "white flight",
            "white flight"
        ],
        "model_ans": "Yuppie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuppie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was responsible for the new building projects in Jacksonville?",
        "answers": [
            "Mayor W. Haydon Burns",
            "Mayor W. Haydon Burns'",
            "Mayor W. Haydon Burns"
        ],
        "model_ans": "Jacksonville City Council",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville City Council</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Jacksonville began to suffer and decline after what major world event?",
        "answers": [
            "World War II",
            "World War II",
            "World War II"
        ],
        "model_ans": "World War II",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> World War II </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the cause for the issues with city funding?",
        "answers": [
            "Much of the city's tax base dissipated",
            "tax base dissipated"
        ],
        "model_ans": "Budget cuts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Budget cuts </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what part of the city did residents suffer from a lack of city services?",
        "answers": [
            "unincorporated suburbs",
            "suburbs",
            "unincorporated suburbs"
        ],
        "model_ans": "Brooklyn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brooklyn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the proposed solution to Jacksonville's tax issues?",
        "answers": [
            "annexing outlying communities",
            "annexing outlying communities",
            "annexing outlying communities"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who voted against Jacksonville's annexation?",
        "answers": [
            "Voters outside the city limits",
            "Voters outside the city limits",
            "Voters outside the city limits"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How were most city officials elected in the 1960s?",
        "answers": [
            "old boy network",
            "old boy network",
            "the traditional old boy network"
        ],
        "model_ans": "By popular vote",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> By popular vote </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many city officials were indicted due to corruption?",
        "answers": [
            "11",
            "11",
            "11"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What political group began to gain support following the corruption scandal?",
        "answers": [
            "Jacksonville Consolidation",
            "Jacksonville Consolidation",
            "Jacksonville Consolidation"
        ],
        "model_ans": "Democratic Party",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Democratic Party </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What spurred increased support for government reform?",
        "answers": [
            "public high schools lost their accreditation",
            "high schools lost their accreditation",
            "public high schools lost their accreditation"
        ],
        "model_ans": "Watergate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Watergate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the result of the 1967 referendum?",
        "answers": [
            "voters approved the plan",
            "governments merged to create the Consolidated City of Jacksonville"
        ],
        "model_ans": "Yes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Jacksonville's mayor at the time of the consolidation?",
        "answers": [
            "Hans Tanzler",
            "Hans Tanzler",
            "Hans Tanzler"
        ],
        "model_ans": "Jake Godbold",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jake Godbold </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Jacksonville referred to as after the consolidation?",
        "answers": [
            "\"Bold New City of the South\"",
            "Bold New City of the South",
            "Consolidated City of Jacksonville"
        ],
        "model_ans": "Chicago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the approved measure that helped cover the cost of major city projects?",
        "answers": [
            "Better Jacksonville Plan",
            "The Better Jacksonville Plan",
            "The Better Jacksonville Plan"
        ],
        "model_ans": "Public-Private Partnership",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public-Private Partnership </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the Better Jacksonville Plan generate money?",
        "answers": [
            "authorized a half-penny sales tax",
            "half-penny sales tax",
            "a half-penny sales tax"
        ],
        "model_ans": "Through a combination of taxes, bonds, and private donations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through a combination of taxes, bonds, and private donations </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the land area of Jacksonville?",
        "answers": [
            "874.3 square miles",
            "874.3 square miles",
            "874.3 square miles"
        ],
        "model_ans": "747.0 square miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 747.0 square miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river separates Jacksonville?",
        "answers": [
            "The St. Johns River",
            "St. Johns River",
            "St. Johns River"
        ],
        "model_ans": "St. Johns River",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> St. Johns River </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the river that is completely contained inside Jacksonville?",
        "answers": [
            "The Trout River",
            "Trout River",
            "The Trout River"
        ],
        "model_ans": "St. Johns River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> St. Johns River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of Jacksonville is made up of water?",
        "answers": [
            "13.34%",
            "13.34%",
            "13.34%"
        ],
        "model_ans": "13%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What town is surrounded by Jacksonville?",
        "answers": [
            "Baldwin",
            "Baldwin",
            "Baldwin"
        ],
        "model_ans": "Jacksonville",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jacksonville</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What distinction does the Bank of America Tower hold?",
        "answers": [
            "tallest building in Downtown Jacksonville",
            "tallest precast, post-tensioned concrete structure",
            "tallest building in Downtown Jacksonville"
        ],
        "model_ans": "tallest building in New York City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> tallest building in New York City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Bank of America Tower was previously known as what?",
        "answers": [
            "Barnett Center",
            "Barnett Center",
            "Barnett Center"
        ],
        "model_ans": "One Bryant Park",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> One Bryant Park </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How tall is the Bank of America Tower?",
        "answers": [
            "617 ft",
            "617 ft",
            "617 ft ("
        ],
        "model_ans": "1,200 feet (365 meters)\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,200 feet (365 meters)\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many floors are there in the building that was completed in 1967?",
        "answers": [
            "28",
            "42",
            "42"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What makes the Wells Fargo Center stand out?",
        "answers": [
            "its distinctive flared base",
            "distinctive flared base",
            "distinctive flared base"
        ],
        "model_ans": "It is the home of the Philadelphia 76ers and the Philadelphia Flyers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It is the home of the Philadelphia 76ers and the Philadelphia Flyers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of climate does Jacksonville have?",
        "answers": [
            "subtropical",
            "humid subtropical",
            "humid subtropical climate"
        ],
        "model_ans": "subtropical",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> subtropical </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When does rain typically fall in Jacksonville?",
        "answers": [
            "May through September",
            "May through September",
            "the warmest months from May through September"
        ],
        "model_ans": "Spring and summer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spring and summer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is winter weather in Jacksonville described as?",
        "answers": [
            "mild",
            "mild and sunny.",
            "mild and sunny"
        ],
        "model_ans": "mild",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> mild </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Aside from being located on the coast, what contributes to Jacksonville's lack of cold weather?",
        "answers": [
            "low latitude",
            "low latitude",
            "low latitude"
        ],
        "model_ans": "The city's proximity to the equator",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The city's proximity to the equator </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Jacksonville's hottest recorded temperature?",
        "answers": [
            "104 \u00b0F",
            "104 \u00b0F",
            "104 \u00b0F"
        ],
        "model_ans": "109\u00b0F (42.8\u00b0C)\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "109\u00b0F (42.8\u00b0C)\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a common occurrence during summer days?",
        "answers": [
            "thunderstorms",
            "thunderstorms",
            "thunderstorms"
        ],
        "model_ans": "Heatwaves",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heatwaves </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What else contributes to Jacksonville's summer storms other than land heating beside the water?",
        "answers": [
            "high humidity",
            "high humidity",
            "extremely high humidity"
        ],
        "model_ans": "wind",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> wind </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Jacksonville's hottest month on average?",
        "answers": [
            "July",
            "July",
            "July"
        ],
        "model_ans": "July",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> July </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What storm had the most significant impact on Jacksonville?",
        "answers": [
            "Hurricane Dora",
            "Hurricane Dora",
            "Hurricane Dora"
        ],
        "model_ans": "Hurricane Dora",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hurricane Dora </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How fast were the winds around St. Augustine in the 1964 hurricane?",
        "answers": [
            "110 mph",
            "110 mph",
            "110 mph"
        ],
        "model_ans": "100 mph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 mph </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the storm that hit Jacksonville in May of 2012?",
        "answers": [
            "Tropical Storm Beryl",
            "Beryl",
            "Tropical Storm Beryl"
        ],
        "model_ans": "Tropical Storm Beryl",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tropical Storm Beryl </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the scale used to measure the strength of hurricanes called?",
        "answers": [
            "Saffir-Simpson Scale",
            "Saffir-Simpson",
            "Saffir-Simpson Scale"
        ],
        "model_ans": "Saffir-Simpson Hurricane Wind Scale",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saffir-Simpson Hurricane Wind Scale </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what year did a tropical storm cause a four day loss of power to Jacksonville?",
        "answers": [
            "2008",
            "Fay",
            "2008"
        ],
        "model_ans": "2008",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2008 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What ethnic group located in Jacksonville is ranked tenth largest?",
        "answers": [
            "Arab",
            "Arab",
            "Arab"
        ],
        "model_ans": "African American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> African American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many residents were recorded in the 2010 census of Jacksonville?",
        "answers": [
            "821,784",
            "821,784",
            "821,784"
        ],
        "model_ans": "821,784\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "821,784\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Compared to the rest of Florida, how does Jacksonville's Filipino population rank?",
        "answers": [
            "largest",
            "largest Filipino American community",
            "largest"
        ],
        "model_ans": "2nd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2nd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Jacksonville community is known for having heavy ties to the Navy?",
        "answers": [
            "Filipino",
            "Filipino community",
            "Filipino"
        ],
        "model_ans": "Riverside",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Riverside </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What portion of households in Jacksonville have only one person?",
        "answers": [
            "29.7%",
            "29.7%",
            "29.7%"
        ],
        "model_ans": "34.4%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 34.4% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many of Jacksonville's city residents are younger than 18?",
        "answers": [
            "23.9%",
            "23.9%",
            "23.9%"
        ],
        "model_ans": "44.6%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 44.6% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which gender is more populous across all groups in Jacksonville?",
        "answers": [
            "females",
            "females",
            "females"
        ],
        "model_ans": "Male",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Male </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many men older than 18 are there for every 100 women?",
        "answers": [
            "91.3",
            "91.3",
            "91.3"
        ],
        "model_ans": "85\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "85\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of global assets does the richest 1% of people have?",
        "answers": [
            "40%",
            "40%",
            "40%",
            "40"
        ],
        "model_ans": "39%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 39% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to Oxfam, the 85 richest people have wealth equal to how many average people?",
        "answers": [
            "about 3.5 billion people",
            "3.5 billion",
            "50%",
            "3.5 billion"
        ],
        "model_ans": "3.5 billion",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 3.5 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In order to be considered in the top percentile, a person would need to amass how much money each year?",
        "answers": [
            "$759,900",
            "$759,900",
            "$759,900"
        ],
        "model_ans": "$1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has caused Oxfam's findings to be questioned?",
        "answers": [
            "the methodology used",
            "basis of the methodology used",
            "\"silly argument\" and \"a non-issue . . . a diversion.\"",
            "basis of the methodology"
        ],
        "model_ans": "Misconduct",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Misconduct </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why does Oxfam and Credit Suisse believe their findings are being doubted?",
        "answers": [
            "a diversion",
            "the basis of the methodology used",
            "there are more poor people in the United States and Western Europe than in China"
        ],
        "model_ans": "Oxfam and Credit Suisse are being doubted because their findings are based on incomplete data and lack transparency",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oxfam and Credit Suisse are being doubted because their findings are based on incomplete data and lack transparency </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percent of the global assets in 2000 were owned by just 1% of adults?",
        "answers": [
            "40%",
            "40%",
            "40%",
            "40"
        ],
        "model_ans": "40%",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 40% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do the three richest people in the world posses more of than the lowest 48 nations together?",
        "answers": [
            "financial assets",
            "financial assets",
            "possess more financial assets than the lowest 48 nations combined.",
            "financial assets"
        ],
        "model_ans": "wealth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wealth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much was the combined wealth of the \"10 Million dollar millionaires\" in 2008?",
        "answers": [
            "nearly $41 trillion",
            "$41 trillion",
            "the \"10 million dollar millionaires\" grew to nearly $41 trillion in 2008",
            "$41 trillion"
        ],
        "model_ans": "$10 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $10 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of the global wealth will the wealthiest 1 percent own by 2016?",
        "answers": [
            "half",
            "more than half",
            "own more than half of the global wealth by 2016",
            "more than half"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are there more poor people in the United States and Europe than China?",
        "answers": [
            "greater tendency to take on debts",
            "greater tendency to take on debts",
            "greater tendency to take on debts"
        ],
        "model_ans": "The United States and Europe have a more developed economy and a higher standard of living, which means that there are more opportunities for people to become wealthy, but also more people who are struggling</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The United States and Europe have a more developed economy and a higher standard of living, which means that there are more opportunities for people to become wealthy, but also more people who are struggling</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many Americans are richer than more than half of all citizens?",
        "answers": [
            "400",
            "400",
            "400"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What publication printed that the wealthiest 1% have more money than those in the bottom 90%?",
        "answers": [
            "New York Times",
            "New York Times",
            "New York Times"
        ],
        "model_ans": "Forbes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Forbes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is considered as a potential advantage for wealth for some Americans?",
        "answers": [
            "Inherited wealth",
            "Inherited wealth",
            "Inherited wealth"
        ],
        "model_ans": "Social Security",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Social Security </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the richest 400 Americans have as children that helped them be successful adults?",
        "answers": [
            "grew up in substantial privilege",
            "substantial privilege",
            "substantial privilege"
        ],
        "model_ans": "Privileged upbringing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Privileged upbringing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the top 400 richest Americans have more of than half of all Americans combined?",
        "answers": [
            "wealth",
            "wealth",
            "wealth"
        ],
        "model_ans": "wealth",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wealth </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who owns more wealth than the bottom 90 percent of people in the U.S.?",
        "answers": [
            "richest 1 percent",
            "richest 1 percent",
            "richest 1 percent"
        ],
        "model_ans": "The top 10 percent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The top 10 percent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What may explain why some Americans who've become rich may have had a head start?",
        "answers": [
            "Inherited wealth",
            "Inherited wealth",
            "Inherited wealth"
        ],
        "model_ans": "Family wealth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Family wealth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many of the richest 400 Americans grew up in substantial privilege?",
        "answers": [
            "over 60 percent",
            "over 60 percent",
            "over 60 percent"
        ],
        "model_ans": "90%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 90% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Institute published findings in September 2012 regarding the Forbes richest 400 Americans?",
        "answers": [
            "Institute for Policy Studies",
            "Institute for Policy Studies",
            "PolitiFact"
        ],
        "model_ans": "Forbes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Forbes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What philosophy of thought  addresses wealth inequality?",
        "answers": [
            "Neoclassical economics",
            "Neoclassical economics",
            "Neoclassical economics"
        ],
        "model_ans": "Marxism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marxism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is income inequality attributed to?",
        "answers": [
            "differences in value added by labor, capital and land",
            "differences in value added by labor, capital and land",
            "differences in value added by different classifications of workers"
        ],
        "model_ans": "Economic factors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic factors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What impacts distribution of wealth when evaluating labor?",
        "answers": [
            "different classifications of workers",
            "differences in value added by different classifications of workers",
            "differences in value added by different classifications of workers"
        ],
        "model_ans": "Market forces",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Market forces </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term that describes the difference between what higher paid and lower paid professionals earn?",
        "answers": [
            "productivity gap",
            "productivity gap",
            "productivity gap"
        ],
        "model_ans": "wage gap",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wage gap </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is income determined in a market with variously skilled workers?",
        "answers": [
            "marginal value added of each economic actor",
            "differences in value",
            "marginal value added of each economic actor"
        ],
        "model_ans": "Supply and demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Neoclassical economics view the inequality in the distribution of income as being from?",
        "answers": [
            "differences in value added by labor, capital and land",
            "differences in value added by labor, capital and land",
            "differences in value added by labor, capital and land"
        ],
        "model_ans": "Natural differences in talent and effort",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Natural differences in talent and effort </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is distribution of income from labor due to the differences of?",
        "answers": [
            "value added by different classifications of workers",
            "value added by labor, capital and land",
            "value added"
        ],
        "model_ans": "skills",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> skills </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the marginal value added by an economic actor determine?",
        "answers": [
            "wages and profits",
            "wages and profits",
            "wages and profits"
        ],
        "model_ans": "Profit",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Profit </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are examples of economic actors?",
        "answers": [
            "worker, capitalist/business owner, landlord",
            "worker, capitalist/business owner, landlord",
            "worker, capitalist/business owner, landlord"
        ],
        "model_ans": "Individuals, businesses, governments, and organizations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Individuals, businesses, governments, and organizations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In a market economy, what is inequality a reflection of?",
        "answers": [
            "productivity gap between highly-paid professions and lower-paid professions",
            "productivity gap",
            "productivity gap"
        ],
        "model_ans": "differences in productivity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> differences in productivity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What pushes businesses to increase pressures on workers?",
        "answers": [
            "reduce costs and maximize profits",
            "substitution of capital equipment for labor",
            "pressure to reduce costs and maximize profits"
        ],
        "model_ans": "Capitalism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Capitalism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What impact does workers working harder have on productivity of a business?",
        "answers": [
            "less workers are required",
            "raises the productivity of each worker,"
        ],
        "model_ans": "Increased productivity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Increased productivity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When less workers are required, what happens to the job market?",
        "answers": [
            "increasing unemployment",
            "increasing unemployment",
            "increasing unemployment"
        ],
        "model_ans": "Unemployment increases",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Unemployment increases </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What impact does higher worker productivity and leveled pay have on higher earners?",
        "answers": [
            "rising levels of property income",
            "rising levels of property income",
            "downward pressure on wages"
        ],
        "model_ans": "Increased disposable income",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Increased disposable income </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do capitalist firms substitute equipment for in a Marxian analysis?",
        "answers": [
            "labor inputs",
            "labor inputs (workers)",
            "labor inputs"
        ],
        "model_ans": "Labor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why do firms substitute equipment for workers?",
        "answers": [
            "reduce costs and maximize profits",
            "to reduce costs and maximize profits",
            "raises the productivity of each worker"
        ],
        "model_ans": "To reduce labor costs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To reduce labor costs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What trend increases the organic composition of capital over the long term?",
        "answers": [
            "substitute capital equipment",
            "increasingly substitute capital equipment for labor inputs",
            "pressure to reduce costs and maximize profits"
        ],
        "model_ans": "Capitalist development",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Capitalist development </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the substitution of equipment for labor raise for workers?",
        "answers": [
            "productivity",
            "organic composition of capital",
            "productivity"
        ],
        "model_ans": "unemployment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unemployment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of wages does mechanization and automation lead to?",
        "answers": [
            "stagnant",
            "stagnant wages",
            "stagnant"
        ],
        "model_ans": "Job displacement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Job displacement </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is controled by the market and economy?",
        "answers": [
            "workers wages",
            "workers wages",
            "wages"
        ],
        "model_ans": "Supply and Demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and Demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Under what law is value of a worker determined?",
        "answers": [
            "supply and demand",
            "law of supply and demand",
            "supply and demand"
        ],
        "model_ans": "Labour Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labour Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What happens when business underpays their workers?",
        "answers": [
            "business is chronically understaffed",
            "their business is chronically understaffed",
            "chronically understaffed"
        ],
        "model_ans": "They may face legal action, fines, and reputational damage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They may face legal action, fines, and reputational damage </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do competing businesses attract workers?",
        "answers": [
            "offering a higher wage",
            "by offering a higher wage",
            "offering a higher wage the best of their labor"
        ],
        "model_ans": "through competitive salaries, benefits, and work-life balance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> through competitive salaries, benefits, and work-life balance </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is income inequality generally viewed by workers?",
        "answers": [
            "unfair",
            "unfair",
            "unfair"
        ],
        "model_ans": "negatively",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> negatively </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What controls wages in a purely capitalist mode of production?",
        "answers": [
            "the market",
            "market",
            "market"
        ],
        "model_ans": "Market forces",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Market forces </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do wages work in the same way as for any other good?",
        "answers": [
            "prices",
            "function of market price of skill",
            "prices"
        ],
        "model_ans": "money",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> money </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can be considered as a function of market price of skill?",
        "answers": [
            "wages",
            "wages",
            "wages"
        ],
        "model_ans": "Supply and Demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and Demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can concentrate wealth, pass environmental costs on to society and abuse both workers and consumers?",
        "answers": [
            "markets",
            "markets",
            "markets"
        ],
        "model_ans": "Corporations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Corporations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of outcomes can even stable markets lead to?",
        "answers": [
            "unfair",
            "high levels of inequality",
            "high levels of inequality"
        ],
        "model_ans": "Unpredictable outcomes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unpredictable outcomes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the tendency to increase wages in a field or job position?",
        "answers": [
            "Competition amongst workers",
            "high demand",
            "competition between employers for employees"
        ],
        "model_ans": "Supply and demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When there are many workers competing for a few jobs its considered as what?",
        "answers": [
            "low demand",
            "high supply",
            "low wage"
        ],
        "model_ans": "Job competition",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Job competition </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the potential earnings for a job where there are few skilled workers but many available positions?",
        "answers": [
            "high wages",
            "high wages",
            "high wages"
        ],
        "model_ans": "High",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> High </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can lead to higher wages for members of labor organizations?",
        "answers": [
            "collective bargaining, political influence, or corruption",
            "collective bargaining, political influence, or corruption",
            "collective bargaining, political influence, or corruption"
        ],
        "model_ans": "Collective bargaining",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Collective bargaining </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who works to get workers higher compensation?",
        "answers": [
            "Professional and labor organizations",
            "Professional and labor organizations",
            "Professional and labor organizations"
        ],
        "model_ans": "Labor unions",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labor unions </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does many workers willing to work for a lot of time competing for a job that only requires a few workers result in?",
        "answers": [
            "low wage",
            "competition",
            "low wage"
        ],
        "model_ans": "Unemployment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Unemployment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What drives down wages in a job with many workers willing to work a lot?",
        "answers": [
            "competition between workers",
            "competition",
            "competition"
        ],
        "model_ans": "Supply and demand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supply and demand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why does competition among workers drive down wages?",
        "answers": [
            "expendable nature of the worker",
            "(high supply) competing for a job that few require (low demand)",
            "the expendable nature of the worker in relation to his or her particular job"
        ],
        "model_ans": "Because it increases the supply of labor, making it easier for employers to find workers willing to work for lower wages",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because it increases the supply of labor, making it easier for employers to find workers willing to work for lower wages </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of wages result from jobs where there is low supply but high demand?",
        "answers": [
            "high",
            "high wages",
            "high"
        ],
        "model_ans": "premium wages",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> premium wages </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "While competition between workers drives down wages for jobs with a high supply of worker, whose competition drives wages up for the inverse?",
        "answers": [
            "employers",
            "employers",
            "employers"
        ],
        "model_ans": "Monopsony",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Monopsony </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What increases with the increase of income inequality?",
        "answers": [
            "entrepreneurship rates",
            "entrepreneurship rates",
            "entrepreneurship rates"
        ],
        "model_ans": "poverty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Survivial is at the heart of what concept for workers?",
        "answers": [
            "Necessity-based entrepreneurship",
            "Necessity-based entrepreneurship",
            "Necessity-based entrepreneurship"
        ],
        "model_ans": "Employee Engagement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Employee Engagement </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of motivators are food and shelter considered?",
        "answers": [
            "push",
            "\"push\" motivations",
            "\"push\""
        ],
        "model_ans": "basic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> basic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of motivators are achievement and self determination considered?",
        "answers": [
            "pull",
            "\"pull\"",
            "\"pull\""
        ],
        "model_ans": "Intrinsic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Intrinsic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of entrepreneurship leads to advancements in technology?",
        "answers": [
            "opportunity-based entrepreneurship",
            "opportunity-based entrepreneurship",
            "opportunity-based"
        ],
        "model_ans": "Technological entrepreneurship",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Technological entrepreneurship </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What increases entrepreneurship rates at the individual level?",
        "answers": [
            "higher economic inequality",
            "higher economic inequality",
            "higher economic inequality"
        ],
        "model_ans": "Education",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Education </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the increased rates of self-employment based on?",
        "answers": [
            "necessity",
            "necessity rather than opportunity"
        ],
        "model_ans": "economic factors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> economic factors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Survival needs such as income for food and shelter motivates what type of entrepreneurship? ",
        "answers": [
            "Necessity-based",
            "Necessity-based entrepreneurship",
            "Necessity-based"
        ],
        "model_ans": "necessity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> necessity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What motivation is opportunity-based entrepreneurship driven by?",
        "answers": [
            "achievement-oriented",
            "achievement-oriented motivations (\"pull\")",
            "achievement-oriented motivations"
        ],
        "model_ans": "The desire to capitalize on a new business opportunity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The desire to capitalize on a new business opportunity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of impact does opportunity-based entrepreneurship tend to have on economic growth?",
        "answers": [
            "positive",
            "positive",
            "more positive"
        ],
        "model_ans": "positive",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> positive </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is it called when the tax rate and base amount increase simultaneously?",
        "answers": [
            "progressive tax",
            "progressive tax",
            "progressive"
        ],
        "model_ans": "Tax hike",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tax hike </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tax rate has a direct relationship with income inequality?",
        "answers": [
            "top tax rate",
            "progressive tax",
            "top"
        ],
        "model_ans": "Progressive",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Progressive </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can work to even the distribution of wealth?",
        "answers": [
            "social spending",
            "social spending",
            "steeper tax progressivity applied to social spending"
        ],
        "model_ans": "Progressive taxation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Progressive taxation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What system has an impact on income inequality?",
        "answers": [
            "tax system",
            "progressive tax system",
            "progressive tax"
        ],
        "model_ans": "Economic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In a progressive tax, what increases as the taxable base amount increases?",
        "answers": [
            "the tax rate",
            "tax rate",
            "tax rate"
        ],
        "model_ans": "Tax rate",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tax rate </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What will have a direct impact of inequality in a system that uses a progressive tax?",
        "answers": [
            "level of the top tax rate",
            "level of the top tax rate",
            "top tax rate"
        ],
        "model_ans": "The tax rate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The tax rate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can result in more equal distribution of income?",
        "answers": [
            "steeper tax",
            "social spending",
            "steeper tax progressivity"
        ],
        "model_ans": "Progressive taxation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Progressive taxation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What index is an indicator of the effects of taxes applied to social spending?",
        "answers": [
            "the Gini index",
            "Gini",
            "Gini"
        ],
        "model_ans": "Gini coefficient",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Gini coefficient </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is key to getting the skills needed for high demand jobs?",
        "answers": [
            "access to education",
            "Education",
            "education"
        ],
        "model_ans": "Education",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Education </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do people with lower income have less access to?",
        "answers": [
            "optional education",
            "education",
            "education"
        ],
        "model_ans": "healthcare",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> healthcare </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does less education lead to when working?",
        "answers": [
            "lower wages",
            "lower wages",
            "lower wages"
        ],
        "model_ans": "Lower salary",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lower salary </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who has limited productive potential when faced with less access to education?",
        "answers": [
            "poor",
            "poor",
            "poor"
        ],
        "model_ans": "Women",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Women </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are those with lower incomes less likely to have in order to prepare for the future?",
        "answers": [
            "savings and investment",
            "education,",
            "education"
        ],
        "model_ans": "retirement savings",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> retirement savings </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is an important factor contributing to inequality for individuals?",
        "answers": [
            "access to education",
            "access to education",
            "access to education"
        ],
        "model_ans": "Socioeconomic status",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Socioeconomic status </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does education in an area where there is high demand for workers tend to create?",
        "answers": [
            "high wages",
            "high wages",
            "high wages"
        ],
        "model_ans": "a surplus of workers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a surplus of workers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of wages do people unable to afford an education receive?",
        "answers": [
            "lower",
            "lower wages",
            "lower wages"
        ],
        "model_ans": "Minimum wage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Minimum wage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does lack of education lead directly to?",
        "answers": [
            "lower incomes",
            "lower incomes",
            "lower incomes"
        ],
        "model_ans": "poverty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What helps to unleash the productivity ability of the poor?",
        "answers": [
            "education",
            "education",
            "education"
        ],
        "model_ans": "Education",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Education </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Standard & Poor recommend to speed economy recovery?",
        "answers": [
            "increasing access to education",
            "increasing access to education",
            "increasing access to education"
        ],
        "model_ans": "fiscal stimulus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fiscal stimulus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much potential economic growth could the United States amass if everyone went through more schooling?",
        "answers": [
            "$105 billion",
            "$105 billion",
            "$105 billion"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the United States at risk for because of the recession of 2008?",
        "answers": [
            "boom-and-bust cycles",
            "boom-and-bust cycles",
            "boom-and-bust cycles"
        ],
        "model_ans": "debt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> debt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who concluded that the rising income inequality gap was not getting better?",
        "answers": [
            "Standard & Poor",
            "Standard & Poor",
            "economists with the Standard & Poor's rating agency"
        ],
        "model_ans": "Thomas Piketty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Piketty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did economists reach a conclusion with the S&P's rating agency?",
        "answers": [
            "2014",
            "2014",
            "2014"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When the recovery between the widening gap between the richest citizens and rest of the nation slow?",
        "answers": [
            "2008-2009",
            "2008-2009"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did S&P recommend to somewhat remedy the wealth gap?",
        "answers": [
            "increasing access to education",
            "increasing access to education",
            "increasing access to education"
        ],
        "model_ans": "Increase the minimum wage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Increase the minimum wage </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If the average U.S. worker were to complete an additional year of school, what amount of growth would be generated over 5 years?",
        "answers": [
            "$105 billion",
            "$105 billion",
            "$105 billion"
        ],
        "model_ans": "1.5%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does wealth disparity make the economy more prone to?",
        "answers": [
            "boom-and-bust cycles",
            "boom-and-bust cycles",
            "boom-and-bust cycles"
        ],
        "model_ans": "Instability",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Instability </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the high school education movement occur?",
        "answers": [
            "1910\u20131940",
            "1910\u20131940",
            "1910\u20131940"
        ],
        "model_ans": "19th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 19th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What impact did the high school education movement have on the presence of skilled workers?",
        "answers": [
            "increase",
            "an increase",
            "increase"
        ],
        "model_ans": "Increased",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Increased </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What impact did the high school education movement have on the wages of skilled workers?",
        "answers": [
            "decrease",
            "decrease in the price of skilled labor",
            "decrease"
        ],
        "model_ans": "Increased wages",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Increased wages </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What impacts gender inequality in wages?",
        "answers": [
            "gender inequality in education",
            "gender inequality in education",
            "education"
        ],
        "model_ans": "societal norms",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> societal norms </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What contributed to the decreased inequality between trained and untrained workers?",
        "answers": [
            "period of compression",
            "decrease in wages",
            "decrease in wages"
        ],
        "model_ans": "Industrial Revolution",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Industrial Revolution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the mass high school education movement?",
        "answers": [
            "from 1910\u20131940",
            "1910\u20131940",
            "1910\u20131940"
        ],
        "model_ans": "1910s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1910s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the increase in skilled workers lead to?",
        "answers": [
            "a decrease in the price of skilled labor",
            "decrease in the price of skilled labor",
            "decrease in the price of skilled labor"
        ],
        "model_ans": "Economic growth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economic growth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the education during the high school education movement differ from the subsequent high school education?",
        "answers": [
            "designed to equip students with necessary skill sets to be able to perform at work",
            "designed to equip students with necessary skill sets to be able to perform at work",
            "designed to equip students with necessary skill sets to be able to perform at work"
        ],
        "model_ans": "The education during the high school education movement was more focused on practical skills and vocational training, whereas subsequent high school education focused more on theoretical knowledge and academic preparation for college.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The education during the high school education movement was more focused on practical skills and vocational training, whereas subsequent high school education focused more on theoretical knowledge and academic preparation for college. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is very important for the growth of the economy?",
        "answers": [
            "Education",
            "Education",
            "Education"
        ],
        "model_ans": "Investment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Investment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can result in creating a poverty trap?",
        "answers": [
            "gender inequality in education",
            "low economic growth",
            "continued gender inequality in education"
        ],
        "model_ans": "Low education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Low education </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What types of organizations are on a decline in the US which adversely effects economic mobility?",
        "answers": [
            "unions",
            "union membership",
            "unions"
        ],
        "model_ans": "Unions",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Unions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which set of countries have higher economic mobility than the United States?",
        "answers": [
            "continental European countries",
            "continental European countries",
            "continental European"
        ],
        "model_ans": "Denmark, Norway, Finland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Denmark, Norway, Finland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under which policy are labor unions encouraged?",
        "answers": [
            "continental European liberalism",
            "European liberalism",
            "continental European liberalism"
        ],
        "model_ans": "Keynesian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Keynesian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much support is there for the US approach to economic development?",
        "answers": [
            "little",
            "little support",
            "little"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is economic liberalism one of the causes of?",
        "answers": [
            "economic inequality",
            "economic inequality",
            "economic inequality"
        ],
        "model_ans": "Globalization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Globalization </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the U.S. economic and social model have substantial levels of?",
        "answers": [
            "social exclusion",
            "social exclusion",
            "social exclusion"
        ],
        "model_ans": "inequality",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inequality </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What organization is John Schmitt and Ben Zipperer members of?",
        "answers": [
            "CEPR",
            "CEPR",
            "CEPR"
        ],
        "model_ans": "Center for Economic and Policy Research",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Center for Economic and Policy Research </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much support does evidence provide for the view that labor-market flexibility improves labor-market outcomes?",
        "answers": [
            "little",
            "little support",
            "little"
        ],
        "model_ans": "moderate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> moderate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What level of economic mobility does the U.S. economy have compared to European countries?",
        "answers": [
            "lower",
            "lower level",
            "lower"
        ],
        "model_ans": "lower",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> lower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What country has low income inequality and high presence of unions?",
        "answers": [
            "Scandinavia",
            "Scandinavia",
            "Scandinavia"
        ],
        "model_ans": "Sweden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sweden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do weak labor movement correlate with?",
        "answers": [
            "high inequality",
            "high inequality",
            "high inequality"
        ],
        "model_ans": "Low union density",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Low union density </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has had a negative impact on the labor markets in the US?",
        "answers": [
            "decline of organized labor",
            "decline of organized labor",
            "decline of organized labor"
        ],
        "model_ans": "Automation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Automation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has presented problems to the US economy more than other nations?",
        "answers": [
            "technological changes and globalization",
            "decline of organized labor",
            "technological changes and globalization"
        ],
        "model_ans": "China",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the profession of Jake Rosenfield?",
        "answers": [
            "Sociologist",
            "Sociologist",
            "Sociologist"
        ],
        "model_ans": "Lawyer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lawyer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What college is Jake Rosenfield associated with?",
        "answers": [
            "University of Washington",
            "University of Washington",
            "University of Washington"
        ],
        "model_ans": "Yale",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yale </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Rosenfield feel plays the most significant role in expanding the income gap?",
        "answers": [
            "decline of organized labor",
            "decline of organized labor",
            "decline of organized labor"
        ],
        "model_ans": "automation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> automation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What rate of unionization do Scandinavian nations have?",
        "answers": [
            "high",
            "high rates",
            "high"
        ],
        "model_ans": "around 60-70%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 60-70% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does high inequality go hand-in-hand with?",
        "answers": [
            "weak labor movements",
            "weak labor movements",
            "weak labor movements"
        ],
        "model_ans": "poverty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What effect does trade with poorer countries have on the workers in richer countries?",
        "answers": [
            "reduced wages",
            "reduced wages",
            "reduced wages"
        ],
        "model_ans": "It can lead to job losses and downward pressure on wages",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It can lead to job losses and downward pressure on wages </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What effect does trade with richer countries have on the workers in poorer countries?",
        "answers": [
            "increased wages",
            "increased wages",
            "increased wages"
        ],
        "model_ans": "It can lead to job displacement and exploitation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It can lead to job displacement and exploitation </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has a bigger impact on the United States' economy more than trade?",
        "answers": [
            "technological innovation",
            "technological innovation",
            "technological innovation"
        ],
        "model_ans": "Federal Reserve",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Federal Reserve </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has replaced lower skilled workers in the United States?",
        "answers": [
            "machine labor",
            "machine labor",
            "machine labor"
        ],
        "model_ans": "automation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> automation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What scale does trade liberalization shift economic inequality from?",
        "answers": [
            "global",
            "global",
            "global"
        ],
        "model_ans": "Gini",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gini </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When rich countries trade with poor countries, whose wages increase?",
        "answers": [
            "workers in the poor countries",
            "low-skilled workers in the poor countries",
            "poor"
        ],
        "model_ans": "poor countries",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poor countries </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does Paul Krugmen think has had an observable effect on inequality in the U.S.?",
        "answers": [
            "trade liberalisation",
            "trade liberalisation",
            "trade liberalisation"
        ],
        "model_ans": "globalization",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> globalization </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Compared to other causes, the effect of trade on inequality in America is what?",
        "answers": [
            "minor",
            "minor",
            "minor"
        ],
        "model_ans": "small",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> small </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has technological innovation and automation replaced low-skilled jobs with?",
        "answers": [
            "machine labor",
            "machine labor",
            "machine labor"
        ],
        "model_ans": "Artificial Intelligence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Artificial Intelligence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the income inequality gap between genders in Botswana?",
        "answers": [
            "53%",
            "53%",
            "53%"
        ],
        "model_ans": "0.43",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.43 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the gender income inequality in Bahrain?",
        "answers": [
            "-40%",
            "-40%",
            "-40%"
        ],
        "model_ans": "0.43",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.43 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is attributed to the income inequality in the United States?",
        "answers": [
            "less willing to travel or relocate",
            "women not taking jobs due to marriage or pregnancy",
            "not taking jobs due to marriage or pregnancy"
        ],
        "model_ans": "globalization",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> globalization </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who does the wage gap between genders provide an advantage?",
        "answers": [
            "males",
            "males",
            "males"
        ],
        "model_ans": "Men",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Men </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In many countries, what kind of pay gap is there?",
        "answers": [
            "Gender",
            "ranges from 53% in Botswana to -40% in Bahrain",
            "Gender"
        ],
        "model_ans": "gender",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gender </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who does a gender pay gap tend to favor?",
        "answers": [
            "males in the labor market",
            "males",
            "males"
        ],
        "model_ans": "Men",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Men </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What gender is less willing to travel or relocate for work?",
        "answers": [
            "women",
            "women",
            "women"
        ],
        "model_ans": "Female",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Female </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the author of the book, \"Knowledge and Decisions\"?",
        "answers": [
            "Thomas Sowell",
            "Thomas Sowell",
            "Thomas Sowell"
        ],
        "model_ans": "Herbert A. Simon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Herbert A. Simon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does a U.S. census report state that even after other factors there still exists this between earnings of men and women?",
        "answers": [
            "a difference",
            "difference",
            "difference in earnings"
        ],
        "model_ans": "gender gap",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gender gap </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of programs help to redistribute wealth?",
        "answers": [
            "social welfare",
            "social welfare",
            "social welfare"
        ],
        "model_ans": "Social welfare programs",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social welfare programs </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the level of inequality in underdeveloped countries?",
        "answers": [
            "relatively equal",
            "relatively equal distributions of wealth",
            "low"
        ],
        "model_ans": "High",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> High </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What introduces inequality to a country?",
        "answers": [
            "more capital",
            "more capital",
            "more capital"
        ],
        "model_ans": "Capitalism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Capitalism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What leads to lower income inequality?",
        "answers": [
            "redistribution mechanisms",
            "redistribution mechanisms such as social welfare programs",
            "redistribution mechanisms"
        ],
        "model_ans": "Progressive taxation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Progressive taxation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What profession does Simon Kuznets have?",
        "answers": [
            "Economist",
            "Economist",
            "Economist"
        ],
        "model_ans": "Economist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Kuznets argue resulted from stages of development?",
        "answers": [
            "levels of economic inequality",
            "economic inequality",
            "economic inequality"
        ],
        "model_ans": "Inequality",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inequality </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does a country acquire as it develops?",
        "answers": [
            "more capital",
            "more capital",
            "more capital"
        ],
        "model_ans": "wealth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wealth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the owners of more capital end up having?",
        "answers": [
            "more wealth",
            "more wealth and income",
            "wealth and income"
        ],
        "model_ans": "more capital",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> more capital </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do redistribution mechanisms lead to?",
        "answers": [
            "lower levels of inequality",
            "lower levels of inequality",
            "lower levels of inequality"
        ],
        "model_ans": "increased efficiency",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> increased efficiency </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what time period did income inequality decrease in the United States?",
        "answers": [
            "1910 to 1940",
            "1910 to 1940",
            "1910 to 1940"
        ],
        "model_ans": "1940s-1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1940s-1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did income inequality begin to increase in the US?",
        "answers": [
            "1970s",
            "1970s",
            "1970s"
        ],
        "model_ans": "1979\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1979\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what sector are jobs beginning to increase?",
        "answers": [
            "service",
            "service"
        ],
        "model_ans": "Technology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Technology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what sector are jobs beginning to decrease?",
        "answers": [
            "manufacturing",
            "manufacturing"
        ],
        "model_ans": "Manufacturing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manufacturing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who plotted the relationships between levels of income and inequality?",
        "answers": [
            "Kuznets",
            "Kuznets",
            "Kuznets"
        ],
        "model_ans": "Thomas Piketty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Piketty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a a developing economy's level of inequality bulging out called?",
        "answers": [
            "Kuznets curve",
            "Kuznets curve",
            "Kuznets curve"
        ],
        "model_ans": "Kuznets Curve",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kuznets Curve </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has recent testing of Kuznets theory with superior data show it to be?",
        "answers": [
            "very weak",
            "very weak",
            "very weak"
        ],
        "model_ans": "invalid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> invalid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does Kuznets' curve predict about income inequality given time?",
        "answers": [
            "eventually decrease",
            "eventually decrease",
            "decrease"
        ],
        "model_ans": "Initially, income inequality increases as countries develop, but eventually, it decreases as countries become more developed",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Initially, income inequality increases as countries develop, but eventually, it decreases as countries become more developed </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What may be possible for multiple Kuznets' cycles to be in at any given time?",
        "answers": [
            "effect",
            "in effect",
            "effect"
        ],
        "model_ans": "multiple economies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> multiple economies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What process attributes new wealth to those that already have it?",
        "answers": [
            "Wealth concentration",
            "Wealth concentration",
            "Wealth concentration"
        ],
        "model_ans": "Inheritance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Inheritance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to the wealth concentration theory, what advantage do the wealthy have in accumulating new wealth?",
        "answers": [
            "means to invest",
            "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth",
            "means to invest in new sources of creating wealth"
        ],
        "model_ans": "Access to better education, networking, and financial resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Access to better education, networking, and financial resources </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the highest impact on wealth accumulation and the resulting income inequality?",
        "answers": [
            "greater return of capital",
            "wealth condensation",
            "wealth condensation"
        ],
        "model_ans": "Education",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Education </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tends to lead to more money?",
        "answers": [
            "larger fortunes",
            "wealth condensation",
            "wealth"
        ],
        "model_ans": "Working",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Working </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does newly created wealth concentrate? ",
        "answers": [
            "the possession of already-wealthy individuals",
            "in the possession of already-wealthy individuals or entities",
            "already-wealthy individuals"
        ],
        "model_ans": "Financial centers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Financial centers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is best able to leverage the accumulation of wealth?",
        "answers": [
            "those who already hold wealth",
            "those who already hold wealth",
            "those who already hold wealth"
        ],
        "model_ans": "Berkshire Hathaway",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Berkshire Hathaway</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can significantly contribute to the continuing inequality in a society over time?",
        "answers": [
            "wealth condensation",
            "wealth condensation",
            "wealth condensation"
        ],
        "model_ans": "Lack of education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lack of education </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote the book \"Capital in the Twenty-First Century\"?",
        "answers": [
            "Thomas Piketty",
            "Thomas Piketty",
            "Thomas Piketty"
        ],
        "model_ans": "Thomas Piketty",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Piketty </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do larger fortunes generate?",
        "answers": [
            "higher returns",
            "higher returns",
            "higher returns"
        ],
        "model_ans": "Interest",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Interest </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What career does Joseph Stiglitz have?",
        "answers": [
            "Economist",
            "Economist",
            "Economist"
        ],
        "model_ans": "Economist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What forces should serve as a brake on wealth concentration?",
        "answers": [
            "market",
            "market forces",
            "market"
        ],
        "model_ans": "Taxation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Taxation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of skills does the market bid up compensation for?",
        "answers": [
            "rare and desired",
            "rare and desired skills",
            "rare and desired skills"
        ],
        "model_ans": "Specialized skills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Specialized skills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is used by certain wealthy groups to obtain policies financially beneficial for them?",
        "answers": [
            "political power generated by wealth",
            "political power",
            "political power"
        ],
        "model_ans": "Lobbying",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lobbying </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Income not from the creation of wealth but by grabbing a larger share of it is know to economists by what term?",
        "answers": [
            "rent-seeking",
            "rent-seeking"
        ],
        "model_ans": "rent-seeking",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rent-seeking </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Higher rates of health and social problems are just two of examples of effects from what?",
        "answers": [
            "inequality",
            "inequality",
            "inequality"
        ],
        "model_ans": "poverty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why does a lower level of economic growth occur due to high-end consumption?",
        "answers": [
            "human capital is neglected",
            "a lower level of economic utility in society",
            "human capital is neglected"
        ],
        "model_ans": "Because high-end consumption is often driven by luxury goods and services, which are typically produced in small quantities and have high production costs, leading to higher prices and reduced affordability for the majority of</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Because high-end consumption is often driven by luxury goods and services, which are typically produced in small quantities and have high production costs, leading to higher prices and reduced affordability for the majority of</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is lower in countries with more inequality for the top 21 industrialized countries?",
        "answers": [
            "life expectancy",
            "life expectancy",
            "life expectancy"
        ],
        "model_ans": "Gini coefficient",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gini coefficient </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a lower rate of social goods an effect of?",
        "answers": [
            "inequality",
            "inequality",
            "inequality"
        ],
        "model_ans": "Economic downturn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic downturn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In U.S. states, what happens to the life expectancy in less economically equal ones?",
        "answers": [
            "life expectancy is lower",
            "life expectancy is lower",
            "lower"
        ],
        "model_ans": "Decreases",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Decreases </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year did Robert J. Shiller win an Economics Nobel prize?",
        "answers": [
            "2013",
            "2013",
            "2013"
        ],
        "model_ans": "2013\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2013\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most important problem in the United States and elsewhere?",
        "answers": [
            "rising inequality",
            "rising inequality",
            "rising inequality"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Persistent unemployment has what effect on long-term economic growth?",
        "answers": [
            "negative",
            "negative effect",
            "negative"
        ],
        "model_ans": "negative",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> negative </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What's one factor in eroding self-esteem?",
        "answers": [
            "Unemployment",
            "Unemployment",
            "Unemployment"
        ],
        "model_ans": "Negative self-talk",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Negative self-talk </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Policies which reduce the inequality associated effects of unemployment support what type of growth?",
        "answers": [
            "economic",
            "economic",
            "economic"
        ],
        "model_ans": "sustainable",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> sustainable </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What nationality are researchers Richard G. Wilkinson and Kate Pickett?",
        "answers": [
            "British",
            "British",
            "British"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What rates of health and social problems are in countries with high inequality?",
        "answers": [
            "higher",
            "higher rates",
            "higher"
        ],
        "model_ans": "higher",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> higher </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How are the rates of social goods in countries with higher inequality?",
        "answers": [
            "lower",
            "lower rates",
            "lower"
        ],
        "model_ans": "lower",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> lower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Health problems were lower in places with higher levels of what?",
        "answers": [
            "equality",
            "equality",
            "equality"
        ],
        "model_ans": "greenery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> greenery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many developed countries did British researchers use to gather statistics from?",
        "answers": [
            "23",
            "23",
            "23"
        ],
        "model_ans": "20",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did higher material living standards lead to for most of human history?",
        "answers": [
            "better health and longer lives",
            "better health and longer lives",
            "better health and longer lives"
        ],
        "model_ans": "population growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> population growth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the pattern of higher income-longer lives still hold true?",
        "answers": [
            "poorer countries",
            "poorer countries",
            "poorer countries"
        ],
        "model_ans": "In many developed countries",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In many developed countries </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What increases rapidly as per capita income increases?",
        "answers": [
            "life expectancy",
            "life expectancy",
            "life expectancy"
        ],
        "model_ans": "consumption",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> consumption </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who lives no longer on average than Greeks and New Zealanders?",
        "answers": [
            "Americans",
            "Americans",
            "Americans"
        ],
        "model_ans": "Japanese",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Japanese </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are incomes distributed in Sweden?",
        "answers": [
            "more equally",
            "more equally",
            "more equally distributed"
        ],
        "model_ans": "The income distribution in Sweden is relatively equal, with a high level of social welfare and a strong social safety net.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The income distribution in Sweden is relatively equal, with a high level of social welfare and a strong social safety net. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What characteristic in recent years has been strongly tied with health in developed countries?",
        "answers": [
            "income inequality",
            "income inequality",
            "income inequality"
        ],
        "model_ans": "Obesity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Obesity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who created an index of health and social problems?",
        "answers": [
            "authors Richard Wilkinson and Kate Pickett",
            "Richard Wilkinson and Kate Pickett",
            "Richard Wilkinson and Kate Pickett"
        ],
        "model_ans": "World Health Organization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World Health Organization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many factors of health and social problems did Wilkinson and PIckett identify?",
        "answers": [
            "nine",
            "nine factors",
            "nine"
        ],
        "model_ans": "24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are health and social problems most common?",
        "answers": [
            "among states in the US with larger income inequalities",
            "countries with bigger income inequalities",
            "countries with bigger income inequalities"
        ],
        "model_ans": "urban areas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> urban areas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does child well-being in rich countries correlate most to?",
        "answers": [
            "greater equality",
            "greater equality",
            "greater equality but not per capita income"
        ],
        "model_ans": "Parental education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Parental education </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has crime rate been show to be correlated with in a society?",
        "answers": [
            "inequality",
            "inequality",
            "inequality"
        ],
        "model_ans": "poverty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is almost identical across all nations and jurisdictions?",
        "answers": [
            "homicides",
            "homicides"
        ],
        "model_ans": "Language",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Language </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Over how many studies have shown that violence is more common in societies with income differences?",
        "answers": [
            "fifty",
            "over fifty",
            "fifty"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of a difference in homicide rates are related to inequality?",
        "answers": [
            "tenfold",
            "tenfold",
            "tenfold"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is it estimated that about half of all variation in homicide rates can be accounted for by?",
        "answers": [
            "differences in the amount of inequality",
            "differences in the amount of inequality",
            "inequality"
        ],
        "model_ans": "socioeconomic factors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> socioeconomic factors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the utilitarian principle seek for the greatest number of people?",
        "answers": [
            "the greatest good",
            "greatest good",
            "good"
        ],
        "model_ans": "happiness",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> happiness </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "An adobe that provides less utility to one person than another is an example of reduced what?",
        "answers": [
            "distributive efficiency",
            "distributive efficiency",
            "\"distributive efficiency\""
        ],
        "model_ans": "marginal utility",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> marginal utility </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A dollar spent by a poor person is likely to provide what for them?",
        "answers": [
            "a great deal of utility",
            "a great deal of utility",
            "basic necessities"
        ],
        "model_ans": "more food",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> more food </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What the marginal utility of wealth per income per person do as that person becomes richer?",
        "answers": [
            "decreases",
            "decreases",
            "decreases"
        ],
        "model_ans": "Decreases",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Decreases </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What will a society with more equality have?",
        "answers": [
            "higher aggregate utility",
            "population-wide satisfaction and happiness",
            "satisfaction and happiness"
        ],
        "model_ans": "Less poverty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Less poverty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do conservative researchers fell should be a measure of inequality?",
        "answers": [
            "consumption",
            "consumption",
            "consumption"
        ],
        "model_ans": "Gini coefficient",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gini coefficient </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What political leaning does the Cato Institute have?",
        "answers": [
            "libertarian",
            "libertarian",
            "libertarian"
        ],
        "model_ans": "Libertarian",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Libertarian </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was consumption inequality lower than it had been in 1986?",
        "answers": [
            "2001",
            "2001",
            "2001"
        ],
        "model_ans": "2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote \"The Hidden Prosperity of the Poor\"?",
        "answers": [
            "Thomas B. Edsall",
            "Thomas B. Edsall",
            "Thomas B. Edsall"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Thomas B. Edsall's profession?",
        "answers": [
            "journalist",
            "journalist",
            "journalist"
        ],
        "model_ans": "Journalist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Journalist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is Raghuram Rajan's career?",
        "answers": [
            "economist",
            "economist",
            "economist"
        ],
        "model_ans": "Economist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does Rajan feel has created deep financial fault lines?",
        "answers": [
            "systematic economic inequalities",
            "systematic economic inequalities",
            "systematic economic inequalities"
        ],
        "model_ans": "Globalization",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Globalization </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most recent example of financial fault lines? ",
        "answers": [
            "the Financial crisis of 2007\u201308",
            "Financial crisis of 2007\u201308",
            "Financial crisis of 2007\u201308"
        ],
        "model_ans": "The 2008 financial crisis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The 2008 financial crisis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does political pressure push to extend to compensate for stagnating purchasing power?",
        "answers": [
            "easier credit",
            "easier credit to the lower and middle income earners",
            "easier credit to the lower and middle income earners"
        ],
        "model_ans": "inflation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inflation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has given the American economy a tendency to go \"from bubble to bubble\"?",
        "answers": [
            "easier credit",
            "easier credit",
            "easier credit"
        ],
        "model_ans": "Federal Reserve",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Federal Reserve </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is negatively correlated to the duration of economic growth?",
        "answers": [
            "inequality in wealth and income",
            "inequality in wealth and income",
            "wealth and income"
        ],
        "model_ans": "Inflation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inflation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do high levels of inequality  prevent beyond economic prosperity?",
        "answers": [
            "quality of a country's institutions",
            "quality of a country's institutions and high levels of education",
            "quality of a country's institutions and high levels of education"
        ],
        "model_ans": "Social cohesion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Social cohesion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to the GDP growth of a country if the income share of the top 20 percent increases, according to IMF staff economists? ",
        "answers": [
            "declines",
            "declines",
            "declines"
        ],
        "model_ans": "The GDP growth rate is likely to decrease",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The GDP growth rate is likely to decrease </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does an increase in the income share of the bottom 20 percent of people of a society result in?",
        "answers": [
            "higher GDP growth",
            "higher GDP growth",
            "higher GDP growth"
        ],
        "model_ans": "Reduced income inequality",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reduced income inequality </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who matters the most for economic growth?",
        "answers": [
            "The poor and the middle class",
            "The poor and the middle class",
            "poor and the middle class"
        ],
        "model_ans": "Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do David Castlles-Quintana and Vicente Royuela do for a living?",
        "answers": [
            "economists",
            "economists",
            "economists"
        ],
        "model_ans": "They are both researchers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They are both researchers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does increasing inequality harm?",
        "answers": [
            "economic growth",
            "economic growth",
            "economic growth"
        ],
        "model_ans": "Social cohesion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social cohesion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was persistent unemployment have a negative effect on?",
        "answers": [
            "subsequent long-run economic growth",
            "subsequent long-run economic growth",
            "long-run economic growth"
        ],
        "model_ans": "Economy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why does unemployment harm growth?",
        "answers": [
            "because it is a waste of resources",
            "waste of resources",
            "waste of resources"
        ],
        "model_ans": "Unemployment reduces consumer spending and investment, leading to a decrease in aggregate demand, which can lead to a decline in economic growth.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unemployment reduces consumer spending and investment, leading to a decrease in aggregate demand, which can lead to a decline in economic growth. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Policies which try to control unemployment support economic growth because they reduce what?",
        "answers": [
            "inequality-associated effects",
            "inequality-associated effects",
            "inequality"
        ],
        "model_ans": "unemployment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unemployment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Stiglitz present in 2009 regarding global inequality?",
        "answers": [
            "evidence",
            "evidence",
            "prevent growth"
        ],
        "model_ans": "The Stiglitz Commission",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Stiglitz Commission </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How does inequality prevent growth?",
        "answers": [
            "by limiting aggregate demand",
            "limiting aggregate demand",
            "limiting aggregate demand"
        ],
        "model_ans": "Inequality can prevent growth by limiting access to resources, education, and opportunities, leading to reduced economic mobility and decreased overall economic growth.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Inequality can prevent growth by limiting access to resources, education, and opportunities, leading to reduced economic mobility and decreased overall economic growth.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are both Branko Milanovic and Joseph Stiglitz?",
        "answers": [
            "Economist",
            "Economist",
            "Economist"
        ],
        "model_ans": "Economists",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economists </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What has been the main reason for the shift to the view that income inequality harms growth?",
        "answers": [
            "increasing importance of human capital in development",
            "increasing importance of human capital in development",
            "increasing importance of human capital"
        ],
        "model_ans": "The work of economists such as Thomas Piketty and Emmanuel Saez",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The work of economists such as Thomas Piketty and Emmanuel Saez </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has become the secret to economic growth?",
        "answers": [
            "widespread education",
            "widespread education",
            "widespread education"
        ],
        "model_ans": "Innovation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Innovation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Galor and Zeria show new information about inequality?",
        "answers": [
            "1993",
            "1993",
            "1993"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Inequality in the presence of credit market imperfections has what kind of effect on human capital formation?",
        "answers": [
            "detrimental",
            "long lasting detrimental effect",
            "long lasting detrimental"
        ],
        "model_ans": "negative",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> negative </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did a 1996 study by Perotti examine?",
        "answers": [
            "channels through which inequality may affect economic growth",
            "channels through which inequality may affect economic growth",
            "channels through which inequality may affect economic growth"
        ],
        "model_ans": "The impact of fiscal policy on economic growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The impact of fiscal policy on economic growth </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is inequality associated with higher levels of?",
        "answers": [
            "redistributive taxation",
            "fertility",
            "fertility"
        ],
        "model_ans": "income",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> income </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do extremely unequal societies tend to be?",
        "answers": [
            "politically and socially unstable",
            "politically and socially unstable",
            "politically and socially unstable"
        ],
        "model_ans": "unstable",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> unstable </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What institution does Robert Barro hail from?",
        "answers": [
            "Harvard",
            "Harvard",
            "Harvard"
        ],
        "model_ans": "Harvard University",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harvard University </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Barro found there is little relation between income inequality and rates of what?",
        "answers": [
            "growth and investment",
            "growth and investment",
            "growth and investment"
        ],
        "model_ans": "poverty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> poverty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does high levels of inequality do to growth in poor countries?",
        "answers": [
            "reduce",
            "reduce growth",
            "reduce"
        ],
        "model_ans": "It can hinder growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It can hinder growth </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does high levels of inequality do for economic growth in richer countries?",
        "answers": [
            "encourage",
            "encourage growth",
            "encourage"
        ],
        "model_ans": "Negative",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Negative </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was a study conducted of Swedish counties?",
        "answers": [
            "between 1960 and 2000",
            "between 1960 and 2000",
            "between 1960 and 2000"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What have studies on income inequality sometimes found evidence confirming?",
        "answers": [
            "Kuznets curve hypothesis",
            "Kuznets curve hypothesis",
            "Kuznets curve hypothesis"
        ],
        "model_ans": "A negative impact on economic growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A negative impact on economic growth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Kuznets curve says with economic development, inequality will decrease after what?",
        "answers": [
            "first increases",
            "inequality first increases",
            "increases"
        ],
        "model_ans": "a certain point",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a certain point </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who challenges the notion of the Kuznets curve hypothesis?",
        "answers": [
            "Thomas Piketty",
            "Thomas Piketty",
            "Thomas Piketty"
        ],
        "model_ans": "David Autor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Autor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What's Thomas Piketty's job?",
        "answers": [
            "Economist",
            "Economist",
            "Economist"
        ],
        "model_ans": "Economist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Economist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does Piketty feel was the biggest factors in reducing inequality between 1914 to 1945?",
        "answers": [
            "wars and \"violent economic and political shocks\"",
            "violent economic and political shocks",
            "wars and \"violent economic and political shocks\""
        ],
        "model_ans": "World War I and World War II",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> World War I and World War II </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were theories developed suggesting inequality may have some positive effect on economic development?",
        "answers": [
            "the 1970s",
            "1970s",
            "1970s"
        ],
        "model_ans": "1970s",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to a 1955 review, what were savings by the wealthy thought to offset?",
        "answers": [
            "reduced consumer demand",
            "reduced consumer demand",
            "reduced consumer demand"
        ],
        "model_ans": "the costs of the poor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the costs of the poor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does a 2013 report on Nigeria suggest it's growth has done?",
        "answers": [
            "risen with increased income inequality",
            "risen",
            "risen"
        ],
        "model_ans": "slowed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> slowed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long does it take for the effects to manifest as changes to economic growth?",
        "answers": [
            "several years",
            "several years",
            "several years"
        ],
        "model_ans": "2-5 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2-5 years </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are longer growth spells associated with?",
        "answers": [
            "more equality in the income distribution",
            "more equality",
            "equality in the income distribution"
        ],
        "model_ans": "taller height",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> taller height </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What needs to be made to ensure poorer members of society can participate in economic growth?",
        "answers": [
            "special efforts",
            "special efforts",
            "special efforts"
        ],
        "model_ans": "Education",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Education </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can the growth elasticity of poverty depend on?",
        "answers": [
            "existing level of inequality",
            "existing level of inequality",
            "existing level of inequality"
        ],
        "model_ans": "income distribution",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> income distribution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does it take a country with high inequality longer to achieve?",
        "answers": [
            "reduction",
            "halve poverty",
            "halve poverty"
        ],
        "model_ans": "Economic growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic growth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Ban Ki-Moon the Secretary General of?",
        "answers": [
            "the United Nations",
            "United Nations",
            "United Nations"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What isn't economic growth sufficient for progress on?",
        "answers": [
            "reducing poverty",
            "reducing poverty",
            "reducing poverty"
        ],
        "model_ans": "Social justice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Social justice </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is held outside the formal legal ownership registration system in many developing countries?",
        "answers": [
            "much land and housing",
            "land and housing",
            "land and housing"
        ],
        "model_ans": "informal land ownership",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> informal land ownership </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is unregistered property held in informal form?",
        "answers": [
            "through various associations and other arrangements",
            "through various associations and other arrangements",
            "through various associations"
        ],
        "model_ans": "Informally",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Informally </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Excessive bureaucratic red tape is one of the reasons for what type of ownership?",
        "answers": [
            "extra-legal",
            "extra-legal",
            "extra-legal"
        ],
        "model_ans": "Public",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Public </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In some countries over how many steps can it take to build on government land?",
        "answers": [
            "200",
            "200",
            "200"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can it sometimes take up to 14 years to get permission to build on?",
        "answers": [
            "government land",
            "government land",
            "government land"
        ],
        "model_ans": "a plot of land",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a plot of land </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do a number of researchers think a shortage of is caused in part by income inequality?",
        "answers": [
            "a shortage of affordable housing",
            "affordable housing",
            "affordable housing"
        ],
        "model_ans": "talent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> talent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What decreased in number between 1984 and 1991?",
        "answers": [
            "quality rental units",
            "quality rental units",
            "quality rental units"
        ],
        "model_ans": "The number of people who died from AIDS",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The number of people who died from AIDS </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did the demand for rentals decrease?",
        "answers": [
            "demand for higher quality housing increased",
            "demand for higher quality housing increased",
            "demand for higher quality housing increased"
        ],
        "model_ans": "The demand for rentals decreased due to the rise of homeownership and the increasing availability of affordable housing options.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The demand for rentals decreased due to the rise of homeownership and the increasing availability of affordable housing options. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What drove increased rental prices in East New York?",
        "answers": [
            "residents willing to pay higher market rate for housing",
            "gentrification of older neighbourhoods",
            "new residents willing to pay higher market rate"
        ],
        "model_ans": "gentrification",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> gentrification </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What combined with ricing prices to make it difficult or impossible for poor people to keep pace?",
        "answers": [
            "ad valorem property tax policy",
            "ad valorem property tax policy",
            "property tax policy"
        ],
        "model_ans": "inflation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inflation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are the certain costs which are difficult to avoid shared?",
        "answers": [
            "by everyone",
            "by everyone"
        ],
        "model_ans": "Fixed costs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fixed costs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are those with lower incomes often unable to manage?",
        "answers": [
            "their finances",
            "finances",
            "finances"
        ],
        "model_ans": "debt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> debt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term when middle income earners aspire to obtain the same standards of living as people wealthier than themselves?",
        "answers": [
            "aspirational consumption",
            "aspirational consumption",
            "aspirational consumption"
        ],
        "model_ans": "Keeping up with the Joneses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Keeping up with the Joneses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one method of achieving aspirational consumption?",
        "answers": [
            "taking on debt",
            "taking on debt",
            "taking on debt"
        ],
        "model_ans": "Luxury consumption",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Luxury consumption </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When people take on debt, it leads potentially to what?",
        "answers": [
            "economic instability",
            "greater inequality and potential economic instability",
            "greater inequality and potential economic instability"
        ],
        "model_ans": "financial difficulties",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> financial difficulties </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When economic inequality is smaller, more waste and pollution is?",
        "answers": [
            "created",
            "created",
            "created",
            "created"
        ],
        "model_ans": "less",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> less </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What would be lower if there were fewer people?",
        "answers": [
            "emissions per person",
            "this multiplier",
            "environmental degradation",
            "environmental degradation"
        ],
        "model_ans": "population",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> population </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the current high level of population have a large impact on?",
        "answers": [
            "environmental degradation",
            "this as well",
            "environmental degradation",
            "environmental degradation"
        ],
        "model_ans": "Environment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Environment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How could human inequality be addressed without resulting in an increase of environmental damage?",
        "answers": [
            "If (as WWF argued), population levels would start to drop to a sustainable level",
            "If (as WWF argued), population levels would start to drop to a sustainable level",
            "population levels would start to drop to a sustainable level",
            "population levels would start to drop to a sustainable level"
        ],
        "model_ans": "Implementing sustainable practices, reducing consumption, and promoting social justice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Implementing sustainable practices, reducing consumption, and promoting social justice </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the vast disparities in wealth attributed to by Socialists?",
        "answers": [
            "private ownership of the means of production",
            "private ownership of the means of production",
            "private ownership of the means of production"
        ],
        "model_ans": "Capitalism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Capitalism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does private ownership create a situation of?",
        "answers": [
            "a small portion of the population lives off unearned property income",
            "small portion of the population lives off unearned property income",
            "small portion of the population lives off unearned property income"
        ],
        "model_ans": "competition",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> competition </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of income is the vast majority of the population dependent on?",
        "answers": [
            "wage or salary",
            "wage or salary",
            "wage or salary"
        ],
        "model_ans": "salary",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> salary </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How do socialists think the means of production should be owned?",
        "answers": [
            "socially",
            "socially",
            "socially"
        ],
        "model_ans": "collectively",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> collectively </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What would income differentials be if individual contributions were relevant to the social product?",
        "answers": [
            "reflective",
            "reflective",
            "reflective of individual contributions"
        ],
        "model_ans": "income differentials would be irrelevant",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> income differentials would be irrelevant </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who argues that the government redistributes wealth by force?",
        "answers": [
            "Robert Nozick",
            "Robert Nozick",
            "Robert Nozick"
        ],
        "model_ans": "Murray Rothbard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Murray Rothbard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the usual form of the government's wealth redistribution? ",
        "answers": [
            "taxation",
            "taxation",
            "taxation"
        ],
        "model_ans": "Taxation",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Taxation </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In an ideal moral society, what would all citizens be free from?",
        "answers": [
            "force",
            "force"
        ],
        "model_ans": "fear",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fear </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How were some modern economic inequalities created?",
        "answers": [
            "forceful taking of property",
            "forceful taking of property",
            "forceful taking of property"
        ],
        "model_ans": "Globalization, technological advancements, and government policies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Globalization, technological advancements, and government policies </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When are inequalities in wealth justified, according to John Rawls?",
        "answers": [
            "when they improve society as a whole",
            "when they improve society as a whole",
            "when they improve society as a whole"
        ],
        "model_ans": "never",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> never </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the capabilities approach look at poverty as a form of?",
        "answers": [
            "capability deprivation",
            "capability deprivation",
            "\u201ccapability deprivation\u201d"
        ],
        "model_ans": "capability deprivation",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> capability deprivation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the capabilities approach, grow and income are considered a means to an end rather than what?",
        "answers": [
            "the end itself",
            "the end itself",
            "the end itself"
        ],
        "model_ans": "an end in itself",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> an end in itself </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the goal of the capabilities approach?",
        "answers": [
            "to \u201cwid[en] people\u2019s choices and the level of their achieved well-being\u201d",
            "wid[en] people\u2019s choices and the level of their achieved well-being",
            "\u201cwid[en] people\u2019s choices and the level of their achieved well-being\u201d"
        ],
        "model_ans": "To promote human well-being",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To promote human well-being </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How would the capabilities approach achieve it's goal?",
        "answers": [
            "through increasing functionings",
            "increasing functionings (the things a person values doing), capabilities (the freedom to enjoy functionings) and agency (the ability to pursue valued goals)",
            "through increasing functionings"
        ],
        "model_ans": "By recognizing the inherent value of human capabilities and providing the necessary resources and opportunities for individuals to develop and exercise them",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By recognizing the inherent value of human capabilities and providing the necessary resources and opportunities for individuals to develop and exercise them </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the definition of agency as it relates to capabilities? ",
        "answers": [
            "the ability to pursue valued goals",
            "the ability to pursue valued goals"
        ],
        "model_ans": "Agency refers to the ability of an entity to make decisions and take actions that affect its own goals and outcomes.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Agency refers to the ability of an entity to make decisions and take actions that affect its own goals and outcomes. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens when a person's capabilities aer lowered, as it relates to their income?",
        "answers": [
            "deprived of earning as much",
            "deprived of earning as much income",
            "deprived of earning as much income as they would otherwise"
        ],
        "model_ans": "Their income is reduced",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Their income is reduced </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can and old, ill man not do?",
        "answers": [
            "earn as much as a healthy young man",
            "earn as much as a healthy young man",
            "earn as much as a healthy young man"
        ],
        "model_ans": "run",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> run </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What issues may prevent women from working outside the home or receiving education?",
        "answers": [
            "gender roles and customs",
            "gender roles and customs",
            "gender roles and customs"
        ],
        "model_ans": "societal expectations, lack of childcare support, gender-based violence, lack of access to education",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> societal expectations, lack of childcare support, gender-based violence, lack of access to education </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why would rampant violence prevent people from going to work?",
        "answers": [
            "for fear of their lives",
            "fear of their lives",
            "fear of their lives"
        ],
        "model_ans": "Because people would be too scared to go to work due to the violence",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because people would be too scared to go to work due to the violence </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can people work towards if they aren't denied their functionings, capabilities and agency?",
        "answers": [
            "a better relevant income.",
            "better relevant income",
            "a better relevant income"
        ],
        "model_ans": "Well-being",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Well-being </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of university is the University of Chicago?",
        "answers": [
            "a private research university",
            "private research",
            "private research university",
            "private research university"
        ],
        "model_ans": "Private",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Private </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the University of Chicago established?",
        "answers": [
            "1890",
            "1890",
            "1890",
            "1890"
        ],
        "model_ans": "1890\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1890\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many professional schools does the University of Chicago have?",
        "answers": [
            "seven",
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many academic research divisions does the University of Chicago have?",
        "answers": [
            "four",
            "four",
            "four",
            "four"
        ],
        "model_ans": "7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many students does the University of Chicago have enlisted?",
        "answers": [
            "5,000",
            "around 15,000",
            "15,000",
            "15,000"
        ],
        "model_ans": "15,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 15,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "University of Chicago scholars played a major part in what development?",
        "answers": [
            "various academic disciplines",
            "various academic disciplines",
            "the world's first man-made, self-sustaining nuclear reaction",
            "the world's first man-made, self-sustaining nuclear reaction"
        ],
        "model_ans": "Nuclear Physics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nuclear Physics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who helped develop the first man-made self-sustaining nuclear reaction?",
        "answers": [
            "Chicago's physics department",
            "Chicago's physics department",
            "Chicago's physics department",
            "Chicago's physics department"
        ],
        "model_ans": "Enrico Fermi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enrico Fermi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the first man-made self-sustaining nuclear reaction located?",
        "answers": [
            "beneath the university's Stagg Field",
            "Stagg Field",
            "beneath the university's Stagg Field",
            "beneath the university's Stagg Field"
        ],
        "model_ans": "Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the largest university press in the U.S?",
        "answers": [
            "University of Chicago Press",
            "University of Chicago Press",
            "University of Chicago Press",
            "University of Chicago Press"
        ],
        "model_ans": "University of Chicago Press",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> University of Chicago Press </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year will the Barack Obama Presidential Center be finished?",
        "answers": [
            "2020",
            "2020",
            "2020",
            "2020"
        ],
        "model_ans": "2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What society founded the University of Chicago?",
        "answers": [
            "the American Baptist Education Society",
            "American Baptist Education Society",
            "American Baptist Education Society",
            "American Baptist Education Society"
        ],
        "model_ans": "The University of Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The University of Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What person helped establish the school with a donation?",
        "answers": [
            "John D. Rockefeller",
            "John D. Rockefeller",
            "John D. Rockefeller",
            "John D. Rockefeller"
        ],
        "model_ans": "John",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first president of the University of Chicago?",
        "answers": [
            "William Rainey Harper",
            "William Rainey Harper",
            "William Rainey Harper",
            "William Rainey Harper"
        ],
        "model_ans": "Robert Maynard Hutchins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robert Maynard Hutchins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year was the university's first president given his position? ",
        "answers": [
            "1891",
            "1891",
            "1891",
            "1891"
        ],
        "model_ans": "1955",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1955 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year was the first class taught at the University of Chicago?",
        "answers": [
            "1892",
            "1892",
            "1892",
            "1892"
        ],
        "model_ans": "1890\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1890\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who donated property to the University of Chicago?",
        "answers": [
            "Marshall Field",
            "Marshall Field",
            "Marshall Field",
            "Marshall Field"
        ],
        "model_ans": "Rockefeller",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rockefeller </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who helped pay for the university's first building structure? ",
        "answers": [
            "Silas B. Cobb",
            "Silas B. Cobb",
            "Silas B. Cobb",
            "Silas B. Cobb"
        ],
        "model_ans": "The University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the first building built on campus grounds?",
        "answers": [
            "Cobb Lecture Hall",
            "Cobb Lecture Hall",
            "Cobb Lecture Hall",
            "Cobb Lecture Hall"
        ],
        "model_ans": "The Old Main",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Old Main </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much did Silas B. Cobb pledge to the university?",
        "answers": [
            "$100,000",
            "$100,000",
            "$100,000",
            "$100,000"
        ],
        "model_ans": "$100,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> $100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the donor who helped establish the Hutchinson Commons?",
        "answers": [
            "Charles L. Hutchinson",
            "Charles L. Hutchinson",
            "Charles L. Hutchinson",
            "Charles L. Hutchinson"
        ],
        "model_ans": "The Hutchinson Family",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Hutchinson Family </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1890, who did the university decide to team up with?",
        "answers": [
            "several regional colleges and universities",
            "Des Moines College, Kalamazoo College, Butler University, and Stetson University",
            "Des Moines College, Kalamazoo College, Butler University, and Stetson University",
            "Des Moines College, Kalamazoo College, Butler University, and Stetson University"
        ],
        "model_ans": "Harvard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harvard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did the university team up with Shimer College?",
        "answers": [
            "1896",
            "1896",
            "1896",
            "1896"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The university agreed to grant a degree to any graduate of affiliate schoos that did what?",
        "answers": [
            "made a grade of A for all four years",
            "made a grade of A for all four years, and on any other graduate who took twelve weeks additional study at the University of Chicago",
            "made a grade of A for all four years",
            "made a grade of A for all four years"
        ],
        "model_ans": "met the requirements",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> met the requirements </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who disliked the affiliate program?",
        "answers": [
            "passed",
            "Several University of Chicago professors",
            "Several University of Chicago professors"
        ],
        "model_ans": "Amazon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Amazon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did the affiliate program end?",
        "answers": [
            "1910",
            "1910",
            "Several University of Chicago professors",
            "1910"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the university's 5th president?",
        "answers": [
            "Robert Maynard Hutchins",
            "Robert Maynard Hutchins",
            "Robert Maynard Hutchins",
            "Robert Maynard Hutchins"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the university's 5th president granted his position?",
        "answers": [
            "1929",
            "1929",
            "1929",
            "1929"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long did the 5th president's tenure last?",
        "answers": [
            "24-year tenure",
            "24-year",
            "24-year tenure.",
            "24-year"
        ],
        "model_ans": "4 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did the 5th president of the university decide to get rid of the football program?",
        "answers": [
            "to emphasize academics over athletics",
            "emphasize academics",
            "an attempt to emphasize academics over athletics",
            "to emphasize academics over athletics,"
        ],
        "model_ans": "No information available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No information available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name given to the undergraduate college's liberal-arts curriculum?",
        "answers": [
            "the Common Core",
            "Common Core",
            "Common Core",
            "Common Core"
        ],
        "model_ans": "Core",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Core </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year did the university first see a drop in applications?",
        "answers": [
            "1950s",
            "early 1950s",
            "the early 1950s",
            "the early 1950s"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did the university see a drop in applicants? ",
        "answers": [
            "a result of increasing crime and poverty",
            "increasing crime and poverty in the Hyde Park neighborhood",
            "increasing crime and poverty in the Hyde Park neighborhood",
            "increasing crime and poverty in the Hyde Park neighborhood"
        ],
        "model_ans": "The university saw a drop in applicants due to a decline in the quality of education and a rise in tuition fees.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The university saw a drop in applicants due to a decline in the quality of education and a rise in tuition fees. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were Shimer College students allowed to transfer to the University of Chicago?",
        "answers": [
            "after their second year",
            "early 1950s",
            "after their second year",
            "after their second year"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The urban renewal project was intended to help the residents of what neighborhood?",
        "answers": [
            "Hyde Park",
            "Hyde Park",
            "Hyde Park",
            "Hyde Park"
        ],
        "model_ans": "Chinatown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chinatown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the early entrant program do for potential students?",
        "answers": [
            "allowed very young students to attend college",
            "allowed very young students to attend college",
            "allowed very young students to attend college",
            "allowed very young students to attend college"
        ],
        "model_ans": "Provided financial aid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Provided financial aid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did student decide to occupy the president's office?",
        "answers": [
            "1962",
            "1962",
            "1962",
            "1962"
        ],
        "model_ans": "1968",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1968 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What made the student decide to occupy the president's office in protest?",
        "answers": [
            "the university's off-campus rental policies.",
            "the university's off-campus rental policies",
            "the university's off-campus rental policies",
            "the university's off-campus rental policies"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year was the Kalven Report issued?",
        "answers": [
            "1967",
            "1967",
            "1967",
            "1967"
        ],
        "model_ans": "1967\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1967\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many pages was the Kalven Report statement?",
        "answers": [
            "a two-page statement",
            "two",
            "two",
            "two"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What policy did the Kelven Report contain?",
        "answers": [
            "social and political action",
            "social and political action",
            "social and political action",
            "social and political action"
        ],
        "model_ans": "The Kelven Report contained a policy on the use of nuclear weapons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Kelven Report contained a policy on the use of nuclear weapons </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the university decide to start multimillion-dollar expansion projects?",
        "answers": [
            "mid-2000s",
            "mid-2000s",
            "mid-2000s",
            "the mid-2000s"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What institute did the university announced to everyone in 2008?",
        "answers": [
            "Milton Friedman Institute",
            "Milton Friedman Institute",
            "Milton Friedman Institute",
            "Milton Friedman Institute"
        ],
        "model_ans": "Harvard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harvard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much did the Milton Friedman Institute roughly cost?",
        "answers": [
            "around $200 million",
            "$200 million",
            "$200 million",
            "$200 million"
        ],
        "model_ans": "$100 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $100 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What buildings held the Milton Friedman Institute?",
        "answers": [
            "the Chicago Theological Seminary",
            "Chicago Theological Seminary",
            "Chicago Theological Seminary",
            "Chicago Theological Seminary"
        ],
        "model_ans": "University of Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who decide to make a very large donation to the university's Booth School of Business?",
        "answers": [
            "David G. Booth",
            "David G. Booth",
            "David G. Booth",
            "David G. Booth"
        ],
        "model_ans": "David Booth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Booth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the first buildings the university built knows as today?",
        "answers": [
            "the Main Quadrangles",
            "Main Quadrangles",
            "the Main Quadrangles",
            "the Main Quadrangles"
        ],
        "model_ans": "The University of Cambridge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The University of Cambridge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many quadrangles does the Main Quadrangles have?",
        "answers": [
            "six",
            "six quadrangles",
            "six",
            "six"
        ],
        "model_ans": "4\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "4\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who helped designed the Main Quadrangles?",
        "answers": [
            "Cobb, Shepley, Rutan and Coolidge, Holabird & Roche,",
            "Henry Ives Cobb",
            "Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms",
            "Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms"
        ],
        "model_ans": "University of Michigan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Michigan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Mitchell Tower is designed to look like what Oxford tower?",
        "answers": [
            "Oxford's Magdalen Tower",
            "Magdalen Tower",
            "Magdalen Tower",
            "Magdalen Tower"
        ],
        "model_ans": "Christ Church",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Christ Church </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Hutchinson Hall was designed to look like what Oxford hall?",
        "answers": [
            "Christ Church Hall",
            "Christ Church Hall",
            "Christ Church Hall",
            "Christ Church Hall"
        ],
        "model_ans": "Brasenose College",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brasenose College </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During what decade did the campus start to look more modern?",
        "answers": [
            "the 1940s",
            "After the 1940s"
        ],
        "model_ans": "1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was assigned to design a second master plan?",
        "answers": [
            "Eero Saarinen",
            "Eero Saarinen",
            "Eero Saarinen"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What administration did Ludwig Mies van der Rohe designa buiding?",
        "answers": [
            "School of Social Service Administration",
            "School of Social Service Administration",
            "the university's School of Social Service Administration"
        ],
        "model_ans": "Bauhaus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bauhaus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What public policy school found it's home in the building that Ludwig Mies van der Rohe designed?",
        "answers": [
            "Harris School of Public Policy Studies",
            "Harris School of Public Policy Studies",
            "the Harris School of Public Policy Studies"
        ],
        "model_ans": "University of Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Gerald Ratner Athletics Center constructed?",
        "answers": [
            "2003",
            "2003"
        ],
        "model_ans": "2001",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2001 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other locations can the Booth School of Business be found?",
        "answers": [
            "Singapore, London, and the downtown Streeterville neighborhood of Chicago",
            "Singapore, London, and the downtown Streeterville neighborhood of Chicago",
            "Singapore, London, and the downtown Streeterville neighborhood of Chicago"
        ],
        "model_ans": "Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Center in Paris is located near what river?",
        "answers": [
            "Seine",
            "Seine",
            "the Seine"
        ],
        "model_ans": "Seine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Seine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The university established a center in Beijing in what year?",
        "answers": [
            "2010",
            "2010",
            "2010"
        ],
        "model_ans": "2005\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2005\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The university's center in Beijing is located next to what school's campus?",
        "answers": [
            "Renmin University",
            "Renmin University",
            "Renmin University"
        ],
        "model_ans": "Tsinghua University",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tsinghua University </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did the university open a center in Hong Kong?",
        "answers": [
            "2015",
            "2015",
            "2015"
        ],
        "model_ans": "1991",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1991 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who runs the University of Chicago?",
        "answers": [
            "a board of trustees",
            "board of trustees",
            "The Board of Trustees"
        ],
        "model_ans": "University of Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many people belong to the university's Board of Trustees?",
        "answers": [
            "50",
            "50",
            "50"
        ],
        "model_ans": "9",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Vice Presidents are in the Board of Trustees?",
        "answers": [
            "fourteen",
            "fourteen",
            "fourteen"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the Chairman of the Board of Trustees?",
        "answers": [
            "Andrew Alper",
            "Andrew Alper",
            "Andrew Alper"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who took Isaacs place as Provost in 2016?",
        "answers": [
            "Robert Zimmer",
            "Daniel Diermeier",
            "Daniel Diermeier"
        ],
        "model_ans": "Dr. David Wilson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dr. David Wilson </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the university accredited by?",
        "answers": [
            "The Higher Learning Commission",
            "The Higher Learning Commission",
            "The Higher Learning Commission"
        ],
        "model_ans": "University of California",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University of California </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The academic body of the university is made up of how many divisions of graduate?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The academic body of the university is made up of how many professional schools?",
        "answers": [
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many academic majors does the university grant in total?",
        "answers": [
            "50",
            "50",
            "50"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many academic minors does the university grant in total?",
        "answers": [
            "28",
            "28",
            "28"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many divisions make up the academics of the university?",
        "answers": [
            "five",
            "five",
            "five"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What division offers more then one branch of studies that don't fit in with the other four?",
        "answers": [
            "the New Collegiate Division",
            "New Collegiate Division",
            "New Collegiate Division"
        ],
        "model_ans": "Arts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the university's core curriculum?",
        "answers": [
            "the Common Core",
            "Common Core",
            "Common Core"
        ],
        "model_ans": "Core Curriculum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Core Curriculum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During 2012-2013, how many student were able to take the Core classes at a single time?",
        "answers": [
            "17",
            "17",
            "17"
        ],
        "model_ans": "200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "UChicago claims to have what kind of learning experience compared to other universities? ",
        "answers": [
            "the most rigorous, intense",
            "the most rigorous, intense"
        ],
        "model_ans": "liberal arts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> liberal arts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What guide states the Univeristy of Chicago is known for their heavy workload and academic difficulty?",
        "answers": [
            "Uni in the USA",
            "Uni in the USA",
            "Uni in the USA"
        ],
        "model_ans": "The Princeton Review",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Princeton Review </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the private day school for K-12 students the university runs?",
        "answers": [
            "University of Chicago Laboratory Schools",
            "University of Chicago Laboratory Schools",
            "University of Chicago Laboratory Schools"
        ],
        "model_ans": "University Laboratory School",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University Laboratory School </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the residential treatment program the university runs?",
        "answers": [
            "the Sonia Shankman Orthogenic School",
            "Sonia Shankman Orthogenic School",
            "the Sonia Shankman Orthogenic School"
        ],
        "model_ans": "University Residential Treatment Program",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University Residential Treatment Program </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many public charter schools does the university run?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Urban Education Institute help run?",
        "answers": [
            "four public charter schools",
            "four public charter schools",
            "public charter schools on the South Side of Chicago"
        ],
        "model_ans": "Chicago Public Schools",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago Public Schools </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the Hyde Park Day School located?",
        "answers": [
            "the University of Chicago campus",
            "University of Chicago campus",
            "the University of Chicago campus"
        ],
        "model_ans": "Chicago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The University of Chicago Library system has how many libraries in total?",
        "answers": [
            "six",
            "six",
            "six"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How man volumes does the The University of Chicago Library system hold?",
        "answers": [
            "9.8 million",
            "9.8 million",
            "9.8 million"
        ],
        "model_ans": "11 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 11 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name given to the university's main library?",
        "answers": [
            "the Regenstein Library",
            "Regenstein Library",
            "the Regenstein Library"
        ],
        "model_ans": "University Library",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University Library </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the Joe and Rika Mansueto Library constructed?",
        "answers": [
            "2011",
            "2011",
            "2011"
        ],
        "model_ans": "2009\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2009\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many volumes does the John Crerar Library roughly hold?",
        "answers": [
            "more than 1.3 million",
            "1.3 million",
            "more than 1.3 million"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many research institutes does the university run on campus?",
        "answers": [
            "12",
            "12",
            "12"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many research centers does the university run on campus?",
        "answers": [
            "113",
            "113",
            "113"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the museum and research center for Near Eastern studies, that is owned by the university?",
        "answers": [
            "the Oriental Institute",
            "Oriental Institute",
            "the Oriental Institute"
        ],
        "model_ans": "Oriental Institute",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oriental Institute </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What lab does the university have a joint stake in? ",
        "answers": [
            "Fermilab",
            "Fermilab",
            "Fermilab"
        ],
        "model_ans": "University of California, Berkeley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University of California, Berkeley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the Apache Point Observatory located?",
        "answers": [
            "Sunspot, New Mexico",
            "Sunspot, New Mexico",
            "Sunspot, New Mexico"
        ],
        "model_ans": "New Mexico",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Mexico </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What role in economics did the university play a major part in?",
        "answers": [
            "shaping ideas about the free market",
            "shaping ideas about the free market",
            "shaping ideas about the free market"
        ],
        "model_ans": "Keynesian economics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Keynesian economics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the first self-sustained man-made nuclear reaction?",
        "answers": [
            "Chicago Pile-1",
            "Chicago Pile-1"
        ],
        "model_ans": "Chicago Pile-1",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago Pile-1 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the name of the experiment that tested how life originated?",
        "answers": [
            "Miller\u2013Urey experiment",
            "Miller\u2013Urey experiment",
            "Chicago Pile-1"
        ],
        "model_ans": "Miller-Urey experiment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Urey experiment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was REM sleep discovered?",
        "answers": [
            "1953",
            "1953",
            "1953"
        ],
        "model_ans": "1953",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1953 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Since what year did the university offer a doctorate in music composition?",
        "answers": [
            "1933",
            "1933",
            "1933"
        ],
        "model_ans": "1950",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Since what year did the university offer a doctorate in Cinema & Media studies?",
        "answers": [
            "2000",
            "2000",
            "2000"
        ],
        "model_ans": "1970",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1970 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the university start having a bachelor's degree program in Cinema & Media studies?",
        "answers": [
            "1996",
            "1996",
            "1996"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the university start having a bachelor's degree program in theater & performance studies?",
        "answers": [
            "2002",
            "2002",
            "2002"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Around roughly how many students enroll yearly in creative and performing arts classes?",
        "answers": [
            "Several thousand",
            "Several thousand",
            "Several thousand"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the fall quarter of 2014, how many students signed up for the college?",
        "answers": [
            "5,792",
            "5,792",
            "5,792"
        ],
        "model_ans": "1000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the fall quarter of 2014, how many students signed up for the university's four graduate divisions?",
        "answers": [
            "3,468",
            "3,468",
            "3,468"
        ],
        "model_ans": "1,200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the fall quarter of 2014, how many students signed up for the university's professional schools?",
        "answers": [
            "5,984",
            "5,984",
            "5,984"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the fall quarter of 2014, how many students signed up for the university's  in total?",
        "answers": [
            "15,244",
            "15,244",
            "15,244"
        ],
        "model_ans": "3000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3000 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who made up 19% of the student body in the 2012 Spring Quarter? ",
        "answers": [
            "international students",
            "international students",
            "international students"
        ],
        "model_ans": "Asian students",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Asian students </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Maroons are apart of what association?",
        "answers": [
            "the University Athletic Association",
            "University Athletic Association (UAA)",
            "University Athletic Association (UAA)"
        ],
        "model_ans": "Major League Baseball",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Major League Baseball </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Maroons compete in what league division?",
        "answers": [
            "NCAA's Division III",
            "NCAA's Division III"
        ],
        "model_ans": "Caribbean Premier League",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Caribbean Premier League </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The university was a founding force behind what conference?",
        "answers": [
            "the Big Ten Conference",
            "Big Ten Conference",
            "the Big Ten Conference"
        ],
        "model_ans": "Ivy League",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ivy League </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What player first won the Heisman Trophy for the university?",
        "answers": [
            "Jay Berwanger",
            "Jay Berwanger",
            "Jay Berwanger"
        ],
        "model_ans": "Jay Berwanger",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jay Berwanger </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did the university eventually leave the conference?",
        "answers": [
            "Robert Maynard Hutchins de-emphasized varsity athletics",
            "University President Robert Maynard Hutchins de-emphasized varsity athletics",
            "University President Robert Maynard Hutchins de-emphasized varsity athletics in 1939"
        ],
        "model_ans": "No information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No information </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Roughly how many clubs are ran at the university?",
        "answers": [
            "over 400",
            "over 400",
            "over 400"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the organization in charge of running the clubs at the university?",
        "answers": [
            "Recognized Student Organizations",
            "Recognized Student Organizations (RSOs)"
        ],
        "model_ans": "Student Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Student Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What club won 118 tournaments and 15 national championships?",
        "answers": [
            "the University of Chicago College Bowl Team",
            "University of Chicago College Bowl Team",
            "University of Chicago College Bowl Team"
        ],
        "model_ans": "Manchester United",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Manchester United </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the country's longest continuously running student film society?",
        "answers": [
            "Doc Films",
            "Doc Films",
            "Doc Films"
        ],
        "model_ans": "The University of Oxford",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The University of Oxford </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the student improvisational theater troupe?",
        "answers": [
            "Off-Off Campus",
            "Off-Off Campus",
            "Off-Off Campus"
        ],
        "model_ans": "Second City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Second City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who makes up the Student Government?",
        "answers": [
            "graduate and undergraduate students",
            "graduate and undergraduate students",
            "graduate and undergraduate students elected to represent members from their respective academic unit"
        ],
        "model_ans": "Students",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Students </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who leads the Student Government?",
        "answers": [
            "an Executive Committee",
            "Executive Committee",
            "an Executive Committee"
        ],
        "model_ans": "The President",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The President </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many vice presidents are on the Student Board?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Roughly how much is the Student Government's budget?",
        "answers": [
            "greater than $2 million",
            "$2 million",
            "greater than $2 million"
        ],
        "model_ans": "$100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many fraternities are apart of the university?",
        "answers": [
            "fifteen",
            "fifteen",
            "fifteen"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many sororities are apart of the university?",
        "answers": [
            "seven",
            "seven",
            "seven"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the co-ed community service fraternity?",
        "answers": [
            "Alpha Phi Omega",
            "Alpha Phi Omega",
            "Alpha Phi Omega"
        ],
        "model_ans": "Alpha Phi Omega",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alpha Phi Omega </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many sororities belong to the National Panhellenic Conference?",
        "answers": [
            "Alpha Phi Omega",
            "Four",
            "Four"
        ],
        "model_ans": "26\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "26\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many fraternities form the University of Chicago Interfraternity Council?",
        "answers": [
            "ten",
            "ten",
            "ten"
        ],
        "model_ans": "15",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 15 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what month is the university's scavenger hunt?",
        "answers": [
            "May",
            "May",
            "May"
        ],
        "model_ans": "October",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did the scavenger hunt begin?",
        "answers": [
            "1987",
            "1987",
            "1987"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does FOTA stand for?",
        "answers": [
            "Festival of the Arts",
            "Festival of the Arts",
            "Festival of the Arts"
        ],
        "model_ans": "Federation of the Automobile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Federation of the Automobile </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the winter festival held in January that is based on fitness? ",
        "answers": [
            "Kuviasungnerk/Kangeiko",
            "Kuviasungnerk/Kangeiko",
            "Kuviasungnerk/Kangeiko"
        ],
        "model_ans": "Winter Fitness Festival",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Winter Fitness Festival </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the university's summer festival?",
        "answers": [
            "Summer Breeze",
            "Summer Breeze",
            "Summer Breeze"
        ],
        "model_ans": "SummerFest",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> SummerFest </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Microsoft CEO is also an alumni of the University of Chicago?",
        "answers": [
            "Satya Nadella",
            "Satya Nadella",
            "Satya Nadella"
        ],
        "model_ans": "Satya Nadella",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Satya Nadella </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the founder of the Oracle Corporation?",
        "answers": [
            "Larry Ellison",
            "Larry Ellison",
            "Larry Ellison"
        ],
        "model_ans": "Larry Ellison",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Larry Ellison </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is the third riches man in America?",
        "answers": [
            "Larry Ellison",
            "Larry Ellison",
            "Larry Ellison"
        ],
        "model_ans": "Warren Buffett",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warren Buffett </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Goldman Sachs CEO is also an alumni of the University of Chicago?",
        "answers": [
            "Jon Corzine",
            "Jon Corzine",
            "Jon Corzine"
        ],
        "model_ans": "Lloyd Blankfein",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lloyd Blankfein </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who founded McKinsey & Company?",
        "answers": [
            "James O. McKinsey",
            "James O. McKinsey",
            "James O. McKinsey"
        ],
        "model_ans": "James McKinsey",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James McKinsey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the founder of modern community organizing?",
        "answers": [
            "Saul Alinsky",
            "Saul Alinsky",
            "Saul Alinsky"
        ],
        "model_ans": "Saul Alinsky",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saul Alinsky </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What alumni was also Obama's campaign adviser?",
        "answers": [
            "David Axelrod",
            "David Axelrod",
            "David Axelrod"
        ],
        "model_ans": "Valerie Jarrett",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Valerie Jarrett </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What alumni was also an Attorney General and a federal judge?",
        "answers": [
            "Robert Bork",
            "Robert Bork",
            "Robert Bork"
        ],
        "model_ans": "Janet Reno",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Janet Reno </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What alumni is also the Governor of the Bank of Japan?",
        "answers": [
            "Masaaki Shirakawa",
            "Masaaki Shirakawa",
            "Masaaki Shirakawa"
        ],
        "model_ans": "Haruhiko Kuroda",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Haruhiko Kuroda </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What prohibition agent was also an alumni at the university?",
        "answers": [
            "Eliot Ness",
            "Eliot Ness",
            "Eliot Ness"
        ],
        "model_ans": "Eliot Ness",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eliot Ness </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What alumni member also write the bestseller Before I Fall?",
        "answers": [
            "Lauren Oliver",
            "Lauren Oliver",
            "Lauren Oliver"
        ],
        "model_ans": "Lauren Oliver",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lauren Oliver </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the Pulitzer Prize novelist who was also a university alumni? ",
        "answers": [
            "Philip Roth",
            "Philip Roth",
            "Philip Roth"
        ],
        "model_ans": "Michael Chabon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Chabon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What alumni wrote \"The Closing of the American Mind\"?",
        "answers": [
            "Allan Bloom",
            "Allan Bloom",
            "Allan Bloom"
        ],
        "model_ans": "Allan Bloom",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Allan Bloom </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What alumni wrote \"The Good War\"?",
        "answers": [
            "Studs Terkel",
            "Studs Terkel",
            "Studs Terkel"
        ],
        "model_ans": "Studs Terkel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Studs Terkel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the American writer and satirist who is also a university alumni?",
        "answers": [
            "Kurt Vonnegut",
            "Kurt Vonnegut",
            "Kurt Vonnegut"
        ],
        "model_ans": "Kurt Vonnegut",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kurt Vonnegut </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What minimalist composer is also a university graduate?",
        "answers": [
            "Philip Glass",
            "Philip Glass",
            "Philip Glass"
        ],
        "model_ans": "Steve Reich",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Steve Reich </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the Bungie Inc. founder who is also a university graduate?",
        "answers": [
            "Alex Seropian",
            "Alex Seropian",
            "Alex Seropian"
        ],
        "model_ans": "Alex Seropian",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Alex Seropian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What video game series did Alex Seropian make?",
        "answers": [
            "Halo",
            "Halo",
            "Halo"
        ],
        "model_ans": "Real Arcade",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Real Arcade </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What American actor is also a university graduate?",
        "answers": [
            "Ed Asner",
            "Ed Asner",
            "Ed Asner"
        ],
        "model_ans": "Tom Hanks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Hanks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What comedian is also a university graduate? ",
        "answers": [
            "Mike Nichols",
            "Mike Nichols",
            "Mike Nichols"
        ],
        "model_ans": "Dave Chappelle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dave Chappelle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What astronomers is also a university alumni member?",
        "answers": [
            "Carl Sagan",
            "Carl Sagan",
            "Carl Sagan"
        ],
        "model_ans": "Neil deGrasse Tyson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neil deGrasse Tyson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What NASA astronaut is also a university alumni member?",
        "answers": [
            "John M. Grunsfeld",
            "John M. Grunsfeld",
            "John M. Grunsfeld"
        ],
        "model_ans": "Mae Jemison",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mae Jemison </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What popular environmentalist is also a university alumni member?",
        "answers": [
            "David Suzuki,",
            "David Suzuki",
            "David Suzuki"
        ],
        "model_ans": "David Suzuki",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Suzuki </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who developed the lithium-ion battery?",
        "answers": [
            "John B. Goodenough",
            "John B. Goodenough",
            "John B. Goodenough"
        ],
        "model_ans": "Sony",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sony </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What geochemist developed the uranium-lead dating method into lead-lead dating?",
        "answers": [
            "Clair Cameron Patterson",
            "Clair Cameron Patterson",
            "Clair Cameron Patterson"
        ],
        "model_ans": "Clair Patterson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Clair Patterson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Nobel Memorial Prize in Economic Sciences winner is also a university alumni member?",
        "answers": [
            "Milton Friedman",
            "Milton Friedman",
            "Milton Friedman"
        ],
        "model_ans": "Paul Krugman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Krugman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What British Prime minister advisor is also a university alumni member?",
        "answers": [
            "George Stigler",
            "George Stigler",
            "George Stigler"
        ],
        "model_ans": "Dominic Cummings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dominic Cummings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first American to win the Nobel Memorial Prize in Economic Sciences?",
        "answers": [
            "Paul Samuelson",
            "Paul Samuelson",
            "Paul Samuelson"
        ],
        "model_ans": "Paul Samuelson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Samuelson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What university alumni member was known for his work on portfolio theory?",
        "answers": [
            "Eugene Fama",
            "Eugene Fama",
            "Eugene Fama"
        ],
        "model_ans": "Harry Markowitz",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harry Markowitz </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What anthropologists are also university alumni members?",
        "answers": [
            "David Graeber and Donald Johanson",
            "David Graeber",
            "David Graeber and Donald Johanson"
        ],
        "model_ans": "Margaret Mead",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Margaret Mead </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What chess grandmaster is also a university alumni?",
        "answers": [
            "Samuel Reshevsky",
            "Samuel Reshevsky",
            "Samuel Reshevsky"
        ],
        "model_ans": "Bobby Fischer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bobby Fischer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What conservative international relations scholar is also a university alumni?",
        "answers": [
            "Samuel P. Huntington",
            "Samuel P. Huntington",
            "Samuel P. Huntington"
        ],
        "model_ans": "John J. Mearsheimer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John J. Mearsheimer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who calculated the speed of light?",
        "answers": [
            "A. A. Michelson",
            "A. A. Michelson",
            "A. A. Michelson"
        ],
        "model_ans": "Ole R\u00f8mer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ole R\u00f8mer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who discovered the Compton Effect?",
        "answers": [
            "Arthur H. Compton",
            "Robert A. Millikan",
            "Arthur H. Compton"
        ],
        "model_ans": "JJ Thomson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>JJ Thomson</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who invented the first nuclear reactor?",
        "answers": [
            "Enrico Fermi",
            "Enrico Fermi",
            "Enrico Fermi"
        ],
        "model_ans": "Enrico Fermi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enrico Fermi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is also known at the father of the hydrogen bomb?",
        "answers": [
            "Edward Teller",
            "Edward Teller",
            "Edward Teller"
        ],
        "model_ans": "J. Robert Oppenheimer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> J. Robert Oppenheimer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the second female Nobel laureate ?",
        "answers": [
            "Maria Goeppert-Mayer",
            "Maria Goeppert-Mayer",
            "Maria Goeppert-Mayer"
        ],
        "model_ans": "Marie Curie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marie Curie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Egyptologist was also apart of the university's faculty?",
        "answers": [
            "James Henry Breasted",
            "James Henry Breasted",
            "James Henry Breasted"
        ],
        "model_ans": "Zahi Hawass",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zahi Hawass </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What mathematician was also apart of the university's faculty?",
        "answers": [
            "Alberto Calder\u00f3n",
            "Alberto Calder\u00f3n",
            "Alberto Calder\u00f3n"
        ],
        "model_ans": "Isaac Newton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Isaac Newton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What meteorologist was also apart of the university's faculty?",
        "answers": [
            "Ted Fujita",
            "Ted Fujita",
            "Ted Fujita"
        ],
        "model_ans": "Jim Cantore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jim Cantore </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who developed the actinide concept?",
        "answers": [
            "Yuan T. Lee",
            "Yuan T. Lee",
            "Glenn T. Seaborg"
        ],
        "model_ans": "Glenn T. Seaborg",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Glenn T. Seaborg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What cancer researchers were also apart of the university's faculty?",
        "answers": [
            "Charles Brenton Huggins and Janet Rowley",
            "Charles Brenton Huggins and Janet Rowley",
            "Charles Brenton Huggins and Janet Rowley"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Hank Paulson is the former Chairman and CEO of what banking firm?",
        "answers": [
            "Goldman Sachs",
            "Goldman Sachs",
            "Goldman Sachs"
        ],
        "model_ans": "Goldman Sachs",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Goldman Sachs </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is the governor of India's central bank?",
        "answers": [
            "Raghuram Rajan",
            "Raghuram Rajan",
            "Raghuram Rajan"
        ],
        "model_ans": "Reserve Bank of India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reserve Bank of India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Shakespeare scholar is currently on the university's faculty?",
        "answers": [
            "David Bevington",
            "David Bevington",
            "John Mearsheimer and Robert Pape"
        ],
        "model_ans": "Harold Bloom",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harold Bloom </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What well known political scientists are currently on the university's faculty?",
        "answers": [
            "John Mearsheimer and Robert Pape",
            "John Mearsheimer and Robert Pape"
        ],
        "model_ans": "I am not aware of any specific well-known political scientists currently on the university's faculty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not aware of any specific well-known political scientists currently on the university's faculty </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What paleontologists are currently on the university's faculty?",
        "answers": [
            "Neil Shubin and Paul Sereno",
            "Neil Shubin and Paul Sereno",
            "Neil Shubin and Paul Sereno"
        ],
        "model_ans": "Dr. Mark Norell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dr. Mark Norell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Chinese name for the Yuan dynasty?",
        "answers": [
            "Yu\u00e1n Ch\u00e1o",
            "Yu\u00e1n Ch\u00e1o",
            "\u5143\u671d"
        ],
        "model_ans": "Yuan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Yuan dynasty's official name?",
        "answers": [
            "the Great Yuan",
            "the Great Yuan",
            "the Great Yuan"
        ],
        "model_ans": "Da Yuan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Da Yuan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who started the Yuan dynasty?",
        "answers": [
            "Kublai Khan",
            "Kublai Khan",
            "Kublai Khan"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who led the Mongolian Borjigin clan?",
        "answers": [
            "Kublai Khan",
            "Kublai Khan",
            "Kublai Khan"
        ],
        "model_ans": "Genghis Khan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Genghis Khan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Khan formally declare the Yuan dynasty?",
        "answers": [
            "1271",
            "1271",
            "1271"
        ],
        "model_ans": "1271",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1271 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What non-Chinese empire did the Yuan dynasty succeed?",
        "answers": [
            "Mongol Empire",
            "Mongol Empire",
            "Mongol Empire"
        ],
        "model_ans": "Mongol Empire",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongol Empire </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What dynasty came before the Yuan?",
        "answers": [
            "Song dynasty",
            "Mongol Empire",
            "the Song dynasty"
        ],
        "model_ans": "Song",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Song </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What dynasty came after the Yuan?",
        "answers": [
            "Ming dynasty",
            "Ming dynasty",
            "the Ming dynasty"
        ],
        "model_ans": "Ming",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ming </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Kublai Khan's grandfather?",
        "answers": [
            "Genghis Khan",
            "Genghis Khan",
            "Genghis Khan"
        ],
        "model_ans": "Genghis Khan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Genghis Khan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Khan establish the Great Yuan?",
        "answers": [
            "1271",
            "1271",
            "1271"
        ],
        "model_ans": "1271",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1271 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What writing inspired the name Great Yuan?",
        "answers": [
            "the Commentaries on the Classic of Changes (I Ching)",
            "the Commentaries on the Classic of Changes"
        ],
        "model_ans": "Confucian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Confucian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Yuan dynasty called in Mongolian?",
        "answers": [
            "Dai \u00d6n Ulus, also rendered as Ikh Yuan \u00dcls or Yekhe Yuan Ulus",
            "Dai \u00d6n Ulus",
            "Dai \u00d6n Ulus"
        ],
        "model_ans": "Da Yuan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Da Yuan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Yeke Mongghul Ulus mean?",
        "answers": [
            "Great Mongol State",
            "Great Mongol State",
            "Great Mongol State"
        ],
        "model_ans": "Mongolian Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongolian Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What nominal title did Yuan emperors have?",
        "answers": [
            "Great Khan",
            "Great Khan",
            "Great Khan"
        ],
        "model_ans": "Huangdi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Huangdi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which tribes did Genghis Khan unite?",
        "answers": [
            "Mongol and Turkic tribes",
            "Mongol and Turkic tribes",
            "the Mongol and Turkic tribes"
        ],
        "model_ans": "Mongols",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Genghis Khan become Great Khan?",
        "answers": [
            "1206",
            "1206",
            "1206"
        ],
        "model_ans": "1206\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1206\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Genghis's 3rd son?",
        "answers": [
            "\u00d6gedei Khan",
            "\u00d6gedei Khan",
            "\u00d6gedei Khan"
        ],
        "model_ans": "Jochi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jochi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Mongke Khan become Great Khan?",
        "answers": [
            "1251",
            "1251",
            "1251"
        ],
        "model_ans": "1246\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1246\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Kublai Khan's relation to Ogedei Khan?",
        "answers": [
            "nephew",
            "nephew",
            "nephew"
        ],
        "model_ans": "Son",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Son </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Han Chinese want to help the Mongols fight?",
        "answers": [
            "the Jin",
            "Jin",
            "the Jin"
        ],
        "model_ans": "Tibetans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tibetans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Khitan leader defected to the Mongols?",
        "answers": [
            "Xiao Zhala",
            "Xiao Zhala",
            "Xiao Zhala"
        ],
        "model_ans": "Yel\u00fc Chucai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yel\u00fc Chucai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Han Chinese leader defected to the Mongols?",
        "answers": [
            "Shi Tianze, Liu Heima",
            "Shi Tianze, Liu Heima",
            "Shi Tianze, Liu Heima"
        ],
        "model_ans": "Li Jing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Li Jing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many soldiers were in each Tumen?",
        "answers": [
            "10,000",
            "10,000",
            "10,000"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Khitan Tumens were there?",
        "answers": [
            "3",
            "three"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What ethnicity was Shi Tianze?",
        "answers": [
            "Han Chinese",
            "Han Chinese",
            "Han Chinese"
        ],
        "model_ans": "Manchu",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manchu </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what dynasty did Tianze live?",
        "answers": [
            "Jin dynasty",
            "Jin dynasty",
            "Jin"
        ],
        "model_ans": "Han",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Han </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of interethnic marriage became common in the Jin dynasty?",
        "answers": [
            "between Han and Jurchen",
            "marriage between Han and Jurchen",
            "Han and Jurchen"
        ],
        "model_ans": "Interfaith marriage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Interfaith marriage </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Shi Tianze's father?",
        "answers": [
            "Shi Bingzhi",
            "Shi Bingzhi",
            "Shi Bingzhi"
        ],
        "model_ans": "Shi Tang",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shi Tang </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What dynasty did Zhang Rhou help attack?",
        "answers": [
            "Song dynasty",
            "Song dynasty",
            "the Song dynasty"
        ],
        "model_ans": "Qin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Qin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who led a Mongol attack on the Song dynasty?",
        "answers": [
            "M\u00f6ngke Khan",
            "M\u00f6ngke Khan",
            "M\u00f6ngke Khan"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Mongke Khan attack the Song dynasty?",
        "answers": [
            "southern China",
            "southern China",
            "in southern China"
        ],
        "model_ans": "Xiangyang",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Xiangyang </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Mongke Khan die?",
        "answers": [
            "1259",
            "1259",
            "in 1259"
        ],
        "model_ans": "1251",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1251 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who challenged Kublai Khan's right to succeed Mongke Khan?",
        "answers": [
            "Ariq B\u00f6ke",
            "Ariq B\u00f6ke",
            "Ariq B\u00f6ke"
        ],
        "model_ans": "Ariq B\u00f6ke",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ariq B\u00f6ke </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Chinese era name did Kublai adopt?",
        "answers": [
            "Zhongtong",
            "Zhongtong. Ariq B\u00f6ke",
            "Zhongtong"
        ],
        "model_ans": "Yuan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Kaidu's grandfather?",
        "answers": [
            "Ogedei",
            "Ogedei",
            "Ogedei"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did the Song dynasty continue to cause problems for Kublai?",
        "answers": [
            "south",
            "the south",
            "the western frontier"
        ],
        "model_ans": "Mongolia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongolia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Kublai make the ruler of Korea?",
        "answers": [
            "Wonjong",
            "prince Wonjong",
            "prince Wonjong"
        ],
        "model_ans": "Goryeo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Goryeo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Korea border Kublai's territory?",
        "answers": [
            "northeast",
            "northeast",
            "the northeast"
        ],
        "model_ans": "Mongolia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongolia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Li Tan lead a revolt?",
        "answers": [
            "1262",
            "1262",
            "1262"
        ],
        "model_ans": "1935",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1935 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Kublai's government have to balance between?",
        "answers": [
            "preserving Mongol interests in China and satisfying the demands of his Chinese subjects",
            "preserving Mongol interests in China and satisfying the demands of his Chinese subjects",
            "preserving Mongol interests in China and satisfying the demands of his Chinese subjects"
        ],
        "model_ans": "Mongol Empire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongol Empire </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What natural resources did the Chinese government have a monopoly on?",
        "answers": [
            "salt and iron",
            "salt and iron",
            "salt and iron"
        ],
        "model_ans": "Salt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Salt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What administrative division did Kublai leave unmodified?",
        "answers": [
            "local administrative structure of past Chinese dynasties",
            "local administrative structure",
            "local"
        ],
        "model_ans": "Mongolia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongolia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many societal class divisions were in the plan Kublai rejected?",
        "answers": [
            "three, later four",
            "four",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who would have been the lowest-ranked class?",
        "answers": [
            "Han Chinese",
            "Han Chinese",
            "the Han Chinese"
        ],
        "model_ans": "E",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> E </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where had the Mongol capital been before Kublai moved it?",
        "answers": [
            "Karakorum",
            "Karakorum",
            "Karakorum"
        ],
        "model_ans": "Karakorum",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Karakorum </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where did Kublai move the Mongol capital to?",
        "answers": [
            "Khanbaliq",
            "Khanbaliq",
            "Khanbaliq"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Kublai move the Mongol capital?",
        "answers": [
            "1264",
            "1264",
            "1264"
        ],
        "model_ans": "1260\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1260\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What city later became Beijing?",
        "answers": [
            "Zhongdu",
            "Zhongdu",
            "Zhongdu"
        ],
        "model_ans": "Khanbaliq",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Khanbaliq </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What rituals did Kublai follow to help his image?",
        "answers": [
            "Confucian propriety and ancestor veneration",
            "Confucian propriety and ancestor veneration",
            "Confucian propriety and ancestor veneration"
        ],
        "model_ans": "Taoist rituals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taoist rituals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kinds of growth did Kublai encourage?",
        "answers": [
            "commercial, scientific, and cultural",
            "commercial, scientific, and cultural",
            "commercial, scientific, and cultural"
        ],
        "model_ans": "Trade",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trade </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does 'Pax Mongolica' mean?",
        "answers": [
            "Mongol peace",
            "Mongol peace",
            "Mongol peace"
        ],
        "model_ans": "Peace of Mongolia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Peace of Mongolia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the Grand Canal start?",
        "answers": [
            "southern China",
            "southern China",
            "southern China"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Kublai extend the Grand Canal to?",
        "answers": [
            "Daidu in the north",
            "Daidu",
            "Daidu"
        ],
        "model_ans": "Hangzhou",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hangzhou </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who described Kublai's China to Europe?",
        "answers": [
            "Marco Polo",
            "Marco Polo",
            "Marco Polo"
        ],
        "model_ans": "Marco Polo",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marco Polo </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who did Duke Yansheng Kong Duanyou flee with?",
        "answers": [
            "the Song Emperor",
            "Song Emperor",
            "the Song Emperor to Quzhou"
        ],
        "model_ans": "Wang",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wang </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Jin dynasty begin?",
        "answers": [
            "1115",
            "1115",
            "1115"
        ],
        "model_ans": "265 CE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 265 CE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Jin dynasty end?",
        "answers": [
            "1234",
            "1234",
            "1234"
        ],
        "model_ans": "1644",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1644 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was appointed as the replacement for Duke Yansheng Kong Duanyou?",
        "answers": [
            "Kong Duancao",
            "Kong Duancao",
            "Kong Duancao"
        ],
        "model_ans": "Yansheng Kong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yansheng Kong </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people in Quzhou are descended from Confucius?",
        "answers": [
            "30,000",
            "30,000",
            "30,000"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Kublai build his administration's strength?",
        "answers": [
            "northern China",
            "northern China",
            "northern China"
        ],
        "model_ans": "Xanadu",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Xanadu </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Kublai attack Xiangyang?",
        "answers": [
            "between 1268 and 1273",
            "between 1268 and 1273",
            "between 1268 and 1273"
        ],
        "model_ans": "1273",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1273 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What area was Kublai trying to capture by attacking Xiangyang?",
        "answers": [
            "Yangzi River basin",
            "Yangzi River basin",
            "the Song dynasty"
        ],
        "model_ans": "Southern Song Dynasty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Southern Song Dynasty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Song dynasty's capital?",
        "answers": [
            "Hangzhou",
            "Hangzhou",
            "Hangzhou"
        ],
        "model_ans": "Hangzhou",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hangzhou </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the final Song emperor die?",
        "answers": [
            "drowned",
            "drowned",
            "drowned"
        ],
        "model_ans": "poisoned",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> poisoned </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Kublai's administration running out of money?",
        "answers": [
            "after 1279",
            "after 1279",
            "after 1279"
        ],
        "model_ans": "1369",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1369 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What interfered with Kublai's second invasion of Japan?",
        "answers": [
            "an inauspicious typhoon",
            "inauspicious typhoon",
            "inauspicious typhoon"
        ],
        "model_ans": "The Mongol Empire's decline",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Mongol Empire's decline </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the Tran dynasty rule?",
        "answers": [
            "Annam (Dai Viet)",
            "Annam",
            "Annam"
        ],
        "model_ans": "Vietnam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vietnam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what battle were the Mongols defeated by the Tran?",
        "answers": [
            "Battle of B\u1ea1ch \u0110\u1eb1ng",
            "Battle of B\u1ea1ch \u0110\u1eb1ng",
            "the Battle of B\u1ea1ch \u0110\u1eb1ng"
        ],
        "model_ans": "Battle of Xuanwu Gate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Battle of Xuanwu Gate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were the Mongols defeated by the Tran?",
        "answers": [
            "1288",
            "1288",
            "1288"
        ],
        "model_ans": "1288",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1288 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Dali conquered by the Yuan?",
        "answers": [
            "1253",
            "1253",
            "1253"
        ],
        "model_ans": "1279",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1279 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who had Kublai wanted to succeed him?",
        "answers": [
            "his eldest son, Zhenjin",
            "Zhenjin",
            "Zhenjin"
        ],
        "model_ans": "M\u00f6ngke Khan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> M\u00f6ngke Khan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Zhenjin die?",
        "answers": [
            "before Kublai in 1285",
            "1285",
            "1285"
        ],
        "model_ans": "1323\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1323\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Temur Khan's Chinese-style name?",
        "answers": [
            "Emperor Chengzong",
            "Emperor Chengzong",
            "Emperor Chengzong"
        ],
        "model_ans": "Haiyan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Haiyan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Temur rule?",
        "answers": [
            "1294 to 1307",
            "1294 to 1307",
            "from 1294 to 1307"
        ],
        "model_ans": "1370-1405\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1370-1405\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the 4th to rule the Yuan dynasty?",
        "answers": [
            "Buyantu Khan",
            "Buyantu Khan",
            "Buyantu Khan"
        ],
        "model_ans": "Toghon Tem\u00fcr",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toghon Tem\u00fcr </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Mongol elites wish Buyantu didn't do?",
        "answers": [
            "actively support and adopt mainstream Chinese culture",
            "actively support and adopt mainstream Chinese culture",
            "adopt mainstream Chinese culture"
        ],
        "model_ans": "die",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> die </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who mentored Buyantu?",
        "answers": [
            "Li Meng",
            "Li Meng",
            "Li Meng"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What government department did Buyantu shut down?",
        "answers": [
            "the Department of State Affairs",
            "Department of State Affairs",
            "the Department of State Affairs"
        ],
        "model_ans": "Ministry of Culture",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ministry of Culture </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Buyantu resume testing potential government employees?",
        "answers": [
            "1313",
            "1313",
            "1313"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Ayurbarwada's son?",
        "answers": [
            "Gegeen Khan",
            "Gegeen Khan",
            "Gegeen Khan"
        ],
        "model_ans": "Zara Yabgu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zara Yabgu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Geegen the emperor?",
        "answers": [
            "1321 to 1323",
            "1321 to 1323",
            "from 1321 to 1323"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Gegeen appoint as grand chancellor?",
        "answers": [
            "Baiju",
            "Baiju",
            "Baiju"
        ],
        "model_ans": "Tseren",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tseren </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did 'Da Yuan Tong Zhi' mean?",
        "answers": [
            "\"the comprehensive institutions of the Great Yuan\"",
            "the comprehensive institutions of the Great Yuan",
            "the comprehensive institutions of the Great Yuan"
        ],
        "model_ans": "Da Yuan Tong Zhi means \"Comprehensive Gazette of the Great Yuan\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Da Yuan Tong Zhi means \"Comprehensive Gazette of the Great Yuan\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many rival princes were involved in assassinating Gegeen?",
        "answers": [
            "five",
            "five",
            "five"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Yesun Temur die?",
        "answers": [
            "Shangdu",
            "Shangdu",
            "Shangdu"
        ],
        "model_ans": "Samarkand",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Samarkand </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the civil war against Ragibagh also called?",
        "answers": [
            "the War of the Two Capitals",
            "War of the Two Capitals",
            "the War of the Two Capitals"
        ],
        "model_ans": "Ragibagh War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ragibagh War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long after a banquet with Tugh Temur did Kusala die?",
        "answers": [
            "four days",
            "four days",
            "four days"
        ],
        "model_ans": "10 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was thought to have killed Tugh Temur?",
        "answers": [
            "El Tem\u00fcr",
            "El Tem\u00fcr"
        ],
        "model_ans": "Muhammad Sultan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad Sultan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who took the throne after Kusala's death?",
        "answers": [
            "Tugh Tem\u00fcr",
            "Tugh Tem\u00fcr",
            "Tugh Tem\u00fcr"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Tugh Temur known for?",
        "answers": [
            "his cultural contribution",
            "his cultural contribution",
            "his cultural contribution"
        ],
        "model_ans": "Conquering Samarkand",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Conquering Samarkand </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What academy did Tugh Temur found?",
        "answers": [
            "Academy of the Pavilion of the Star of Literature",
            "Academy of the Pavilion of the Star of Literature",
            "Academy of the Pavilion of the Star of Literature"
        ],
        "model_ans": "Madrasa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Madrasa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Tugh Temur found his academy?",
        "answers": [
            "spring of 1329",
            "1329",
            "the spring of 1329"
        ],
        "model_ans": "1360",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1360 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the most notable publication of Tugh's academy?",
        "answers": [
            "Jingshi Dadian",
            "Jingshi Dadian",
            "Jingshi Dadian"
        ],
        "model_ans": "The Tugh's Academy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Tugh's Academy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What religions did Tugh Temur follow?",
        "answers": [
            "supported Zhu Xi's Neo-Confucianism and also devoted himself in Buddhism",
            "Buddhism",
            "Neo-Confucianism and also devoted himself in Buddhism"
        ],
        "model_ans": "Islam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Tugh Temur die?",
        "answers": [
            "1332",
            "1332",
            "1332"
        ],
        "model_ans": "1363\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1363\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Chinese-style name did Rinchinbal use?",
        "answers": [
            "Emperor Ningzong",
            "Emperor Ningzong",
            "Emperor Ningzong"
        ],
        "model_ans": "Kh\u00fcbilai Khan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kh\u00fcbilai Khan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How old was Toghun Temur when he became emperor?",
        "answers": [
            "13",
            "13",
            "13"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many successors of Kublai was Toghun the last of?",
        "answers": [
            "nine",
            "nine",
            "nine"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which dynasties' histories were officially documented during Toghun's reign?",
        "answers": [
            "Liao, Jin, and Song",
            "Liao, Jin, and Song",
            "the Liao, Jin, and Song"
        ],
        "model_ans": "Yuan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What problems did the Yuan dynasty have near its end?",
        "answers": [
            "struggle, famine, and bitterness",
            "struggle, famine, and bitterness",
            "struggle, famine, and bitterness"
        ],
        "model_ans": "Mongol invasions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongol invasions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Kublai's successors lose control of the rest of the Mongol empire?",
        "answers": [
            "Mongols beyond the Middle Kingdom saw them as too Chinese",
            "saw them as too Chinese"
        ],
        "model_ans": "The Mongol Empire was divided among Kublai's brothers and other relatives, leading to infighting and eventually the loss of control over the rest of the empire.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Mongol Empire was divided among Kublai's brothers and other relatives, leading to infighting and eventually the loss of control over the rest of the empire. </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who were later Yuan emperors isolated from?",
        "answers": [
            "both the army and the populace",
            "army and the populace",
            "the army and the populace"
        ],
        "model_ans": "Mongols",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were the Yuan armies too weak to stop?",
        "answers": [
            "Outlaws ravaged the country",
            "Outlaws",
            "Outlaws"
        ],
        "model_ans": "Mongol invasion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongol invasion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were later Yuan emperors disinterested in?",
        "answers": [
            "administration",
            "administration",
            "administration"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Buddhism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Yuan people suffer a series of natural disasters?",
        "answers": [
            "From the late 1340s onwards",
            "1340s onwards",
            "the late 1340s"
        ],
        "model_ans": "1368",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What uprising began in 1351?",
        "answers": [
            "the Red Turban Rebellion",
            "Red Turban Rebellion",
            "Red Turban Rebellion"
        ],
        "model_ans": "Peasants' Revolt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Peasants' Revolt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Toghun Temur dismiss Toghtogha?",
        "answers": [
            "fear of betrayal",
            "fear of betrayal",
            "fear of betrayal"
        ],
        "model_ans": "Toghtogha's failure to capture the Ming capital",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toghtogha's failure to capture the Ming capital </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who had Toghtogha tried to defeat?",
        "answers": [
            "the Red Turban rebels",
            "Red Turban rebels",
            "the Red Turban rebels"
        ],
        "model_ans": "Mongke Khan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongke Khan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Ming dynasty in power?",
        "answers": [
            "1368\u20131644",
            "1368\u20131644",
            "1368\u20131644"
        ],
        "model_ans": "1368-1644\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1368-1644\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What encouraged trade under the Yuan?",
        "answers": [
            "The political unity of China and much of central Asia",
            "political unity of China and much of central Asia",
            "political unity"
        ],
        "model_ans": "Marco Polo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marco Polo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What encouraged cultural exchange under the Yuan?",
        "answers": [
            "The Mongols' extensive West Asian and European contacts",
            "The Mongols' extensive West Asian and European contacts"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Buddhism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Yuan's Persian ally?",
        "answers": [
            "the Ilkhanate",
            "Ilkhanate"
        ],
        "model_ans": "Ilkhanate",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ilkhanate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What crops were introduced or popularized in the Yuan?",
        "answers": [
            "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton",
            "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton",
            "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton"
        ],
        "model_ans": "rice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of musical instruments did the Yuan bring to China?",
        "answers": [
            "Western",
            "Western",
            "Western"
        ],
        "model_ans": "Jin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jin </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides Confucianism, Buddhism, and Islam, what religions were tolerated during the Yuan?",
        "answers": [
            "Nestorianism and Roman Catholicism",
            "Nestorianism and Roman Catholicism",
            "Nestorianism and Roman Catholicism"
        ],
        "model_ans": "Taoism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Taoism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What religion did the Yuan discourage, to support Buddhism?",
        "answers": [
            "Taoism",
            "Taoism",
            "Taoism"
        ],
        "model_ans": "Taoism",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Taoism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of practices did the Yuan reintroduce in government?",
        "answers": [
            "Confucian",
            "Confucian governmental practices and examinations",
            "Confucian"
        ],
        "model_ans": "Confucianism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Confucianism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What fields of study were advanced during the Yuan?",
        "answers": [
            "travel literature, cartography, geography, and scientific education",
            "travel literature, cartography, geography, and scientific education",
            "literature, cartography, geography, and scientific education"
        ],
        "model_ans": "Astronomy, Medicine, and Mathematics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Astronomy, Medicine, and Mathematics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first known European to visit China and return?",
        "answers": [
            "Marco Polo",
            "Marco Polo",
            "Marco Polo"
        ],
        "model_ans": "Marco Polo",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marco Polo </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Polo call the Yuan capital?",
        "answers": [
            "Cambaluc",
            "Cambaluc",
            "Cambaluc"
        ],
        "model_ans": "Khanbaliq",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Khanbaliq </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the English title of Polo's book?",
        "answers": [
            "Travels of Marco Polo",
            "Travels of Marco Polo",
            "the Travels of Marco Polo"
        ],
        "model_ans": "The Art of War",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Art of War </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the Italian title of Polo's book?",
        "answers": [
            "Il milione",
            "Il milione",
            "Il milione"
        ],
        "model_ans": "Il mio inseparabile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Il mio inseparabile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did some suspect that Polo learned about China instead of by actually visiting it?",
        "answers": [
            "through contact with Persian traders",
            "through contact with Persian traders",
            "through contact with Persian traders"
        ],
        "model_ans": "Polo learned about China through Marco Polo's father Niccol\u00f2 Polo, who had visited China before Marco Polo did.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Polo learned about China through Marco Polo's father Niccol\u00f2 Polo, who had visited China before Marco Polo did.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What astronomer worked for Kublai?",
        "answers": [
            "Guo Shoujing",
            "Guo Shoujing",
            "Guo Shoujing"
        ],
        "model_ans": "Giovanni de Dondi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Giovanni de Dondi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How accurate did Guo make the reformed lunisolar calendar?",
        "answers": [
            "26 seconds off the modern Gregorian calendar",
            "365.2425 days of the year",
            "365.2425 days of the year"
        ],
        "model_ans": "90%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 90% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Kublai do to prevent famines?",
        "answers": [
            "granaries were ordered built throughout the empire",
            "granaries were ordered built throughout the empire",
            "granaries were ordered built"
        ],
        "model_ans": "He built canals and irrigation systems",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He built canals and irrigation systems </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What city did the Grand Canal reach during the Yuan?",
        "answers": [
            "Beijing",
            "Beijing",
            "Beijing"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What major crop was brought to China from the west?",
        "answers": [
            "sorghum",
            "sorghum",
            "sorghum"
        ],
        "model_ans": "Wheat",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wheat </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Yuan was the first time all of China was ruled by whom?",
        "answers": [
            "non-native Chinese people",
            "non-native Chinese people",
            "non-native Chinese"
        ],
        "model_ans": "Mongols",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Mongols worship?",
        "answers": [
            "the Eternal Heaven",
            "Eternal Heaven",
            "the Eternal Heaven"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Buddhism</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What legitimate dynasty came before the Yuan?",
        "answers": [
            "Song",
            "Song dynasty",
            "the Song dynasty"
        ],
        "model_ans": "Song",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Song </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What legitimate dynasty came after the Yuan?",
        "answers": [
            "Ming",
            "Ming dynasty",
            "the Ming dynasty"
        ],
        "model_ans": "Ming",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ming </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Some Chinese considered the Yuan a legitimate dynasty, but what did other Chinese think it was?",
        "answers": [
            "a period of foreign domination",
            "continuation of the Mongol Empire",
            "a period of foreign domination"
        ],
        "model_ans": "Mongol occupation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongol occupation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What cultures were part of Kublai's administration?",
        "answers": [
            "Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists",
            "Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists.",
            "the Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists"
        ],
        "model_ans": "Mongolian, Chinese",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongolian, Chinese </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What dynasties inspired the Chinese-like elements of Kublai's government?",
        "answers": [
            "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties",
            "native Chinese dynasties",
            "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties"
        ],
        "model_ans": "Mongol",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongol </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who were two of Kublai's Chinese advisers?",
        "answers": [
            "Liu Bingzhong and Yao Shu",
            "Liu Bingzhong and Yao Shu",
            "Liu Bingzhong and Yao Shu"
        ],
        "model_ans": "Marco Polo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Marco Polo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of division of power did Kublai's government have?",
        "answers": [
            "tripartite",
            "tripartite division",
            "tripartite"
        ],
        "model_ans": "Imperial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Imperial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the three parts of Kublai's government?",
        "answers": [
            "civil, military, and censorial offices",
            "civil, military, and censorial",
            "civil, military, and censorial offices"
        ],
        "model_ans": "Executive, Legislative, and Judicial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Executive, Legislative, and Judicial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who had military control during the Yuan?",
        "answers": [
            "the Privy Council",
            "Privy Council",
            "the Privy Council"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When had the Six Ministries existed?",
        "answers": [
            "since the Sui and Tang dynasties",
            "Sui and Tang dynasties",
            "since the Sui and Tang dynasties"
        ],
        "model_ans": "1368-1644",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368-1644 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who were exempt from the Ministry of Justice?",
        "answers": [
            "Mongols and Semuren",
            "Mongols and Semuren",
            "Mongols and Semuren"
        ],
        "model_ans": "Judges",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Judges </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who had no real military power during the Yuan?",
        "answers": [
            "the Ministry of War",
            "Ministry of War",
            "the Ministry of War"
        ],
        "model_ans": "Tibet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tibet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Phags-pa script invented?",
        "answers": [
            "1269",
            "1269",
            "1269"
        ],
        "model_ans": "13th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which languages used the Phags-pa script?",
        "answers": [
            "Mongolian, Tibetan, and Chinese",
            "Mongolian, Tibetan, and Chinese",
            "Mongolian, Tibetan, and Chinese"
        ],
        "model_ans": "Tibetan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tibetan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How well did the Mongol Emperors know Chinese?",
        "answers": [
            "could not master written Chinese, but they could generally converse well",
            "could not master written Chinese, but they could generally converse well",
            "well"
        ],
        "model_ans": "fluently",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fluently </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The mother of which emperor was a concubine?",
        "answers": [
            "Tugh Temur",
            "Tugh Temur",
            "Tugh Temur"
        ],
        "model_ans": "Wu Zetian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wu Zetian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Tugh's Chinese-style name?",
        "answers": [
            "Emperor Wenzong",
            "Emperor Wenzong",
            "Wenzong"
        ],
        "model_ans": "Tugh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tugh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By what year was selling children into slavery common among the Mongols?",
        "answers": [
            "1290",
            "1290",
            "1290"
        ],
        "model_ans": "13th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Kublai ban the international Mongol slave trade?",
        "answers": [
            "1291",
            "1291",
            "1291"
        ],
        "model_ans": "1368",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How were the Mongol garrison families earning money?",
        "answers": [
            "income from the harvests of their Chinese tenants",
            "harvests of their Chinese tenants",
            "harvests of their Chinese tenants"
        ],
        "model_ans": "By farming",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By farming </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of arts flourished in the Yuan?",
        "answers": [
            "painting, mathematics, calligraphy, poetry, and theater",
            "painting, mathematics, calligraphy, poetry, and theater",
            "painting, mathematics, calligraphy, poetry, and theater"
        ],
        "model_ans": "Chinese painting",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chinese painting </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which arts were often practiced together by the same artists?",
        "answers": [
            "painting, poetry, and calligraphy",
            "painting, poetry, and calligraphy",
            "painting, poetry, and calligraphy"
        ],
        "model_ans": "painting and sculpture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> painting and sculpture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What dynasty shared artistic inspiration with the Yuan?",
        "answers": [
            "Song",
            "Song",
            "the Song dynasty"
        ],
        "model_ans": "Ming",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ming </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What form of poetry was developed in the Yuan?",
        "answers": [
            "the qu",
            "the qu",
            "qu"
        ],
        "model_ans": "Ci",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ci </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was a popular type of variety show during the Yuan?",
        "answers": [
            "zaju",
            "zaju",
            "zaju"
        ],
        "model_ans": "Zaju",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zaju </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which khanates had converted to Islam?",
        "answers": [
            "western",
            "Yuan dynasty",
            "western"
        ],
        "model_ans": "Golden Horde, Ilkhanate, Chagatai Khanate, and Timurid Empire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Golden Horde, Ilkhanate, Chagatai Khanate, and Timurid Empire </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which religion did Kublai prefer?",
        "answers": [
            "Buddhism, especially the Tibetan variants",
            "Buddhism",
            "Buddhism"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Buddhism</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Yuan's unofficial state religion?",
        "answers": [
            "Tibetan Buddhism",
            "Tibetan Buddhism",
            "Tibetan Buddhism"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Buddhism</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What government agency supervised Buddhist monks?",
        "answers": [
            "Bureau of Buddhist and Tibetan Affairs",
            "Bureau of Buddhist and Tibetan Affairs",
            "the Bureau of Buddhist and Tibetan Affairs"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Kublai's favorite sect of Tibetan Buddhism?",
        "answers": [
            "Sakya",
            "Sakya sect",
            "Sakya sect"
        ],
        "model_ans": "Gelug",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gelug </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Zhu Shijie born?",
        "answers": [
            "1249",
            "1249",
            "1249"
        ],
        "model_ans": "1260",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1260 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Zhu Shijie die?",
        "answers": [
            "1314",
            "1314",
            "1314"
        ],
        "model_ans": "1330",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1330 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What modern math concept did Zhu Shijie do work similar to?",
        "answers": [
            "matrices",
            "matrices",
            "matrices"
        ],
        "model_ans": "Linear Algebra",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Linear Algebra </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of math was advanced during the Yuan?",
        "answers": [
            "polynomial algebra",
            "polynomial algebra",
            "polynomial algebra"
        ],
        "model_ans": "algebra",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> algebra </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Zhu publish 'Jade Mirror of the Four Unknowns'?",
        "answers": [
            "1303",
            "1303",
            "1303"
        ],
        "model_ans": "1368",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Guo Shoujing do for calendars?",
        "answers": [
            "applied mathematics to the construction of calendars",
            "applied mathematics",
            "applied mathematics"
        ],
        "model_ans": "He created the calendar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He created the calendar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Gou use for astronomy?",
        "answers": [
            "a cubic interpolation formula",
            "cubic interpolation formula",
            "derived a cubic interpolation formula"
        ],
        "model_ans": "Binoculars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Binoculars </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Chinese name of Gou's calendar?",
        "answers": [
            "Shoushi Li",
            "\u6388\u6642\u66a6",
            "\u6388\u6642\u66a6"
        ],
        "model_ans": "Gou's calendar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gou's calendar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the English name of Gou's calendar?",
        "answers": [
            "Calendar for Fixing the Seasons",
            "Calendar for Fixing the Seasons",
            "Calendar for Fixing the Seasons"
        ],
        "model_ans": "Chinese calendar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chinese calendar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Gou's calendar become the official calendar of the Yuan?",
        "answers": [
            "1281",
            "1281",
            "1281"
        ],
        "model_ans": "1368",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who were otachi?",
        "answers": [
            "non-Mongol physicians",
            "non-Mongol physicians",
            "non-Mongol physicians"
        ],
        "model_ans": "Otachi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Otachi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of medicine did otachi focus on?",
        "answers": [
            "herbal remedies",
            "herbal",
            "herbal remedies"
        ],
        "model_ans": "Traditional Chinese Medicine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Traditional Chinese Medicine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of medicine did Mongol shamans use?",
        "answers": [
            "spiritual cures",
            "spiritual",
            "spiritual"
        ],
        "model_ans": "Herbal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Herbal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What department did Kublai create to train doctors?",
        "answers": [
            "Imperial Academy of Medicine",
            "Imperial Academy of Medicine",
            "Imperial Academy of Medicine"
        ],
        "model_ans": "Medicine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medicine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did Confucians like the medical field?",
        "answers": [
            "it ensured a high income and medical ethics were compatible with Confucian virtues",
            "it ensured a high income and medical ethics were compatible with Confucian virtues",
            "it ensured a high income and medical ethics were compatible with Confucian virtues"
        ],
        "model_ans": "Because they believed in the importance of balance and harmony in the body",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they believed in the importance of balance and harmony in the body </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many schools of medicine were recognized in China?",
        "answers": [
            "four",
            "Four",
            "Four"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the Yuan come to have the 4 schools of medicine?",
        "answers": [
            "inherited from the Jin dynasty",
            "inherited from the Jin dynasty",
            "inherited from the Jin dynasty"
        ],
        "model_ans": "The Yuan dynasty was influenced by the Song dynasty's medical tradition, which was based on the four humors theory.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Yuan dynasty was influenced by the Song dynasty's medical tradition, which was based on the four humors theory. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Chinese medicine spread?",
        "answers": [
            "Chinese physicians were brought along military campaigns by the Mongols",
            "to other parts of the empire",
            "Under the Mongols"
        ],
        "model_ans": "Through trade and cultural exchange",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through trade and cultural exchange </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What techniques did Chinese medicine include?",
        "answers": [
            "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs",
            "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs",
            "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs"
        ],
        "model_ans": "acupuncture, herbal medicine, massage, meditation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> acupuncture, herbal medicine, massage, meditation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Wei Yilin die?",
        "answers": [
            "1347",
            "1347",
            "1347"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was huihui?",
        "answers": [
            "Muslim medicine",
            "Muslim medicine",
            "Muslim medicine"
        ],
        "model_ans": "Huihui is a Chinese term that refers to a type of traditional Chinese music",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Huihui is a Chinese term that refers to a type of traditional Chinese music </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who founded the Office of Western Medicine?",
        "answers": [
            "Jesus the Interpreter",
            "Jesus the Interpreter",
            "Jesus the Interpreter"
        ],
        "model_ans": "French",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> French </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Office of Western Medicine founded?",
        "answers": [
            "1263",
            "1263",
            "1263"
        ],
        "model_ans": "1881",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1881 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What aspect of Western medicine did the Chinese dislike?",
        "answers": [
            "its humoral system",
            "its humoral system",
            "humoral system"
        ],
        "model_ans": "Surgery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Surgery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What philosophies underlay Chinese medicine?",
        "answers": [
            "yin-yang and wuxing",
            "yin-yang and wuxing",
            "yin-yang and wuxing philosophy"
        ],
        "model_ans": "Taoism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Taoism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the Mongols acquire Chinese printing technology?",
        "answers": [
            "through Kingdom of Qocho and Tibetan intermediaries",
            "through Kingdom of Qocho and Tibetan intermediaries",
            "through Kingdom of Qocho and Tibetan intermediaries"
        ],
        "model_ans": "They acquired it from the Chinese",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They acquired it from the Chinese </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who wrote the Nong Shu?",
        "answers": [
            "Wang Zhen",
            "Wang Zhen",
            "Wang Zhen"
        ],
        "model_ans": "Zhu Zaiyu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zhu Zaiyu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was earthenware movable type invented?",
        "answers": [
            "in the 12th century",
            "12th century",
            "the 12th century"
        ],
        "model_ans": "1045 AD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1045 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Ogedei's wife?",
        "answers": [
            "T\u00f6regene Khatun",
            "T\u00f6regene Khatun",
            "T\u00f6regene Khatun"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Imperial Library Directorate established?",
        "answers": [
            "1273",
            "1273",
            "In 1273"
        ],
        "model_ans": "1924",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1924 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Yuan's paper money called?",
        "answers": [
            "chao",
            "chao",
            "the chao"
        ],
        "model_ans": "Jiaozi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jiaozi</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were chao made out of?",
        "answers": [
            "bark of mulberry trees",
            "bark of mulberry trees",
            "bark of mulberry trees"
        ],
        "model_ans": "clay",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> clay </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Yuan begin using bronze printing plates for its money?",
        "answers": [
            "1275",
            "1275",
            "1275"
        ],
        "model_ans": "1368",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1368 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What had the Yuan used to print its money before bronze plates?",
        "answers": [
            "woodblocks",
            "woodblocks",
            "woodblocks"
        ],
        "model_ans": "Paper",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paper </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Il-khanate experiment with paper money?",
        "answers": [
            "1294",
            "1294",
            "1294"
        ],
        "model_ans": "1295",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1295 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Mongolian system did Kublai's government compromise with?",
        "answers": [
            "patrimonial feudalism",
            "patrimonial feudalism",
            "patrimonial feudalism"
        ],
        "model_ans": "Imperial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Imperial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Chinese system did Kublai's government compromise with?",
        "answers": [
            "traditional Chinese autocratic-bureaucratic system",
            "autocratic-bureaucratic",
            "autocratic-bureaucratic system"
        ],
        "model_ans": "Confucianism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Confucianism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who were the Semuren?",
        "answers": [
            "allied groups from Central Asia and the western end of the empire",
            "various allied groups from Central Asia and the western end of the empire",
            "various allied groups"
        ],
        "model_ans": "The Semuren were a group of supernatural beings in Persian mythology",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Semuren were a group of supernatural beings in Persian mythology </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the unequal treatment of Chinese versus Mongols in the Yuan make the dynasty seem?",
        "answers": [
            "colonial",
            "somewhat strong \"colonial\" coloration",
            "colonial"
        ],
        "model_ans": "unstable",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unstable </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where were Persians more successful compared to Chinese in the Yuan?",
        "answers": [
            "Ilkhanate",
            "Ilkhanate",
            "reaching the highest-post in the government"
        ],
        "model_ans": "Persians were more successful in the Yuan dynasty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Persians were more successful in the Yuan dynasty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Mongols bring to China as administrators?",
        "answers": [
            "Central Asian Muslims",
            "Central Asian Muslims",
            "Central Asian Muslims"
        ],
        "model_ans": "Khitan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Khitan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Mongols send to Bukhara as administrators?",
        "answers": [
            "Han Chinese and Khitans",
            "Han Chinese and Khitans",
            "Han Chinese and Khitans"
        ],
        "model_ans": "Chinggis Khan's relatives",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chinggis Khan's relatives </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where in Central Asia did the Han Chinese move?",
        "answers": [
            "Besh Baliq, Almaliq, and Samarqand",
            "Besh Baliq, Almaliq, and Samarqand",
            "Bukhara"
        ],
        "model_ans": "Xinjiang",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Xinjiang </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What types of work did the Han do in Central Asia?",
        "answers": [
            "artisans and farmers",
            "artisans and farmers",
            "artisans and farmers"
        ],
        "model_ans": "Trade",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trade </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was made Governor of Samarqand?",
        "answers": [
            "a Qara-Khitay (Khitan",
            "Ahai",
            "Ahai"
        ],
        "model_ans": "Ahmed Shah Massoud",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ahmed Shah Massoud </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Yuan policies did Muslims dislike?",
        "answers": [
            "restricting Halal slaughter and other Islamic practices like circumcision",
            "circumcision",
            "restricting Halal slaughter and other Islamic practices like circumcision"
        ],
        "model_ans": "Capital controls",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Capital controls </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Jewish practice did the Yuan ban?",
        "answers": [
            "Kosher butchering",
            "Kosher butchering"
        ],
        "model_ans": "Judaism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Judaism</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who founded the Ming dynasty?",
        "answers": [
            "Zhu Yuanzhang",
            "Zhu Yuanzhang",
            "thanks"
        ],
        "model_ans": "Zhu Yuanzhang",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zhu Yuanzhang </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the second meaning of a Chinese word for 'barracks'?",
        "answers": [
            "thanks",
            "thanks",
            "thanks"
        ],
        "model_ans": "hostel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hostel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who revolted in the Ispah Rebellion?",
        "answers": [
            "Muslims in the semu class",
            "Muslims in the semu class",
            "Muslims in the semu class"
        ],
        "model_ans": "The Ispahs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Ispahs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who thought that the Yuan's social class system shouldn't be called social classes?",
        "answers": [
            "Frederick W. Mote",
            "Frederick W. Mote",
            "Frederick W. Mote"
        ],
        "model_ans": "Mao Zedong",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mao Zedong </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Mote think the Yuan class system really represented?",
        "answers": [
            "degrees of privilege",
            "degrees of privilege",
            "degrees of privilege"
        ],
        "model_ans": "Mote thought the Yuan class system represented a hierarchical society",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mote thought the Yuan class system represented a hierarchical society </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There were many Chinese with what unexpected status?",
        "answers": [
            "rich and well socially standing",
            "rich and well",
            "rich and well socially standing"
        ],
        "model_ans": "Taiwanese",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taiwanese </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There were many Mongols with what unexpected status?",
        "answers": [
            "lived in poverty and were ill treated",
            "poverty",
            "poverty and were ill treated"
        ],
        "model_ans": "slaves",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> slaves </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which part of China had people ranked higher in the class system?",
        "answers": [
            "Northern",
            "Northern Chinese",
            "Northern"
        ],
        "model_ans": "Shanghai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shanghai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which part of China had people ranked lower in the class system?",
        "answers": [
            "Southern",
            "Southern Chinese",
            "southern"
        ],
        "model_ans": "South",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> South </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why were Southern Chinese ranked lower?",
        "answers": [
            "southern China withstood and fought to the last",
            "because southern China withstood and fought to the last before caving in",
            "withstood and fought to the last"
        ],
        "model_ans": "Due to the historical influence of Confucianism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Due to the historical influence of Confucianism </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why were Northern Chinese ranked higher?",
        "answers": [
            "The earlier they surrendered to the Mongols, the higher they were placed",
            "The earlier they surrendered to the Mongols",
            "they surrendered"
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Yuan's increase in commerce help?",
        "answers": [
            "private southern Chinese manufacturers and merchants",
            "private southern Chinese manufacturers and merchants",
            "southern Chinese manufacturers and merchants"
        ],
        "model_ans": "Mongols",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the Mongols give control of Korea?",
        "answers": [
            "Uighurs",
            "Uighurs of the Kingdom of Qocho"
        ],
        "model_ans": "Goryeo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Goryeo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the Uighur King of Qocho ranked above?",
        "answers": [
            "the Karluk Kara-Khanid ruler",
            "Karluk Kara-Khanid",
            "the Karluk Kara-Khanid ruler"
        ],
        "model_ans": "Emperor of China",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Emperor of China </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the Karluk Kara-Khanid ruler ranked above?",
        "answers": [
            "the Korean King",
            "Korean King",
            "the Korean King"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why were the Uighurs ranked higher by the Mongols?",
        "answers": [
            "the Uighurs surrendered peacefully without violently resisting",
            "Uighurs surrendered peacefully without violently resisting",
            "surrendered peacefully without violently resisting"
        ],
        "model_ans": "Because they were skilled archers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they were skilled archers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What region of China is Hebei part of?",
        "answers": [
            "The Central Region",
            "Central Region",
            "Central"
        ],
        "model_ans": "North",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who governed the Central Region in the Yuan?",
        "answers": [
            "the Central Secretariat",
            "Central Secretariat",
            "the Central Secretariat"
        ],
        "model_ans": "Kublai Khan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kublai Khan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the Central Secretariat based?",
        "answers": [
            "Khanbaliq",
            "Khanbaliq",
            "Khanbaliq"
        ],
        "model_ans": "New Delhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Delhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What modern city did Khanbaliq become?",
        "answers": [
            "Beijing",
            "Beijing",
            "Beijing"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the Chinese name for the Central Secretariat?",
        "answers": [
            "Zhongshu Sheng",
            "Zhongshu Sheng",
            "Zhongshu Sheng"
        ],
        "model_ans": "Zh\u014dngy\u0101ng M\u00ecsh\u016b T\u01d4w\u011bi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zh\u014dngy\u0101ng M\u00ecsh\u016b T\u01d4w\u011bi </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The immune system protects organisms against what?",
        "answers": [
            "disease",
            "disease",
            "disease",
            "disease"
        ],
        "model_ans": "pathogens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pathogens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the agents the immune system detects known as?",
        "answers": [
            "pathogens",
            "pathogens",
            "pathogens",
            "pathogens"
        ],
        "model_ans": "antigens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antigens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which part of the immune system protects the brain?",
        "answers": [
            "neuroimmune system",
            "neuroimmune",
            "neuroimmune",
            "neuroimmune system"
        ],
        "model_ans": "Blood-brain barrier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Blood-brain barrier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What separates the neuroimmune system and peripheral immune system in humans?",
        "answers": [
            "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier",
            "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers",
            "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers",
            "fluid\u2013brain barriers"
        ],
        "model_ans": "Blood-brain barrier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Blood-brain barrier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the agents detected by the immune system called?",
        "answers": [
            "pathogens",
            "pathogens",
            "pathogens",
            "pathogens"
        ],
        "model_ans": "Antigens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antigens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two different types of immunity?",
        "answers": [
            "humoral immunity versus cell-mediated immunity",
            "humoral immunity versus cell-mediated immunity",
            "humoral immunity versus cell-mediated immunity",
            "humoral immunity versus cell-mediated immunity"
        ],
        "model_ans": "Innate immunity and adaptive immunity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Innate immunity and adaptive immunity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the two major subsystems of the immune system?",
        "answers": [
            "innate immune system versus the adaptive immune system",
            "innate immune system versus the adaptive immune system",
            "innate immune system versus the adaptive immune system",
            "innate immune system versus the adaptive immune system"
        ],
        "model_ans": "Innate and Adaptive",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Innate and Adaptive </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the immune system of the brained known as?",
        "answers": [
            "neuroimmune system",
            "neuroimmune",
            "neuroimmune system",
            "neuroimmune system"
        ],
        "model_ans": "Immune system",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Immune system </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What happens when the immune system less active than normal?",
        "answers": [
            "Immunodeficiency",
            "Immunodeficiency",
            "Immunodeficiency occurs"
        ],
        "model_ans": "The immune system is less effective at fighting off infections and diseases",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The immune system is less effective at fighting off infections and diseases </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for a hyperactive immune system that attacks normal tissues?",
        "answers": [
            "autoimmunity",
            "autoimmunity",
            "autoimmunity"
        ],
        "model_ans": "Autoimmune disease",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Autoimmune disease </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What field involves the study of the immune system?",
        "answers": [
            "Immunology",
            "Immunology",
            "Immunology"
        ],
        "model_ans": "Immunology",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Immunology </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What acquired condition results in immunodeficiency in humans?",
        "answers": [
            "HIV/AIDS",
            "HIV/AIDS",
            "HIV/AIDS"
        ],
        "model_ans": "HIV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> HIV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who won the Nobel Prize in 1905?",
        "answers": [
            "Robert Koch",
            "Robert Koch",
            "Robert Koch"
        ],
        "model_ans": "Marie Curie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marie Curie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Robert Koch prove was the cause of infectious disease?",
        "answers": [
            "microorganisms",
            "microorganisms",
            "microorganisms"
        ],
        "model_ans": "Bacteria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bacteria</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What virus did Walter Reed discover?",
        "answers": [
            "yellow fever virus",
            "yellow fever",
            "yellow fever virus"
        ],
        "model_ans": "Yellow Fever",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yellow Fever </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the first known historical reference to immunity?",
        "answers": [
            "Athens in 430 BC",
            "430 BC",
            "430 BC."
        ],
        "model_ans": "400 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 400 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of immune systems are found in all plants and animals?",
        "answers": [
            "Innate immune systems",
            "Innate",
            "Innate immune systems"
        ],
        "model_ans": "Innate immune system",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Innate immune system </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What immune system is activated by the innate response?",
        "answers": [
            "adaptive immune system",
            "adaptive",
            "the adaptive immune system"
        ],
        "model_ans": "Inflammatory response",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Inflammatory response </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What allows the adaptive immune system to react faster and more strongly each subsequent time a pathogen is encountered?",
        "answers": [
            "immunological memory",
            "immunological memory",
            "immunological memory"
        ],
        "model_ans": "Immunological memory",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Immunological memory </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the first line of defense against pathogens that prevents them from entering an organism?",
        "answers": [
            "physical barriers",
            "physical barriers",
            "physical barriers"
        ],
        "model_ans": "Epithelial barrier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Epithelial barrier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The adaptive immune system must distinguish between what types of molecules?",
        "answers": [
            "self and non-self",
            "self and non-self",
            "self and non-self molecules"
        ],
        "model_ans": "self and non-self",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> self and non-self </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What molecules are parts of the body of an organism in immunology?",
        "answers": [
            "self molecules",
            "self",
            "self molecules"
        ],
        "model_ans": "cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What molecules are recognized as foreign by the immune system?",
        "answers": [
            "non-self molecules",
            "non-self",
            "non-self molecules"
        ],
        "model_ans": "antigens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antigens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What term is shorthand for antibody generators?",
        "answers": [
            "antigens",
            "antigens",
            "antigens"
        ],
        "model_ans": "Ab",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ab </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Antigens bind to what in order to elicit a response of the immune system?",
        "answers": [
            "specific immune receptors",
            "receptors",
            "specific immune receptors"
        ],
        "model_ans": "antibodies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antibodies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What part of the innate immune system identifies microbes and triggers immune response?",
        "answers": [
            "pattern recognition receptors",
            "receptors",
            "cells"
        ],
        "model_ans": "Toll-like receptors",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Toll-like receptors </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "For most organisms, what is the dominant system of defense?",
        "answers": [
            "innate immune system",
            "innate immune system",
            "The innate immune"
        ],
        "model_ans": "Immune system",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Immune system </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Pattern recognition receptors recognize components present in broad groups of what?",
        "answers": [
            "microorganisms",
            "microorganisms",
            "microorganisms"
        ],
        "model_ans": "pathogens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pathogens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The innate immune system responds in a generic way, meaning it is what?",
        "answers": [
            "non-specific",
            "non-specific",
            "non-specific"
        ],
        "model_ans": "non-specific",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> non-specific </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a mechanical barrier in insects that protects the insect?",
        "answers": [
            "exoskeleton",
            "exoskeleton",
            "exoskeleton"
        ],
        "model_ans": "Exoskeleton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exoskeleton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an example of a mechanical barrier on leaves?",
        "answers": [
            "The waxy cuticle",
            "waxy cuticle",
            "waxy cuticle"
        ],
        "model_ans": "Cuticle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cuticle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What responses protect the lungs by mechanically ejecting pathogens from the respiratory system?",
        "answers": [
            "coughing and sneezing",
            "coughing and sneezing",
            "coughing and sneezing"
        ],
        "model_ans": "Cilia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cilia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is secreted by the respiratory tract to trap microorganisms?",
        "answers": [
            "mucus",
            "mucus",
            "mucus"
        ],
        "model_ans": "Mucus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mucus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The flushing action of what expels pathogens from the eyes?",
        "answers": [
            "tears",
            "tears",
            "tears"
        ],
        "model_ans": "Tears",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tears </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the anitmicrobial peptides secreted by the skin called?",
        "answers": [
            "\u03b2-defensins",
            "\u03b2-defensins",
            "\u03b2-defensins"
        ],
        "model_ans": "Defensins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Defensins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What enzymes in saliva are antibacterial in nature?",
        "answers": [
            "lysozyme and phospholipase A2",
            "lysozyme and phospholipase A2",
            "lysozyme"
        ],
        "model_ans": "lysozyme",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lysozyme </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Semen contains what in order to kill pathogens?",
        "answers": [
            "defensins and zinc",
            "defensins and zinc",
            "defensins"
        ],
        "model_ans": "enzymes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> enzymes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What compounds in the stomach protect against ingested pathogens?",
        "answers": [
            "gastric acid and proteases",
            "gastric acid and proteases",
            "gastric acid"
        ],
        "model_ans": "Gastric acid and mucus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gastric acid and mucus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Vaginal secretions serve as a chemical protective barrier following what?",
        "answers": [
            "menarche",
            "menarche",
            "menarche"
        ],
        "model_ans": "sexual intercourse",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sexual intercourse </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What serves as a biological barrier by competing for space and food in the GI tract?",
        "answers": [
            "commensal flora",
            "commensal flora",
            "commensal flora"
        ],
        "model_ans": "Probiotics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Probiotics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Most antibiotics target bacteria and don't affect what class of organisms?",
        "answers": [
            "fungi",
            "fungi",
            "fungi"
        ],
        "model_ans": "viruses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> viruses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What probiotic flora is found in unpasteurized yogurt?",
        "answers": [
            "lactobacilli",
            "lactobacilli",
            "lactobacilli"
        ],
        "model_ans": "Lactobacillus acidophilus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lactobacillus acidophilus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Commensal flora can change what specific conditions of their environment in the gastrointestinal tract?",
        "answers": [
            "pH or available iron",
            "pH or available iron",
            "balance of microbial populations"
        ],
        "model_ans": "pH",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pH </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one of the first responses the immune system has to infection?",
        "answers": [
            "Inflammation",
            "Inflammation",
            "Inflammation"
        ],
        "model_ans": "Inflammation",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Inflammation </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What causes the symptoms of inflammation?",
        "answers": [
            "increased blood flow into tissue",
            "increased blood flow into tissue",
            "increased blood flow into tissue"
        ],
        "model_ans": "Chemical mediators",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chemical mediators </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What compounds are released by injured or infected cells, triggering inflammation?",
        "answers": [
            "eicosanoids and cytokines",
            "eicosanoids and cytokines",
            "eicosanoids"
        ],
        "model_ans": "cytokines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cytokines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Eicosanoids include what compounds that result in fever and blood vessel dilation?",
        "answers": [
            "prostaglandins",
            "prostaglandins",
            "prostaglandins"
        ],
        "model_ans": "Prostaglandins",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prostaglandins </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What cytokines are responsible for communication between white blood cells?",
        "answers": [
            "interleukins",
            "interleukins",
            "interleukins"
        ],
        "model_ans": "Interleukins",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Interleukins </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of cells engulf or eat pathogens and foreign particles?",
        "answers": [
            "phagocytes",
            "phagocytes",
            "phagocytes"
        ],
        "model_ans": "Phagocytes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Phagocytes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Phagocytes can be called to a specific location by what?",
        "answers": [
            "cytokines",
            "cytokines",
            "cytokines"
        ],
        "model_ans": "chemotaxis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> chemotaxis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When a pathogen has been eaten by a phagocyte it becomes trapped in what vesicle?",
        "answers": [
            "phagosome",
            "phagosome",
            "phagosome"
        ],
        "model_ans": "phagolysosome",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> phagolysosome </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is formed when a phagosome fuses with a lysosome?",
        "answers": [
            "phagolysosome",
            "phagolysosome",
            "phagolysosome"
        ],
        "model_ans": "Autophagosome",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Autophagosome </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Phagocytosis first evolved as means of doing what?",
        "answers": [
            "acquiring nutrients",
            "acquiring nutrients",
            "acquiring nutrients"
        ],
        "model_ans": "capturing and digesting bacteria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> capturing and digesting bacteria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are two types of phagocytes that travel through the body to find invading pathogens?",
        "answers": [
            "Neutrophils and macrophages",
            "Neutrophils and macrophages",
            "Neutrophils and macrophages"
        ],
        "model_ans": "Neutrophils and macrophages",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neutrophils and macrophages </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the most abundant kind of phagocyte?",
        "answers": [
            "Neutrophils",
            "Neutrophils",
            "Neutrophils"
        ],
        "model_ans": "Neutrophils",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neutrophils </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What percentage of leukocytes do neutrophils represent?",
        "answers": [
            "50% to 60%",
            "50% to 60%",
            "50% to 60%"
        ],
        "model_ans": "50-70%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50-70% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the process in which neutrophils move towards the site of inflammation called?",
        "answers": [
            "chemotaxis",
            "chemotaxis",
            "chemotaxis"
        ],
        "model_ans": "chemotaxis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> chemotaxis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a regulatory factor produced by macrophages?",
        "answers": [
            "interleukin 1",
            "interleukin 1",
            "interleukin 1"
        ],
        "model_ans": "IL-10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IL-10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are white blood cells known as?",
        "answers": [
            "Leukocytes",
            "Leukocytes",
            "Leukocytes"
        ],
        "model_ans": "Leukocytes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leukocytes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What cells are the second arm of the innate immune system?",
        "answers": [
            "Leukocytes (white blood cells)",
            "white blood cells",
            "white blood cells"
        ],
        "model_ans": "Dendritic cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dendritic cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Innate cells can act as mediators in the activation of what branch of the immune system?",
        "answers": [
            "adaptive immune system",
            "adaptive",
            "adaptive immune system."
        ],
        "model_ans": "adaptive",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> adaptive </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are three kinds of phagocytes?",
        "answers": [
            "macrophages, neutrophils, and dendritic cells",
            "macrophages, neutrophils, and dendritic cells",
            "macrophages, neutrophils, and dendritic cells"
        ],
        "model_ans": "Neutrophils, Monocytes, and Macrophages",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neutrophils, Monocytes, and Macrophages </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the phagocytes that are located in tissues in contact with the external environment called?",
        "answers": [
            "Dendritic cells",
            "Dendritic cells",
            "Dendritic cells"
        ],
        "model_ans": "Mucosal phagocytes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mucosal phagocytes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Dendritic cells are named that because they resemble what?",
        "answers": [
            "neuronal dendrites",
            "neuronal dendrites",
            "neuronal dendrites"
        ],
        "model_ans": "trees",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> trees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are one of the key cell types of the adaptive immune system?",
        "answers": [
            "T cells",
            "T cells",
            "T cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Dendritic cells present antigens to what cells of the adaptive nervous system?",
        "answers": [
            "T cells",
            "T cells",
            "T cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is one part of the innate immune system that doesn't attack microbes directly?",
        "answers": [
            "Natural killer cells",
            "Natural killer cells",
            "Natural killer cells"
        ],
        "model_ans": "Complement system",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Complement system </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Natural killer cells recognize cells that should be targeted by a condition known as what?",
        "answers": [
            "missing self",
            "missing self",
            "missing self"
        ],
        "model_ans": "MHC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> MHC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Missing self desribes cells that only have small amounts of what cell-surface marker?",
        "answers": [
            "MHC I (major histocompatibility complex)",
            "MHC I",
            "MHC I (major histocompatibility complex)"
        ],
        "model_ans": "CD45",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> CD45 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "MHC antigens on normal body cells are recognized by what receptor on NK cells?",
        "answers": [
            "killer cell immunoglobulin receptors (KIR",
            "killer cell immunoglobulin",
            "killer cell immunoglobulin receptors (KIR)"
        ],
        "model_ans": "CD94",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> CD94 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what types of organisms did the adaptive immune system first evolve?",
        "answers": [
            "vertebrates",
            "vertebrates",
            "early vertebrates"
        ],
        "model_ans": "Jurassic fish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jurassic fish</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The adaptive immune system recognizes non-self antigens during a process called what?",
        "answers": [
            "antigen presentation",
            "antigen presentation",
            "antigen presentation"
        ],
        "model_ans": "immunogenicity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> immunogenicity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Antigen specificity  allows responses that are specific to certain types of what?",
        "answers": [
            "pathogens or pathogen-infected cells",
            "pathogens",
            "pathogen-infected cells"
        ],
        "model_ans": "pathogens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pathogens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the two major subtypes of T cells?",
        "answers": [
            "killer T cell and the helper T cell",
            "killer T cell and the helper T cell",
            "the killer T cell and the helper T cell"
        ],
        "model_ans": "CD4+ T cells and CD8+ T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CD4+ T cells and CD8+ T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of T cells have the purpose of modulating the immune response?",
        "answers": [
            "regulatory T cells",
            "regulatory",
            "regulatory T cells"
        ],
        "model_ans": "Regulatory T cells",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Regulatory T cells </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Killer T cells can only recognize antigens coupled to what kind of molecules?",
        "answers": [
            "Class I MHC molecules",
            "Class I MHC",
            "Class I MHC molecules"
        ],
        "model_ans": "MHC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MHC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Helper and regulatory T cells can only recognize antigens coupled to what kind of molecules?",
        "answers": [
            "Class II MHC molecules",
            "Class II MHC",
            "Class II MHC molecules"
        ],
        "model_ans": "MHC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MHC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What class of T cells recognizes intact antigens that are not associated with MHC receptors?",
        "answers": [
            "\u03b3\u03b4 T cells",
            "\u03b3\u03b4",
            "\u03b3\u03b4 T cells"
        ],
        "model_ans": "CD4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> CD4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of T cells kill cells that are infected with pathogens?",
        "answers": [
            "Killer T cells",
            "Killer T",
            "Killer T cells"
        ],
        "model_ans": "CD8 T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CD8 T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the receptor that killer T cells use to bind to specific antigens that are complexed with the MHC Class 1 receptor of another cell?",
        "answers": [
            "T cell receptor (TCR)",
            "T cell receptor",
            "T cell receptor (TCR)"
        ],
        "model_ans": "TCR",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> TCR </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What co-receptor on the T cell helps in recognizing the MHC-antigen complex?",
        "answers": [
            "CD8",
            "CD8",
            "CD8"
        ],
        "model_ans": "CD4",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CD4 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When an activated killer T cell finds cells where the MHC 1 receptor has specific antigens, it releases cytotoxins such as what?",
        "answers": [
            "perforin",
            "perforin",
            "perforin"
        ],
        "model_ans": "perforin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> perforin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What toxin induces apoptosis in the target cell?",
        "answers": [
            "granulysin",
            "granulysin",
            "granulysin (a protease)"
        ],
        "model_ans": "Cytotoxin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cytotoxin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What co-receptor recruits molecules inside the T cell that are responsible for cell activation?",
        "answers": [
            "CD4 co-receptor",
            "CD4",
            "CD4 co-receptor"
        ],
        "model_ans": "CD4",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CD4 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many receptors on a helper T cell must be bound to a MHC:antigen complex in order for the cell to be activated?",
        "answers": [
            "around 200\u2013300",
            "around 200\u2013300",
            "around 200\u2013300"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The receptors on a killer T cell must bind to how many MHC: antigen complexes in order to activate the cell?",
        "answers": [
            "a single MHC:antigen molecule",
            "single",
            "a single MHC:antigen molecule"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Activation of a helper T cell causes it to release what chemicals that influence cell activity?",
        "answers": [
            "cytokines",
            "cytokines",
            "cytokines"
        ],
        "model_ans": "cytokines",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cytokines </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a ligand on the cell surface that is upregulated after helper T cell activation?",
        "answers": [
            "CD40 ligand",
            "CD40",
            "CD40 ligand"
        ],
        "model_ans": "CD40",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> CD40 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Gamma delta T cells share the characteristics of what other types of T cells?",
        "answers": [
            "helper T cells, cytotoxic T cells and NK cells",
            "helper T cells, cytotoxic T cells",
            "helper T cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Gamma delta T cells have a different version of what receptor?",
        "answers": [
            "alternative T cell receptor (TCR)",
            "T cell",
            "T cell receptor (TCR)"
        ],
        "model_ans": "T cell receptor",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cell receptor </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of T cells help with both innnate and adaptive immunity?",
        "answers": [
            "\u03b3\u03b4 T cells",
            "\u03b3\u03b4",
            "\u03b3\u03b4 T cells"
        ],
        "model_ans": "Tc1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tc1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Gamma delta T cells rearrange TCR genes to produce what?",
        "answers": [
            "receptor diversity",
            "receptor diversity",
            "receptor diversity"
        ],
        "model_ans": "T cell receptors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cell receptors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of human T cells respond to common molecules produced by microbes?",
        "answers": [
            "V\u03b39/V\u03b42 T cells",
            "V\u03b39/V\u03b42",
            "V\u03b39/V\u03b42 T cells"
        ],
        "model_ans": "CD4 T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CD4 T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of cell identifies pathogens when the antibodies on its surface complex with a specific foreign antigen?",
        "answers": [
            "B cell",
            "B",
            "A B cell"
        ],
        "model_ans": "Dendritic cell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dendritic cell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the process by which the antigen/antibody complex is processed in to peptides?",
        "answers": [
            "proteolysis",
            "proteolysis",
            "proteolysis"
        ],
        "model_ans": "Proteolysis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Proteolysis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the matching helper T cell release when it binds with the MHC:antigen complex of the B cell?",
        "answers": [
            "lymphokines",
            "lymphokines",
            "lymphokines"
        ],
        "model_ans": "Interleukin-2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Interleukin-2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When B cells and T cells begin to replicate, what do some of their offspring cells become?",
        "answers": [
            "long-lived memory cells",
            "long-lived memory cells",
            "long-lived memory cells"
        ],
        "model_ans": "Plasma cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plasma cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The function of long-lived memory cells is an example of what kind of immune response?",
        "answers": [
            "adaptive",
            "adaptive",
            "strong response"
        ],
        "model_ans": "humoral",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> humoral </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Immunological memory can take what two forms?",
        "answers": [
            "passive short-term memory or active long-term memory",
            "passive short-term memory or active long-term memory",
            "passive short-term memory or active long-term memory"
        ],
        "model_ans": "T cell memory and B cell memory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cell memory and B cell memory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Long-lived memory cells can remember previous encounters with what?",
        "answers": [
            "specific pathogen",
            "pathogen",
            "each specific pathogen"
        ],
        "model_ans": "antigens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antigens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Newborns are vulnerable to infection because they have no previous exposure to what?",
        "answers": [
            "microbes",
            "microbes",
            "microbes"
        ],
        "model_ans": "pathogens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pathogens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What antibody is transported from the mother to baby across the placenta?",
        "answers": [
            "IgG",
            "IgG",
            "IgG"
        ],
        "model_ans": "IgG",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IgG </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Antibodies are transferred to the gut of the infant through what means?",
        "answers": [
            "Breast milk or colostrum",
            "Breast milk",
            "Breast milk or colostrum"
        ],
        "model_ans": "breast milk",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> breast milk </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Antibodies transported from the mother to an infant via the placenta is an example of what type of short-lived immunity?",
        "answers": [
            "passive immunity",
            "passive",
            "passive immunity"
        ],
        "model_ans": "Passive immunity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Passive immunity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Hormones can alter the sensitivity of the immune system, so they can be referred to as what?",
        "answers": [
            "immunomodulators",
            "immunomodulators",
            "immunomodulators"
        ],
        "model_ans": "immunomodulators",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> immunomodulators </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Female sex hormones are immunostimulators of which immune responses?",
        "answers": [
            "adaptive and innate immune responses",
            "both adaptive and innate",
            "adaptive and innate immune responses"
        ],
        "model_ans": "Th1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Th1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an autoimmune disease that affects women preferentially?",
        "answers": [
            "lupus erythematosus",
            "lupus erythematosus",
            "lupus erythematosus"
        ],
        "model_ans": "Lupus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lupus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the effect of testosterone on the male immune system?",
        "answers": [
            "immunosuppressive",
            "immunosuppressive",
            "immunosuppressive"
        ],
        "model_ans": "Testosterone has been shown to have both positive and negative effects on the male immune system.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Testosterone has been shown to have both positive and negative effects on the male immune system. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a protein that is closely intertwined with circadian rhythms?",
        "answers": [
            "NFIL3",
            "NFIL3",
            "NFIL3"
        ],
        "model_ans": "PER2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> PER2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Disruptions in sleep can lead to increase in what chronic conditions?",
        "answers": [
            "heart disease, chronic pain, and asthma",
            "heart disease, chronic pain, and asthma",
            "chronic pain"
        ],
        "model_ans": "cardiovascular disease",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> cardiovascular disease </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of deprivation results in diminished immune response and lower antibody production?",
        "answers": [
            "sleep deprivation",
            "sleep",
            "sleep deprivation"
        ],
        "model_ans": "Malnutrition",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Malnutrition </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is partially responsible for weakened immune response in older individuals?",
        "answers": [
            "decline in hormone levels with age",
            "decline in hormone levels",
            "decline in hormone levels"
        ],
        "model_ans": "Telomere shortening",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Telomere shortening </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "As a person gets older, what does the skin produce less of?",
        "answers": [
            "vitamin D",
            "vitamin D",
            "vitamin D."
        ],
        "model_ans": "collagen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> collagen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The production of what signalling molecules is regulated by the immune system?",
        "answers": [
            "hormones",
            "hormones",
            "hormones"
        ],
        "model_ans": "cytokines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cytokines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Older people get less sun and produce less of what chemical via UVB radiation?",
        "answers": [
            "cholecalciferol",
            "cholecalciferol",
            "cholecalciferol"
        ],
        "model_ans": "Vitamin D",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vitamin D </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of immune cells help to destroy abnormal cells in tumors?",
        "answers": [
            "killer T cells",
            "killer T cells",
            "killer T cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Lots of tumor cells have fewer of what type of molecule on their surface?",
        "answers": [
            "MHC class I molecules",
            "MHC class I",
            "MHC class I molecules"
        ],
        "model_ans": "receptors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> receptors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Tumor antigens are complexed with MHC class I molecules in the same way as what antigens?",
        "answers": [
            "viral antigens",
            "viral",
            "viral antigens"
        ],
        "model_ans": "viral",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> viral </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The immune system also produces what molecules in order to allow for tumor destruction by the complement system?",
        "answers": [
            "antibodies",
            "antibodies",
            "antibodies"
        ],
        "model_ans": "C3b",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> C3b </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Plants lack what kind of immune cells?",
        "answers": [
            "phagocytic cells",
            "phagocytic",
            "phagocytic cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Plant cells respond to the molecules associated with pathogens known as what?",
        "answers": [
            "Pathogen-associated molecular patterns",
            "Pathogen-associated molecular patterns",
            "Pathogen-associated molecular patterns or PAMPs"
        ],
        "model_ans": "elicitors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> elicitors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Cells of the site of an infection in a plant undergo what process to prevent spread of the disease?",
        "answers": [
            "apoptosis",
            "apoptosis",
            "rapid apoptosis"
        ],
        "model_ans": "apoptosis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> apoptosis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a kind of defense response that makes the entire plant resistant to a particular agent?",
        "answers": [
            "Systemic acquired resistance (SAR)",
            "Systemic acquired resistance",
            "Systemic acquired resistance (SAR)"
        ],
        "model_ans": "systemic resistance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> systemic resistance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a mechanism that can help plants block virus replication?",
        "answers": [
            "RNA silencing mechanisms",
            "RNA silencing mechanisms",
            "RNA silencing mechanisms"
        ],
        "model_ans": "RNA interference",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RNA interference </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of disorders are the result of an overactive immune response?",
        "answers": [
            "autoimmune disorders",
            "autoimmune",
            "autoimmune disorders"
        ],
        "model_ans": "Autoimmune disorders",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Autoimmune disorders </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In autoimmune disorders, the immune system doesn't distinguish between what types of cells?",
        "answers": [
            "self and non-self",
            "self and non-self",
            "self and non-self"
        ],
        "model_ans": "self",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> self </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are the specialized cells that eliminate cells that recognize self-antigens located?",
        "answers": [
            "thymus and bone marrow",
            "thymus and bone marrow",
            "thymus and bone marrow"
        ],
        "model_ans": "Thymus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thymus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Under normal conditions, T cells and antibodies produce what kind of peptides?",
        "answers": [
            "\"self\" peptides",
            "self",
            "self\" peptides"
        ],
        "model_ans": "antigens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antigens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of disorders occur when part of the immune system isn't active?",
        "answers": [
            "Immunodeficiencies",
            "Immunodeficiencies",
            "Immunodeficiencies"
        ],
        "model_ans": "Autoimmune disorders",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Autoimmune disorders </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what two age groups is the strength of the immune system reduced?",
        "answers": [
            "the young and the elderly",
            "the young and the elderly",
            "young and the elderly"
        ],
        "model_ans": "Infancy and old age",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Infancy and old age </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "At what age do immune responses typically begin to decline?",
        "answers": [
            "around 50 years of age",
            "50",
            "around 50 years of age"
        ],
        "model_ans": "65",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 65 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are some causes of reduced immune function in developed countries?",
        "answers": [
            "obesity, alcoholism, and drug use",
            "obesity, alcoholism, and drug use",
            "obesity, alcoholism, and drug use"
        ],
        "model_ans": "Sedentary lifestyle, poor diet, lack of sleep, stress, and exposure to environmental toxins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sedentary lifestyle, poor diet, lack of sleep, stress, and exposure to environmental toxins </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the most common cause of immunodeficiency in developing nations?",
        "answers": [
            "malnutrition",
            "malnutrition",
            "malnutrition"
        ],
        "model_ans": "HIV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> HIV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By what process can active immunity be generated in an artificial manner?",
        "answers": [
            "vaccination",
            "vaccination",
            "vaccination"
        ],
        "model_ans": "Vaccination",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vaccination </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the process of vaccination also known as?",
        "answers": [
            "immunization",
            "immunization",
            "immunization"
        ],
        "model_ans": "Immunization",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Immunization </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In the process of vaccination, what is introduced in order to develop a specific immunity?",
        "answers": [
            "an antigen from a pathogen",
            "antigen",
            "antigen from a pathogen"
        ],
        "model_ans": "Antigen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antigen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Vaccination exploits what feature of the human immune system in order to be successful?",
        "answers": [
            "natural specificity of the immune system",
            "natural specificity",
            "the natural specificity"
        ],
        "model_ans": "specificity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> specificity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Bacteria often secrete what kind of proteins to ingest a physical barrier?",
        "answers": [
            "enzymes",
            "enzymes",
            "enzymes"
        ],
        "model_ans": "Exoproteins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Exoproteins </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of system of infection involves inserting a hollow tube into a host cell?",
        "answers": [
            "type III secretion system",
            "type III secretion system",
            "type III secretion system"
        ],
        "model_ans": "Viral",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Viral </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In a type III secretion system, proteins are transported to the host cell in order to do what?",
        "answers": [
            "shut down host defenses",
            "shut down host defenses",
            "shut down host defenses."
        ],
        "model_ans": "manipulate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> manipulate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The success of pathogens is predicated on their ability to do what?",
        "answers": [
            "elude host immune responses",
            "elude host immune responses",
            "ability to elude host immune responses"
        ],
        "model_ans": "adapt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> adapt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who formulated the idea of clonal selection theory of immunity?",
        "answers": [
            "Frank Burnet",
            "Frank Burnet",
            "Frank Burnet"
        ],
        "model_ans": "Jean Dausset",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Dausset</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are two examples of nonself entities in accordance with Frank Burnet's theory?",
        "answers": [
            "pathogens, an allograft",
            "pathogens, an allograft",
            "pathogens, an allograft"
        ],
        "model_ans": "Bacteria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bacteria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the complex \"two-signal\" activation of T cells referred to?",
        "answers": [
            "histocompatibility",
            "histocompatibility",
            "histocompatibility"
        ],
        "model_ans": "T cell receptor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cell receptor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other scientist influence Frank Burnet when he was formulating his theory of immunity?",
        "answers": [
            "Niels Jerne",
            "Niels Jerne",
            "Niels Jerne"
        ],
        "model_ans": "Louis Pasteur",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louis Pasteur </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the most powerful class of anti-inflammatory drugs?",
        "answers": [
            "Glucocorticoids",
            "Glucocorticoids",
            "Glucocorticoids"
        ],
        "model_ans": "Corticosteroids",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Corticosteroids </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Low doses of anti-inflammatories are sometimes used with what classes of drugs?",
        "answers": [
            "cytotoxic or immunosuppressive drugs",
            "cytotoxic or immunosuppressive",
            "Cytotoxic drugs"
        ],
        "model_ans": "NSAIDs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NSAIDs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are two examples of cytotoxic or immunosuppressive drugs?",
        "answers": [
            "methotrexate or azathioprine",
            "methotrexate or azathioprine",
            "methotrexate or azathioprine"
        ],
        "model_ans": "Cyclophosphamide and Methotrexate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cyclophosphamide and Methotrexate </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of an immunosuppressive drug that prevents T cell activity by altering signal transduction pathways?",
        "answers": [
            "cyclosporin",
            "cyclosporin",
            "cyclosporin"
        ],
        "model_ans": "Tacrolimus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tacrolimus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are examples of differentiated effector cells that peak during wake periods?",
        "answers": [
            "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)",
            "cytotoxic natural killer cells and CTLs",
            "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)"
        ],
        "model_ans": "T cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are two anti-inflammatory molecules that peak during awake hours?",
        "answers": [
            "cortisol and catecholamines",
            "cortisol and catecholamines",
            "cortisol and catecholamines"
        ],
        "model_ans": "TNF-alpha and IL-1 beta",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> TNF-alpha and IL-1 beta </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Inflammation occurs during sleep times because of the presence of what molecule?",
        "answers": [
            "melatonin",
            "melatonin",
            "melatonin"
        ],
        "model_ans": "cytokines",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> cytokines </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Melatonin during sleep can actively counteract the production of what?",
        "answers": [
            "free radical production",
            "free radical",
            "free radical production"
        ],
        "model_ans": "cortisol",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cortisol </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does a T cell extend when it encounters a foreign pathogen?",
        "answers": [
            "a vitamin D receptor",
            "extends a vitamin D receptor",
            "vitamin D receptor"
        ],
        "model_ans": "an antigen-presenting cell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> an antigen-presenting cell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the active form of vitamin D known as?",
        "answers": [
            "calcitriol",
            "calcitriol",
            "steroid hormone calcitriol"
        ],
        "model_ans": "calcitriol",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> calcitriol </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the nature of the relationship between T-cells and vitamin D?",
        "answers": [
            "symbiotic relationship",
            "symbiotic",
            "symbiotic relationship"
        ],
        "model_ans": "T-cells are activated by vitamin D",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> T-cells are activated by vitamin D </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What gene is responsible for converting calcidiol into calcitriol?",
        "answers": [
            "gene CYP27B1",
            "CYP27B1",
            "gene CYP27B1"
        ],
        "model_ans": "CYP27B1",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CYP27B1 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than T cells, what other immune cells express CYP27B1?",
        "answers": [
            "dendritic cells, keratinocytes and macrophages",
            "dendritic cells, keratinocytes and macrophages",
            "dendritic cells"
        ],
        "model_ans": "macrophages",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> macrophages </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the proteins that organisms use to identify molecules associated with pathogens?",
        "answers": [
            "Pattern recognition receptors",
            "Pattern recognition receptors",
            "Pattern recognition receptors"
        ],
        "model_ans": "Pattern recognition receptors",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pattern recognition receptors </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the antimicrobial peptides that are the main form of invertebrate systemic immunity called?",
        "answers": [
            "defensins",
            "defensins",
            "defensins"
        ],
        "model_ans": "defensins",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> defensins </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What cell type is also used for immune response in most types of invertebrate life?",
        "answers": [
            "phagocytic cells",
            "phagocytic",
            "phagocytic cells"
        ],
        "model_ans": "Hemocyte",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hemocyte </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What pathway that plays a role in immune response to viruses is present in all eukaryotes?",
        "answers": [
            "RNA interference pathway",
            "RNA interference",
            "RNA interference pathway"
        ],
        "model_ans": "RIG-I-like",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> RIG-I-like </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What molecules of the adaptive immune system only exist in jawed vertebrates?",
        "answers": [
            "immunoglobulins and T cell receptors",
            "immunoglobulins and T cell receptors",
            "immunoglobulins"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are two examples of primitive jawless vertebrates?",
        "answers": [
            "the lamprey and hagfish",
            "lamprey and hagfish",
            "the lamprey and hagfish"
        ],
        "model_ans": "lamprey and hagfish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lamprey and hagfish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Primitive jawless vertebrates possess an array of receptors referred to as what?",
        "answers": [
            "Variable lymphocyte receptors (VLRs)",
            "Variable lymphocyte receptors",
            "Variable lymphocyte receptors (VLRs)"
        ],
        "model_ans": "ampullae of Lorenzini",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ampullae of Lorenzini </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Evolution of what part of the immune system occurred in the evolutionary ancestor of jawed vertebrates?",
        "answers": [
            "adaptive immune system",
            "adaptive",
            "the adaptive immune system"
        ],
        "model_ans": "adaptive immunity",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> adaptive immunity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Invertebrates do not generate what type of cells that are a part of the vertebrate adaptive immune system?",
        "answers": [
            "lymphocytes",
            "lymphocytes",
            "lymphocytes"
        ],
        "model_ans": "T cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the main defense mechanism of bacteria known as?",
        "answers": [
            "the restriction modification system",
            "restriction modification system",
            "restriction modification system"
        ],
        "model_ans": "Peptidoglycan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Peptidoglycan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The restriction modification system is used by bacteria for protection from what pathogens?",
        "answers": [
            "bacteriophages",
            "viral",
            "bacteriophages"
        ],
        "model_ans": "viruses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> viruses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the system by which prokaryotes retain phage gene fragments that they have previously come in contact with?",
        "answers": [
            "CRISPR",
            "CRISPR sequences",
            "CRISPR"
        ],
        "model_ans": "Lateral gene transfer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lateral gene transfer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were the two main theories of immunity at the end of the 19th century?",
        "answers": [
            "\"cellular\" and \"humoral\" theories of immunity",
            "\"cellular\" and \"humoral\"",
            "\"cellular\" and \"humoral\" theories"
        ],
        "model_ans": "The germ theory and the miasma theory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The germ theory and the miasma theory </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the main proponent of the cellular theory of immunity?",
        "answers": [
            "Elie Metchnikoff",
            "Elie Metchnikoff",
            "Elie Metchnikoff"
        ],
        "model_ans": "Rudolph Virchow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rudolph Virchow </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under Elie Metchnikoff's cellular theory, what cells were responsible for immune response?",
        "answers": [
            "phagocytes",
            "phagocytes",
            "phagocytes"
        ],
        "model_ans": "Phagocytes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Phagocytes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What two scientists were proponents of the humoral theory of immunity?",
        "answers": [
            "Robert Koch and Emil von Behring",
            "Robert Koch and Emil von Behring",
            "Robert Koch and Emil von Behring,"
        ],
        "model_ans": "Galen and Hippocrates",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Galen and Hippocrates </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to the humoral theory of immunity, what were the bodies immune agents?",
        "answers": [
            "soluble components (molecules)",
            "soluble components",
            "soluble components (molecules)"
        ],
        "model_ans": "Humors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Humors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Tumors that are able to evade the body's immune response can become what?",
        "answers": [
            "cancers",
            "cancers",
            "cancers"
        ],
        "model_ans": "malignant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> malignant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What receptors do tumor cells often have reduced concentrations of?",
        "answers": [
            "MHC class I molecules",
            "MHC class I",
            "MHC class I molecules"
        ],
        "model_ans": "Tumor suppressor receptors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tumor suppressor receptors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a chemical secreted by tumors that suppresses the immune response?",
        "answers": [
            "cytokine TGF-\u03b2",
            "cytokine TGF-\u03b2",
            "cytokine TGF-\u03b2"
        ],
        "model_ans": "Tumor necrosis factor-alpha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tumor necrosis factor-alpha </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Cytokine TBF-B suppresses the activity of what cell types?",
        "answers": [
            "macrophages and lymphocytes",
            "macrophages and lymphocytes",
            "macrophages and lymphocytes"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name for a response of the immune system that damages the body's native tissues?",
        "answers": [
            "Hypersensitivity",
            "Hypersensitivity",
            "Hypersensitivity"
        ],
        "model_ans": "Autoimmune response",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Autoimmune response </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many classes of immune hypersensitivity are there?",
        "answers": [
            "four classes (Type I \u2013 IV)",
            "four",
            "four classes"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of hypersensitivity is associated with allergies?",
        "answers": [
            "Type I",
            "Type I",
            "Type I hypersensitivity"
        ],
        "model_ans": "Type I",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Type I </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the chemical that mediates Type 1 hypersensitivity?",
        "answers": [
            "IgE",
            "IgE",
            "IgE"
        ],
        "model_ans": "IgE",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IgE </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Antibody-dependent hypersensitivity belongs to what class of hypersensitivity?",
        "answers": [
            "Type II hypersensitivity",
            "Type II",
            "Type II hypersensitivity"
        ],
        "model_ans": "Type III",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Type III </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the process by which pathogens evade the immune system by hiding inside the host cells called?",
        "answers": [
            "intracellular pathogenesis",
            "intracellular pathogenesis",
            "intracellular pathogenesis"
        ],
        "model_ans": "Phagocytosis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Phagocytosis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What food bacteria is an example of intracellular pathogenesis?",
        "answers": [
            "Salmonella",
            "Salmonella",
            "Salmonella"
        ],
        "model_ans": "Listeria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Listeria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the eukaryotic parasite responsible for malaria known as?",
        "answers": [
            "Plasmodium falciparum",
            "Plasmodium falciparum",
            "Plasmodium falciparum"
        ],
        "model_ans": "Plasmodium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Plasmodium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What bacteria lives inside a protective capsule that serves to prevent cell lysis?",
        "answers": [
            "Mycobacterium tuberculosis",
            "Mycobacterium tuberculosis",
            "Mycobacterium tuberculosis"
        ],
        "model_ans": "Streptococcus pneumoniae",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Streptococcus pneumoniae </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What protein does Staphylococcus aureus produce to make antibodies ineffective?",
        "answers": [
            "protein A",
            "G",
            "Streptococcus (protein G)"
        ],
        "model_ans": "Protein A",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Protein A </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the process by which the adaptive immune system is evaded by the chainging of non-essential epitopes called?",
        "answers": [
            "antigenic variation",
            "antigenic variation",
            "antigenic variation"
        ],
        "model_ans": "Antigenic drift",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Antigenic drift </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an example of a virus that uses antigenic variation?",
        "answers": [
            "HIV",
            "HIV",
            "HIV"
        ],
        "model_ans": "HIV",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> HIV </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an example of a parasite that used the antigenic variation strategy to evade destruction?",
        "answers": [
            "Trypanosoma brucei",
            "Trypanosoma brucei",
            "Trypanosoma brucei"
        ],
        "model_ans": "Trypanosoma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trypanosoma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What compounds can be masked with the molecules of the host cell in order for a virus to evade detection?",
        "answers": [
            "antigens",
            "antigens",
            "antigens"
        ],
        "model_ans": "MHC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> MHC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the process by which the immune system identifies tumors called?",
        "answers": [
            "immune surveillance",
            "immune surveillance",
            "immune surveillance"
        ],
        "model_ans": "Immunotherapy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Immunotherapy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the virus in humans that causes cervical cancer?",
        "answers": [
            "human papillomavirus",
            "human papillomavirus",
            "human papillomavirus"
        ],
        "model_ans": "Human Papillomavirus (HPV)",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Human Papillomavirus (HPV) </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an example of an enzyme that can transform skin cells into tumors when expressed at high levels?",
        "answers": [
            "tyrosinase",
            "tyrosinase",
            "tyrosinase"
        ],
        "model_ans": "Ras",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ras </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are cancerous tumors of the skin known as?",
        "answers": [
            "melanomas",
            "melanomas",
            "melanomas"
        ],
        "model_ans": "Carcinomas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carcinomas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the skin cells that can be transformed into tumors known as?",
        "answers": [
            "melanocytes",
            "melanocytes",
            "melanocytes"
        ],
        "model_ans": "Stem cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stem cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what size and larger can drugs elicit a neutralizing immune response?",
        "answers": [
            ">500 Da",
            ">500 Da",
            ">500 Da"
        ],
        "model_ans": "10-100 nanograms",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10-100 nanograms </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of amino acids are overrepresented in epitope regions?",
        "answers": [
            "hydrophilic amino acids",
            "hydrophilic",
            "hydrophilic amino acids"
        ],
        "model_ans": "hydrophobic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hydrophobic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the study of proteins involved in immune response known as?",
        "answers": [
            "Immunoproteomics",
            "Immunoproteomics",
            "Immunoproteomics"
        ],
        "model_ans": "Immunoproteomics",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Immunoproteomics </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There is a public database of epitopes for pathogens known to be recognizable by what cells?",
        "answers": [
            "B cells",
            "B",
            "B cells"
        ],
        "model_ans": "T cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> T cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the field of studying immunogenicity through bioinformatics known as?",
        "answers": [
            "immunoinformatics",
            "immunoinformatics",
            "immunoinformatics"
        ],
        "model_ans": "Immunoinformatics",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Immunoinformatics</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Drop in the blood levels of cortisol and epinephrine results in increase levels of what hormones?",
        "answers": [
            "leptin, pituitary growth hormone, and prolactin",
            "leptin, pituitary growth hormone, and prolactin",
            "leptin"
        ],
        "model_ans": "Insulin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Insulin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Hormones released during sleep support the interaction of T-cells and what species?",
        "answers": [
            "APCs",
            "APCs",
            "APCs"
        ],
        "model_ans": "B-cells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> B-cells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Sleep hormones shift the cytokine balance to which cytokine?",
        "answers": [
            "Th1",
            "one that supports Th1"
        ],
        "model_ans": "anti-inflammatory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> anti-inflammatory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Sleep hormone release supports formation of immune memory by initiating what immune response?",
        "answers": [
            "Th1 immune responses",
            "Th1",
            "Th1 immune responses"
        ],
        "model_ans": "adaptive immune response",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> adaptive immune response </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The immune systems of bacteria have enzymes that protect against infection by what kind of cells?",
        "answers": [
            "bacteriophage",
            "bacteriophage",
            "bacteriophage infections"
        ],
        "model_ans": "viruses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> viruses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are antimicrobial peptides that evolved as immune defense in eukaryotes called?",
        "answers": [
            "defensins",
            "defensins",
            "defensins"
        ],
        "model_ans": "Defensins",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Defensins </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The idea of acquired immunity in jawed vertebrates is the basis of what medical treatment?",
        "answers": [
            "vaccination",
            "vaccination",
            "vaccination"
        ],
        "model_ans": "vaccination",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> vaccination </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the ability to recognize and adapt to new specific pathogens called?",
        "answers": [
            "Adaptive (or acquired) immunity",
            "Adaptive (or acquired) immunity",
            "Adaptive (or acquired) immunity"
        ],
        "model_ans": "Immune memory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Immune memory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Complement proteins bind to what kind of molecules on the surface of microbes in order to elicit an immune response?",
        "answers": [
            "carbohydrates",
            "carbohydrates",
            "carbohydrates"
        ],
        "model_ans": "carbohydrates",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> carbohydrates </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The speed of the killing response of the human immune system is a product of what process?",
        "answers": [
            "signal amplification",
            "signal amplification",
            "signal amplification"
        ],
        "model_ans": "chemotaxis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> chemotaxis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of cascade results when complement proteins bind to microbes and activate their protease activity?",
        "answers": [
            "catalytic cascade",
            "catalytic",
            "catalytic"
        ],
        "model_ans": "classical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> classical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How can the deposition of compliment kill invader cells directly?",
        "answers": [
            "disrupting their plasma membrane",
            "disrupting their plasma membrane",
            "disrupting their plasma membrane."
        ],
        "model_ans": "Complement proteins can directly kill invader cells through the formation of a membrane attack complex (MAC)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Complement proteins can directly kill invader cells through the formation of a membrane attack complex (MAC) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization is the IPCC a part of?",
        "answers": [
            "the United Nations",
            "the United Nations",
            "the United Nations"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What UN organizations established the IPCC?",
        "answers": [
            "the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)",
            "World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP),",
            "the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the UN want to stabilize?",
        "answers": [
            "greenhouse gas concentrations in the atmosphere",
            "greenhouse gas concentrations in the atmosphere",
            "stabilize greenhouse gas concentrations in the atmosphere"
        ],
        "model_ans": "the world",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the world </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the UN's climate change treaty?",
        "answers": [
            "United Nations Framework Convention on Climate Change",
            "United Nations Framework Convention on Climate Change (UNFCCC)",
            "the United Nations Framework Convention on Climate Change (UNFCCC),"
        ],
        "model_ans": "Paris Agreement",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris Agreement </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What UN resolution endorsed the IPCC?",
        "answers": [
            "Resolution 43/53",
            "Resolution 43/53",
            "Resolution 43/53"
        ],
        "model_ans": "1992",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is the chair of the IPCC?",
        "answers": [
            "Hoesung Lee",
            "Hoesung Lee",
            "Hoesung Lee"
        ],
        "model_ans": "Hoesung Lee",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hoesung Lee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What nationality is Hoesung Lee?",
        "answers": [
            "Korean",
            "onomist",
            "Korean"
        ],
        "model_ans": "Korean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Korean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who is the vice-chair of the IPCC?",
        "answers": [
            "Ismail El Gizouli",
            "Ismail El Gizouli",
            "Ismail El Gizouli"
        ],
        "model_ans": "Jean-Pascal van Ypersele",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Pascal van Ypersele </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first chair of the IPCC?",
        "answers": [
            "Bert Bolin",
            "Bert Bolin",
            "Bert Bolin"
        ],
        "model_ans": "Jean Jouzel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Jouzel</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Pachauri resign as chair of the IPCC?",
        "answers": [
            "February 2015",
            "February 2015",
            "February 2015"
        ],
        "model_ans": "2015\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2015\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is on the IPCC Panel?",
        "answers": [
            "representatives appointed by governments and organizations",
            "representatives appointed by governments and organizations",
            "representatives appointed by governments and organizations"
        ],
        "model_ans": "Intergovernmental Panel on Climate Change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Intergovernmental Panel on Climate Change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many people attended the 2003 IPCC meeting?",
        "answers": [
            "350",
            "350",
            "350"
        ],
        "model_ans": "150",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of people attend the IPCC meetings?",
        "answers": [
            "government officials and climate change experts",
            "government officials and climate change experts",
            "government officials and climate change experts"
        ],
        "model_ans": "Scientists",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scientists </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of the IPCC attendees are government representatives?",
        "answers": [
            "about seven-eighths",
            "seven-eighths",
            "about seven-eighths"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the IPCC Trust Fund founded?",
        "answers": [
            "1989",
            "1989",
            "1989"
        ],
        "model_ans": "1989",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1989 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who started the IPCC Trust Fund?",
        "answers": [
            "the United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO)",
            "United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO)",
            "the United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO),"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who funds the IPCC's Secretary?",
        "answers": [
            "World Meteorological Organization",
            "WMO",
            "the WMO"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who funds the IPCC's Deputy Secretary?",
        "answers": [
            "United Nations Environment Programme",
            "UNEP",
            "UNEP"
        ],
        "model_ans": "UN",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UN </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What rules does the IPCC have to follow?",
        "answers": [
            "the Financial Regulations and Rules of the WMO",
            "Financial Regulations and Rules of the WMO",
            "Financial Regulations and Rules of the WMO"
        ],
        "model_ans": "The Intergovernmental Panel on Climate Change (IPCC) follows the rules of the United Nations Framework Convention on Climate Change (UNFCCC) and the Paris Agreement.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Intergovernmental Panel on Climate Change (IPCC) follows the rules of the United Nations Framework Convention on Climate Change (UNFCCC) and the Paris Agreement.</answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the IPCC not do?",
        "answers": [
            "does not carry out research nor does it monitor climate related data",
            "research",
            "carry out research nor does it monitor climate related data"
        ],
        "model_ans": "IPCC does not predict weather forecasts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IPCC does not predict weather forecasts </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do IPCC reports get their information?",
        "answers": [
            "available information about climate change based on published sources",
            "published sources",
            "peer-reviewed sources"
        ],
        "model_ans": "From various sources, including peer-reviewed scientific literature, observations, and data from around the world",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> From various sources, including peer-reviewed scientific literature, observations, and data from around the world </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is 'grey literature'?",
        "answers": [
            "non-peer-reviewed sources",
            "non-peer-reviewed sources",
            "non-peer-reviewed sources"
        ],
        "model_ans": "Grey literature refers to published or unpublished materials that are not commercially available, such as technical reports, conference proceedings, and theses.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Grey literature refers to published or unpublished materials that are not commercially available, such as technical reports, conference proceedings, and theses.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kind of non-peer-reviewed sources does the IPCC use?",
        "answers": [
            "model results, reports from government agencies and non-governmental organizations, and industry journals",
            "model results",
            "model results, reports from government agencies and non-governmental organizations, and industry journals"
        ],
        "model_ans": "grey literature",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> grey literature </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many coordinating lead authors does an IPCC report chapter have?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many lead authors does an IPCC report chapter have?",
        "answers": [
            "ten to fifteen",
            "ten to fifteen",
            "ten to fifteen"
        ],
        "model_ans": "2-5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2-5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many contributing authors does an IPCC report chapter have?",
        "answers": [
            "a somewhat larger number",
            "a somewhat larger number of \"contributing authors\"",
            "a somewhat larger number"
        ],
        "model_ans": "10-30",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10-30 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who assembles the authors' contributions?",
        "answers": [
            "The coordinating lead authors",
            "coordinating lead authors",
            "coordinating lead authors"
        ],
        "model_ans": "Editor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Editor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who do coordinating lead authors report to?",
        "answers": [
            "the Working Group chairs",
            "Working Group chairs",
            "Working Group chairs"
        ],
        "model_ans": "Senior authors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Senior authors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the WG I Summary for Policymakers report say human activities are doing to greenhouse gases?",
        "answers": [
            "substantially increasing the atmospheric concentrations",
            "substantially increasing the atmospheric concentrations of the greenhouse gases",
            "substantially increasing the atmospheric concentrations"
        ],
        "model_ans": "increasing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> increasing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do increased greenhouse gases cause?",
        "answers": [
            "additional warming of the Earth's surface",
            "warming of the Earth's surface",
            "additional warming of the Earth's surface"
        ],
        "model_ans": "Global warming",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Global warming </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of the greenhouse effect is due to carbon dioxide?",
        "answers": [
            "over half",
            "over half",
            "over half"
        ],
        "model_ans": "65%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 65% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the scenario called in which we don't change our greenhouse gas creation practices?",
        "answers": [
            "\"business as usual\" (BAU)",
            "enhanced greenhouse effect",
            "\"business as usual\" (BAU)"
        ],
        "model_ans": "Business as usual",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Business as usual </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much has global mean surface air temperature changed in the last century?",
        "answers": [
            "increased by 0.3 to 0.6 \u00b0C",
            "0.3 to 0.6 \u00b0C",
            "0.3 to 0.6 \u00b0C"
        ],
        "model_ans": "1\u00b0C\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1\u00b0C\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the joint statement on climate change issued?",
        "answers": [
            "2001",
            "2001",
            "2001"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many organizations issued the joint statement on climate change?",
        "answers": [
            "16 national science academies",
            "16",
            "16"
        ],
        "model_ans": "196",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 196 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which journal was the joint statement published in?",
        "answers": [
            "Science",
            "Science",
            "Science"
        ],
        "model_ans": "Nature",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nature </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How sure did the statement say scientists were that temperatures would keep rising?",
        "answers": [
            "at least 90%",
            "at least 90%",
            "at least 90% certain"
        ],
        "model_ans": "95%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 95% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much did the statement predict global surface temperature would increase by 2100?",
        "answers": [
            "between 1.4 and 5.8 \u00b0C above 1990 levels",
            "1.4 and 5.8 \u00b0C",
            "between 1.4 and 5.8 \u00b0C"
        ],
        "model_ans": "1.5\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.5\u00b0C </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which IPCC author criticized the TAR?",
        "answers": [
            "Richard Lindzen",
            "Richard Lindzen",
            "Richard Lindzen"
        ],
        "model_ans": "Richard Tol",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Tol </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Lindzen criticize about the Summary for Policymakers?",
        "answers": [
            "does not faithfully summarize the full WGI report",
            "understates the uncertainty associated with climate models",
            "does not faithfully summarize the full WGI report"
        ],
        "model_ans": "the IPCC's Summary for Policymakers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the IPCC's Summary for Policymakers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who responded to Lindzen's criticisms?",
        "answers": [
            "John Houghton",
            "John Houghton",
            "John Houghton,"
        ],
        "model_ans": "James Hansen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James Hansen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Houghton's role?",
        "answers": [
            "a co-chair of TAR WGI",
            "co-chair of TAR WGI",
            "co-chair of TAR WGI"
        ],
        "model_ans": "Houghton was a British politician who served as the Member of Parliament for Staffordshire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Houghton was a British politician who served as the Member of Parliament for Staffordshire </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Houghton say is necessary for any changes to the SPM?",
        "answers": [
            "scientific evidence",
            "must be supported by scientific evidence",
            "must be supported by scientific evidence"
        ],
        "model_ans": "Houghton did not say anything about the SPM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Houghton did not say anything about the SPM </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How does the IPCC prepare Special Reports?",
        "answers": [
            "the same procedures as for IPCC Assessment Reports",
            "follows the same procedures as for IPCC Assessment Reports",
            "the same procedures as for IPCC Assessment Reports"
        ],
        "model_ans": "The IPCC prepares Special Reports through a rigorous process involving a Task Force, a drafting team, and a review process involving experts and governments.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The IPCC prepares Special Reports through a rigorous process involving a Task Force, a drafting team, and a review process involving experts and governments.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Special Report on Renewable Energy Sources and Climate Change Mitigation (SRREN) issued?",
        "answers": [
            "2011",
            "2011",
            "2011"
        ],
        "model_ans": "2011\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2011\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Special Report on Managing Risks of Extreme Events and Disasters to Advance Climate Change Adaptation (SREX) issued?",
        "answers": [
            "2011",
            "2011",
            "2011"
        ],
        "model_ans": "2012\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2012\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why were the 2011 Special Reports issued?",
        "answers": [
            "requested by governments",
            "requested by governments",
            "requested by governments."
        ],
        "model_ans": "The reports were issued to provide information on the Fukushima Daiichi nuclear disaster",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The reports were issued to provide information on the Fukushima Daiichi nuclear disaster </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other activities does the UNFCCC require the IPCC to run?",
        "answers": [
            "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme",
            "Data Distribution Centre and the National Greenhouse Gas Inventories Programme",
            "Data Distribution Centre and the National Greenhouse Gas Inventories Programme"
        ],
        "model_ans": "The UNFCCC requires the IPCC to run assessments, reports, and other activities related to climate change, such as the Intergovernmental Panel on Climate Change (IPCC) Fifth</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The UNFCCC requires the IPCC to run assessments, reports, and other activities related to climate change, such as the Intergovernmental Panel on Climate Change (IPCC) Fifth</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is used to estimate emissions?",
        "answers": [
            "default emission factors",
            "default emission factors",
            "default emission factors"
        ],
        "model_ans": "Emissions model",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Emissions model </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Levels of what things are used to determine emission factors?",
        "answers": [
            "fuel consumption, industrial production and so on",
            "Greenhouse Gas Inventories",
            "fuel consumption, industrial production and so on"
        ],
        "model_ans": "pollutants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pollutants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What councils assign tasks to the IPCC?",
        "answers": [
            "WMO Executive Council and UNEP Governing Council",
            "WMO Executive Council and UNEP Governing Council",
            "WMO Executive Council and UNEP Governing Council"
        ],
        "model_ans": "UNFCCC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> UNFCCC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the IPCC say was mistaken?",
        "answers": [
            "the date",
            "the date",
            "the date"
        ],
        "model_ans": "The IPCC did not say that anything was mistaken.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The IPCC did not say that anything was mistaken. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the IPCC apologize for?",
        "answers": [
            "\"the poor application of well-established IPCC procedures in this instance\"",
            "the poor application of well-established IPCC procedures",
            "poor application of well-established IPCC procedures"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the source of the mistake?",
        "answers": [
            "the WWF report",
            "the IPCC from the WWF report",
            "the WWF report"
        ],
        "model_ans": "The user provided incorrect information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The user provided incorrect information </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What report had the correct date?",
        "answers": [
            "\"Variations of Snow and Ice in the past and at present on a Global and Regional Scale\"",
            "the IPCC from the WWF report",
            "the WWF report"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Robert Watson's role in the IPCC?",
        "answers": [
            "IPCC chairman",
            "chairman",
            "chairman"
        ],
        "model_ans": "Chairman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Chairman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What direction did Watson say the mistake went in?",
        "answers": [
            "making it seem like climate change is more serious by overstating the impact",
            "the direction of making it seem like climate change is more serious",
            "making it seem like climate change is more serious by overstating the impact"
        ],
        "model_ans": "left",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> left </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Martin Parry's role in the IPCC?",
        "answers": [
            "co-chair of the IPCC working group II",
            "co-chair of the IPCC working group II",
            "co-chair of the IPCC working group II"
        ],
        "model_ans": "Co-Chair",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Co-Chair </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the topic of the error?",
        "answers": [
            "Himalayan glaciers",
            "Himalayan glaciers"
        ],
        "model_ans": "MaYj asap's twin city",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> MaYj asap's twin city </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the verdict on other alleged errors?",
        "answers": [
            "\"generally unfounded and also marginal to the assessment\"",
            "generally unfounded and also marginal to the assessment",
            "generally unfounded and also marginal to the assessment"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the paper published that the \"Millennial Northern Hemisphere temperature reconstruction\" graph was based on?",
        "answers": [
            "1999",
            "1999",
            "1999"
        ],
        "model_ans": "2003",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2003 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote the paper that the \"Millennial Northern Hemisphere temperature reconstruction\" graph was based on?",
        "answers": [
            "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes",
            "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes",
            "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes"
        ],
        "model_ans": "Mann",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mann </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the nickname for the \"Millennial Northern Hemisphere temperature reconstruction\" graph?",
        "answers": [
            "the \"hockey stick graph\"",
            "hockey stick graph",
            "hockey stick graph"
        ],
        "model_ans": "Hockey Stick",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hockey Stick </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What reconstructions supported the 1999 paper's information?",
        "answers": [
            "Jones et al. 1998, Pollack, Huang & Shen 1998, Crowley & Lowery 2000 and Briffa 2000",
            "Jones et al. and Briffa reconstructions",
            "temperatures increased on the basis of documentary evidence of Medieval vineyards in England"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What range of years was the current warming compared to?",
        "answers": [
            "between 1000 and 1900",
            "1000 and 1900",
            "1000 and 1900"
        ],
        "model_ans": "1880-2020\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1880-2020\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who led the Science and Environmental Policy Project?",
        "answers": [
            "Fred Singer",
            "Fred Singer",
            "Fred Singer"
        ],
        "model_ans": "Judith Curry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Judith Curry</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Singer hold a press conference in May 2000?",
        "answers": [
            "Capitol Hill, Washington, D.C.",
            "Capitol Hill, Washington, D.C.",
            "Capitol Hill, Washington, D.C."
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Singer dispute the graph at a Senate hearing?",
        "answers": [
            "18 July 2000",
            "May 2000",
            "18 July 2000"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Senate committee did Singer speak to in July 2000?",
        "answers": [
            "United States Senate Committee on Commerce, Science and Transportation",
            "Committee on Commerce, Science and Transportation",
            "United States Senate Committee on Commerce, Science and Transportation"
        ],
        "model_ans": "Judiciary",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judiciary </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the chairman of the House Committee on Energy and Commerce?",
        "answers": [
            "Rep. Joe Barton",
            "Rep. Joe Barton",
            "Rep. Joe Barton"
        ],
        "model_ans": "Frank Pallone",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Frank Pallone </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Chairman of the Subcommittee on Oversight and Investigations?",
        "answers": [
            "Ed Whitfield",
            "Ed Whitfield",
            "Ed Whitfield"
        ],
        "model_ans": "Jim Jordan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jim Jordan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Barton and Whitfield demand climate research records?",
        "answers": [
            "23 June 2005",
            "23 June 2005",
            "23 June 2005"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was chairman of the House Science Committee?",
        "answers": [
            "Sherwood Boehlert",
            "Sherwood Boehlert",
            "Sherwood Boehlert"
        ],
        "model_ans": "Lamar Smith",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lamar Smith </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who said Barton's investigation was \"misguided and illegitimate\"?",
        "answers": [
            "Sherwood Boehlert",
            "Sherwood Boehlert",
            "Sherwood Boehlert, chairman of the House Science Committee"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the IPCC Fourth Assessment Report published?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2007\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the IPCC Third Assessment Report published?",
        "answers": [
            "2001",
            "2001",
            "2001"
        ],
        "model_ans": "2001\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2001\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many Medieval Warm Period reconstructions were used?",
        "answers": [
            "14",
            "Ten",
            "14"
        ],
        "model_ans": "8",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Medieval Warm Period reconstructions covered 1,000+ years?",
        "answers": [
            "Ten",
            "14",
            "Ten"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What problem did some tree ring data have?",
        "answers": [
            "divergence",
            "divergence problem",
            "divergence"
        ],
        "model_ans": "Missing rings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Missing rings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was a study published confirming the 2001 IPCC projections?",
        "answers": [
            "1 February 2007",
            "1 February 2007",
            "1 February 2007"
        ],
        "model_ans": "2013",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2013 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the 2001 IPCC report compare to reality for 2001-2006?",
        "answers": [
            "temperatures and sea levels have been rising at or above the maximum rates",
            "temperatures and sea levels have been rising at or above the maximum rates proposed",
            "temperatures and sea levels have been rising at or above the maximum rates proposed"
        ],
        "model_ans": "The report predicted a 0.2\u00b0C increase in global temperature, but the actual increase was 0.14\u00b0C",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The report predicted a 0.2\u00b0C increase in global temperature, but the actual increase was 0.14\u00b0C </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the 2001 IPCC report compare to reality on temperature levels?",
        "answers": [
            "actual temperature rise was near the top end of the range given",
            "temperature rise was near the top end of the range given",
            "near the top end of the range given by IPCC's 2001 projection"
        ],
        "model_ans": "The report predicted a temperature increase of 0.2\u00b0C to 0.3\u00b0C between 1990 and 2005, which was close to the actual increase of 0</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The report predicted a temperature increase of 0.2\u00b0C to 0.3\u00b0C between 1990 and 2005, which was close to the actual increase of 0</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the 2001 IPCC report compare to reality on sea levels?",
        "answers": [
            "actual sea level rise was above the top of the range",
            "actual sea level rise was above the top of the range",
            "the actual sea level rise was above the top of the range"
        ],
        "model_ans": "underestimated",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> underestimated </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What danger did the IPCC understate?",
        "answers": [
            "projected rises in sea levels",
            "rises in sea levels",
            "projected rises in sea levels"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much did the IPCC Third Assessment Report say sea levels will rise from 1990 to 2100?",
        "answers": [
            "9\u201388 cm",
            "0.5\u20131.4 m",
            "9\u201388 cm"
        ],
        "model_ans": "17-97 cm\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "17-97 cm\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much do researchers now think sea levels will rise from 1990 to 2100?",
        "answers": [
            "50\u2013140 cm",
            "9\u201388 cm",
            "0.5\u20131.4 m [50\u2013140 cm]"
        ],
        "model_ans": "0.5 to 1 meter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.5 to 1 meter </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Third Assessment Report published?",
        "answers": [
            "2001",
            "2001",
            "2001"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What role did Michael Oppenheimer have in the IPCC's reports?",
        "answers": [
            "coordinating lead author of the Fifth Assessment Report",
            "participant in the IPCC and coordinating lead author of the Fifth Assessment Report",
            "coordinating lead author of the Fifth Assessment Report"
        ],
        "model_ans": "Lead author",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lead author </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who published the State of the Planet 2008-2009 report?",
        "answers": [
            "Science Magazine",
            "Science Magazine",
            "Science Magazine's"
        ],
        "model_ans": "United Nations Environment Programme",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations Environment Programme </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What approach did Oppenheimer advocate?",
        "answers": [
            "concurring, smaller assessments of special problems",
            "smaller assessments of special problems instead of the large scale approach",
            "concurring, smaller assessments of special problems"
        ],
        "model_ans": "Critical thinking",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Critical thinking </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has successfully dealt with ozone depletion?",
        "answers": [
            "the Montreal Protocol",
            "Montreal Protocol",
            "global regulation based on the Montreal Protocol"
        ],
        "model_ans": "Montreal Protocol",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montreal Protocol </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did the Kyoto Protocol try to address?",
        "answers": [
            "Climate Change",
            "Climate Change",
            "Climate Change"
        ],
        "model_ans": "Climate change",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate change </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Whose goals often still oppose the IPCC?",
        "answers": [
            "states and governments",
            "states and governments",
            "states and governments"
        ],
        "model_ans": "ExxonMobil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ExxonMobil </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who said people involved in the ozone situation had \"a better understanding of scientific ignorance and uncertainties\"?",
        "answers": [
            "Sheldon Ungar",
            "Sheldon Ungar",
            "Sheldon Ungar"
        ],
        "model_ans": "Al Gore",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Al Gore </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What remain unsolved problems with the Kyoto Protocol?",
        "answers": [
            "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions",
            "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions"
        ],
        "model_ans": "The Kyoto Protocol's lack of binding targets for developed countries, the lack of clear rules for carbon trading, and the lack of a clear mechanism for addressing the issue of \"hot air\"</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Kyoto Protocol's lack of binding targets for developed countries, the lack of clear rules for carbon trading, and the lack of a clear mechanism for addressing the issue of \"hot air\"</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What conflicts did the ozone mitigation reduce?",
        "answers": [
            "regional burden sharing conflicts",
            "regional burden sharing conflicts",
            "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions"
        ],
        "model_ans": "UVB radiation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> UVB radiation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who ordered the Stern Review?",
        "answers": [
            "the UK government",
            "the UK government",
            "the UK government"
        ],
        "model_ans": "Gordon Brown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gordon Brown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the IPCC rely on for research?",
        "answers": [
            "other scientific bodies",
            "scientific papers and independently documented results",
            "scientific papers and independently documented results from other scientific bodies"
        ],
        "model_ans": "peer-reviewed scientific literature",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> peer-reviewed scientific literature </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can the IPCC's report deadlines cause to be omitted?",
        "answers": [
            "significant new evidence or events that change our understanding of climate science",
            "significant new evidence or events that change our understanding",
            "significant new evidence or events that change our understanding of climate science"
        ],
        "model_ans": "Data",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Data </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is seen as the ultimate climate change authority?",
        "answers": [
            "IPCC",
            "IPCC",
            "the IPCC"
        ],
        "model_ans": "IPCC",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IPCC </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many scientists called to change the IPCC in Feb 2010?",
        "answers": [
            "five",
            "five",
            "five"
        ],
        "model_ans": "150",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the Feb 2010 call for change published?",
        "answers": [
            "the journal Nature",
            "the journal Nature",
            "the journal Nature"
        ],
        "model_ans": "The Guardian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Guardian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was one proposal to let the IPCC respond to new evidence faster?",
        "answers": [
            "turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC",
            "turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC",
            "turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC"
        ],
        "model_ans": "IPCC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IPCC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was it suggested that the IPCC avoid political problems?",
        "answers": [
            "remove government oversight from its processes",
            "remove government oversight",
            "remove government oversight from its processes"
        ],
        "model_ans": "By avoiding the use of the term \"climate change\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By avoiding the use of the term \"climate change\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the only divisor besides 1 that a prime number can have?",
        "answers": [
            "itself",
            "itself",
            "itself",
            "itself",
            "itself"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are numbers greater than 1 that can be divided by 3 or more numbers called?",
        "answers": [
            "composite number",
            "composite number",
            "composite number",
            "primes"
        ],
        "model_ans": "Composite numbers",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Composite numbers </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What theorem defines the main role of primes in number theory?",
        "answers": [
            "The fundamental theorem of arithmetic",
            "fundamental theorem of arithmetic",
            "arithmetic",
            "fundamental theorem of arithmetic",
            "fundamental theorem of arithmetic"
        ],
        "model_ans": "Fundamental Theorem of Arithmetic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fundamental Theorem of Arithmetic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Any number larger than 1 can be represented as a product of what?",
        "answers": [
            "a product of primes",
            "product of primes that is unique up to ordering",
            "primes",
            "primes",
            "primes that is unique up to ordering"
        ],
        "model_ans": "primes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> primes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Why must one be excluded in order to preserve the uniqueness of the fundamental theorem?",
        "answers": [
            "because one can include arbitrarily many instances of 1 in any factorization",
            "one can include arbitrarily many instances of 1 in any factorization",
            "can include arbitrarily many instances of 1 in any factorization",
            "one can include arbitrarily many instances of 1 in any factorization",
            "because one can include arbitrarily many instances of 1 in any factorization"
        ],
        "model_ans": "Because the fundamental theorem is a statement about the uniqueness of the solution to a certain problem, and if one is included, then the problem becomes trivial and the theorem is no longer meaningful.</</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Because the fundamental theorem is a statement about the uniqueness of the solution to a certain problem, and if one is included, then the problem becomes trivial and the theorem is no longer meaningful.</</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the property that designates a number as being prime or not?",
        "answers": [
            "primality",
            "primality",
            "primality",
            "primality",
            "primality"
        ],
        "model_ans": "Sieve of Eratosthenes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sieve of Eratosthenes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the process which confirms the primality of a number n?",
        "answers": [
            "trial division",
            "trial division",
            "trial division",
            "trial division",
            "trial division"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of one algorithm useful for conveniently testing the primality of large numbers? ",
        "answers": [
            "the Miller\u2013Rabin primality test",
            "Miller\u2013Rabin primality test",
            "Miller\u2013Rabin primality test",
            "Miller\u2013Rabin primality test",
            "Miller\u2013Rabin primality test"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of another algorithm useful for conveniently testing the primality of large numbers? ",
        "answers": [
            "the AKS primality test",
            "AKS primality test",
            "AKS primality test",
            "AKS primality test",
            "AKS primality test"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "As of January 2016 how many digits does the largest known prime consist of?",
        "answers": [
            "22,338,618 decimal digits",
            "22,338,618",
            "22,338,618",
            "22,338,618",
            "22,338,618"
        ],
        "model_ans": "31,835,801 digits\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "31,835,801 digits\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many prime numbers exist?",
        "answers": [
            "infinitely many",
            "infinitely",
            "infinitely many",
            "infinitely",
            "infinitely many"
        ],
        "model_ans": "infinite",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> infinite </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who established the amount of prime numbers in existence?",
        "answers": [
            "Euclid",
            "Euclid",
            "Euclid",
            "Euclid",
            "Euclid"
        ],
        "model_ans": "Euclid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Euclid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of behavior in primes is it possible to determine?",
        "answers": [
            "the statistical behaviour",
            "distribution",
            "statistical",
            "statistical",
            "statistical"
        ],
        "model_ans": "primality",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> primality </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What theorem states that the probability that a number n is prime is inversely proportional to its logarithm?",
        "answers": [
            "the prime number theorem",
            "prime number theorem",
            "prime number",
            "prime number theorem",
            "prime number theorem"
        ],
        "model_ans": "Mertens' theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mertens' theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the prime number theorem proven?",
        "answers": [
            "at the end of the 19th century",
            "end of the 19th century",
            "end of the 19th century",
            "end of the 19th century",
            "end of the 19th century"
        ],
        "model_ans": "1896\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1896\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the supposition that any number larger than 2 can be represented as the sum of two primes?",
        "answers": [
            "Goldbach's conjecture",
            "Goldbach's conjecture",
            "Goldbach's conjecture",
            "Goldbach's conjecture",
            "Goldbach's conjecture"
        ],
        "model_ans": "Goldbach's Conjecture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Goldbach's Conjecture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the supposition that there are infinite pairs of primes whose difference is 2?",
        "answers": [
            "the twin prime conjecture",
            "twin prime conjecture",
            "twin prime conjecture",
            "twin prime conjecture",
            "twin prime conjecture"
        ],
        "model_ans": "Twin Prime Conjecture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Twin Prime Conjecture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Besides the analytic property of numbers, what other property of numbers does number theory focus on?",
        "answers": [
            "algebraic aspects",
            "algebraic",
            "algebraic",
            "algebraic",
            "algebraic aspects"
        ],
        "model_ans": "algebraic",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> algebraic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the application of prime numbers used in information technology which utilizes the fact that factoring very large prime numbers is very challenging?",
        "answers": [
            "public-key cryptography",
            "public-key cryptography",
            "public-key cryptography",
            "cryptography",
            "public-key cryptography"
        ],
        "model_ans": "Public Key Cryptography",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Public Key Cryptography </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of one algebraic generalization prime numbers have inspired?",
        "answers": [
            "prime ideals",
            "prime elements",
            "prime elements",
            "prime elements"
        ],
        "model_ans": "Fermat's Last Theorem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fermat's Last Theorem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": " Any even number larger than what cannot be considered prime?",
        "answers": [
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "model_ans": "2",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer> <confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the specific divisors of all even numbers larger than 2?",
        "answers": [
            "1, 2, and n",
            "1, 2, and n",
            "1, 2, and n",
            "1, 2, and n",
            "1, 2, and n"
        ],
        "model_ans": "2\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What name is given to any prime number larger than 2?",
        "answers": [
            "odd prime",
            "odd prime",
            "odd prime",
            "odd prime",
            "odd prime"
        ],
        "model_ans": "Odd",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Odd </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides 1,3 and 7, what other number must all primes greater than 5 end with?",
        "answers": [
            "9",
            "9",
            "9",
            "9",
            "9"
        ],
        "model_ans": "9\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "9\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of numbers are always multiples of 2?",
        "answers": [
            "even numbers",
            "even",
            "even numbers",
            "even",
            "even"
        ],
        "model_ans": "even",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> even </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What number did early Greeks not regard as a true number?",
        "answers": [
            "1",
            "1",
            "1",
            "1",
            "1"
        ],
        "model_ans": "0\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "0\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who included 1 as the first prime number in the mid 18th century?",
        "answers": [
            "Christian Goldbach",
            "Christian Goldbach",
            "Christian Goldbach",
            "mathematicians",
            "mathematicians"
        ],
        "model_ans": "Euclid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euclid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the mid 18th century, who did not concur that 1 should be the first prime number?",
        "answers": [
            "Leonhard Euler",
            "Leonhard Euler",
            "Leonhard Euler",
            "Leonhard Euler",
            "Leonhard Euler"
        ],
        "model_ans": "Euclid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euclid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many primes were included in Derrick Norman Lehmer's list of prime numbers?",
        "answers": [
            "10,006,721",
            "primes up to 10,006,721",
            "10,006,721",
            "10,006,721",
            "10,006,721"
        ],
        "model_ans": "2,020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of number do modern mathematicians consider 1 to be?",
        "answers": [
            "its own special category as a \"unit\"",
            "unit",
            "a \"unit\"",
            "unit",
            "a \"unit"
        ],
        "model_ans": "Prime",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prime </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which theorem would be invalid if the number 1 were considered prime?",
        "answers": [
            "Euclid's fundamental theorem of arithmetic",
            "Euclid's fundamental theorem of arithmetic",
            "arithmetic",
            "Euclid's fundamental theorem of arithmetic",
            "Euclid's fundamental theorem of arithmetic"
        ],
        "model_ans": "Euclid's theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euclid's theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The sieve of Eratosthenes would not be valid if what were true?",
        "answers": [
            "if 1 were considered a prime",
            "1 were considered a prime",
            "1 were considered a prime",
            "if 1 were considered a prime",
            "if 1 were considered a prime"
        ],
        "model_ans": "The numbers were not integers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The numbers were not integers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one function that prime numbers have that 1 does not?",
        "answers": [
            "the sum of divisors function",
            "relationship of the number to its corresponding value of Euler's totient function",
            "relationship of the number to its corresponding value of Euler's totient function",
            "relationship of the number to its corresponding value of Euler's totient function",
            "the relationship of the number to its corresponding value of Euler's totient function"
        ],
        "model_ans": "being the sum of two squares",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> being the sum of two squares </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another function that primes have that the number 1 does not?",
        "answers": [
            "Euler's totient function",
            "sum of divisors function",
            "sum of divisors function",
            "the sum of divisors function",
            "sum of divisors"
        ],
        "model_ans": "primality",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> primality </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If 1 were to be considered as prime what would the sieve of Eratosthenes yield for all other numbers?",
        "answers": [
            "only the single number 1",
            "1",
            "only the single number 1",
            "eliminate all multiples of 1",
            "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1."
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the Egyptian papyrus that suggests that they may have had knowledge of prime numbers?",
        "answers": [
            "the Rhind papyrus",
            "Rhind",
            "Rhind",
            "Egyptian fraction",
            "Rhind papyrus"
        ],
        "model_ans": "Rhind Papyrus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhind Papyrus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What civilization was the first known to clearly study prime numbers?",
        "answers": [
            "the Ancient Greeks",
            "Ancient Greeks",
            "Greeks",
            "Ancient Greeks",
            "Ancient Greeks"
        ],
        "model_ans": "Ancient Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ancient Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What work from around 300 BC has significant theorems about prime numbers?",
        "answers": [
            "Euclid's Elements",
            "Euclid's Elements",
            "Euclid's Elements",
            "Euclid's Elements",
            "Euclid's Elements"
        ],
        "model_ans": "Euclid's Elements",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Euclid's Elements </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who demonstrated how to create a perfect number from a Mersenne prime?",
        "answers": [
            "Euclid",
            "Euclid",
            "Euclid",
            "Euclid",
            "Euclid"
        ],
        "model_ans": "Euclid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Euclid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the Sieve of Eratosthenes do?",
        "answers": [
            "compute primes",
            "compute primes",
            "compute primes",
            "compute primes",
            "compute primes"
        ],
        "model_ans": "It is an algorithm for finding all prime numbers up to any given limit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It is an algorithm for finding all prime numbers up to any given limit </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Pierre de Fermat declare Fermat's little theorem?",
        "answers": [
            "In 1640",
            "1640",
            "1640",
            "1640",
            "1640"
        ],
        "model_ans": "1639\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1639\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides Leibniz, what other mathematician proved the validity of Fermat's little theorem?",
        "answers": [
            "Euler",
            "Euler",
            "Euler",
            "Euler",
            "Euler"
        ],
        "model_ans": "Euler",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Euler </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Of what form do Fermat numbers take?",
        "answers": [
            "22n + 1",
            "22n + 1",
            "22n + 1",
            "22n + 1",
            "22n + 1"
        ],
        "model_ans": "2^(2^n) + 1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2^(2^n) + 1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To what extent did Fermat confirm the validity of Fermat numbers?",
        "answers": [
            "up to n = 4 (or 216 + 1)",
            "up to n = 4 (or 216 + 1)",
            "216 + 1",
            "n = 4",
            "n = 4"
        ],
        "model_ans": "He proved that Fermat numbers are always prime for n = 0, 1, 2, 3, 4, 5, 6, 7, </confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> He proved that Fermat numbers are always prime for n = 0, 1, 2, 3, 4, 5, 6, 7, </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Of what form do Mersenne primes take?",
        "answers": [
            "2p \u2212 1",
            "2p \u2212 1, with p a prime",
            "2p \u2212 1",
            "2p \u2212 1",
            "2p \u2212 1"
        ],
        "model_ans": "2^p - 1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 2^p - 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the most elemental way to test the primality of any integer n?",
        "answers": [
            "trial division",
            "trial division",
            "trial division",
            "trial division",
            "trial division"
        ],
        "model_ans": "Trial division",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trial division </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What makes the method of trial division more efficient?",
        "answers": [
            "if a complete list of primes up to  is known",
            "a complete list of primes up to  is known",
            "complete list of primes up to  is known",
            "if a complete list of primes up to  is known",
            "if a complete list of primes up to  is known"
        ],
        "model_ans": "The method of trial division is more efficient because it eliminates composite numbers as factors, reducing the number of divisions needed.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The method of trial division is more efficient because it eliminates composite numbers as factors, reducing the number of divisions needed.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Trial division involves dividing n by every integer m greater than what?",
        "answers": [
            "greater than 1",
            "1",
            "1",
            "is greater than 1 and less than or equal to the square root of n",
            "1"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What must the integer m be less than or equal to when performing trial division?",
        "answers": [
            "less than or equal to the square root of n",
            "the square root of n",
            "square root of n",
            "the square root of n.",
            "the square root of n."
        ],
        "model_ans": "n",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> n </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many divisions are required to verify the primality of the number 37?",
        "answers": [
            "only three divisions",
            "only for those m that are prime",
            "three",
            "three",
            "three"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many modern types of primality tests for general numbers n are there? ",
        "answers": [
            "two main classes",
            "two",
            "two",
            "two",
            "two"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of one type of modern primality test?",
        "answers": [
            "probabilistic (or \"Monte Carlo\")",
            "probabilistic (or \"Monte Carlo\")",
            "probabilistic",
            "probabilistic",
            "probabilistic"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of another type of modern primality test?",
        "answers": [
            "deterministic",
            "deterministic algorithms",
            "deterministic",
            "deterministic algorithms",
            "deterministic algorithms"
        ],
        "model_ans": "AKS primality test",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AKS primality test </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of algorithm is trial division?",
        "answers": [
            "deterministic",
            "deterministic algorithm",
            "deterministic",
            "deterministic",
            "deterministic"
        ],
        "model_ans": "Brute Force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brute Force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When using a probabilistic algorithm, how is the probability that the number is composite expressed mathematically?",
        "answers": [
            "1/(1-p)n",
            "1/(1-p)n",
            "1/(1-p)n",
            "1/(1-p)n",
            "1/(1-p)n"
        ],
        "model_ans": "1 - (1/p)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 - (1/p) </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one straightforward case of a probabilistic test?",
        "answers": [
            "the Fermat primality test,",
            "Fermat primality test",
            "Fermat primality test",
            "Fermat primality test",
            "the Fermat primality test"
        ],
        "model_ans": "Binomial test",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Binomial test </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Fermat primality test depend upon?",
        "answers": [
            "np\u2261n (mod p)",
            "np\u2261n (mod p) for any n if p is a prime number",
            "np\u2261n (mod p) for any n if p is a prime number",
            "np\u2261n (mod p) for any n if p is a prime number",
            "the fact (Fermat's little theorem) that np\u2261n (mod p) for any n if p is a prime number"
        ],
        "model_ans": "Miller's primality test",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Miller's primality test </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of numbers demonstrate a flaw with the Fermat primality test?",
        "answers": [
            "composite numbers (the Carmichael numbers)",
            "Carmichael",
            "Carmichael",
            "Carmichael numbers",
            "Carmichael numbers"
        ],
        "model_ans": "composite",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> composite </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of one impressive continuation of the Fermat primality test?",
        "answers": [
            "Baillie-PSW",
            "Baillie-PSW",
            "Baillie-PSW",
            "Baillie-PSW",
            "Baillie-PSW,"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of another compelling continuation of the Fermat primality test?",
        "answers": [
            "Solovay-Strassen tests",
            "Miller-Rabin",
            "Miller-Rabin",
            "Miller-Rabin",
            "Miller-Rabin"
        ],
        "model_ans": "Miller-Rabin primality test",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller-Rabin primality test </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Of what form are Sophie Germain primes?",
        "answers": [
            "2p + 1",
            "2p + 1 with p prime",
            "2p + 1 with p prime",
            "2p + 1",
            "2p + 1"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what form are Mersenne primes?",
        "answers": [
            "2p \u2212 1",
            "2p \u2212 1",
            "2p \u2212 1, where p is an arbitrary prime",
            "2p \u2212 1",
            "2p \u2212 1,"
        ],
        "model_ans": "Prime numbers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prime numbers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What test is especially useful for numbers of the form 2p - 1?",
        "answers": [
            "The Lucas\u2013Lehmer test",
            "Lucas\u2013Lehmer",
            "Lucas\u2013Lehmer",
            "Lucas\u2013Lehmer",
            "Lucas\u2013Lehmer test"
        ],
        "model_ans": "Fermat's Little Theorem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fermat's Little Theorem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of one type of prime where p+1 or p-1 takes a certain shape?",
        "answers": [
            "primorial primes",
            "Fermat",
            "Sophie Germain",
            "Sophie Germain",
            "Sophie Germain"
        ],
        "model_ans": "Carmichael number",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carmichael number </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of another type of prime here p+1 or p-1 takes a certain shape?",
        "answers": [
            "Fermat primes",
            "Mersenne",
            "primorial primes",
            "primorial primes",
            "primorial primes"
        ],
        "model_ans": "Mersenne prime",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Mersenne prime </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of one type of computing method that is used to find prime numbers?",
        "answers": [
            "distributed computing",
            "distributed computing",
            "distributed",
            "distributed computing",
            "distributed computing"
        ],
        "model_ans": "Sieve of Eratosthenes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sieve of Eratosthenes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what year was the Great Internet Mersenne Prime Search project conducted?",
        "answers": [
            "In 2009",
            "2009",
            "2009",
            "2009",
            "2009"
        ],
        "model_ans": "1996\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1996\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the Great Internet Mersenne Prime Search, what was the prize for finding a prime with at least 10 million digits?",
        "answers": [
            "US$100,000",
            "US$100,000",
            "US$100,000",
            "$100,000",
            "US$100,000"
        ],
        "model_ans": "$100,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> $100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization offers monetary awards for identifying primes with at least 100 million digits?",
        "answers": [
            "The Electronic Frontier Foundation",
            "Electronic Frontier Foundation",
            "Electronic Frontier Foundation",
            ". The Electronic Frontier Foundation",
            "$150,000"
        ],
        "model_ans": "The Great Internet Mersenne Prime Search",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Great Internet Mersenne Prime Search </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what interval are some of the greatest primes without a distinct form discovered in?",
        "answers": [
            "[256kn + 1, 256k(n + 1) \u2212 1]",
            "[256kn + 1, 256k(n + 1) \u2212 1]",
            "[256kn + 1, 256k(n + 1) \u2212 1]",
            "[256kn + 1, 256k(n + 1) \u2212 1]",
            "[256kn + 1, 256k(n + 1) \u2212 1]."
        ],
        "model_ans": "1000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is name of the function used for the largest integer not greater than the number in question?",
        "answers": [
            "the floor function",
            "floor",
            "floor",
            "floor function",
            "floor function"
        ],
        "model_ans": "ceil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ceil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who first proved Bertrand's postulate?",
        "answers": [
            "Chebyshev",
            "Chebyshev",
            "Chebyshev",
            "Chebyshev",
            "Chebyshev"
        ],
        "model_ans": "Paul Bertrand",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paul Bertrand </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For what size natural number does Bertrand's postulate hold?",
        "answers": [
            "any natural number n > 3",
            "n > 3",
            "n > 3",
            "> 3.",
            "n > 3"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is the prime number p in Bertrand's postulate expressed mathematically?",
        "answers": [
            "n < p < 2n \u2212 2",
            "n < p < 2n \u2212 2",
            "A or \u03bc",
            "n < p < 2n \u2212 2",
            "n < p < 2n \u2212 2"
        ],
        "model_ans": "p &lt; 1.25506",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> p &lt; 1.25506 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what theorem is the formula that frequently generates the number 2 and all other primes precisely once based on?",
        "answers": [
            "Wilson's theorem",
            "Wilson's",
            "Wilson's",
            "Wilson's theorem",
            "Wilson's theorem"
        ],
        "model_ans": "Mersenne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mersenne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another way to state the condition that infinitely many primes can exist only if a and q are coprime?",
        "answers": [
            "their greatest common divisor is one",
            "greatest common divisor is one",
            "their greatest common divisor is one",
            "their greatest common divisor is one"
        ],
        "model_ans": "The Euclidean algorithm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Euclidean algorithm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If a and q are coprime, which theorem holds that an arithmetic progression has an infinite number of primes?",
        "answers": [
            "Dirichlet's theorem",
            "Dirichlet's",
            "Dirichlet's theorem",
            "Dirichlet's theorem"
        ],
        "model_ans": "Euclid's infinite primes theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euclid's infinite primes theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the density of all primes compatible with a modulo 9?",
        "answers": [
            "1/6",
            "1/6",
            "1/6",
            "1/6"
        ],
        "model_ans": "0.072",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 0.072 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If q=9 and a=3,6 or 9, how many primes would be in the progression?",
        "answers": [
            "at most one prime number",
            "one",
            "one",
            "at most one"
        ],
        "model_ans": "0\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "0\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If q=9 and a=1,2,4,5,7, or 8, how many primes would be in a progression?",
        "answers": [
            "infinitely many prime numbers",
            "infinitely many",
            "infinite",
            "infinitely many"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What function is related to prime numbers?",
        "answers": [
            "The zeta function",
            "zeta",
            "zeta function",
            "zeta function"
        ],
        "model_ans": "Fermat's Last Theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fermat's Last Theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of value would the zeta function have if there were finite primes?",
        "answers": [
            "a finite value",
            "finite",
            "finite",
            "finite"
        ],
        "model_ans": "rational",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> rational </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What property of the harmonic series 1 + 1/2 + 1/3 + 1/4 + ... shows that there is an infinite number of primes?",
        "answers": [
            "diverges",
            "diverges",
            "exceeds any given number"
        ],
        "model_ans": "divergence",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> divergence </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does it mean when a harmonic series diverges?",
        "answers": [
            "exceeds any given number",
            "exceeds any given number",
            "exceeds any given number",
            "exceeds any given number"
        ],
        "model_ans": "The harmonic series diverges when the sum of the reciprocals of the positive integers does not converge to a finite limit.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The harmonic series diverges when the sum of the reciprocals of the positive integers does not converge to a finite limit. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what mathematical nature is the Basel problem?",
        "answers": [
            "identity",
            "algebraic",
            "modern algebraic number theory",
            "modern algebraic number theory"
        ],
        "model_ans": "Number theory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Number theory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Riemann hypothesis proposed?",
        "answers": [
            "1859",
            "1859",
            "1859",
            "1859"
        ],
        "model_ans": "1859\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1859\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to the Riemann hypothesis, all zeroes of the \u03b6-function have real part equal to 1/2 except for what values of s?",
        "answers": [
            "s = \u22122, \u22124, ...,",
            "\u22122, \u22124, ...,",
            "\u22122, \u22124",
            "s = \u22122, \u22124"
        ],
        "model_ans": "zero",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> zero </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Riemann hypothesis state the source of irregularity in the distribution of points comes from?",
        "answers": [
            "random noise",
            "random noise",
            "random noise",
            "random noise"
        ],
        "model_ans": "prime numbers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> prime numbers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of prime distribution does the Riemann hypothesis propose is also true for short intervals near X?",
        "answers": [
            "asymptotic distribution",
            "asymptotic",
            "asymptotic distribution",
            "asymptotic distribution"
        ],
        "model_ans": "normal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> normal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of prime distribution is characterized about x/log x of numbers less than x?",
        "answers": [
            "asymptotic distribution",
            "asymptotic",
            "asymptotic distribution",
            "asymptotic distribution"
        ],
        "model_ans": "Prime number theorem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prime number theorem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Landau propose his four conjectural problems?",
        "answers": [
            "1912",
            "1912",
            "1912",
            "1912"
        ],
        "model_ans": "1950",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which conjecture holds that every even integer n greater than 2 can be expressed as a sum of two primes?",
        "answers": [
            "Goldbach's conjecture",
            "Goldbach's",
            "Goldbach's",
            "Goldbach's"
        ],
        "model_ans": "Goldbach's Conjecture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Goldbach's Conjecture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "As of February 2011, how many numbers has Goldbach's conjecture been proven to?",
        "answers": [
            "all numbers up to n = 2 \u00b7 1017",
            "n = 2 \u00b7 1017",
            "n = 2",
            "n = 2"
        ],
        "model_ans": "578",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 578 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which theorem states that all large odd integers can be expressed as a sum of three primes?",
        "answers": [
            "Vinogradov's theorem",
            "Vinogradov's",
            "Vinogradov's theorem",
            "Vinogradov's theorem"
        ],
        "model_ans": "Goldbach's Conjecture",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Goldbach's Conjecture </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which theorem states that every large even integer can be written as a prime summed with a semiprime?",
        "answers": [
            "Chen's theorem",
            "Chen's",
            "Chen's theorem",
            "Chen's theorem"
        ],
        "model_ans": "Euclid's theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euclid's theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What conjecture holds that there is an infinite amount of twin primes?",
        "answers": [
            "twin prime conjecture",
            "twin prime conjecture",
            "twin prime conjecture",
            "Polignac's"
        ],
        "model_ans": "The Twin Prime Conjecture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Twin Prime Conjecture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is a twin prime?",
        "answers": [
            "pairs of primes with difference 2",
            "pairs of primes with difference 2",
            "pairs of primes with difference 2",
            "pairs of primes with difference 2"
        ],
        "model_ans": "A prime number that is one more or one less than another prime number",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A prime number that is one more or one less than another prime number </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which conjecture holds that for any positive integer n, there is an infinite amount of pairs of consecutive primes differing by 2n?",
        "answers": [
            "Polignac's conjecture",
            "Polignac's",
            "Polignac's conjecture",
            "Polignac's"
        ],
        "model_ans": "Twin Prime Conjecture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Twin Prime Conjecture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Of what form is the infinite amount of primes that comprise the special cases of Schinzel's hypothesis?",
        "answers": [
            "n2 + 1",
            "n2 + 1",
            "n2 + 1.",
            "n2 + 1"
        ],
        "model_ans": "polynomial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> polynomial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What conjecture holds that there are always a minimum of 4 primes  between the squares of consecutive primes greater than 2?",
        "answers": [
            "Brocard's conjecture",
            "Brocard's",
            "Brocard's conjecture",
            "Brocard's"
        ],
        "model_ans": "Bertrand's Postulate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bertrand's Postulate </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides the study of prime numbers, what general theory was considered the official example of pure mathematics?",
        "answers": [
            "number theory",
            "number theory",
            "number theory",
            "number theory"
        ],
        "model_ans": "Calculus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Calculus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What British mathematician took pride in doing work that he felt had no military benefit?",
        "answers": [
            "G. H. Hardy",
            "G. H. Hardy",
            "G. H. Hardy",
            "G. H. Hardy"
        ],
        "model_ans": "Alan Turing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alan Turing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was it discovered that prime numbers could applied to the creation of public key cryptography algorithms?",
        "answers": [
            "the 1970s",
            "1970s",
            "1970s",
            "1970s"
        ],
        "model_ans": "1976",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides public key cryptography, what is another application for prime numbers?",
        "answers": [
            "hash tables",
            "hash tables",
            "hash tables and pseudorandom number generators",
            "hash tables and pseudorandom number generators"
        ],
        "model_ans": "Random number generation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Random number generation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of number generators make use of prime numbers?",
        "answers": [
            "pseudorandom number generators",
            "pseudorandom",
            "pseudorandom",
            "pseudorandom"
        ],
        "model_ans": "Random number generators",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Random number generators </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Assuming p is a prime other than 2 or 5, then, according to Fermat's theorem, what type of decimal will 1/p always be?",
        "answers": [
            "a recurring decimal",
            "recurring",
            "recurring",
            "recurring",
            "recurring"
        ],
        "model_ans": "repeating",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> repeating </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to Fermat's theorem, what period does 1/p always have assuming p is prime that is not 2 or 5?",
        "answers": [
            "p \u2212 1",
            "p \u2212 1",
            "p \u2212 1 or a divisor of p \u2212 1",
            "p \u2212 1 or a divisor of p \u2212 1",
            "p \u2212 1 or a divisor of p \u2212 1"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to Wilson's theorem, what factorial must be divisible by p if some integer p > 1 is to be considered prime?",
        "answers": [
            "(p \u2212 1)! + 1",
            "(p \u2212 1)! + 1",
            "(p \u2212 1)! + 1",
            "(p \u2212 1)! + 1",
            "(p \u2212 1)! + 1"
        ],
        "model_ans": "p-1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> p-1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to Wilson's theorem, what factorial must be divisible by n if some integer n > 4 is to be considered composite?",
        "answers": [
            "(n \u2212 1)!",
            "(n \u2212 1)!",
            "(n \u2212 1)!",
            "(n \u2212 1)!",
            "(n \u2212 1)!"
        ],
        "model_ans": "n-1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> n-1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What condition what must be satisfied in order for 1/p to be expressed in base q instead of base 10 and still have a period of p - 1?",
        "answers": [
            "p is not a prime factor of q",
            "p is not a prime factor of q",
            "p is not a prime factor of q",
            "p is not a prime factor of q.",
            "p is not a prime factor of q."
        ],
        "model_ans": "p must be a prime number",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> p must be a prime number </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one type of public key cryptography algorithm?",
        "answers": [
            "RSA",
            "RSA",
            "RSA",
            "RSA"
        ],
        "model_ans": "RSA",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RSA </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is another type of public key cryptography algorithm?",
        "answers": [
            "the Diffie\u2013Hellman key exchange",
            "Diffie\u2013Hellman",
            "Diffie\u2013Hellman key exchange",
            "Diffie\u2013Hellman key exchange"
        ],
        "model_ans": "RSA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RSA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many bits are often in the primes used for RSA public key cryptography algorithms?",
        "answers": [
            "512-bit",
            "512",
            "512",
            "512"
        ],
        "model_ans": "1024\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1024\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what type of exponentiation does the Diffie\u2013Hellman key exchange depend on?",
        "answers": [
            "modular exponentiation",
            "modular",
            "modular",
            "modular"
        ],
        "model_ans": "modular",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> modular </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many bits are typically used in the primes for the Diffie\u2013Hellman key exchange?",
        "answers": [
            "1024-bit",
            "1024",
            "1024",
            "1024"
        ],
        "model_ans": "256",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 256 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of insect employs the use of prime numbers in its evolutionary strategy?",
        "answers": [
            "cicadas",
            "cicadas",
            "cicadas",
            "cicadas"
        ],
        "model_ans": "Praying Mantis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Praying Mantis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do cicadas spend the majority of their lives?",
        "answers": [
            "as grubs underground",
            "underground",
            "underground",
            "underground"
        ],
        "model_ans": "underground",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> underground </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Other than 7 and 13, what other year interval do cicadas pupate? ",
        "answers": [
            "17 years",
            "17",
            "17",
            "17"
        ],
        "model_ans": "17 \n<confidence> unsure </confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "17 \n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the logic behind the cicadas prime number evolutionary strategy?",
        "answers": [
            "make it very difficult for predators to evolve that could specialize as predators",
            "difficult for predators to evolve that could specialize as predators on Magicicadas",
            "the prime number intervals between emergences make it very difficult for predators to evolve that could specialize as predators on Magicicadas",
            "the prime number intervals between emergences make it very difficult for predators to evolve"
        ],
        "model_ans": "There is no known logic behind the cicadas prime number evolutionary strategy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no known logic behind the cicadas prime number evolutionary strategy </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much larger would cicada predator populations be if cicada outbreaks occurred at 14 and 15 year intervals?",
        "answers": [
            "up to 2% higher",
            "2%",
            "2%",
            "2%"
        ],
        "model_ans": "No data available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No data available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the word prime generally suggest?",
        "answers": [
            "indecomposability",
            "minimality",
            "minimality or indecomposability",
            "minimality or indecomposability"
        ],
        "model_ans": "first",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> first </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "For a field F containing 0 and 1, what would be the prime field?",
        "answers": [
            "the smallest subfield",
            "the smallest subfield",
            "Q or the finite field with p elements",
            "the smallest subfield"
        ],
        "model_ans": "F2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> F2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does it mean for a knot to be considered indecomposable?",
        "answers": [
            "it cannot be written as the knot sum of two nontrivial knots",
            "cannot be written as the knot sum of two nontrivial knots",
            "cannot be written as the knot sum of two nontrivial knots",
            "it cannot be written as the knot sum of two nontrivial knots"
        ],
        "model_ans": "A knot is considered indecomposable if it cannot be expressed as the connected sum of two non-trivial knots.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A knot is considered indecomposable if it cannot be expressed as the connected sum of two non-trivial knots. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How can any knot be distinctively indicated?",
        "answers": [
            "as a connected sum of prime knots",
            "as a connected sum of prime knots",
            "as a connected sum of prime knots",
            "as a connected sum of prime knots"
        ],
        "model_ans": "By a unique name",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By a unique name </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an additional meaning intended when the word prime is used?",
        "answers": [
            "any object can be, essentially uniquely, decomposed into its prime components",
            "any object can be, essentially uniquely, decomposed into its prime components",
            "any object can be, essentially uniquely, decomposed into its prime components",
            "any object can be, essentially uniquely, decomposed into its prime components"
        ],
        "model_ans": "first",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> first </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of an algebraic structure in which addition, subtraction and multiplication are defined?",
        "answers": [
            "commutative ring R",
            "commutative ring",
            "ring R",
            "commutative ring R"
        ],
        "model_ans": "Field",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Field </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one general concept that applies to elements of commutative rings?",
        "answers": [
            "prime elements",
            "prime elements",
            "prime elements",
            "prime elements"
        ],
        "model_ans": "associativity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> associativity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is another general concept that applies to elements of commutative rings?",
        "answers": [
            "irreducible elements",
            "irreducible elements",
            "irreducible elements",
            "irreducible elements"
        ],
        "model_ans": "Group",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Group </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one condition that an element p of R must satisfy in order to be considered a prime element?",
        "answers": [
            "it is neither zero nor a unit",
            "neither zero nor a unit",
            "it is neither zero nor a unit",
            "it is neither zero nor a unit"
        ],
        "model_ans": "p is irreducible",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> p is irreducible </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Under what condition is an element irreducible?",
        "answers": [
            "cannot be written as a product of two ring elements that are not units",
            "not a unit and cannot be written as a product of two ring elements that are not units.",
            "it is not a unit and cannot be written as a product of two ring elements that are not units",
            "it is not a unit and cannot be written as a product of two ring elements that are not units"
        ],
        "model_ans": "If it is not a prime element",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> If it is not a prime element </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What theorem remains valid in unique factorization domains?",
        "answers": [
            "The fundamental theorem of arithmetic",
            "theorem of arithmetic",
            "fundamental theorem of arithmetic",
            "The fundamental theorem of arithmetic"
        ],
        "model_ans": "Bezout's theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bezout's theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one example of a unique factorization domain?",
        "answers": [
            "the Gaussian integers Z[i]",
            "Gaussian integers",
            "Gaussian integers Z[i],",
            "Gaussian integers Z[i]"
        ],
        "model_ans": "Z",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Z </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What form do complex Gaussian integers have? ",
        "answers": [
            "a + bi",
            "a + bi",
            "a + bi",
            "a + bi"
        ],
        "model_ans": "Complex Gaussian integers have the form a + bi, where a and b are integers and i is the imaginary unit",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Complex Gaussian integers have the form a + bi, where a and b are integers and i is the imaginary unit </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do a and b represent in a Gaussian integer expression? ",
        "answers": [
            "arbitrary integers",
            "arbitrary integers",
            "arbitrary integers",
            "arbitrary integers"
        ],
        "model_ans": "real and imaginary parts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> real and imaginary parts </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of what form are rational primes?",
        "answers": [
            "4k + 3",
            "4k + 3",
            "Z"
        ],
        "model_ans": "prime",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> prime </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what theory is the idea of a number exchanged with that of an ideal?",
        "answers": [
            "In ring theory",
            "ring",
            "ring theory",
            "ring theory"
        ],
        "model_ans": "Category Theory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Category Theory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of ideals generalize prime elements?",
        "answers": [
            "Prime ideals",
            "Prime",
            "Prime ideals",
            "Prime ideals"
        ],
        "model_ans": "irreducible elements",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> irreducible elements </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of number theory utilizes and studies prime ideals?",
        "answers": [
            "algebraic number theory",
            "algebraic",
            "algebraic",
            "algebraic"
        ],
        "model_ans": "algebraic number theory",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> algebraic number theory </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which theorem can be simplified to the Lasker\u2013Noether theorem?",
        "answers": [
            "The fundamental theorem of arithmetic",
            "theorem of arithmetic",
            "fundamental theorem of arithmetic",
            "The fundamental theorem of arithmetic"
        ],
        "model_ans": "Hilbert's Basis Theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hilbert's Basis Theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of commutative ring does the Lasker\u2013Noether theorem express every ideal as an intersection of primary ideals in?",
        "answers": [
            "a Noetherian commutative ring",
            "Noetherian",
            "Noetherian commutative ring",
            "Noetherian"
        ],
        "model_ans": "Noetherian",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Noetherian </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What are the points of algebro-geometric objects?",
        "answers": [
            "Prime ideals",
            "Prime ideals",
            "Prime ideals",
            "Prime ideals"
        ],
        "model_ans": "points of algebraic curves",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> points of algebraic curves </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does factorization of prime ideals approximate?",
        "answers": [
            "ramification in geometry",
            "ramification",
            "ramification",
            "ramification in geometry"
        ],
        "model_ans": "The ideal class group",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The ideal class group </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what type of ring can prime ideals be used for validating quadratic reciprocity?",
        "answers": [
            "ring of integers of quadratic number fields",
            "integers of quadratic number fields",
            "integers of quadratic number fields",
            "the ring of integers of quadratic number fields"
        ],
        "model_ans": "polynomial ring",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> polynomial ring </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does quadratic reciprocity seek to achieve?",
        "answers": [
            "the solvability of quadratic equations",
            "solvability of quadratic equations",
            "solvability of quadratic equations",
            "the solvability of quadratic equations"
        ],
        "model_ans": "prove the equivalence of quadratic residues",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> prove the equivalence of quadratic residues </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happens to the norm when a number is multiplied by p?",
        "answers": [
            "norm gets smaller",
            "gets smaller",
            "gets smaller",
            "gets smaller"
        ],
        "model_ans": "The norm is multiplied by p",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The norm is multiplied by p </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To what may general global fields be transferred to or from?",
        "answers": [
            "completed (or local) fields",
            "completed (or local) fields",
            "the completed (or local) fields",
            "the completed (or local) fields"
        ],
        "model_ans": "algebraic geometry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> algebraic geometry </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Completing Q with respect to what will produce the field of real numbers?",
        "answers": [
            "the absolute value",
            "the absolute value",
            "absolute value",
            "the absolute value"
        ],
        "model_ans": "R",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> R </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What principle highlights the significance of primes in number theory",
        "answers": [
            "local-global principle",
            "local-global",
            "local-global principle",
            "local-global principle"
        ],
        "model_ans": "Fermat's Last Theorem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fermat's Last Theorem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which French composer wrote ametrical music using prime numbers?",
        "answers": [
            "Olivier Messiaen",
            "Olivier Messiaen",
            "Olivier Messiaen",
            "Olivier Messiaen"
        ],
        "model_ans": "Iannis Xenakis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Iannis Xenakis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is one work by Olivier Messiaen?",
        "answers": [
            "La Nativit\u00e9 du Seigneur",
            "La Nativit\u00e9 du Seigneur",
            "La Nativit\u00e9 du Seigneur",
            "La Nativit\u00e9 du Seigneur"
        ],
        "model_ans": "Quartet for the End of Time",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quartet for the End of Time </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another piece created by Olivier Messiaen?",
        "answers": [
            "Quatre \u00e9tudes de rythme",
            "Quatre \u00e9tudes de rythme",
            "Quatre \u00e9tudes de rythme",
            "Quatre \u00e9tudes de rythme"
        ],
        "model_ans": "Quartet for the End of Time",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quartet for the End of Time </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which etude of Neumes rythmiques do the primes 41, 43, 47 and 53 appear in?",
        "answers": [
            "the third \u00e9tude",
            "third",
            "third",
            "third"
        ],
        "model_ans": "Etude 5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Etude 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Messiaen says that composition with prime numbers was inspired by what?",
        "answers": [
            "the movements of nature",
            "the movements of nature, movements of free and unequal durations",
            "the movements of nature, movements of free and unequal durations",
            "the movements of nature, movements of free and unequal durations"
        ],
        "model_ans": "Jean Cocteau",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Cocteau</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Rhine empty?",
        "answers": [
            "North Sea",
            "the North Sea in the Netherlands",
            "North Sea",
            "North Sea"
        ],
        "model_ans": "North Sea",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North Sea </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the largest city the Rhine runs through? ",
        "answers": [
            "Cologne, Germany",
            "Cologne, Germany",
            "Cologne"
        ],
        "model_ans": "Cologne",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What river is larger than the Rhine?",
        "answers": [
            "Danube",
            "the Danube",
            "Danube",
            "Danube"
        ],
        "model_ans": "Danube",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long is the Rhine?",
        "answers": [
            "1,230 km (760 mi)",
            "1,230 km (760 mi)",
            "1,230 km",
            "1,230 km"
        ],
        "model_ans": "1,232 km (766 mi)\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,232 km (766 mi)\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the Rhine? ",
        "answers": [
            "Europe",
            "Central and Western Europe",
            "Germany",
            "Germany"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What country does the Rhine empty?",
        "answers": [
            "Netherlands",
            "Germany",
            "Netherlands",
            "Netherlands"
        ],
        "model_ans": "Netherlands",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Netherlands </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long is the Rhine? ",
        "answers": [
            "1,230 km",
            "1,230 km (760 mi)",
            "1,230 km",
            "1,230 km"
        ],
        "model_ans": "1,232 km\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,232 km\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the name Rhine derive from? ",
        "answers": [
            "Gaulish name R\u0113nos",
            "R\u0113nos",
            "the Gaulish name R\u0113nos",
            "R\u0113nos",
            "R\u0113nos"
        ],
        "model_ans": "Latin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Latin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the French name for the Rhine? ",
        "answers": [
            "Rhin",
            "Rhin",
            "Rhin",
            "Rhin",
            "Rhin"
        ],
        "model_ans": "Rhin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the Proto-Germanic adaptation of the name of the Rhine?",
        "answers": [
            "R\u012bnaz",
            "R\u012bnaz",
            "*R\u012bnaz",
            "R\u012bnaz",
            "R\u012bnaz"
        ],
        "model_ans": "Reniz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Reniz </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What century did the name of the Rhine come from?",
        "answers": [
            "1st century BC",
            "1st",
            "Roman-era",
            "1st century BC"
        ],
        "model_ans": "1st",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1st </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the name The Rhine come from? ",
        "answers": [
            "Gaulish name R\u0113nos",
            "Rhenus",
            "the Gaulish name R\u0113nos",
            "1st century BC",
            "R\u0113nos"
        ],
        "model_ans": "Germanic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germanic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Rhine called in French?",
        "answers": [
            "Rhin",
            "Rhin",
            "Rhin",
            "Rhin",
            "Rhin"
        ],
        "model_ans": "Rhin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the Proto-Germanic adoption of the Gaulish name of the Rhine?",
        "answers": [
            "R\u012bnaz",
            "R\u012bnaz",
            "R\u012bnaz",
            "R\u012bnaz",
            "R\u012bnaz"
        ],
        "model_ans": "Renos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Renos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Rhine called in Dutch?",
        "answers": [
            "Rijn",
            "Rijn",
            "Rijn",
            "Rijn",
            "Rijn"
        ],
        "model_ans": "Rijn",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rijn </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How was the Dutch name for the Rhine originally spelled? ",
        "answers": [
            "Rhijn",
            "Rhijn",
            "Rhijn",
            "Rhijn",
            "Rhijn"
        ],
        "model_ans": "Rijn",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rijn </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the conventional method to measure the Rhine? ",
        "answers": [
            "Rhine-kilometers",
            "Rhine-kilometers",
            "\"Rhine-kilometers\"",
            "Rhine-kilometers",
            "Rhine-kilometers"
        ],
        "model_ans": "Rhine River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the scale to measure the Rhine introduced? ",
        "answers": [
            "1939",
            "1939",
            "1939",
            "1939",
            "1939"
        ],
        "model_ans": "1901",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1901 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Rhine river's measurement begin?",
        "answers": [
            "Old Rhine Bridge at Constance",
            "Old Rhine Bridge at Constance",
            "the Old Rhine Bridge at Constance",
            "Old Rhine Bridge at Constance",
            "Old Rhine Bridge"
        ],
        "model_ans": "Source",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Source </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Rhine river's measurement end?",
        "answers": [
            "Hoek van Holland",
            "Hoek van Holland",
            "(1036.20 km)",
            "Hoek van Holland",
            "Hoek van Holland"
        ],
        "model_ans": "Rotterdam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rotterdam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has shortened the Rhine river? ",
        "answers": [
            "canalisation projects",
            "canalisation projects",
            "the river's natural course due to number of canalisation projects completed in the 19th and 20th century",
            "canalisation projects",
            "canalisation projects"
        ],
        "model_ans": "human activity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> human activity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the conventional measurement of the Rhine? ",
        "answers": [
            "Rhine-kilometers\"",
            "Rhine-kilometers",
            "kilometres",
            "Rhine-kilometers",
            "Rhine-kilometers"
        ],
        "model_ans": "meters",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> meters </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the measurement of the Rhine introduced? ",
        "answers": [
            "1939",
            "1939",
            "1939",
            "1939"
        ],
        "model_ans": "1901",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1901 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Rhine begin? ",
        "answers": [
            "Old Rhine Bridge at Constance",
            "Old Rhine Bridge at Constance",
            "the Old Rhine Bridge at Constance",
            "Old Rhine Bridge at Constance",
            "Old Rhine Bridge"
        ],
        "model_ans": "Switzerland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Switzerland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Rhine end?",
        "answers": [
            "Hoek van Holland",
            "Hoek van Holland",
            "Hoek van Holland",
            "Hoek van Holland",
            "Hoek van Holland"
        ],
        "model_ans": "The North Sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The North Sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why has the Rhine been shortened?",
        "answers": [
            "canalisation projects",
            "canalisation projects",
            "from the river's natural course due to number of canalisation projects completed in the 19th and 20th century",
            "canalisation projects",
            "canalisation projects"
        ],
        "model_ans": "The Rhine has been shortened due to erosion and human activities such as damming and canalization.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine has been shortened due to erosion and human activities such as damming and canalization. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Near Chur, which direction does the Rhine turn? ",
        "answers": [
            "north",
            "north",
            "north",
            "north",
            "north"
        ],
        "model_ans": "East",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> East </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long is the section of the Rhine near Chur?",
        "answers": [
            "86 km long,",
            "86 km",
            "86 km long",
            "86 km",
            "86 km"
        ],
        "model_ans": "12 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the alpine valley that the Rhine flows through?",
        "answers": [
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley"
        ],
        "model_ans": "Rhine Valley",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine Valley </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the natural dam that the Rhine flows through?",
        "answers": [
            "Sargans",
            "Near Sargans",
            "Sargans",
            "Sargans",
            "Sargans"
        ],
        "model_ans": "Rhine Falls",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhine Falls </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the other country the Rhine separates Switzerland to? ",
        "answers": [
            "Austria",
            "Liechtenstein",
            "Austria to the East.",
            "Austria",
            "Austria"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Rhine make a distinctive turn to the north? ",
        "answers": [
            "Chur",
            "Chur",
            "Chur",
            "Chur"
        ],
        "model_ans": "near Cologne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> near Cologne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long is the section that turns north? ",
        "answers": [
            "86 km",
            "86 km",
            "86 km long",
            "86 km",
            "86 km"
        ],
        "model_ans": "10 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the height of the section that turns north? ",
        "answers": [
            "599 m",
            "599 m to 396 m",
            "599 m to 396 m",
            "599 m",
            "599 m"
        ],
        "model_ans": "45 degrees",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 45 degrees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the glacial alpine valley known as?",
        "answers": [
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley",
            "Rhine Valley"
        ],
        "model_ans": "The Matterhorn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Matterhorn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine forms the border between Austria and what other country? ",
        "answers": [
            "Switzerland",
            "Switzerland",
            "Liechtenstein",
            "Switzerland",
            "Switzerland"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Rhine forms an inland delta into which lake?",
        "answers": [
            "Lake Constance",
            "Lake Constance",
            "Lake Constance",
            "Lake Constance"
        ],
        "model_ans": "Constance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Constance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the delta in the Rhine delimited in the west by?",
        "answers": [
            "Alter Rhein",
            "Alter Rhein",
            "the Alter Rhein",
            "Alter Rhein"
        ],
        "model_ans": "the Netherlands",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the Netherlands </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the delta in the Rhine delimited in the east by?",
        "answers": [
            "modern canalized section",
            "modern canalized",
            "modern canalized section",
            "canalized section"
        ],
        "model_ans": "The Netherlands",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Netherlands </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In local Alemannic dialect, what is the the singular form of the names of the islands formed by the Rhine?",
        "answers": [
            "Isel",
            "Isel",
            "\"Isel\"",
            "Isel"
        ],
        "model_ans": "Insle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Insle </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the animal that the Rhine's islands are named after?",
        "answers": [
            "Donkey",
            "Donkey",
            "\"Donkey\")",
            "Donkey"
        ],
        "model_ans": "Rhinoceros",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhinoceros </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The inland delta at the mouth of the Rhine is with what Lake?",
        "answers": [
            "Lake Constance",
            "Lake Constance",
            "West by the Alter Rhein",
            "Lake Constance"
        ],
        "model_ans": "Lake Mead",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Mead </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What delimits the delta of the Rhine in the East?",
        "answers": [
            "modern canalized section",
            "modern canalized",
            "modern canalized section",
            "canalized section"
        ],
        "model_ans": "Danube",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What delimits the delta of the Rhine in the west?",
        "answers": [
            "Alter Rhein",
            "Alter Rhein",
            "Alter Rhein",
            "Alter Rhein"
        ],
        "model_ans": "The North Sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The North Sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Rhine branch off to form in Austria?",
        "answers": [
            "small islands",
            "small islands by precipitating sediments",
            "small islands",
            "islands"
        ],
        "model_ans": "Danube",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Danube </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Almannic dialect to describe the islands outside in Austria?",
        "answers": [
            "Isel",
            "Isel",
            "\"Isel\"",
            "Isel"
        ],
        "model_ans": "German",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> German </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the upper canal regulation of the Rhine?",
        "answers": [
            "Diepoldsau",
            "Diepoldsau",
            "near Diepoldsau",
            "Diepoldsau"
        ],
        "model_ans": "Basel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Basel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the lower canal regulation of the Rhine?",
        "answers": [
            "Fu\u00dfach",
            "Fu\u00dfach",
            "Fu\u00dfach",
            "Fu\u00dfach"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides constant flooding, why else was there regulation of the Rhine?",
        "answers": [
            "strong sedimentation",
            "strong sedimentation",
            "strong sedimentation in the western Rhine Delta",
            "strong sedimentation"
        ],
        "model_ans": "Navigation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Navigation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After the Dornbirner Ach was diverted, where does the Rhine flow now?",
        "answers": [
            "parallel to the canalized Rhine",
            "the canalized Rhine",
            "parallel to the canalized Rhine into the lake.",
            "into the lake"
        ],
        "model_ans": "into the Danube",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> into the Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is expected with the continuous input of sediment into the Dornbirner Ach?",
        "answers": [
            "silt",
            "silt up the lake",
            "the continuous input of sediment into the lake will silt up the lake",
            "silt up the lake"
        ],
        "model_ans": "The river will continue to change its course and shape over time",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The river will continue to change its course and shape over time </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the Rhine regulated with a lower canal?",
        "answers": [
            "Fu\u00dfach",
            "Fu\u00dfach",
            "Fu\u00dfach",
            "Fu\u00dfach"
        ],
        "model_ans": "Cologne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the Rhine regulated with an upper canal?",
        "answers": [
            "Diepoldsau",
            "Diepoldsau",
            "near Diepoldsau",
            "Diepoldsau"
        ],
        "model_ans": "Cologne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why was the Rhine regulated? ",
        "answers": [
            "constant flooding",
            "constant flooding and strong sedimentation",
            "to counteract the constant flooding and strong sedimentation in the western Rhine Delta",
            "to counteract the constant flooding and strong sedimentation"
        ],
        "model_ans": "To prevent flooding",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To prevent flooding </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was diverted and now flows parallel to the Rhine?",
        "answers": [
            "Dornbirner Ach",
            "Dornbirner Ach",
            "The Dornbirner Ach",
            "Dornbirner Ach"
        ],
        "model_ans": "Moselle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Moselle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What will cause the lake near the Rhine to silt up?",
        "answers": [
            "continuous input of sediment",
            "continuous input of sediment",
            "It is expected that the continuous input of sediment into the lake will silt up the lake",
            "continuous input of sediment into the lake"
        ],
        "model_ans": "sedimentation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sedimentation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many bodies of water makes up Lake Constance? ",
        "answers": [
            "three",
            "three",
            "three bodies of water:",
            "three"
        ],
        "model_ans": "3\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What lake connects the Rhine to Lake Constance? ",
        "answers": [
            "Lake Rhine",
            "Seerhein",
            "Untersee",
            "Seerhein"
        ],
        "model_ans": "Bodensee",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bodensee</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Obersee mean?",
        "answers": [
            "upper lake",
            "upper lake",
            "(\"upper lake\"",
            "upper lake"
        ],
        "model_ans": "Lake",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lake </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Untersee mean?",
        "answers": [
            "lower lake",
            "lower lake",
            "\"lower lake\"",
            "lower lake"
        ],
        "model_ans": "German for \"undersea\"",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> German for \"undersea\" </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which border does the Rhine flow from the south?",
        "answers": [
            "Swiss-Austrian border",
            "Swiss-Austrian",
            "Swiss-Austrian border"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many bodies of water makes up Lake Constance?",
        "answers": [
            "three",
            "three",
            "three bodies of water",
            "three"
        ],
        "model_ans": "3\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides Germany and Switzerland, where else is Lake Constance?",
        "answers": [
            "Austria",
            "Austria",
            "Austria",
            "Austria"
        ],
        "model_ans": "Austria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Austria </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What mountainous region is Lake Constance by?",
        "answers": [
            "Alps",
            "Alps",
            "the Alps",
            "Alps"
        ],
        "model_ans": "Alps",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alps </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is the border of Swiss and Austria?",
        "answers": [
            "47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317.",
            "47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317",
            "47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317"
        ],
        "model_ans": "The border is approximately 156 km (97 mi) long and runs from the Swiss canton of Grisons in the east to the Austrian state of Tyrol in the west. </</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The border is approximately 156 km (97 mi) long and runs from the Swiss canton of Grisons in the east to the Austrian state of Tyrol in the west. </</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Lake Constance separates the German state Bavaria from what other one?",
        "answers": [
            "Baden-W\u00fcrttemberg",
            "Baden-W\u00fcrttemberg",
            "Baden-W\u00fcrttemberg",
            "Baden-W\u00fcrttemberg"
        ],
        "model_ans": "Switzerland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Switzerland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why does the Rhine water fall into depths at the Rheinbrech?",
        "answers": [
            "greater density of cold water",
            "greater density of cold water",
            "because of the greater density of cold water"
        ],
        "model_ans": "The Rhine water falls into depths at the Rheinbrech due to the geological structure of the area, which is characterized by a deep valley and a fault line.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine water falls into depths at the Rheinbrech due to the geological structure of the area, which is characterized by a deep valley and a fault line. </answer>\n</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the cold and warm water meet the warm water?",
        "answers": [
            "Rheinbrech",
            "Upper Lake",
            "Rheinbrech"
        ],
        "model_ans": "Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Island off of the German shore of the Rhine that this warm and cold water meet?",
        "answers": [
            "Lindau",
            "Lindau",
            "Lindau"
        ],
        "model_ans": "Mainau",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mainau </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Lake in a German island Mainau receives a fraction of the Rhine's flow?",
        "answers": [
            "Lake \u00dcberlingen",
            "Lake \u00dcberlingen",
            "Lake \u00dcberlingen"
        ],
        "model_ans": "Lake Constance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Constance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of the lake connecting with the Rhine can you see from the German islands?",
        "answers": [
            "entire length",
            "the entire length of the lake",
            "entire length of the lake"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the cold water mix with Lake Constance?",
        "answers": [
            "Rheinbrech",
            "Upper Lake",
            "Rheinrinne"
        ],
        "model_ans": "Rhine River",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhine River </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What island does the cold water flow of the Rhine and Lake Constance flow to?",
        "answers": [
            "Lindau",
            "Lindau",
            "Mainau"
        ],
        "model_ans": "Netherlands",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Netherlands </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A small fraction of the cold water flow from Lake Constance goes to what other lake?",
        "answers": [
            "Lake \u00dcberlingen",
            "Lake \u00dcberlingen",
            "Lake \u00dcberlingen"
        ],
        "model_ans": "Lake Geneva",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Geneva </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the word Rheinrinne translate to?",
        "answers": [
            "Rhine Gutter",
            "Rhine Gutter",
            "Rhine Gutter"
        ],
        "model_ans": "Rhine memory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhine memory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the flow of the Rhine being visible depend on?",
        "answers": [
            "water level",
            "water level",
            "water level"
        ],
        "model_ans": "Water level",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Water level </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After the Rhine emerges from Lake Constance, what direction does it flow?",
        "answers": [
            "westward",
            "westward",
            "westward"
        ],
        "model_ans": "west",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> west </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the major tributary of the Rhine?",
        "answers": [
            "river Aare",
            "Aare",
            "river Aare"
        ],
        "model_ans": "Moselle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Moselle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much water does the Aare give to the Rhine?",
        "answers": [
            "1,000 m3/s (35,000 cu ft/s)",
            "1,000 m3/s"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the highest point of the Rhine basin?",
        "answers": [
            "Finsteraarhorn",
            "summit of Finsteraarhorn",
            "Finsteraarhorn, t"
        ],
        "model_ans": "S\u00e4ntis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> S\u00e4ntis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the so-called Rhine Knee?",
        "answers": [
            "Basel",
            "Basel",
            "Basel, leaving Switzerland"
        ],
        "model_ans": "Switzerland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Switzerland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When the Rhine emerges from Lake Constance which way does it flow?",
        "answers": [
            "westward",
            "westward",
            "westward"
        ],
        "model_ans": "west",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> west </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the major tributary for the Rhine? ",
        "answers": [
            "Aare",
            "Aare",
            "river Aare"
        ],
        "model_ans": "Moselle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Moselle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine gets how much water from the Aare?",
        "answers": [
            "1,000 m3/s (35,000 cu ft/s),",
            "1,000 m3/s"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the highest point of the Rhine basin called?",
        "answers": [
            "Finsteraarhorn",
            "summit of Finsteraarhorn",
            "Finsteraarhorn"
        ],
        "model_ans": "S\u00e4ntis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> S\u00e4ntis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There's a rough border between Switzerland and what other country formed by the Rhine?",
        "answers": [
            "German",
            "German-Swiss border",
            "German"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the first major city in the stream of the Rhine?",
        "answers": [
            "Basel",
            "Basel",
            "Basel,"
        ],
        "model_ans": "Cologne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the bend of Rhine in Basel called? ",
        "answers": [
            "Rhine knee",
            "Rhine knee",
            "Rhine knee"
        ],
        "model_ans": "Rhine bend",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine bend </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the boundary between the High and Upper Rhine? ",
        "answers": [
            "Central Bridge",
            "Central Bridge",
            "Central Bridge"
        ],
        "model_ans": "Rhine River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long is the Upper Rhine Plain?",
        "answers": [
            "300 km long",
            "300 km long",
            "300 km long"
        ],
        "model_ans": "300 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 300 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How wide is the Upper Rhine Plain? ",
        "answers": [
            "40 km wide",
            "40 km wide",
            "40 km"
        ],
        "model_ans": "50-100 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50-100 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the first major city in the course of the Rhine?",
        "answers": [
            "Basel",
            "Basel",
            "Basel"
        ],
        "model_ans": "Cologne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the first major bend in the Rhine called?",
        "answers": [
            "Rhine knee",
            "Rhine knee",
            "Rhine knee"
        ],
        "model_ans": "Rheinb\u00f6llen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rheinb\u00f6llen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The bend on the Rhine goes from the West to what direction?",
        "answers": [
            "North",
            "North",
            "North"
        ],
        "model_ans": "East",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> East </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What ends at this bend in the Rhine?",
        "answers": [
            "High Rhine",
            "High Rhine",
            "High Rhine"
        ],
        "model_ans": "river",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> river </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the legal boundary behind the High and Upper Rind?",
        "answers": [
            "Central Bridge",
            "Central Bridge",
            "Central Bridge"
        ],
        "model_ans": "The High and Upper Rind",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The High and Upper Rind </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which century was there a program to straighten the Rhine? ",
        "answers": [
            "19th Century",
            "19th",
            "19th"
        ],
        "model_ans": "19th",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 19th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened to the rate of flow in the Rhine during the Rhine straightening program?",
        "answers": [
            "increased",
            "increased",
            "rate of flow was increased"
        ],
        "model_ans": "increased",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> increased </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened to the ground water in the Rhine during the Rhine straightening program?",
        "answers": [
            "fell significantly",
            "fell significantly",
            "level fell significantly"
        ],
        "model_ans": "The Rhine's water level dropped significantly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine's water level dropped significantly </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which canal was dug in France to carry Rhine's water?",
        "answers": [
            "Grand Canal d'Alsace",
            "Grand Canal d'Alsace",
            "Grand Canal d'Alsace"
        ],
        "model_ans": "Rhine-Rhone Canal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhine-Rhone Canal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Bassin de compensation de Plobsheim in Alsace? ",
        "answers": [
            "large compensation pools",
            "large compensation pools",
            "compensation pools"
        ],
        "model_ans": "a water reservoir",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a water reservoir </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What region of the Rhine was changed by the Rhine Straightening program?",
        "answers": [
            "Upper Rhine",
            "Upper Rhine",
            "Upper Rhine region"
        ],
        "model_ans": "Lower",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lower </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Rhine Straightening program begin?",
        "answers": [
            "19th Century",
            "19th",
            "19th Century"
        ],
        "model_ans": "1876",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1876 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened with the rate of flow in the Rhine with the straightening program?",
        "answers": [
            "increased",
            "increased",
            "was increased"
        ],
        "model_ans": "increased",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> increased </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened with the ground water level with the Rhine straightening program?",
        "answers": [
            "fell significantly",
            "fell significantly",
            "level fell"
        ],
        "model_ans": "The Rhine straightening program led to a significant decrease in the groundwater level",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine straightening program led to a significant decrease in the groundwater level </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What carries a significant amount of the Rhine flow through France?",
        "answers": [
            "Grand Canal d'Alsace",
            "Grand Canal d'Alsace",
            "Grand Canal d'Alsace"
        ],
        "model_ans": "Moselle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Moselle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the longest river in Germany?",
        "answers": [
            "Rhine",
            "Rhine",
            "The Rhine"
        ],
        "model_ans": "Elbe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elbe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Rhine encounter it's tributary the Neckar? ",
        "answers": [
            "Germany",
            "Germany",
            "Germany"
        ],
        "model_ans": "Heidelberg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Heidelberg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the average discharge of the Moselle to the Rhine?",
        "answers": [
            "300 m3/s (11,000 cu ft/s)",
            "300 m3/s",
            "300 m3/s"
        ],
        "model_ans": "300 cubic meters per second",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 300 cubic meters per second </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a main tributary to the Rhine that goes through Northeastern France and part of Belgium?",
        "answers": [
            "Moselle",
            "Moselle",
            "the Moselle"
        ],
        "model_ans": "Meuse",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Meuse </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the average width of the Rhine?",
        "answers": [
            "400 m (1,300 ft).",
            "400 m",
            "400 m"
        ],
        "model_ans": "1 km\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1 km\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine is the longest river in what country?",
        "answers": [
            "Germany",
            "Germany",
            "Germany"
        ],
        "model_ans": "Germany\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Germany\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which country does the Rhine encounter it's main tributaries?",
        "answers": [
            "Germany",
            "Germany",
            "Germany"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which of the tributaries in Germany contributes most? ",
        "answers": [
            "Moselle",
            "Neckar",
            "Neckar"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What country does the Moselle take the Rhine to?",
        "answers": [
            "France",
            "France",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much does the Rhine discharge at the Dutch border?",
        "answers": [
            "2,290 m3/s (81,000 cu ft/s)",
            "2,290 m3/s",
            "2,290 m3/s"
        ],
        "model_ans": "2,900 m\u00b3/s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,900 m\u00b3/s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What flows between the Bingen and Bonn?",
        "answers": [
            "Middle Rhine",
            "Middle Rhine",
            "Middle Rhine"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What gorge is between the Bingen and Bonn?",
        "answers": [
            "Rhine Gorge",
            "Rhine Gorge",
            "Rhine Gorge"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How was the Rhine Gorge formed?",
        "answers": [
            "erosion",
            "erosion",
            "by erosion"
        ],
        "model_ans": "erosion",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> erosion </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the area called near the Rhine Gorge with castles from the middle ages?",
        "answers": [
            "the Romantic Rhine",
            "the Romantic Rhine",
            "the Romantic Rhine"
        ],
        "model_ans": "Rhine Valley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine Valley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What flows between Bingen and Bonn?",
        "answers": [
            "Middle Rhine",
            "Middle Rhine",
            "Middle Rhine"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Middle Rhine flow between Bingen and Bonn?",
        "answers": [
            "Rhine Gorge",
            "Rhine Gorge",
            "Rhine Gorge"
        ],
        "model_ans": "Rhine River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Rhine Gorge known for?",
        "answers": [
            "castles",
            "castles and vineyards",
            "castles and vineyards"
        ],
        "model_ans": "scenic beauty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> scenic beauty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the section of the Rhine Gorge recognized by UNESCO called?",
        "answers": [
            "Romantic Rhine",
            "the Romantic Rhine",
            "the Romantic Rhine"
        ],
        "model_ans": "Upper Middle Rhine Valley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Upper Middle Rhine Valley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What contributed to water pollution in the Rhine? ",
        "answers": [
            "plants and factories",
            "industry",
            "industry"
        ],
        "model_ans": "Industrial waste",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Industrial waste </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are a bulk of factories concentrated along the Rhine?",
        "answers": [
            "Switzerland",
            "Lower Rhine",
            "Lower Rhine"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is Europe's largest inland port?",
        "answers": [
            "Duisburg",
            "Duisburg",
            "Duisburg"
        ],
        "model_ans": "Amsterdam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amsterdam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What rive joins the Rhine in Duisburg? ",
        "answers": [
            "Ruhr",
            "Ruhr",
            "The Ruhr"
        ],
        "model_ans": "Ruhr",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ruhr </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the Ruhr provide to it's community?",
        "answers": [
            "drinking water",
            "drinking water",
            "drinking water"
        ],
        "model_ans": "coal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> coal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did industry do to the Rhine until the 1980s?",
        "answers": [
            "pollution",
            "pollution",
            "water pollution"
        ],
        "model_ans": "polluted",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> polluted </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which section of the Rhine is most factories found?",
        "answers": [
            "Lower Rhine",
            "Lower Rhine",
            "Lower Rhine"
        ],
        "model_ans": "Ruhr",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ruhr </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What country has the most factories that pollute the Rhine?",
        "answers": [
            "Switzerland",
            "Duisburg",
            "Switzerland"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What city has the largest inland port in Europe?",
        "answers": [
            "Duisburg",
            "Duisburg",
            "Duisburg"
        ],
        "model_ans": "Amsterdam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amsterdam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which river joins the Rhine in Duisburg?",
        "answers": [
            "Ruhr",
            "Ruhr",
            "The Ruhr"
        ],
        "model_ans": "Ruhr",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ruhr </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Besides viniculture, what's a dominant economic sector of the Middle Rhine?",
        "answers": [
            "tourism",
            "tourism",
            "tourism"
        ],
        "model_ans": "Tourism",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tourism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "There's a UNESCO World Heritage site in the Rhine Gorge between the Koblenz and what?",
        "answers": [
            "R\u00fcdesheim am Rhein",
            "R\u00fcdesheim am Rhein",
            "R\u00fcdesheim am Rhein"
        ],
        "model_ans": "Bingen am Rhein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bingen am Rhein</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the famous rock near Sanke Goarshausen?",
        "answers": [
            "Lorelei",
            "Lorelei",
            "Lorelei"
        ],
        "model_ans": "Loreley Rock",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Loreley Rock </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is considered the epitome of the Rhine romanticism? ",
        "answers": [
            "Middle Rhine Valley",
            "Middle Rhine Valley",
            "Middle Rhine Valley"
        ],
        "model_ans": "Cologne Cathedral",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cologne Cathedral </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides viniculture, what is the other dominate economic sector in the middle rhine?",
        "answers": [
            "tourism",
            "tourism",
            "tourism"
        ],
        "model_ans": "Tourism",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tourism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Rhine Gorge listed as?",
        "answers": [
            "UNESCO World Heritage Site.",
            "UNESCO World Heritage Site",
            "World Heritage Site"
        ],
        "model_ans": "UNESCO World Heritage Site",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO World Heritage Site </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Rhine Gorge is between Koblenz and what other city?",
        "answers": [
            "R\u00fcdesheim am Rhein",
            "R\u00fcdesheim am Rhein",
            "R\u00fcdesheim am Rhein"
        ],
        "model_ans": "Mainz",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mainz </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the famous rock called that the Rhine flows around?",
        "answers": [
            "Lorelei",
            "Lorelei",
            "Lorelei"
        ],
        "model_ans": "Lorelei",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lorelei </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is the famous rock the Rhine flows around?",
        "answers": [
            "Sankt Goarshausen",
            "Near Sankt Goarshausen",
            "Lorelei"
        ],
        "model_ans": "Cologne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What city has the biggest port in Germany?",
        "answers": [
            "Duisburg",
            "Duisburg",
            "Duisburg"
        ],
        "model_ans": "Bremen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bremen</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Canal in Wesel? ",
        "answers": [
            "Wesel-Datteln Canal",
            "Wesel-Datteln Canal",
            "Wesel-Datteln Canal"
        ],
        "model_ans": "Rhine-Herne Canal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rhine-Herne Canal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Wessel-Datteln canal run parallel to?",
        "answers": [
            "Lippe",
            "Lippe",
            "Lippe"
        ],
        "model_ans": "Ruhr",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Ruhr</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the largest suspension bridge in Germany?",
        "answers": [
            "Emmerich Rhine Bridge",
            "Emmerich Rhine Bridge",
            "Emmerich Rhine Bridge,"
        ],
        "model_ans": "Eiserner Steg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Eiserner Steg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How wide is the Rhine in Germany between Emmrich and Cleves?",
        "answers": [
            "400 m",
            "400 m",
            "400 m"
        ],
        "model_ans": "200-400 meters",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 200-400 meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What part of the Rhine flows through North Rhine-Westphalia?",
        "answers": [
            "Lower Rhine",
            "Lower",
            "Lower Rhine"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the region called that is the largest conurbation of the Rhine?",
        "answers": [
            "Rhine-Ruhr",
            "Rhine-Ruhr",
            "Rhine-Ruhr region"
        ],
        "model_ans": "Rhine-Ruhr",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine-Ruhr </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the largest port in Europe called?",
        "answers": [
            "Duisport",
            "Duisport",
            "Duisburg"
        ],
        "model_ans": "Rotterdam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rotterdam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the longest bridge in Germany?",
        "answers": [
            "Emmerich Rhine Bridge",
            "Emmerich Rhine Bridge",
            "Emmerich Rhine Bridge"
        ],
        "model_ans": "Eiserner Steg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Eiserner Steg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How wide is the Rhine in Germany?",
        "answers": [
            "400 m wide",
            "400 m",
            "400 m"
        ],
        "model_ans": "100-200 meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100-200 meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the Dutch name for the Rhine?",
        "answers": [
            "Rijn",
            "Rijn",
            "Rijn"
        ],
        "model_ans": "Rijn",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rijn </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the water flow of the Rhine merge with after flowing through Merwede?",
        "answers": [
            "Meuse",
            "Meuse",
            "Meuse"
        ],
        "model_ans": "North Sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North Sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of the water flow does the Waal get from the Rhine?",
        "answers": [
            "Two thirds",
            "Two thirds",
            "Two thirds"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which direction does two thirds of the Rhine flow outside of Germany?",
        "answers": [
            "west",
            "west",
            "west"
        ],
        "model_ans": "west",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> west </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does two thirds of the Rhine flow outside of Germany?",
        "answers": [
            "Waal",
            "Waal",
            "through the Waal"
        ],
        "model_ans": "Netherlands",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Netherlands </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Rhine merge with outside of Germany?",
        "answers": [
            "Meuse",
            "Meuse",
            "Meuse"
        ],
        "model_ans": "North Sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North Sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What's the name of where the Rhine branches off near Dordrecht?",
        "answers": [
            "The Oude Maas",
            "Oude Maas",
            "Oude Maas"
        ],
        "model_ans": "Waal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Waal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If two thirds of the Rhine flows through the Maas, where doe the other one third flow through?",
        "answers": [
            "Pannerdens Kanaal",
            "Pannerdens Kanaal",
            "the Pannerdens Kanaal"
        ],
        "model_ans": "The other one third flows through the Danube",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The other one third flows through the Danube </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine redistributes into the Ijssel and what other body?",
        "answers": [
            "Nederrijn",
            "Nederrijn",
            "Nederrijn"
        ],
        "model_ans": "Main",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Main </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Nederrikn's name change into?",
        "answers": [
            "Lek",
            "Lek",
            "the Lek"
        ],
        "model_ans": "Nederrijn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nederrijn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does the Lek join? ",
        "answers": [
            "Noord River",
            "Nieuwe Maas",
            "Noord River"
        ],
        "model_ans": "Jhelum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jhelum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If two thirds of the Rhine flows through Waal, where does the other third flow through?",
        "answers": [
            "Pannerdens Kanaal",
            "Pannerdens Kanaal",
            "the Pannerdens Kanaal"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than the Ijssel, where does the water from the Pannerdens Kanaal redsitrubute?",
        "answers": [
            "Nederrijn",
            "Nederrijn",
            "Nederrijn"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of the Rhine flow does Ijssel carry?",
        "answers": [
            "one ninth",
            "one ninth",
            "one ninth"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Nederrijn change it's name to?",
        "answers": [
            "Lek",
            "Lek",
            "the Lek"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Nederrijn change it's name?",
        "answers": [
            "Wijk bij Duurstede",
            "at Wijk bij Duurstede",
            "Wijk bij Duurstede"
        ],
        "model_ans": "Wupper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wupper </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name for the smaller streams along the region northern Germany?",
        "answers": [
            "Rijn",
            "Rijn",
            "Rijn"
        ],
        "model_ans": "Bach",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bach </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The smaller streams are used for what?",
        "answers": [
            "draining the surrounding land",
            "draining the surrounding land and polders",
            "for draining the surrounding land and polders"
        ],
        "model_ans": "irrigation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> irrigation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the name of the old north branch of the Rhine?",
        "answers": [
            "Kromme Rijn",
            "Kromme Rijn",
            "Kromme Rijn"
        ],
        "model_ans": "Oberer Rhein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oberer Rhein </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the translation of the old north branch of rhe Rhine?",
        "answers": [
            "Bent Rhine",
            "Bent Rhine",
            "Bent Rhine"
        ],
        "model_ans": "Alte Nahe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alte Nahe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What part of the Rhine flows west at Katwijk?",
        "answers": [
            "Old Rhine",
            "Oude Rijn",
            "Oude Rijn"
        ],
        "model_ans": "The Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of the Delta in the Netherlands? ",
        "answers": [
            "Rhine-Meuse",
            "Rhine-Meuse Delta",
            "Rhine-Meuse"
        ],
        "model_ans": "Delta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Delta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Delta in the Netherlands begin?",
        "answers": [
            "Millingen aan de Rijn,",
            "near Millingen aan de Rijn",
            "near Millingen aan de Rijn"
        ],
        "model_ans": "Rotterdam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rotterdam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the nickname for the Delta in the Netherlands?",
        "answers": [
            "Rhine Delta",
            "Rhine Delta",
            "Rhine Delta"
        ],
        "model_ans": "Waterwolf",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Waterwolf </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At Millingen aan de Rijn where the Rhine splits, what does it change it's name to?",
        "answers": [
            "Nederrijn at Angeren",
            "Nederrijn at Angeren",
            "Nederrijn at Angeren"
        ],
        "model_ans": "Waal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Waal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many main flows are branched off from the Nederrijn?",
        "answers": [
            "three",
            "three",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the largest main branch of the Rhine?",
        "answers": [
            "Waal",
            "Waal",
            "Waal"
        ],
        "model_ans": "Main",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Main </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the English translation of Het Scheur?",
        "answers": [
            "the Rip",
            "the Rip",
            "the Rip"
        ],
        "model_ans": "The Tear",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Tear </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the translation of Oude Maas?",
        "answers": [
            "Old Meuse",
            "Old Meuse",
            "Old Meuse"
        ],
        "model_ans": "Old Meuse",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Old Meuse </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What flood impacted the Meuse?",
        "answers": [
            "St. Elizabeth's",
            "St. Elizabeth's",
            "St. Elizabeth's flood"
        ],
        "model_ans": "1993",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1993 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did the flood that impacted the Meuse take place?",
        "answers": [
            "1421",
            "1421",
            "1421"
        ],
        "model_ans": "1993\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1993\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the Meuse flow before the flood? ",
        "answers": [
            "Merwede-Oude Maas",
            "Merwede-Oude Maas",
            "North Sea"
        ],
        "model_ans": "Meuse",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Meuse </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Merwede-Oude Maas form with Waal and Lek?",
        "answers": [
            "archipelago-like estuary",
            "archipelago-like estuary",
            "archipelago-like estuary"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Meuse and Waal merge?",
        "answers": [
            "1421 to 1904",
            "1421 to 1904",
            "From 1421 to 1904"
        ],
        "model_ans": "1996",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1996 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for closing off rivers that are no longer connected?",
        "answers": [
            "dammed",
            "dammed",
            "dammed"
        ],
        "model_ans": "River cutoff",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> River cutoff </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do closed rivers serve as after they close?",
        "answers": [
            "drainage channels",
            "drainage channels",
            "drainage channels"
        ],
        "model_ans": "Habitat for aquatic life",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Habitat for aquatic life </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What changed the Rhine's Delta?",
        "answers": [
            "construction of Delta Works",
            "construction of Delta Works",
            "construction of Delta Works"
        ],
        "model_ans": "Human activities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Human activities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the construction that changed the Rhine's Delta?",
        "answers": [
            "20th Century",
            "20th Century",
            "second half of the 20th Century"
        ],
        "model_ans": "1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of Delta is the Rhine-Meuse?",
        "answers": [
            "tidal delta",
            "tidal",
            "tidal delta"
        ],
        "model_ans": "River Delta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> River Delta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Besides rivers, what shapes the sedimentation of the rivers?",
        "answers": [
            "tidal currents",
            "tidal currents",
            "tidal currents"
        ],
        "model_ans": "wind",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> wind </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does a high tide risk near lands? ",
        "answers": [
            "tear huge areas of land into the sea.",
            "tidal currents",
            "tear huge areas of land into the sea"
        ],
        "model_ans": "Flooding",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Flooding </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Between Brakel and what other city can the most landward tidal influence be detected?",
        "answers": [
            "Zaltbommel",
            "Zaltbommel",
            "Zaltbommel"
        ],
        "model_ans": "Antwerp",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Antwerp </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The present Mediterranean Sea descends from what sea?",
        "answers": [
            "Tethys sea",
            "Tethys",
            "Tethys sea"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What period opened the Tethys Ocean?",
        "answers": [
            "Mesozoic Era",
            "Triassic Period",
            "Triassic Period"
        ],
        "model_ans": "Jurassic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jurassic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What period did plates reverse directions to compress the Tethys floor?",
        "answers": [
            "Jurassic Period",
            "Jurassic Period",
            "Jurassic Period"
        ],
        "model_ans": "Paleogene",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paleogene </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Microplates squeezing and rotating created the features of what?",
        "answers": [
            "Mediterranean geography",
            "Mediterranean geography",
            "Mediterranean geography"
        ],
        "model_ans": "the Earth's surface",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the Earth's surface </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What pushed up the Pyrenees?",
        "answers": [
            "Iberia",
            "Iberia",
            "Iberia"
        ],
        "model_ans": "Continental collision",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Continental collision </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What rift system developed in the Alpine orogeny?",
        "answers": [
            "N\u2013S",
            "N\u2013S",
            "N\u2013S rift system"
        ],
        "model_ans": "The Rhine Rift",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine Rift </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What elements from the rift system in the Alpine orogeny in Southwest Germany?",
        "answers": [
            "Upper Rhine Graben",
            "Upper Rhine Graben",
            "Upper Rhine Graben"
        ],
        "model_ans": "Granite",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Granite </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What time did a river system develop in the Upper Rhine Graben?",
        "answers": [
            "Miocene",
            "By the time of the Miocene",
            "time of the Miocene"
        ],
        "model_ans": "20 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine and what other river drained the northern flanks of the alps?",
        "answers": [
            "Danube",
            "Danube",
            "Danube"
        ],
        "model_ans": "Danube",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the Rhine extend watershed southward? ",
        "answers": [
            "stream capture",
            "stream capture",
            "stream capture"
        ],
        "model_ans": "The Rhine extended its watershed southward through the formation of the Rhine-Main-Danube Canal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine extended its watershed southward through the formation of the Rhine-Main-Danube Canal </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What period did the Rhine capture streams?",
        "answers": [
            "Pliocene period",
            "Pliocene",
            "Pliocene period"
        ],
        "model_ans": "Pleistocene",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pleistocene </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are the streams the Rhine captured?",
        "answers": [
            "Vosges Mountains",
            "Vosges Mountains",
            "Vosges Mountains,"
        ],
        "model_ans": "Switzerland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Switzerland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What period was 2.5 million years ago?",
        "answers": [
            "Ice Ages",
            "geological period",
            "geological period of the Ice Ages"
        ],
        "model_ans": "Pliocene",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pliocene </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many major ice ages have occurred? ",
        "answers": [
            "six",
            "six",
            "six"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far did the sea level drop in the ice ages?",
        "answers": [
            "120 m",
            "120 m",
            "120 m"
        ],
        "model_ans": "120 meters",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 120 meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In early Pleistocene, what direction did the Rhine flow?",
        "answers": [
            "northwest",
            "northwest",
            "northwest"
        ],
        "model_ans": "east",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> east </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During glacial times, where was the mouth of the Rhine located?",
        "answers": [
            "Brest",
            "Brest, France",
            "offshore of Brest,"
        ],
        "model_ans": "The North Sea",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The North Sea </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the last glacial start?",
        "answers": [
            "74,000 (BP",
            "~74,000 (BP = Before Present)",
            "~74,000 (BP = Before Present)"
        ],
        "model_ans": "110,000 years ago\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "110,000 years ago\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the last glacial end?",
        "answers": [
            "11,600 BP",
            "(~11,600 BP",
            "end of the Pleistocene (~11,600 BP)"
        ],
        "model_ans": "11,700 years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 11,700 years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which direction did the Rhine flow during the last cold phase?",
        "answers": [
            "west",
            "west",
            "west"
        ],
        "model_ans": "East",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> East </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much lower was the North Sea in the last cold phase than it is today?",
        "answers": [
            "120 m",
            "120 m",
            "120 m"
        ],
        "model_ans": "100 meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides the North Sea and the Irish Channel, what else was lowered in the last cold phase?",
        "answers": [
            "English Channel",
            "English Channel",
            "English Channel"
        ],
        "model_ans": "The Baltic Sea",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Baltic Sea </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the source of the Rhine in the last Ice Age?",
        "answers": [
            "glacier",
            "glacier",
            "a glacier"
        ],
        "model_ans": "Lake Balaton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Balaton </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What stretched across middle Europe in the last ice age?",
        "answers": [
            "tundra",
            "tundra",
            "A tundra"
        ],
        "model_ans": "Weichselian glaciation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Weichselian glaciation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Last Glacial Maximum?",
        "answers": [
            "22,000\u201314,000 yr BP",
            "22,000\u201314,000 yr BP",
            "ca. 22,000\u201314,000 yr BP"
        ],
        "model_ans": "20,000 years ago\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "20,000 years ago\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What covered Scandinavia, the Baltics, Scotland, and the Alps in the last Ice Age?",
        "answers": [
            "ice-sheets",
            "ice-sheets",
            "ice-sheets"
        ],
        "model_ans": "Ice",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ice </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the term for wind-blown dust in a tundra?",
        "answers": [
            "loess",
            "loess",
            "loess"
        ],
        "model_ans": "loess",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> loess </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Europe slowly begin to warm up from the last Ice Age?",
        "answers": [
            "22,000 years ago",
            "22,000 years ago",
            "22,000 years ago"
        ],
        "model_ans": "around 15,000 years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 15,000 years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did frozen subsoil and expanded alpine glaciers begin to do?",
        "answers": [
            "thaw",
            "thaw and fall-winter snow covers",
            "thaw"
        ],
        "model_ans": "cool",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cool </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did the discharge from glaciers go in Europe in the last Ice Age?",
        "answers": [
            "Rhine",
            "Rhine",
            "the Rhine"
        ],
        "model_ans": "Oceans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oceans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did rapid warming begin and help vegetation?",
        "answers": [
            "13,000 BP",
            "13,000 BP",
            "13,000 BP"
        ],
        "model_ans": "10,000 years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Europe fully forested and recovered from the last Ice Age?",
        "answers": [
            "9000 BP",
            "9000 BP",
            "9000 BP"
        ],
        "model_ans": "around 4000 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 4000 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did tides and currents similar to our current system begin?",
        "answers": [
            "7500 yr ago",
            "7500 yr ago",
            "7500 yr ago"
        ],
        "model_ans": "3.5 billion years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3.5 billion years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did natural sedimentation by the Rhine compensate the transgression bby the sea?",
        "answers": [
            "Rates of sea-level rise",
            "sea-level rise had dropped",
            "Rates of sea-level rise had dropped"
        ],
        "model_ans": "Not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long has the Rhine coastline been in the same location?",
        "answers": [
            "last 7000 years",
            "7000 years",
            "last 7000 years"
        ],
        "model_ans": "approximately 20 million years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> approximately 20 million years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is the current sea level rising?",
        "answers": [
            "tectonic subsidence",
            "tectonic subsidence",
            "ongoing tectonic subsidence"
        ],
        "model_ans": "due to climate change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> due to climate change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How quickly is the sea level rising?",
        "answers": [
            "1\u20133 cm (0.39\u20131.18 in) per century",
            "1\u20133 cm (0.39\u20131.18 in) per century",
            "1\u20133 cm (0.39\u20131.18 in) per century"
        ],
        "model_ans": "3.2 mm/year",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3.2 mm/year </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Holocene?",
        "answers": [
            "11,700 years ago",
            "~11,700 years ago",
            "~11,700 years ago"
        ],
        "model_ans": "11,700 years ago",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 11,700 years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did the Rhine occupy during the Holocene?",
        "answers": [
            "Late-Glacial valley",
            "Late-Glacial valley",
            "Late-Glacial valley"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What country did the Rhine continue to rise during the holocene?",
        "answers": [
            "Netherlands",
            "Netherlands",
            "Netherlands"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the formation of the Holocene Rhine-Meuse delta begin?",
        "answers": [
            "8,000 years ago",
            "~8,000 years ago",
            "~8,000 years ago"
        ],
        "model_ans": "10,000 years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When have humans started impacting the delta?",
        "answers": [
            "3000 yr BP",
            "~3000 yr BP",
            "~3000 yr BP"
        ],
        "model_ans": "1950s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What increased in the Rhine because of the land clearance in the upland areas?",
        "answers": [
            "sediment load",
            "sediment load",
            "sediment load"
        ],
        "model_ans": "sediment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sediment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has increased sediment and delta growth also produced in the Rhine?",
        "answers": [
            "increased flooding and sedimentation",
            "Bronze Age agriculture",
            "increased flooding and sedimentation"
        ],
        "model_ans": "Human activities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Human activities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many avulsions have occurred in the past 6000 yeas?",
        "answers": [
            "80",
            "80",
            "80"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did embankment of the major Rhine distributaries take palce?",
        "answers": [
            "11\u201313th century",
            "11\u201313th century AD",
            "11\u201313th century AD"
        ],
        "model_ans": "12th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do the branches Waal and Nederrijn-Lek discharge to?",
        "answers": [
            "North Sea",
            "North Sea",
            "North Sea",
            "North Sea"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the Waal and the Nederrijn-Lek discharge throguh?",
        "answers": [
            "Meuse estuary",
            "Meuse estuary",
            "Meuse estuary",
            "Meuse estuary"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the Ijssel branch flow?",
        "answers": [
            "IJsselmeer",
            "IJsselmeer",
            "IJsselmeer",
            "IJsselmeer"
        ],
        "model_ans": "Netherlands",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Netherlands </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Zuider Zee brackish lagoon change into?",
        "answers": [
            "freshwater lake",
            "freshwater lake",
            "freshwater lake",
            "freshwater lake"
        ],
        "model_ans": "IJsselmeer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IJsselmeer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many branches does the Rhine branch into?",
        "answers": [
            "three",
            "three",
            "three",
            "three"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Rhine first discovered?",
        "answers": [
            "1st century BC",
            "1st century BC",
            "1st century BC"
        ],
        "model_ans": "5000 BC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5000 BC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine first formed a boundary between Gaul and what else?",
        "answers": [
            "Germania",
            "Germania",
            "Germania"
        ],
        "model_ans": "Germania",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Germania </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Since when was the Rhine part of the areal of Hallstatt culture?",
        "answers": [
            "6th century BC",
            "6th century BC",
            "6th century BC"
        ],
        "model_ans": "800 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 800 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who first wrote about the Rhine's discovery and border?",
        "answers": [
            "Maurus Servius Honoratus",
            "Maurus Servius Honoratus"
        ],
        "model_ans": "Tacitus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tacitus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Augustus die?",
        "answers": [
            "AD 14",
            "AD 14",
            "AD 14"
        ],
        "model_ans": "14 AD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine and what other river were accepted as the Germanic frontier?",
        "answers": [
            "Danube",
            "upper Danube",
            "upper Danube"
        ],
        "model_ans": "Danube",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Rhine stop being the Roman boundary?",
        "answers": [
            "the empire fell",
            "until the empire fell",
            "until the empire fell"
        ],
        "model_ans": "5th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are the upper Rhine and upper Danube crossed?",
        "answers": [
            "southern",
            "between the modern Baden and W\u00fcrttemberg"
        ],
        "model_ans": "Basel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Basel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which direction did Romans use to drift through the Rhine?",
        "answers": [
            "eastwards",
            "eastwards",
            "eastwards"
        ],
        "model_ans": "Upstream",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Upstream </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many legions in five bases were along the Rhine by the Romans?",
        "answers": [
            "eight",
            "eight",
            "eight"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the number of legions in Roman times depend on?",
        "answers": [
            "threat of war",
            "whether a state or threat of war existed",
            "whether a state or threat of war existed"
        ],
        "model_ans": "the number of soldiers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the number of soldiers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Vetra and I Germanica and XX Valeria were the two legions for what?",
        "answers": [
            "army of Germania Inferior",
            "army of Germania Inferior",
            "army of Germania Inferior"
        ],
        "model_ans": "Rome",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rome </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the Colonia Agrippina's original name?",
        "answers": [
            "Ubiorum",
            "oppidum Ubiorum",
            "oppidum Ubiorum"
        ],
        "model_ans": "Portus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Portus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does Colonia Agrippina's original name translate into?",
        "answers": [
            "town of the Ubii",
            "town of the Ubii",
            "town of the Ubii"
        ],
        "model_ans": "Rome",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rome </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Germanic tribes cross the Rhine to migrate?",
        "answers": [
            "5th century",
            "Migration period",
            "5th century"
        ],
        "model_ans": "3rd century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3rd century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Germanic tribes establish with help from the Rhine?",
        "answers": [
            "kingdoms",
            "kingdoms",
            "kingdoms"
        ],
        "model_ans": "The Roman Empire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Roman Empire </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the translation of Siebengebirge?",
        "answers": [
            "dragons rock",
            "dragons rock",
            "dragons rock"
        ],
        "model_ans": "Seven Hills",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Seven Hills </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the hero who killed a dragon on the Drachenfels?",
        "answers": [
            "Siegfried",
            "Siegfried",
            "Siegfried"
        ],
        "model_ans": "Elric",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elric </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who threw gold into the Rhine, according to legend?",
        "answers": [
            "Hagen",
            "Hagen",
            "Hagen"
        ],
        "model_ans": "Sigurd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sigurd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Rhine become borders with Francia?",
        "answers": [
            "6th century",
            "6th century"
        ],
        "model_ans": "843",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 843 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Rhine fully within the Holy Roman Empire?",
        "answers": [
            "10th century",
            "10th century",
            "10th century"
        ],
        "model_ans": "1234",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1234 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Rhine flowed through Swabia, Franconia and what other location in the 10th Century?",
        "answers": [
            "Lower Lorraine",
            "Lower Lorraine",
            "Lower Lorraine"
        ],
        "model_ans": "Bavaria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bavaria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who sold the Upper Rhine to Burgundy?",
        "answers": [
            "Archduke Sigismund",
            "Archduke Sigismund of Austria",
            "Archduke Sigismund of Austria"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Upper Rhine sold to Burgundy?",
        "answers": [
            "1469",
            "1469",
            "1469"
        ],
        "model_ans": "1338",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1338 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the time the Upper Rhine form a border between France and Germany?",
        "answers": [
            "Peace of Westphalia",
            "Peace of Westphalia",
            "Peace of Westphalia"
        ],
        "model_ans": "Rhine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rhine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was a long term goal of French foreign policy along the Rhine?",
        "answers": [
            "Establishing \"natural borders\"",
            "Establishing \"natural borders\"",
            "Establishing \"natural borders\" on the Rhine"
        ],
        "model_ans": "To prevent Germany from becoming too powerful",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To prevent Germany from becoming too powerful </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who established the Confederation of the Rhine?",
        "answers": [
            "Napoleon",
            "Napoleon",
            "Napoleon"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the confederation of the Rhine?",
        "answers": [
            "1806",
            "1806",
            "1806"
        ],
        "model_ans": "1806\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1806\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Rhine crisis?",
        "answers": [
            "1840",
            "1840",
            "1840"
        ],
        "model_ans": "1840",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1840 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Rhineland subject to the Treaty of Versailles?",
        "answers": [
            "end of World War I",
            "end of World War I",
            "end of World War I"
        ],
        "model_ans": "1919\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1919\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When would the occupation of allies leave Rhineland?",
        "answers": [
            "1935",
            "1930",
            "1935"
        ],
        "model_ans": "1936  March",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1936 <answer> March </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "After 1935, who would be forbidden to enter Rhineland?",
        "answers": [
            "German army",
            "German army",
            "German army"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do some believe the Treaty of Versailles assisted in?",
        "answers": [
            "Adolf Hitler's rise to power",
            "helping Adolf Hitler's rise to power",
            "Adolf Hitler's rise to power"
        ],
        "model_ans": "World War II",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> World War II </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the German army reoccupy Rhineland?",
        "answers": [
            "1936",
            "1936",
            "1936"
        ],
        "model_ans": "1936\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1936\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is the Rhine Bridge?",
        "answers": [
            "Arnhem",
            "Arnhem",
            "Arnhem"
        ],
        "model_ans": "Cologne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cologne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Rhine considered to invaders in WWII?",
        "answers": [
            "formidable natural obstacle",
            "formidable natural obstacle",
            "natural obstacle"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Operation Market Garden?",
        "answers": [
            "September 1944",
            "September 1944",
            "September 1944"
        ],
        "model_ans": "17-26 September 1944\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "17-26 September 1944\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What bridge did the Germans fail to demolish?",
        "answers": [
            "Ludendorff Bridge",
            "Ludendorff Bridge",
            "Ludendorff Bridge"
        ],
        "model_ans": "The Rhine Bridge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine Bridge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Warsaw Pact war plan?",
        "answers": [
            "Seven Days to the River Rhine",
            "plan for an invasion of Western Europe",
            "plan for an invasion of Western Europe during the Cold War"
        ],
        "model_ans": "Operation Danube",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Operation Danube </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the accepted length of the Rhine prior to 1932?",
        "answers": [
            "1,230 kilometres (764 miles)",
            "1,230 kilometres",
            "1,230 kilometres"
        ],
        "model_ans": "1,232 km\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,232 km\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who stated a change of the length of the Rhine?",
        "answers": [
            "Knaurs Lexikon",
            "Knaurs Lexikon",
            "Knaurs Lexikon"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in 1932 what was the Rhine measurement changed to?",
        "answers": [
            "1,320 kilometres (820 miles)",
            "1,320 kilometres",
            "1,320 kilometres"
        ],
        "model_ans": "600",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 600 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why was the Rhine measurement changed? ",
        "answers": [
            "typographical error",
            "typographical error",
            "a typographical error"
        ],
        "model_ans": "The Rhine measurement was changed because of the introduction of the metric system in Germany in 1872.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Rhine measurement was changed because of the introduction of the metric system in Germany in 1872. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Rhine measurement corrected back to the original?",
        "answers": [
            "2010",
            "2010",
            "2010"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the current parliament of Scotland convened?",
        "answers": [
            "Following a referendum in 1997",
            "1998",
            "1998"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What act set out the Parliament's powers as a devolved legislature?",
        "answers": [
            "Scotland Act 1998",
            "Scotland Act 1998",
            "Scotland Act"
        ],
        "model_ans": "Government of Wales Act 1998",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Government of Wales Act 1998 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The legislative competence of the Parliament species what areas?",
        "answers": [
            "in which it can make laws",
            "the areas in which it can make laws",
            "powers that are \"reserved\" to the Parliament of the United Kingdom"
        ],
        "model_ans": "Federal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Federal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "To what body are certain powers explicitly specified as being reserved for?",
        "answers": [
            "Parliament of the United Kingdom",
            "Parliament of the United Kingdom",
            "The British Parliament"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Scottish Parliament may legislate as it pleases as long as the powers aren't already reserved by where?",
        "answers": [
            "Westminster",
            "Westminster",
            "Westminster"
        ],
        "model_ans": "Westminster",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Westminster </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What remained an important issue in Scottish national identity for many years?",
        "answers": [
            "lack of a Parliament of Scotland",
            "the lack of a Parliament of Scotland",
            "the lack of a Parliament of Scotland"
        ],
        "model_ans": "The Act of Union",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Act of Union </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many hundred of years was Scotland directly governed by the parliament of Great Britain?",
        "answers": [
            "three hundred",
            "three hundred years",
            "three hundred years"
        ],
        "model_ans": "200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why were the initial suggestions for a devolved parliament before 1914 shelved?",
        "answers": [
            "First World War.",
            "First World War",
            "the outbreak of the First World War"
        ],
        "model_ans": "The Home Rule Bill was shelved due to the outbreak of World War I",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Home Rule Bill was shelved due to the outbreak of World War I </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was there a sharp rise in nationalism in Scotland?",
        "answers": [
            "the late 1960s",
            "late 1960s",
            "late 1960s"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Kllbrandon's report in 1973 recommend establishing?",
        "answers": [
            "directly elected Scottish Assembly",
            "directly elected Scottish Assembly",
            "a directly elected Scottish Assembly"
        ],
        "model_ans": "A national health insurance program",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A national health insurance program </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which sea was oil discovered in?",
        "answers": [
            "North",
            "North Sea",
            "the North Sea"
        ],
        "model_ans": "Persian Gulf",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Persian Gulf </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What campaigh did the Scottish National Party (SNP) run?",
        "answers": [
            "\"It's Scotland's oil\"",
            "It's Scotland's oil",
            "\"It's Scotland's oil\""
        ],
        "model_ans": "Yes Scotland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yes Scotland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the SNP publicly opine about the oil revenues?",
        "answers": [
            "not benefitting Scotland as much as they should",
            "not benefitting Scotland as much as they should",
            "the revenues from the oil were not benefitting Scotland as much as they should"
        ],
        "model_ans": "Scotland should keep the oil revenues",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Scotland should keep the oil revenues </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Prime Minister Wilson commit to some form of devolved legislature?",
        "answers": [
            "1974",
            "1974",
            "1974"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the final legislative proposals for a Scottish Assembly passed?",
        "answers": [
            "1978",
            "1978",
            "1978"
        ],
        "model_ans": "1998",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1998 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was an elected assembly to be set up, under the terms of the Scotland Act of 1978?",
        "answers": [
            "Edinburgh",
            "Edinburgh",
            "Edinburgh"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many of the Scottish electorate would need to for it on the referendum?",
        "answers": [
            "majority",
            "40%",
            "at least 40%"
        ],
        "model_ans": "50%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did trying to establish a devolved Scottish Assembly go in 1979?",
        "answers": [
            "failed",
            "failed",
            "failed"
        ],
        "model_ans": "Failed",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Failed </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What percentage of the vote for a Scottish Assembly in favor of it?",
        "answers": [
            "51.6%",
            "51.6%",
            "51.6%"
        ],
        "model_ans": "63%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 63% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of Scotland's voting population failed to actually vote?",
        "answers": [
            "32.9%",
            "32.9%",
            "32.9%"
        ],
        "model_ans": "38%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 38% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In the range between 1980 and 1990, what did demand for grow?",
        "answers": [
            "a Scottish Parliament",
            "Scottish Parliament",
            "Scottish Parliament grew"
        ],
        "model_ans": "computers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> computers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose control of the UK's government helped fuel a desire for a Scottish Parliament?",
        "answers": [
            "the Conservative Party",
            "Conservative Party",
            "the Conservative Party"
        ],
        "model_ans": "Margaret Thatcher",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Margaret Thatcher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Scottish Constitutional Convention held?",
        "answers": [
            "1989",
            "1989",
            "1989"
        ],
        "model_ans": "1989\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1989\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What provided much of the basis for the structure of the Parliament in 1995?",
        "answers": [
            "blueprint",
            "blueprint",
            "the Convention"
        ],
        "model_ans": "The Magna Carta",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Magna Carta </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where has the official home of the Scottish Parliament been since 2004?",
        "answers": [
            "Scottish Parliament Building",
            "Scottish Parliament Building",
            "Edinburgh"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who designed the Scottish Parliament building?",
        "answers": [
            "Enric Miralles",
            "Enric Miralles",
            "Enric Miralles"
        ],
        "model_ans": "Enric Miralles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enric Miralles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What nationality is the architect Enric Miralles?",
        "answers": [
            "Spanish",
            "Spanish",
            "Spanish"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What shape are some of the buildings in the Parliament complex?",
        "answers": [
            "leaf-shaped",
            "leaf-shaped",
            "leaf-shaped buildings"
        ],
        "model_ans": "Gothic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who opened the new Parliament building on October 9, 2004?",
        "answers": [
            "Queen Elizabeth II",
            "Queen Elizabeth II",
            "Queen Elizabeth II"
        ],
        "model_ans": "Queen Elizabeth II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Elizabeth II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where was Parliament's temporary home whilst the permanent building was being built?",
        "answers": [
            "General Assembly Hall of the Church of Scotland",
            "General Assembly Hall of the Church of Scotland",
            "the General Assembly Hall of the Church of Scotland"
        ],
        "model_ans": "Whitehall",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Whitehall </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where were interviews held while the parliament was in its temporary building?",
        "answers": [
            "courtyard",
            "courtyard adjoining the Assembly Hall",
            "the courtyard"
        ],
        "model_ans": "Canberra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Canberra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the building vacated twice to allow for?",
        "answers": [
            "meeting of the Church's General Assembly",
            "meeting of the Church's General Assembly",
            "the meeting of the Church's General Assembly"
        ],
        "model_ans": "construction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> construction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was Parliament temporarily relocated to in May of 2000?",
        "answers": [
            "former Strathclyde Regional Council debating chamber in Glasgow",
            "former Strathclyde Regional Council debating chamber",
            "the former Strathclyde Regional Council debating chamber"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In May 2002, where would you go to address the Parliament?",
        "answers": [
            "University of Aberdeen",
            "University of Aberdeen",
            "the University of Aberdeen"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did the Parliament rent additional buildings from?",
        "answers": [
            "City of Edinburgh Council",
            "City of Edinburgh Council",
            "the City of Edinburgh Council"
        ],
        "model_ans": "The Crown Estate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Crown Estate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What  former administrative building was used for the MSP's offices?",
        "answers": [
            "Lothian Regional Council",
            "Lothian Regional Council",
            "Lothian Regional Council on George IV Bridge"
        ],
        "model_ans": "The Old City Hall",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Old City Hall </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened to the building on George IV Bridge when the Parliament was done with it?",
        "answers": [
            "demolished",
            "demolished",
            "demolished"
        ],
        "model_ans": "It was demolished",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> It was demolished </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do the former Midlothian County Buildings face?",
        "answers": [
            "Parliament Square, High Street and George IV Bridge in Edinburgh",
            "Parliament Square, High Street and George IV Bridge",
            "Parliament Square"
        ],
        "model_ans": "Market Square",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Market Square </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which hall was used as Parliament's principle committee room?",
        "answers": [
            "main",
            "main",
            "the main hall"
        ],
        "model_ans": "Westminster Hall",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Westminster Hall </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is elected to serve as the Presiding Officer at the beginning of each parliamentary session?",
        "answers": [
            "one MSP",
            "MSP",
            "MSP"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is currently speaker of the Scottish Parliament?",
        "answers": [
            "Tricia Marwick",
            "Tricia Marwick",
            "Tricia Marwick"
        ],
        "model_ans": "Alison Johnstone",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alison Johnstone </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of ballot is used to elect the Presiding Officer and deputies of the Parliament?",
        "answers": [
            "secret",
            "secret",
            "a secret ballot"
        ],
        "model_ans": "Secret ballot",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Secret ballot </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many MSPs are there?",
        "answers": [
            "129",
            "129",
            "129"
        ],
        "model_ans": "129",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 129 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is responsible for operating the electronic voting equipment and chamber clocks?",
        "answers": [
            "A vote clerk",
            "vote clerk",
            "vote clerk"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is responsible for ensuring the Parliament works smoothly?",
        "answers": [
            "Presiding Officer",
            "Presiding Officer",
            "the Presiding Officer"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who sets the work agenda and allocates time in the chamber?",
        "answers": [
            "the Parliamentary Bureau",
            "Presiding Officer",
            "the Parliamentary Bureau"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many seats must a political party have to be represented on the Parliamentary Bureau?",
        "answers": [
            "five",
            "five or more",
            "five or more seats"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who represents the Scottish Parliament at home and abroad in an official capacity?",
        "answers": [
            "The Presiding Officer",
            "Presiding Officer",
            "The Presiding Officer"
        ],
        "model_ans": "The Scottish Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Scottish Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the seating arrangement of the debating chamber?",
        "answers": [
            "hemicycle",
            "hemicycle",
            "a hemicycle"
        ],
        "model_ans": "The seating arrangement of the debating chamber is typically arranged in a semicircle or a horseshoe shape, with the presiding officer at the apex.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The seating arrangement of the debating chamber is typically arranged in a semicircle or a horseshoe shape, with the presiding officer at the apex. </answer>\n<confidence></confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is the seating of the debating chamber arranged as it is?",
        "answers": [
            "encourage consensus amongst elected members",
            "encourage consensus amongst elected members",
            "reflects the desire to encourage consensus amongst elected members"
        ],
        "model_ans": "To facilitate the speaker's movement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To facilitate the speaker's movement </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many seats are in the debating chamber?",
        "answers": [
            "131",
            "131",
            "131"
        ],
        "model_ans": "600",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 600 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many members in the seats of the Scottish Parliament are members of the Scottish Government?",
        "answers": [
            "2",
            "2",
            "2"
        ],
        "model_ans": "7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can the non-elected members from the Scottish Government not do?",
        "answers": [
            "vote",
            "vote",
            "vote"
        ],
        "model_ans": "vote",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> vote </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the parliamentary mace made of?",
        "answers": [
            "silver",
            "silver",
            "silver and inlaid with gold"
        ],
        "model_ans": "Wood",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wood </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does the gold in the parliamentary mace come from?",
        "answers": [
            "Scottish rivers",
            "Scottish rivers",
            "Scottish rivers"
        ],
        "model_ans": "South Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> South Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What words are inscribed on the mace of parliament?",
        "answers": [
            "Wisdom, Compassion, Justice and Integrity",
            "Wisdom, Compassion, Justice and Integrity",
            "Wisdom, Compassion, Justice and Integrity"
        ],
        "model_ans": "Dieu et Mon Droit",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dieu et Mon Droit </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who presented the mac to the Scottish Parliament when it was initially opened?",
        "answers": [
            "the Queen",
            "the Queen",
            "the Queen"
        ],
        "model_ans": "Queen Elizabeth II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Elizabeth II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the mace displayed in?",
        "answers": [
            "a glass case suspended from the lid",
            "glass case",
            "a glass case"
        ],
        "model_ans": "a museum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a museum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which month is the first in the year Parliament takes a two week vacation?",
        "answers": [
            "April",
            "April",
            "April"
        ],
        "model_ans": "August",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where do plenary meetings take place?",
        "answers": [
            "debating chamber",
            "debating chamber",
            "Wednesday afternoons"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who are debates and meetings open to?",
        "answers": [
            "the public",
            "the public.",
            "public"
        ],
        "model_ans": "Public",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Public </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How much does it cost to gain entry to a parliament meeting?",
        "answers": [
            "free",
            "free",
            "free"
        ],
        "model_ans": "varies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> varies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What contains a nearly verbatim of parliamentary debates?",
        "answers": [
            "the Official Report",
            "the Official Report",
            "the Official Report"
        ],
        "model_ans": "Hansard",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hansard </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What day of the week does the Time for Reflection take place?",
        "answers": [
            "Wednesdays",
            "Wednesdays",
            "Wednesdays"
        ],
        "model_ans": "Sunday",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sunday </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long might a speaker address the members during the Time of Reflection?",
        "answers": [
            "up to four minutes",
            "up to four minutes",
            "up to four minutes"
        ],
        "model_ans": "1-2 minutes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1-2 minutes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Because speakers are drawn from across Scotland, what do the represent the balance of?",
        "answers": [
            "religious beliefs",
            "religious beliefs",
            "the balance of religious beliefs"
        ],
        "model_ans": "Scotland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who decides who gets to address the members of Parliament to share their thoughts on issues of faith?",
        "answers": [
            "Presiding Officer",
            "Presiding Officer",
            "the Presiding Officer"
        ],
        "model_ans": "The Speaker of the House",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Speaker of the House </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can faith groups ask the Presiding Officer to do for them?",
        "answers": [
            "nominate speakers",
            "nominate speakers",
            "nominate speakers"
        ],
        "model_ans": "grant a debate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> grant a debate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who decides who gets to speak in the chamber debates?",
        "answers": [
            "The Presiding Officer",
            "Presiding Officer",
            "The Presiding Officer"
        ],
        "model_ans": "The Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is also decided by the Presiding Officer?",
        "answers": [
            "amount of time for which they are allowed to speak",
            "amount of time for which they are allowed to speak",
            "the amount of time for which they are allowed to speak"
        ],
        "model_ans": "the order of business",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the order of business </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Presiding Officer try to achieve a balance of between speakers?",
        "answers": [
            "different viewpoints",
            "different viewpoints and political parties",
            "a balance between different viewpoints and political parties"
        ],
        "model_ans": "time",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> time </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What members typically open debates?",
        "answers": [
            "ministers or party leaders",
            "ministers or party leaders",
            "ministers or party leaders"
        ],
        "model_ans": "Moderators",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Moderators </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What language other than English has the Scottish Parliament had meetings in?",
        "answers": [
            "Gaelic",
            "Gaelic",
            "Scots, Gaelic, or any other language with the agreement of the Presiding Officer"
        ],
        "model_ans": "Gaelic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gaelic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What time do the MSPs normally decide on the motions and amendments from that day?",
        "answers": [
            "5 pm",
            "5 pm",
            "5 pm"
        ],
        "model_ans": "5:00 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5:00 PM </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is heralded by the sounding of the division bell?",
        "answers": [
            "\"Decision Time\"",
            "Decision Time",
            "\"Decision Time\""
        ],
        "model_ans": "Parliament",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do MSPs who are not in the chamber when the division bell rings return to do?",
        "answers": [
            "vote",
            "vote",
            "vote"
        ],
        "model_ans": "They return to their offices",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They return to their offices </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How do members vote when there is a division?",
        "answers": [
            "electronic consoles on their desks",
            "electronic consoles",
            "electronic consoles on their desks"
        ],
        "model_ans": "By a show of hands",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By a show of hands </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long does it take to know the outcome of a division?",
        "answers": [
            "seconds",
            "seconds",
            "seconds"
        ],
        "model_ans": "depends on the complexity of the division",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> depends on the complexity of the division </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can often be predicted beforehand?",
        "answers": [
            "votes",
            "outcome of most votes",
            "outcome"
        ],
        "model_ans": "Future",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Future </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who normally instructs members how to vote?",
        "answers": [
            "political parties",
            "political parties",
            "political parties"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who has the task of ensuring party members vote according to the party line?",
        "answers": [
            "whips",
            "whips",
            "whips"
        ],
        "model_ans": "Whip",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Whip </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What happens if a member doesn't vote the party line?",
        "answers": [
            "deselected as official party candidates during future elections",
            "deselected as official party candidates",
            "deselected as official party candidates during future elections"
        ],
        "model_ans": "They may face disciplinary action or even expulsion from the party",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They may face disciplinary action or even expulsion from the party </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of issues are members typically allowed to vote as they please?",
        "answers": [
            "moral",
            "moral",
            "moral issues"
        ],
        "model_ans": "binding",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> binding </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is the Members Debate held?",
        "answers": [
            "Immediately after Decision Time",
            "Immediately after Decision Time",
            "Immediately after Decision Time"
        ],
        "model_ans": "The Members Debate is held annually in the House of Commons, typically in June or July.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Members Debate is held annually in the House of Commons, typically in June or July. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long does the Members Debate last?",
        "answers": [
            "45 minutes",
            "45 minutes",
            "45 minutes"
        ],
        "model_ans": "3 hours",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 hours </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are debates on proposed motions by an MSP conducted?",
        "answers": [
            "not a Scottish minister",
            "may be of interest to a particular area such as a member's own constituency",
            "issues which may be of interest to a particular area such as a member's own constituency"
        ],
        "model_ans": "to discuss and decide on the proposed motion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to discuss and decide on the proposed motion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who contributes to Members Business in addition to the proposer?",
        "answers": [
            "other members",
            "other members",
            "other members"
        ],
        "model_ans": "The proposer's party",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The proposer's party </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the minister who was the catalyst of the Members Business do by speaking after everyone else?",
        "answers": [
            "winds up",
            "winds up",
            "\"winds up\" the debate"
        ],
        "model_ans": "Speaks last",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaks last </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is much of the work of the Scottish Parliament done?",
        "answers": [
            "committee",
            "committee",
            "in committee"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are committees in the Scottish Parliament compared to other systems?",
        "answers": [
            "stronger",
            "stronger",
            "stronger in the Scottish Parliament than in other parliamentary systems"
        ],
        "model_ans": "committees",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> committees </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one avenue being compensated for by having committees serve such a large role?",
        "answers": [
            "no revising chamber",
            "no revising chamber",
            "take evidence from witnesses, conduct inquiries and scrutinise legislation"
        ],
        "model_ans": "accountability",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> accountability </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Taking evidence from witnesses is one of committees' what?",
        "answers": [
            "principal role",
            "principal role",
            "principal role"
        ],
        "model_ans": "responsibilities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> responsibilities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where might committees meet outside of Parliament?",
        "answers": [
            "other locations throughout Scotland",
            "other locations throughout Scotland",
            "other locations throughout Scotland"
        ],
        "model_ans": "Hotels",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hotels </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who are committees comprised of?",
        "answers": [
            "a small number of MSPs",
            "a small number of MSPs",
            "a small number of MSPs"
        ],
        "model_ans": "members",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> members </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the membership of the committees reflect?",
        "answers": [
            "balance of parties",
            "balance of parties across Parliament",
            "the balance of parties across Parliament"
        ],
        "model_ans": "The diversity of the organization",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The diversity of the organization </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Different committees have what set out in different ways?",
        "answers": [
            "functions",
            "their functions",
            "their functions"
        ],
        "model_ans": "rules",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rules </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of committee is set down under the SP's standing orders?",
        "answers": [
            "Mandatory",
            "Mandatory",
            "Mandatory Committees"
        ],
        "model_ans": "Standing Committee",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Standing Committee </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What session is the Scottish Parliament in?",
        "answers": [
            "fourth",
            "fourth",
            "the fourth Session"
        ],
        "model_ans": "Holyrood",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Holyrood </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When are subject committees established?",
        "answers": [
            "beginning of each parliamentary session",
            "beginning of each parliamentary session",
            "at the beginning of each parliamentary session"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many ministries of the Scottish government does a committee typically correspond to?",
        "answers": [
            "one",
            "one (or more",
            "one (or more) of the departments (or ministries) of the Scottish Government"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Economy, Energy and Tourism is one of the what?",
        "answers": [
            "current Subject Committees",
            "Subject Committees",
            "Subject Committees"
        ],
        "model_ans": "ministries",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ministries </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Scottish Parliament currently in the fourth of?",
        "answers": [
            "Session",
            "Session",
            "Session"
        ],
        "model_ans": "session",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> session </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is set up to scrutinize private bills submitted by party outsiders?",
        "answers": [
            "type of committee",
            "committee",
            "committee"
        ],
        "model_ans": "Joint Committee on Private Bills",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Joint Committee on Private Bills </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What topic do private bills typically have?",
        "answers": [
            "large-scale development projects",
            "large-scale development projects",
            "large-scale development projects"
        ],
        "model_ans": "legislation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> legislation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who decides how land or property is allowed to be used?",
        "answers": [
            "Scottish Government.",
            "Committees",
            "Private Bill Committees"
        ],
        "model_ans": "Local government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Local government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What kind of committee considered legislation on the development of the Edinburgh Tram Network?",
        "answers": [
            "Private Bill",
            "Private Bill",
            "Private Bill Committees"
        ],
        "model_ans": "City of Edinburgh Council",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> City of Edinburgh Council </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What act sets forth the functions of the Scottish Parliament?",
        "answers": [
            "Scotland Act 1998",
            "The Scotland Act 1998",
            "The Scotland Act 1998"
        ],
        "model_ans": "Scotland Act 1998",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotland Act 1998 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who gave her royal assent to the Scotland Act of 1998?",
        "answers": [
            "Queen Elizabeth II",
            "Queen Elizabeth II",
            "Queen Elizabeth II"
        ],
        "model_ans": "Queen Elizabeth II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Elizabeth II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does the Scotland Act of 2012 extend?",
        "answers": [
            "devolved competencies",
            "devolved competencies",
            "the devolved competencies"
        ],
        "model_ans": "Scottish Parliament's powers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish Parliament's powers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What body constitutes the supreme legislature of Scotland?",
        "answers": [
            "Parliament of the United Kingdom at Westminster",
            "Parliament of the United Kingdom at Westminster",
            "the Parliament of the United Kingdom at Westminster"
        ],
        "model_ans": "Scottish Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who has the role of holding the Scottish Government to account?",
        "answers": [
            "Scottish Parliament",
            "Parliament",
            "the Parliament"
        ],
        "model_ans": "Scottish Parliament",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish Parliament </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where are reserved matters stated in the Scotland Act?",
        "answers": [
            "Schedule 5",
            "Schedule 5",
            "Schedule 5"
        ],
        "model_ans": "Section 30",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Section 30 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If a matter is not specifically reserved, who is it devolved to?",
        "answers": [
            "Scottish Parliament",
            "Scottish Parliament",
            "the Scottish Parliament"
        ],
        "model_ans": "The High Court",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The High Court </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why do police and fire services fall under the purview of the Scottish Parliament?",
        "answers": [
            "automatically devolved",
            "not specifically reserved",
            "All matters that are not specifically reserved are automatically devolved to the Scottish Parliament"
        ],
        "model_ans": "They do not",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They do not </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much can the SP alter income tax in Scotland?",
        "answers": [
            "up to 3 pence in the pound",
            "up to 3 pence in the pound",
            "up to 3 pence in the pound"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Setting speed limits was one of the further devolutions which was conferred by what act?",
        "answers": [
            "2012 Act",
            "2012 Act",
            "The 2012 Act"
        ],
        "model_ans": "Road Traffic Act",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Road Traffic Act </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the name of matters outside the legislative ability of the Scottish Parliament?",
        "answers": [
            "Reserved",
            "Reserved",
            "Reserved matters"
        ],
        "model_ans": "Reserved matters",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reserved matters </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Issues dealt with at Westminster are not ones who is able to deal with?",
        "answers": [
            "Scottish Parliament",
            "The Scottish Parliament",
            "The Scottish Parliament"
        ],
        "model_ans": "Scotland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Scotland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are issues like abortion and drug policy legislated on?",
        "answers": [
            "Westminster",
            "Westminster",
            "Westminster"
        ],
        "model_ans": "Congress",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Congress </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Most aspects of transport safety is a subject dealt with by whom?",
        "answers": [
            "UK Government ministers",
            "UK Government ministers",
            "Westminster"
        ],
        "model_ans": "International Civil Aviation Organization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> International Civil Aviation Organization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What may be presented to Parliament in various ways?",
        "answers": [
            "Bills",
            "Bills",
            "Bills"
        ],
        "model_ans": "Bills",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bills</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who may introduce new laws or amendments to laws already on the books as a bill?",
        "answers": [
            "the Scottish Government",
            "Scottish Government",
            "the Scottish Government"
        ],
        "model_ans": "Congress",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Congress </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "An MSP may introduce a bill as what?",
        "answers": [
            "a private member",
            "a private member",
            "private member"
        ],
        "model_ans": "a member",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a member </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who may also submit private bills to Parliament?",
        "answers": [
            "an outside proposer",
            "an outside proposer",
            "an outside proposer"
        ],
        "model_ans": "The Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How do bills pass through Parliament?",
        "answers": [
            "in a number of stages",
            "a number of stages",
            "in a number of stages"
        ],
        "model_ans": "Bills are introduced in the House of Commons, debated, amended, and voted on. If passed, they are sent to the House of Lords for further debate and voting. If approved,</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bills are introduced in the House of Commons, debated, amended, and voted on. If passed, they are sent to the House of Lords for further debate and voting. If approved,</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is stage 1 in the life of a bill?",
        "answers": [
            "introductory",
            "introductory",
            "introductory stage of the bill"
        ],
        "model_ans": "Introduced",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Introduced </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are presented to parliament in addition to the bill itself?",
        "answers": [
            "accompanying documents",
            "accompanying documents",
            "accompanying documents \u2013 Explanatory Notes"
        ],
        "model_ans": "Explanatory notes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Explanatory notes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do statements from the PO and member in charge of the bill also indicate?",
        "answers": [
            "whether the bill is within the legislative competence of the Parliament",
            "whether the bill is within the legislative competence of the Parliament",
            "whether the bill is within the legislative competence of the Parliament"
        ],
        "model_ans": "The PO and member in charge of the bill also indicate that the bill is being taken seriously and that there is a level of commitment to its passage.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The PO and member in charge of the bill also indicate that the bill is being taken seriously and that there is a level of commitment to its passage.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where are bills typically gestated in Stage 1?",
        "answers": [
            "in the relevant committee or committees",
            "committee",
            "the whole Parliament"
        ],
        "model_ans": "uterus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> uterus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If Parliament agrees in a vote to the general principle of a bill, what does it then proceed to?",
        "answers": [
            "Stage 2",
            "Stage 2",
            "Stage 2"
        ],
        "model_ans": "Consider the details of the bill",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Consider the details of the bill </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the final stage of a bill in the Scottish Parliament?",
        "answers": [
            "Stage 3",
            "Stage 3",
            "Stage 3"
        ],
        "model_ans": "Royal Assent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Royal Assent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many parts does the consideration of a bill in Stage 3 have?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "3\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "3\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What vote on a bill takes place in Stage 3?",
        "answers": [
            "final",
            "final",
            "final vote"
        ],
        "model_ans": "The final vote",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The final vote </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of amendments might members opposed to a bill put on the table?",
        "answers": [
            "wrecking",
            "wrecking",
            "\"wrecking amendments\""
        ],
        "model_ans": "Amendments",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amendments </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When do members proceed to vote on whether they agree to the principles of the final bill?",
        "answers": [
            "Decision Time",
            "Decision Time",
            "After a general debate on the final form of the bill"
        ],
        "model_ans": "After the bill has been debated",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> After the bill has been debated </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who does the Presiding Officer submit the final bill to?",
        "answers": [
            "the Monarch",
            "Monarch",
            "the Monarch"
        ],
        "model_ans": "The Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why is the final bill passed to the Monarch?",
        "answers": [
            "royal assent",
            "royal assent",
            "royal assent"
        ],
        "model_ans": "Tradition",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tradition </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the minimum amount of time before a bill can go into law?",
        "answers": [
            "a 4-week period",
            "a 4-week period",
            "4-week period"
        ],
        "model_ans": "10 days",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 days </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who is a bill referred to for a ruling on whether it's within the powers of the Parliament?",
        "answers": [
            "Supreme Court of the United Kingdom",
            "Supreme Court of the United Kingdom",
            "the Supreme Court"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the template for bills passed by the Scottish Parliament include?",
        "answers": [
            "[Date]",
            "[Date]",
            "\"The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]\"."
        ],
        "model_ans": "A template for bills passed by the Scottish Parliament includes the following sections:",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A template for bills passed by the Scottish Parliament includes the following sections: </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What party forms the Scottish Parliament?",
        "answers": [
            "hold the majority of seats",
            "hold the majority of seats",
            "The party, or parties, that hold the majority of seats in the Parliament"
        ],
        "model_ans": "Scottish National Party",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish National Party </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is elected at the beginning of each term?",
        "answers": [
            "First Minister",
            "First Minister",
            "a First Minister"
        ],
        "model_ans": "President",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> President </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is eligible to toss their name in the hat to be First Minister?",
        "answers": [
            "Any member",
            "Any member",
            "Any member"
        ],
        "model_ans": "Members of the Scottish Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Members of the Scottish Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Other than Scotland's Chief Law Officer, from whence are most ministers drawn from amongst?",
        "answers": [
            "elected MSPs",
            "the elected MSPs",
            "amongst the elected MSPs"
        ],
        "model_ans": "Westminster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Westminster </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who makes formal appointment or dismissal decisions?",
        "answers": [
            "the Sovereign",
            "the Sovereign",
            "the Sovereign"
        ],
        "model_ans": "HR",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> HR </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What day of the week are general elections held?",
        "answers": [
            "Thursday",
            "Thursday",
            "Thursday"
        ],
        "model_ans": "Thursday",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Thursday </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What month, every four years, are the ordinary general elections held on?",
        "answers": [
            "May",
            "May",
            "May"
        ],
        "model_ans": "May",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> May </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who may change the date by up to a month, on the proposal of the PO?",
        "answers": [
            "the Monarch",
            "Monarch",
            "the Monarch"
        ],
        "model_ans": "President of the Office",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> President of the Office </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many days does the Parliament have to nominate a First Minister after a General Election?",
        "answers": [
            "28",
            "28",
            "28 days"
        ],
        "model_ans": "28 days\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "28 days\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If an extraordinary election is held within less than six months before the date of an ordinary election, what does it do to the ordinary election?",
        "answers": [
            "supplant it.",
            "supplant it",
            "reverts to the first Thursday in May, a multiple of four years after 1999"
        ],
        "model_ans": "cancels",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> cancels </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What enables the Scottish Parliament to scrutinize the government?",
        "answers": [
            "Several procedures",
            "Several procedures",
            "Several procedures"
        ],
        "model_ans": "The Scottish Parliament's committees",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Scottish Parliament's committees </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who can question statements the First Minister or members of the cabinet make?",
        "answers": [
            "MSPs",
            "leaders of the opposition parties and other MSPs",
            "MSPs"
        ],
        "model_ans": "The Scottish Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Scottish Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the First Minister deliver at the beginning of each parliamentary year?",
        "answers": [
            "legislative programme for the forthcoming year",
            "a statement",
            "a statement to the chamber setting out the Government's legislative programme for the forthcoming year"
        ],
        "model_ans": "The Queen's Speech",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Queen's Speech </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do the leaders of the opposition parties and other MSPs question the First Minister about?",
        "answers": [
            "issues related to the substance of the statement",
            "issues",
            "issues related to the substance of the statement"
        ],
        "model_ans": "the Scottish Government's policies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the Scottish Government's policies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is set aside for question periods in the debating chamber?",
        "answers": [
            "Parliamentary time",
            "Parliamentary time",
            "Parliamentary time"
        ],
        "model_ans": "30 minutes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30 minutes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what day does a General Question Time take place?",
        "answers": [
            "Thursday",
            "Thursday",
            "Thursday"
        ],
        "model_ans": "Thursday",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Thursday </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who may members direct questions towards during General Question Time?",
        "answers": [
            "any member of the Scottish Government",
            "any member of the Scottish Government",
            "ministers in departments that are selected for questioning that sitting day"
        ],
        "model_ans": "The Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What may members question the First Minister about directly during First Minister's Question Time?",
        "answers": [
            "issues under their jurisdiction",
            "issues under their jurisdiction",
            "the First Minister"
        ],
        "model_ans": "Government policies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government policies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many general questions are available to opposition leaders?",
        "answers": [
            "four",
            "four",
            "four"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the number of Constituency MSPs?",
        "answers": [
            "73",
            "73",
            "73"
        ],
        "model_ans": "73",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 73 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many members can voters choose to represent the constituency? ",
        "answers": [
            "one",
            "one",
            "one"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was there a reduction in the number of Scottish MPs?",
        "answers": [
            "2005",
            "2005",
            "2005"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the current number of electors currently in a Scottish Parliament constituency? ",
        "answers": [
            "55,000",
            "55,000",
            "55,000"
        ],
        "model_ans": "7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why do the island archipelagos comprise a smaller number of electors?",
        "answers": [
            "dispersed population and distance",
            "dispersed population and distance",
            "their dispersed population and distance from the Scottish Parliament in Edinburgh"
        ],
        "model_ans": "Because they have a smaller population",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they have a smaller population </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are the total numbers of seats allocated to parties?",
        "answers": [
            "proportionally to the number of votes received",
            "proportionally to the number of votes received",
            "proportionally to the number of votes received in the second vote of the ballot using the d'Hondt method"
        ],
        "model_ans": "proportional representation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> proportional representation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What method is used for tallying votes in the second vote of the ballot?",
        "answers": [
            "the d'Hondt method",
            "d'Hondt",
            "the d'Hondt method"
        ],
        "model_ans": "Instant-runoff voting",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Instant-runoff voting </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The party awarded a seat is the one with the highest what?",
        "answers": [
            "quotient",
            "quotient",
            "quotient"
        ],
        "model_ans": "number of votes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> number of votes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What set is a seat added to after being allocated?",
        "answers": [
            "constituency seats",
            "constituency",
            "second"
        ],
        "model_ans": "table",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> table </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How is the process of allocating seats repeated until all available seats have been determined?",
        "answers": [
            "iteratively",
            "iteratively",
            "iteratively"
        ],
        "model_ans": "The process is repeated until all available seats have been determined",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The process is repeated until all available seats have been determined </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does being an MSP share with the House of Commons?",
        "answers": [
            "a number of qualifications",
            "a number of qualifications",
            "qualifications"
        ],
        "model_ans": "Both are legislative bodies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Both are legislative bodies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the British Nationality Act passed?",
        "answers": [
            "1981",
            "1981",
            "1981"
        ],
        "model_ans": "1981\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1981\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How old most a person be to apply to be an MSP?",
        "answers": [
            "over the age of 18",
            "over the age of 18",
            "18"
        ],
        "model_ans": "18",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 18 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Members of which organizations are disqualified from sitting in the SP as elected MSPs?",
        "answers": [
            "police and the armed forces",
            "police and the armed forces",
            "the police and the armed forces"
        ],
        "model_ans": "Government employees",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Government employees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What act sets the term for judging the boundaries of sanity to which individuals wishing to sit on the SP must adhere?",
        "answers": [
            "Mental Health (Care and Treatment) (Scotland) Act 2003",
            "Mental Health (Care and Treatment) (Scotland) Act 2003",
            "Mental Health (Care and Treatment) (Scotland) Act 2003"
        ],
        "model_ans": "The SP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The SP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When the election produced an SNP majority government, what was it the first occurrence of?",
        "answers": [
            "a party has commanded a parliamentary majority",
            "a parliamentary majority",
            "a party has commanded a parliamentary majority"
        ],
        "model_ans": "2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the SNP obtain 16 seats from?",
        "answers": [
            "Labour",
            "Labour",
            "Labour"
        ],
        "model_ans": "Scotland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By how much did Labour lead Lain Gray retain East Lothian?",
        "answers": [
            "151 votes",
            "151 votes",
            "151 votes"
        ],
        "model_ans": "5,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many seats did the SNP take from the Liberal Democrats?",
        "answers": [
            "eight",
            "eight",
            "eight"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the result of the SNP majority allow a referendum be held on?",
        "answers": [
            "Scottish independence",
            "Scottish independence",
            "Scottish independence"
        ],
        "model_ans": "Scottish independence",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scottish independence </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The loss of Edinburgh Pentlands really disappointed whom the most?",
        "answers": [
            "the Conservatives",
            "Conservatives",
            "Conservatives"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the seat of former party leader David McLetchie?",
        "answers": [
            "Edinburgh Pentlands",
            "Edinburgh Pentlands",
            "former party leader"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What net loss did the Conservatives suffer?",
        "answers": [
            "five seats",
            "five seats",
            "five seats"
        ],
        "model_ans": "13",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who announced she would step down as leader of the Conservatives? ",
        "answers": [
            "Annabel Goldie",
            "Annabel Goldie",
            "Annabel Goldie"
        ],
        "model_ans": "Boris Johnson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Boris Johnson</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who congratulated the SNP while vowing to campaign against their referendum?",
        "answers": [
            "Cameron",
            "Cameron",
            "Cameron"
        ],
        "model_ans": "David Cameron",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Cameron </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What consequence of establishing the Scottish Parliament applies to Scottish MPs sitting in the UK House of Commons?",
        "answers": [
            "able to vote on domestic legislation that applies only to England, Wales and Northern Ireland",
            "able to vote on domestic legislation that applies only to England, Wales and Northern Ireland",
            "procedural consequence"
        ],
        "model_ans": "They are no longer able to vote on matters that are devolved to the Scottish Parliament",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They are no longer able to vote on matters that are devolved to the Scottish Parliament </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are MPs unable to vote upon?",
        "answers": [
            "domestic legislation of the Scottish Parliament",
            "domestic legislation of the Scottish Parliament.",
            "domestic legislation of the Scottish Parliament"
        ],
        "model_ans": "Their own salaries",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Their own salaries </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What phenomenon has led to criticism?",
        "answers": [
            "West Lothian question",
            "West Lothian question",
            "the West Lothian question"
        ],
        "model_ans": "Climate Change",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Climate Change </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What party had a victory in the 2015 UK election?",
        "answers": [
            "the Conservative",
            "Conservative",
            "Conservative"
        ],
        "model_ans": "Conservative",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Conservative </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "MPs representing English constituencies can only veto laws affecting which country? ",
        "answers": [
            "England",
            "England",
            "England"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is an Islamic revival movement?",
        "answers": [
            "Islamism",
            "Islamism",
            "Islamism"
        ],
        "model_ans": "Islamic fundamentalism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Islamic fundamentalism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What aspects of life does Islamism seek to integrate itself into?",
        "answers": [
            "all spheres of life.",
            "all spheres of life",
            "all spheres"
        ],
        "model_ans": "politics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> politics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What goal does Islamism have when it comes to society and government?",
        "answers": [
            "reordering",
            "reordering of government and society in accordance with the Shari'a",
            "reordering"
        ],
        "model_ans": "Establish an Islamic state",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Establish an Islamic state </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What have the two different Islamist movements been described as oscillating between?",
        "answers": [
            "poles",
            "two poles",
            "poles"
        ],
        "model_ans": "democracy and authoritarianism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> democracy and authoritarianism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "One strategy of Islamization is to seize power by what methods?",
        "answers": [
            "revolution or invasion",
            "revolution or invasion",
            "revolution"
        ],
        "model_ans": "coup",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> coup </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What process do moderate and reformist Islamists work within the boundaries of?",
        "answers": [
            "democratic",
            "democratic process",
            "democratic"
        ],
        "model_ans": "Democracy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Democracy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does Hamas originate?",
        "answers": [
            "Palestine",
            "Palestine",
            "Palestine"
        ],
        "model_ans": "Gaza",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gaza </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the goal of Islamist groups like Hezbollah and Hamas?",
        "answers": [
            "abolish the state of Israel",
            "abolish the state of Israel",
            "abolish the state of Israel"
        ],
        "model_ans": "to establish an Islamic state",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> to establish an Islamic state </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do radical Islamist organizations reject entirely?",
        "answers": [
            "democracy",
            "democracy",
            "democracy"
        ],
        "model_ans": "Western values",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Western values </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "On what basis do the radical Islamist organizations conduct their attacks?",
        "answers": [
            "religious",
            "religious",
            "religious"
        ],
        "model_ans": "religious beliefs",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> religious beliefs </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What exists between fundamentalist Islamism and reformist Islamism?",
        "answers": [
            "major division",
            "major division",
            "division"
        ],
        "model_ans": "Moderate Islamism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Moderate Islamism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Olivier Roy state underwent a remarkable shift in the second half of the 20th century?",
        "answers": [
            "Sunni pan-Islamism",
            "Sunni pan-Islamism",
            "Sunni pan-Islamism"
        ],
        "model_ans": "Islam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Islam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Salafi movement put emphasis on?",
        "answers": [
            "sharia rather than the building of Islamic institutions,",
            "sharia",
            "sharia"
        ],
        "model_ans": "Islamic law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has Islamism been increasingly interdependent with following the Arab Spring?",
        "answers": [
            "democracy",
            "democracy",
            "democracy"
        ],
        "model_ans": "Democracy",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Democracy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why do Islamists need democratic elections?",
        "answers": [
            "to maintain their legitimacy",
            "to maintain their legitimacy",
            "to maintain their legitimacy"
        ],
        "model_ans": "To gain legitimacy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To gain legitimacy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of role that Islamism seeks makes it a somewhat controversial concept?",
        "answers": [
            "political",
            "political",
            "political"
        ],
        "model_ans": "political",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> political </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do supporters of Islamism believe their views reflect?",
        "answers": [
            "Islam",
            "Islam",
            "Islam"
        ],
        "model_ans": "Islam",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islam </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The idea that Islam can be apolitical isn't able to be embraced by whom?",
        "answers": [
            "its supporters",
            "Scholars and observers",
            "Islamism"
        ],
        "model_ans": "Muslims",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muslims </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the inability to separate Islam from Islamism lead many in the West to support?",
        "answers": [
            "illiberal Islamic regimes",
            "illiberal Islamic regimes",
            "illiberal Islamic regimes"
        ],
        "model_ans": "Extremism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Extremism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do progressive moderates of Islam seek to separate?",
        "answers": [
            "religion from politics",
            "religion from politics",
            "religion from politics"
        ],
        "model_ans": "Church and State",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Church and State </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What term do Islamists think should be applied to them?",
        "answers": [
            "Muslims",
            "Muslims"
        ],
        "model_ans": "Muslim",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muslim </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does a writer for the International Crisis Group think the concept of political Islam is a creation of?",
        "answers": [
            "Americans",
            "Americans",
            "Americans"
        ],
        "model_ans": "Western scholars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Western scholars </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was apolitical Islam?",
        "answers": [
            "a historical fluke",
            "political Islam",
            "historical fluke"
        ],
        "model_ans": "Islam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the heyday of secular Arab nationalism?",
        "answers": [
            "between 1945 and 1970",
            "between 1945 and 1970",
            "between 1945 and 1970"
        ],
        "model_ans": "1950s-1970s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s-1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What, rather than Islamism, requires explanation?",
        "answers": [
            "non-political Islam",
            "quietist/non-political Islam",
            "quietist/non-political Islam"
        ],
        "model_ans": "Christianity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Western governments support fledgling Islamists?",
        "answers": [
            "During the 1970s",
            "the 1970s",
            "1970s"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did some of the Islamist groups supported by the West later become to be seen as?",
        "answers": [
            "dangerous enemies",
            "dangerous enemies",
            "dangerous enemies"
        ],
        "model_ans": "Terrorist groups",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Terrorist groups </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Western governments considered Islamists to be the lesser of two evils when compared to whom?",
        "answers": [
            "leftist/communist/nationalist insurgents/opposition",
            "leftist/communist/nationalist insurgents/opposition",
            "communist"
        ],
        "model_ans": "Saddam Hussein",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saddam Hussein </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the US provide aid to, to fight against the Soviet Union?",
        "answers": [
            "the mujahideen Muslim Afghanistan",
            "mujahideen",
            "mujahideen Muslim Afghanistan"
        ],
        "model_ans": "Afghanistan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Afghanistan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the non-Afghan veterans returning home have in addition to their prestige?",
        "answers": [
            "considerable impact",
            "experience, ideology, and weapons",
            "experience, ideology, and weapons"
        ],
        "model_ans": "medals",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medals </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who is the President of Egypt?",
        "answers": [
            "Anwar Sadat",
            "Anwar Sadat",
            "Anwar Sadat"
        ],
        "model_ans": "Abdel Fattah el-Sisi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abdel Fattah el-Sisi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What relationship with Israel is Sadat for?",
        "answers": [
            "peace",
            "peace"
        ],
        "model_ans": "Peace",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Peace </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was Sadat seeking by releasing Islamists from prison?",
        "answers": [
            "political support",
            "making peace with Israel",
            "political support"
        ],
        "model_ans": "To gain popularity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To gain popularity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the so called gentlemen's agreement between Sadat and the Islamists break down?",
        "answers": [
            "1975",
            "1975",
            "1975"
        ],
        "model_ans": "1981",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1981 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How was Sadat rewarded by the Islamists for his attempts to bring Egypt into modern times and civilization?",
        "answers": [
            "assassinated",
            "Islamists came to completely dominate university student unions",
            "assassinated"
        ],
        "model_ans": "Assassinated",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Assassinated </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of interpretation of Islam does Salafism promote?",
        "answers": [
            "conservative",
            "strict, conservative",
            "strict, conservative"
        ],
        "model_ans": "literal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> literal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Salafism in its harshest form encourage its followers to view the religion of others with?",
        "answers": [
            "hate",
            "hate them for their religion",
            "hate them for their religion"
        ],
        "model_ans": "contempt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> contempt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Salafism posits that democracy is responsible for what type of horrible events of the 20th century?",
        "answers": [
            "wars",
            "horrible wars",
            "all the horrible wars"
        ],
        "model_ans": "the decline of the Islamic world",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the decline of the Islamic world </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Conservative Islam classifies Muslims who follow Shia interpretation as what?",
        "answers": [
            "infidels",
            "infidels",
            "infidels"
        ],
        "model_ans": "non-Muslim",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> non-Muslim </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What interpretation of Islam is, for many of the adherents, the \"gold standard\" of their religion?",
        "answers": [
            "Saudi",
            "the Saudi-interpretation",
            "Saudi"
        ],
        "model_ans": "Sunni",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sunni </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of movement is the Muslim Brotherhood?",
        "answers": [
            "Islamist",
            "Islamist",
            "Islamist"
        ],
        "model_ans": "Islamist",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamist </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of assistance to out of town students is the Muslim Brotherhood known for?",
        "answers": [
            "housing",
            "shelters, educational assistance, free or low cost medical clinics, housing assistance",
            "shelters, educational assistance, free or low cost medical clinics, housing assistance"
        ],
        "model_ans": "Financial",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Financial </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why has the Muslim Brotherhood facilitated inexpensive mass marriage ceremonies?",
        "answers": [
            "avoid prohibitively costly dowry demands",
            "to avoid prohibitively costly dowry demands",
            "avoid prohibitively costly dowry demands"
        ],
        "model_ans": "No information available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No information available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Muslim Brotherhood's competence compares well against what type of local governments?",
        "answers": [
            "incompetent, inefficient, or neglectful",
            "incompetent, inefficient, or neglectful governments",
            "incompetent, inefficient, or neglectful"
        ],
        "model_ans": "Municipal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Municipal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are incompetent government's commitment to social justice limited to?",
        "answers": [
            "rhetoric",
            "rhetoric",
            "rhetoric"
        ],
        "model_ans": "nothing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> nothing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Iqbal studying in England and Germany?",
        "answers": [
            "law and philosophy",
            "law and philosophy",
            "law and philosophy"
        ],
        "model_ans": "Philosophy and Law",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Philosophy and Law </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization did Iqbal join in London?",
        "answers": [
            "the All India Muslim League",
            "All India Muslim League",
            "All India Muslim League"
        ],
        "model_ans": "Muslim League",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Muslim League </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did Iqbal return to Lahore?",
        "answers": [
            "1908",
            "1908",
            "1908"
        ],
        "model_ans": "1935\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1935\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Iqbal a critic of?",
        "answers": [
            "the mainstream Indian nationalist and secularist Indian National Congress",
            "mainstream Indian nationalist and secularist Indian National Congress",
            "mainstream Indian nationalist and secularist Indian National Congress"
        ],
        "model_ans": "British colonialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British colonialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What book was Iqbal's seven English lectures published as?",
        "answers": [
            "The Reconstruction of Religious Thought in Islam",
            "The Reconstruction of Religious Thought in Islam",
            "The Reconstruction of Religious Thought in Islam"
        ],
        "model_ans": "The Reconstruction of Religious Thought in Islam",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Reconstruction of Religious Thought in Islam </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Iqbal fear would weaken the spiritual foundations of Islam and Muslim society?",
        "answers": [
            "secularism and secular nationalism",
            "secularism and secular nationalism",
            "secularism"
        ],
        "model_ans": "Westernization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Westernization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Iqbal worried that India's mostly Hindu population would do what to Muslim heritage and culture?",
        "answers": [
            "crowd out",
            "crowd out Muslim heritage",
            "crowd out"
        ],
        "model_ans": "destroy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> destroy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When Iqbal promoted ideas of greater Islamic political unity, what did he encourage ending?",
        "answers": [
            "nationalist differences",
            "nationalist differences",
            "nationalist differences"
        ],
        "model_ans": "Colonialism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Colonialism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Iqbal elected president of the Muslim League?",
        "answers": [
            "1930",
            "1930",
            "1930"
        ],
        "model_ans": "1936",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1936 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Iqbal's Allahabad address inspire?",
        "answers": [
            "Pakistan movement",
            "the Pakistan movement",
            "Pakistan movement"
        ],
        "model_ans": "Khilafat Movement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Khilafat Movement </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was an important figure in the twentieth-century Islamic revival in India?",
        "answers": [
            "Sayyid Abul Ala Maududi",
            "Sayyid Abul Ala Maududi",
            "Sayyid Abul Ala Maududi"
        ],
        "model_ans": "Maulana Abul Kalam Azad",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maulana Abul Kalam Azad </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Maududi was trained as a lawyer, but chose what professional for himself instead?",
        "answers": [
            "journalism",
            "journalism",
            "journalism"
        ],
        "model_ans": "Islamic scholar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic scholar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Maududi found the Jamaat-e-Islami party?",
        "answers": [
            "1941",
            "1941",
            "1941"
        ],
        "model_ans": "1941\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1941\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was an important early figure in the Islamic revival in India?",
        "answers": [
            "Sayyid Abul Ala Maududi",
            "Sayyid Abul Ala Maududi",
            "Sayyid Abul Ala Maududi"
        ],
        "model_ans": "Shah Waliullah",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shah Waliullah </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Though trained as a lawyer, what profession did Maududi pursue instead?",
        "answers": [
            "journalism",
            "journalism",
            "journalism"
        ],
        "model_ans": "Journalist",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Journalist </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Maududi exert the most impact?",
        "answers": [
            "through his writing",
            "writing",
            "writing"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Maududi's books place Islam?",
        "answers": [
            "a modern context",
            "a modern context",
            "modern context"
        ],
        "model_ans": "20th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Maududi believe Muslim society could not be Islamic in the absence of?",
        "answers": [
            "Sharia",
            "Sharia",
            "Sharia"
        ],
        "model_ans": "Sharia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sharia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Maududi believed that Islam needed what to be established?",
        "answers": [
            "an Islamic state",
            "an Islamic state",
            "an Islamic state"
        ],
        "model_ans": "a caliphate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a caliphate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the English translation of tawhid?",
        "answers": [
            "unity of God",
            "unity of God",
            "unity of God"
        ],
        "model_ans": "Unity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Unity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of revolution did Maududi advocate?",
        "answers": [
            "gradual",
            "Islamic revolution",
            "gradual"
        ],
        "model_ans": "Islamic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By what method did Maududi want to change the hearts and minds of individuals?",
        "answers": [
            "an educational process",
            "an educational process or da'wah",
            "educational process or da'wah"
        ],
        "model_ans": "Islamic revival",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Islamic revival </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Muslim Brotherhood founded?",
        "answers": [
            "1928",
            "1928",
            "1928"
        ],
        "model_ans": "1928\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1928\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the Muslim Brotherhood founded?",
        "answers": [
            "Ismailiyah, Egypt",
            "Ismailiyah, Egypt",
            "Egypt"
        ],
        "model_ans": "Cairo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cairo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who founded the Muslim Brotherhood?",
        "answers": [
            "Hassan al Banna",
            "Hassan al Banna",
            "Hassan al Banna"
        ],
        "model_ans": "Hassan al-Banna",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hassan al-Banna </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The motto of the Muslim Brotherhood specifies what as being their constitution?",
        "answers": [
            "the Qur'an",
            "the Qur'an",
            "Qur'an"
        ],
        "model_ans": "Islam is the solution",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Islam is the solution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What influence did Al Banna wish to eliminate from the Muslim world?",
        "answers": [
            "imperialist",
            "imperialist influence",
            "imperialist"
        ],
        "model_ans": "Western influence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Western influence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Some elements of the Brotherhood directed what action against the government?",
        "answers": [
            "violence",
            "violence",
            "violence"
        ],
        "model_ans": "coup",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> coup </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Al-Banna assassinated?",
        "answers": [
            "1949",
            "1949",
            "1949"
        ],
        "model_ans": "1949\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1949\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was Al-Banna's assassination a retaliation for the prior assassination of?",
        "answers": [
            "Egypt's premier Mahmud Fami Naqrashi",
            "Mahmud Fami Naqrashi",
            "Mahmud Fami Naqrashi"
        ],
        "model_ans": "Anwar El-Sadat",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anwar El-Sadat </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Brotherhood first banned in Egypt?",
        "answers": [
            "1948",
            "1948",
            "1948"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What Egyptian president jailed thousands of members of the Brotherhood?",
        "answers": [
            "Gamal Abdul Nasser",
            "Gamal Abdul Nasser",
            "Gamal Abdul Nasser"
        ],
        "model_ans": "Abdel Fattah el-Sisi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abdel Fattah el-Sisi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What status has the Brotherhood obtained in the Islamic world?",
        "answers": [
            "one of the most influential movements",
            "one of the most influential movements",
            "one of the most influential"
        ],
        "model_ans": "Unrecognized",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unrecognized </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "For many years, what was the Brotherhood described as?",
        "answers": [
            "\"semi-legal\"",
            "semi-legal",
            "semi-legal"
        ],
        "model_ans": "a secret society",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a secret society </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Brotherhood was the only opposition group in Egypt able to do what during elections?",
        "answers": [
            "field candidates",
            "field candidates",
            "field candidates"
        ],
        "model_ans": "win",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> win </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of seats did political parties identifying as Islamist win in the Egyptian parliamentary election of 2011-2012?",
        "answers": [
            "75% of the total seats",
            "75%",
            "75%"
        ],
        "model_ans": "25%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 25% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the first democratically elected president of Egypt?",
        "answers": [
            "Mohamed Morsi",
            "Mohamed Morsi",
            "Mohamed Morsi"
        ],
        "model_ans": "Mohamed Morsi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mohamed Morsi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the defeat of the Arab troops at the hand of the Israeli troops during the Six-Day War?",
        "answers": [
            "quick and decisive",
            "quick and decisive defeat",
            "quick and decisive"
        ],
        "model_ans": "The Battle of Jerusalem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Battle of Jerusalem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The defeat of the Arab troops in the Six-Day War constituted what for the Arab Muslim world?",
        "answers": [
            "a pivotal event",
            "a pivotal event in the Arab Muslim world",
            "pivotal event"
        ],
        "model_ans": "a disaster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a disaster </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Secular Arab nationalism was blamed for both the defeat of Arab troops as well as what type of stagnation?",
        "answers": [
            "economic",
            "economic stagnation",
            "economic"
        ],
        "model_ans": "economic",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> economic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What happened to the credibility of secular politics as a result of the Six-Day War?",
        "answers": [
            "A steep and steady decline",
            "A steep and steady decline",
            "steep and steady decline"
        ],
        "model_ans": "It was damaged",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It was damaged </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What gained ground when Arab nationalism suffered?",
        "answers": [
            "anti-democratic Islamist movements",
            "anti-democratic Islamist movements inspired by Maududi and Sayyid Qutb",
            "anti-democratic Islamist movements"
        ],
        "model_ans": "Islamism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the ideologue of the Iranian Revolution?",
        "answers": [
            "Ali Shariati",
            "Ali Shariati",
            "Ali Shariati"
        ],
        "model_ans": "Ayatollah Khomeini",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ayatollah Khomeini </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Mohammad Iqbal was what type of father to the State of Pakistan?",
        "answers": [
            "ideological",
            "ideological",
            "ideological"
        ],
        "model_ans": "Founder",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Founder </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does Khomeini's beliefs fall as compared to Mawdudi and Qutb?",
        "answers": [
            "somewhere between",
            "between",
            "somewhere between"
        ],
        "model_ans": "Islamic fundamentalism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic fundamentalism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was it essential to Islam to imitate?",
        "answers": [
            "the Prophet Mohammad",
            "Prophet Mohammad and his successors",
            "Prophet Mohammad"
        ],
        "model_ans": "Abraham",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abraham </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What long term agenda was the acts of plundering Muslim lands by the West?",
        "answers": [
            "conspiracy",
            "Westernizing Muslims",
            "conspiracy"
        ],
        "model_ans": "Colonialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Colonialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Republic has maintained its control of Iran?",
        "answers": [
            "Islamic",
            "The Islamic Republic",
            "Islamic"
        ],
        "model_ans": "Islamic Republic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic Republic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What type of sanctions has the US directed at Iran?",
        "answers": [
            "economic",
            "economic",
            "economic"
        ],
        "model_ans": "economic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> economic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Iran has assisted what type of groups in Iraq?",
        "answers": [
            "Shia terrorist",
            "Shia terrorist groups",
            "Shia terrorist"
        ],
        "model_ans": "Shia militias",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shia militias </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Iranian government enjoy something of a resurgence?",
        "answers": [
            "During the 2006 Israel-Lebanon conflict",
            "the 2006 Israel-Lebanon conflict",
            "2006"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who stated he wanted Israel to vanish?",
        "answers": [
            "President Mahmoud Ahmadinejad",
            "President Mahmoud Ahmadinejad",
            "President Mahmoud Ahmadinejad"
        ],
        "model_ans": "Mahmoud Ahmadinejad",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahmoud Ahmadinejad </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who deployed its army into Afghanistan in 1979?",
        "answers": [
            "the Soviet Union",
            "the Soviet Union",
            "Soviet Union"
        ],
        "model_ans": "Soviet Union",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Soviet Union </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the Soviet Union trying to suppress with its army?",
        "answers": [
            "an Islamic rebellion",
            "an Islamic rebellion against an allied Marxist regime",
            "Islamic rebellion"
        ],
        "model_ans": "The Hungarian Revolution",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Hungarian Revolution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the conflict galvanize Muslims around the world to do?",
        "answers": [
            "send aid and sometimes to go themselves to fight for their faith",
            "send aid and sometimes to go themselves to fight for their faith",
            "send aid and sometimes to go themselves to fight for their faith"
        ],
        "model_ans": "Unite",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unite </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How effective was the military use of the \"Afghan Arabs\"?",
        "answers": [
            "marginal",
            "marginal",
            "marginal"
        ],
        "model_ans": "Not effective",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not effective </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Muslims came from around the world to fight in Afghanistan?",
        "answers": [
            "16,000 to 35,000",
            "16,000 to 35,000",
            "16,000 to 35,000"
        ],
        "model_ans": "20,000 to 40,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20,000 to 40,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Gulf War inadvertently do in the early 1990s?",
        "answers": [
            "worked to radicalize the Islamist movement",
            "radicalize the Islamist movement",
            "radicalize the Islamist movement"
        ],
        "model_ans": "Released Kuwaiti oil onto the global market",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Released Kuwaiti oil onto the global market </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Whose occupation of Kuwait did the US military personal seek to put an end to?",
        "answers": [
            "Saddam Hussein",
            "Saddam Hussein's",
            "Saddam Hussein's"
        ],
        "model_ans": "Iraq",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iraq </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Up until 1990, Saudi Arabia played an important role in restraining what groups?",
        "answers": [
            "Islamist",
            "Islamist",
            "Islamist"
        ],
        "model_ans": "Iran",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Iran </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What monarchy did western troops protect?",
        "answers": [
            "Saudi",
            "Saudi",
            "Saudi"
        ],
        "model_ans": "Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose puppet did Islamists accuse the Saudi regime of being?",
        "answers": [
            "the west",
            "the west",
            "the west"
        ],
        "model_ans": "Mossad",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mossad </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did the attacks resonate most with?",
        "answers": [
            "conservative Muslims",
            "Muslims",
            "conservative Muslims"
        ],
        "model_ans": "The people of the United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The people of the United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did American troops remain stationed after Saddam's defeat?",
        "answers": [
            "in the kingdom",
            "in the kingdom",
            "the kingdom"
        ],
        "model_ans": "Iraq",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iraq </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Saudi Arabia try to repress to compensate for its loss of stature? ",
        "answers": [
            "domestic Islamists",
            "domestic Islamists",
            "domestic Islamists"
        ],
        "model_ans": "Yemen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yemen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did a bloody civil war break out?",
        "answers": [
            "Algeria",
            "Algeria",
            "Algeria"
        ],
        "model_ans": "America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who masterminded many terror attacks?",
        "answers": [
            "Osama bin Laden",
            "Osama bin Laden",
            "Osama bin Laden"
        ],
        "model_ans": "Osama bin Laden",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Osama bin Laden </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Whose ideas became increasingly radical during his imprisonment? ",
        "answers": [
            "Qutb's",
            "Qutb",
            "Qutb's"
        ],
        "model_ans": "Nelson Mandela",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nelson Mandela </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Qutb executed?",
        "answers": [
            "1966",
            "1966",
            "1966"
        ],
        "model_ans": "1964\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1964\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization was led by Hasan al-Hudaybi?",
        "answers": [
            "the Brotherhood",
            "the Brotherhood",
            "Brotherhood"
        ],
        "model_ans": "Muslim Brotherhood",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muslim Brotherhood </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What movements pursued a more radical direction?",
        "answers": [
            "Fringe or splinter",
            "Fringe or splinter movements",
            "Fringe"
        ],
        "model_ans": "Surrealism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Surrealism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When had the Brotherhood renounced violence as a means of achieving its goals?",
        "answers": [
            "By the 1970s",
            "the 1970s",
            "1970s"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who took up the path of violence?",
        "answers": [
            "Egyptian Islamic Jihad organization",
            "the Egyptian Islamic Jihad organization",
            "Egyptian Islamic Jihad"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Egyptian Islamic Jihad assassinate Anwar Sadat?",
        "answers": [
            "1981",
            "1981",
            "1981"
        ],
        "model_ans": "1981\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1981\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which leaders did the Islamic extremists attack?",
        "answers": [
            "apostate",
            "\"apostate\" leaders of Muslim states,",
            "apostate"
        ],
        "model_ans": "World Trade Center",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World Trade Center </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What sin were the leaders the extremists attacked guilty of?",
        "answers": [
            "promoted Western/foreign ideas and practices into Islamic societies",
            "held secular leanings or who had introduced or promoted Western/foreign ideas and practices into Islamic societies",
            "secular leanings"
        ],
        "model_ans": "Blasphemy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Blasphemy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote a pamphlet outlining the radical ideas of the extremists?",
        "answers": [
            "Muhammad Abd al-Salaam Farag",
            "Muhammad Abd al-Salaam Farag",
            "Muhammad Abd al-Salaam Farag"
        ],
        "model_ans": "Mao Zedong",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mao Zedong </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did al-Gama'a al-Islamiyya use to get its way?",
        "answers": [
            "violence",
            "violence",
            "violence"
        ],
        "model_ans": "Violence",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Violence </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Over 100 Egyptian police were victims of what group's campaign of terror?",
        "answers": [
            "al-Gama'a al-Islamiyya",
            "al-Gama'a al-Islamiyya",
            "Islamic Group"
        ],
        "model_ans": "ISIS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ISIS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the Islamic Group's campaign to overthrow the government turn out?",
        "answers": [
            "unsuccessful",
            "unsuccessful",
            "unsuccessful"
        ],
        "model_ans": "failed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> failed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Jamaa Islamiya renounce violence?",
        "answers": [
            "in 2003",
            "2003",
            "2003"
        ],
        "model_ans": "2003",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2003 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who has the Islamic Liberation Party attempted to assassinate? ",
        "answers": [
            "political figures",
            "political figures",
            "political figures"
        ],
        "model_ans": "Anwar al-Awlaki",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anwar al-Awlaki </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Until 1987, what stance did the Muslim Brotherhood in Palestine take towards Israel?",
        "answers": [
            "quiescent",
            "quiescent",
            "quiescent"
        ],
        "model_ans": "rejection",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> rejection </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization is devoted to Jihad against Israel?",
        "answers": [
            "HAMAS",
            "HAMAS",
            "HAMAS"
        ],
        "model_ans": "Hamas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hamas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did the Hamas charter uncompromisingly encourage?",
        "answers": [
            "destruction of Israel",
            "the destruction of Israel",
            "destruction of Israel"
        ],
        "model_ans": "Jihad",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jihad </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where does HAMAS want to establish an Islamic state?",
        "answers": [
            "Palestine",
            "Palestine",
            "Palestine"
        ],
        "model_ans": "Gaza",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gaza </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The Brotherhood's members are against consuming what beverage?",
        "answers": [
            "alcohol",
            "alcohol",
            "alcohol"
        ],
        "model_ans": "coffee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> coffee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What organization has continued to be a major disruptive force in Palestine?",
        "answers": [
            "Hamas",
            "Hamas",
            "Hamas"
        ],
        "model_ans": "Hamas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hamas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many people did Hamas kill between 2000 to 2007?",
        "answers": [
            "542",
            "542",
            "542"
        ],
        "model_ans": "4,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Hamas win in the January 2006 legislative election?",
        "answers": [
            "majority of the seats,",
            "the majority of the seats",
            "majority of the seats"
        ],
        "model_ans": "74 seats",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 74 seats </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Hamas drive the PLO out of Gaza?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2007",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What have Muslims praised Hamas for doing?",
        "answers": [
            "driving Israel out of the Gaza Strip",
            "driving Israel out of the Gaza Strip",
            "driving Israel out of the Gaza Strip"
        ],
        "model_ans": "Protecting Palestine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Protecting Palestine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of regime ruled over Sudan for many years?",
        "answers": [
            "Islamist",
            "Islamist",
            "Islamist"
        ],
        "model_ans": "Military",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Military </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the leader of the Islamist regime in Sudan?",
        "answers": [
            "Hassan al-Turabi",
            "Hassan al-Turabi",
            "Hassan al-Turabi"
        ],
        "model_ans": "Omar al-Bashir",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Omar al-Bashir </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What organization did General Gaafar al-Nimeiry invite members of to serve in his government?",
        "answers": [
            "National Islamic Front",
            "National Islamic Front",
            "National Islamic Front"
        ],
        "model_ans": "Sudanese Communist Party",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sudanese Communist Party </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Turabi build a strong economic base?",
        "answers": [
            "money from foreign Islamist banking systems",
            "with money from foreign Islamist banking systems",
            "money from foreign Islamist banking systems"
        ],
        "model_ans": "I couldn't find reliable information on this topic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I couldn't find reliable information on this topic </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Turabi place students sympathetic to his views?",
        "answers": [
            "university and military academy",
            "the university and military academy",
            "university and military academy"
        ],
        "model_ans": "University of Khartoum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Khartoum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was al-Nimeiry overthrown?",
        "answers": [
            "1985",
            "1985",
            "1985"
        ],
        "model_ans": "1985\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1985\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did the party overthrow the elected government in 1989?",
        "answers": [
            "with the help of the military",
            "with the help of the military",
            "military"
        ],
        "model_ans": "Tiananmen Square protests",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tiananmen Square protests </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Though Turabi proclaimed his support for the democratic process, he strictly applied what after coming into power?",
        "answers": [
            "sharia law",
            "sharia law",
            "sharia law"
        ],
        "model_ans": "Islamic law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did the NIF regime harbor prior to 9/11?",
        "answers": [
            "Osama bin Laden",
            "Osama bin Laden",
            "Osama bin Laden"
        ],
        "model_ans": "Osama bin Laden",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Osama bin Laden </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did the NIF try to unify Islamist opposition against?",
        "answers": [
            "American attack on Iraq",
            "the American attack on Iraq",
            "American attack on Iraq"
        ],
        "model_ans": "the Syrian government",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the Syrian government </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the acronym FIS stand for?",
        "answers": [
            "Front Islamique de Salut",
            "Front Islamique de Salut",
            "Front Islamique de Salut"
        ],
        "model_ans": "Federation Internationale de Ski",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Federation Internationale de Ski </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the FIS formed?",
        "answers": [
            "Algeria",
            "Algeria",
            "Afghanistan"
        ],
        "model_ans": "Davos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Davos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the FIS founded?",
        "answers": [
            "1989",
            "1989",
            "1989"
        ],
        "model_ans": "1924",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1924 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "One of FIS' agenda items was to force women to start doing what?",
        "answers": [
            "staying home",
            "staying home to alleviate the high rate of unemployment among young Algerian men",
            "staying home"
        ],
        "model_ans": "skiing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> skiing </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the national elections in 1991 canceled by?",
        "answers": [
            "a military coup d'\u00e9tat",
            "a military coup d'\u00e9tat",
            "a military coup d'\u00e9tat"
        ],
        "model_ans": "President Ibrahim Babangida",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> President Ibrahim Babangida </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Unsurprisingly, the mujahideen's victory against the Soviets in the 1980s failed to produce what?",
        "answers": [
            "justice and prosperity",
            "justice and prosperity",
            "justice and prosperity"
        ],
        "model_ans": "a lasting peace",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a lasting peace </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of civil war was fought between political and tribal warlords?",
        "answers": [
            "vicious and destructive",
            "vicious and destructive",
            "civil"
        ],
        "model_ans": "proxy war",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> proxy war </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the civil war leave the state of Afghanistan's economy in?",
        "answers": [
            "one of the poorest countries on earth",
            "one of the poorest countries on earth",
            "one of the poorest countries on earth"
        ],
        "model_ans": "devastated",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> devastated </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Democratic Republic of Afghanistan collapse?",
        "answers": [
            "1992",
            "1992",
            "1992"
        ],
        "model_ans": "1992\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1992\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much of Afghanistan did the Taliban take over?",
        "answers": [
            "80%",
            "roughly 80%",
            "roughly 80%"
        ],
        "model_ans": "90% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "90% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Thousands of madrasahs spawned what organization?",
        "answers": [
            "The Taliban",
            "The Taliban",
            "Taliban"
        ],
        "model_ans": "Al-Qaeda",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Al-Qaeda </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did support from governmental and religious groups come from?",
        "answers": [
            "Pakistan",
            "Pakistan",
            "Pakistan"
        ],
        "model_ans": "United States",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Taliban was so different from other moments that they could be more accurately described as being what?",
        "answers": [
            "neofundamentalist",
            "Islamic fundamentalist or neofundamentalist",
            "neofundamentalist"
        ],
        "model_ans": "Islamic fundamentalist",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic fundamentalist </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Taliban want to subject the entire country to?",
        "answers": [
            "Sharia",
            "an idealized and systematized version of conservative tribal village customs",
            "Sharia"
        ],
        "model_ans": "Islamic law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who influenced the Taliban's ideology?",
        "answers": [
            "Osama bin Laden",
            "Osama bin Laden",
            "Osama bin Laden"
        ],
        "model_ans": "Islamic scholars",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic scholars </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the regime in Pakistan overthrown by General Zia-ul-Haq?",
        "answers": [
            "July 1977",
            "July 1977",
            "1977"
        ],
        "model_ans": "1977\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1977\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What had Bhutto planned on banning within six months, before he was overthrown?",
        "answers": [
            "alcohol and nightclubs",
            "alcohol and nightclubs",
            "alcohol and nightclubs"
        ],
        "model_ans": "Press censorship",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Press censorship </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Zia-ul-Haq's official state ideology?",
        "answers": [
            "Islamism",
            "Islamism",
            "Islamism"
        ],
        "model_ans": "Islamization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Zia-ul-Haq accused of using Islamization to legitimize? ",
        "answers": [
            "his means of seizing power",
            "his means of seizing",
            "seizing power"
        ],
        "model_ans": "authoritarian rule",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> authoritarian rule </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Zia-ul-Haq killed?",
        "answers": [
            "1988",
            "1988",
            "1988"
        ],
        "model_ans": "1988\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1988\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of group is The Islamic State?",
        "answers": [
            "Wahhabi/Salafi jihadist extremist militant",
            "Wahhabi/Salafi jihadist extremist militant group",
            "extremist militant"
        ],
        "model_ans": "Terrorist organization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Terrorist organization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who leads The Islamic State?",
        "answers": [
            "Sunni Arabs",
            "Sunni Arabs",
            "Sunni Arabs"
        ],
        "model_ans": "Abu Bakr al-Baghdadi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abu Bakr al-Baghdadi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the Islamic State proclaim itself in 2014?",
        "answers": [
            "a caliphate",
            "a caliphate",
            "caliphate"
        ],
        "model_ans": "Caliphate",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Caliphate </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many people did the Islamic State control the territory of as of March 2015?",
        "answers": [
            "ten million",
            "ten million",
            "ten million"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Islamic State lack from the international community?",
        "answers": [
            "recognition",
            "international recognition",
            "recognition"
        ],
        "model_ans": "Recognition",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Recognition </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did ISIL pledge allegiance to al-Qaeda?",
        "answers": [
            "2004",
            "2004",
            "2004"
        ],
        "model_ans": "2013\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2013\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Western forces invade Iraq?",
        "answers": [
            "2003",
            "March 2003",
            "March 200"
        ],
        "model_ans": "2003\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2003\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the Syrian Civil War begin?",
        "answers": [
            "March 2011",
            "March 2011",
            "March 2011"
        ],
        "model_ans": "2011\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2011\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did al-Qaeda tell ISIL to take a hike?",
        "answers": [
            "notorious intransigence",
            "its failure to consult and \"notorious intransigence\"",
            "notorious intransigence"
        ],
        "model_ans": "No information available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No information available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the United Nations designed ISIL?",
        "answers": [
            "a terrorist organisation",
            "a terrorist organisation",
            "terrorist organisation"
        ],
        "model_ans": "Daesh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Daesh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What's the party's take on Muslim history?",
        "answers": [
            "a different view",
            "Islam's pivotal turning point as occurring not with the death of Ali",
            "different view"
        ],
        "model_ans": "The party's take on Muslim history is not specified",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The party's take on Muslim history is not specified </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the four rightly guided Caliphs die?",
        "answers": [
            "7th century",
            "the 7th century",
            "7th century"
        ],
        "model_ans": "The dates of death are not recorded in historical records",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The dates of death are not recorded in historical records </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Ottoman Caliphate abolished?",
        "answers": [
            "1924",
            "1924",
            "1924"
        ],
        "model_ans": "1924\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1924\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The abolition of the Ottoman Caliphate is believed to have ended what system?",
        "answers": [
            "true Islamic",
            "the true Islamic system",
            "true Islamic"
        ],
        "model_ans": "Islamic Caliphate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Islamic Caliphate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are colonial powers blamed for?",
        "answers": [
            "ended the true Islamic system",
            "working through Turkish modernist Mustafa Kemal Atat\u00fcrk",
            "abolition of the Ottoman Caliphate"
        ],
        "model_ans": "Imperialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Imperialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of jihad does HT avoid engaging in?",
        "answers": [
            "armed",
            "armed jihad",
            "armed"
        ],
        "model_ans": "Non-violent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Non-violent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How does HT strive to amass power?",
        "answers": [
            "ideological struggle",
            "ideological struggle",
            "ideological struggle"
        ],
        "model_ans": "HT strives to amass power through its ability to provide high-quality, reliable, and efficient energy solutions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> HT strives to amass power through its ability to provide high-quality, reliable, and efficient energy solutions </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who specifically does HT target to change the opinion of?",
        "answers": [
            "elites",
            "government",
            "elites"
        ],
        "model_ans": "The general public",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The general public </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did HT fail to pull off a bloodless coup in 1974?",
        "answers": [
            "Egypt",
            "Egypt",
            "Egypt"
        ],
        "model_ans": "Chile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What have many HT members graduated to joining?",
        "answers": [
            "terrorist groups",
            "terrorist groups",
            "terrorist groups"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Muslims are in Greater London?",
        "answers": [
            "over 900,000",
            "900,000",
            "over 900,000"
        ],
        "model_ans": "1,000,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000,000 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of outlook do some of the Muslims in London have?",
        "answers": [
            "strong Islamist",
            "a strong Islamist outlook",
            "Islamist"
        ],
        "model_ans": "Multicultural",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Multicultural </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Channel 4 documentary Undercover Mosque air?",
        "answers": [
            "2007",
            "2007",
            "2007"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The perceived British policy of being hands off of its Muslim population has resulted in what derogatory term for London?",
        "answers": [
            "Londonistan",
            "Londonistan",
            "Londonistan"
        ],
        "model_ans": "Londonistan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Londonistan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was Abu Hamaz al-Masri charged with when he was arrested?",
        "answers": [
            "incitement to terrorism",
            "incitement to terrorism",
            "incitement to terrorism"
        ],
        "model_ans": "Conspiracy to commit murder",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Conspiracy to commit murder </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long as the U.S. government been actively engaged in efforts to counter Islamism?",
        "answers": [
            "since 2001",
            "since 2001",
            "2001"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What department in the U.S. spearheaded the efforts against Islamism? ",
        "answers": [
            "State",
            "State Department",
            "State"
        ],
        "model_ans": "Department of Homeland Security",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Department of Homeland Security </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who called for an agency to be created to be solely focused at undermining the Islamism ideology?",
        "answers": [
            "Christian Whiton",
            "George W. Bush",
            "Christian Whiton"
        ],
        "model_ans": "France",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What position in the government does Robert Gates hold?",
        "answers": [
            "U.S. Defense Secretary",
            "Defense Secretary",
            "Defense Secretary"
        ],
        "model_ans": "Secretary of Defense",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Secretary of Defense </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the U.S. Information Agency charged with doing during the Cold War?",
        "answers": [
            "undermining the communist ideology",
            "undermining the communist ideology",
            "undermining the communist ideology"
        ],
        "model_ans": "spreading American culture and ideas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> spreading American culture and ideas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The word imperialism has it's origins in which ancient language? ",
        "answers": [
            "Latin",
            "Latin",
            "Latin",
            "Latin",
            "Latin"
        ],
        "model_ans": "Latin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Latin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By what means is imperialism usually administered?",
        "answers": [
            "military force",
            "colonization, use of military force, or other means",
            "colonization, use of military force, or other means",
            "colonization, use of military force, or other",
            "colonization"
        ],
        "model_ans": "colonialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> colonialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The term imperialism has been applied to western countries, and which eastern county?",
        "answers": [
            "Japan",
            "Japan",
            "Japanese",
            "Japanese",
            "Japan"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Imperialism is responsible for the rapid spread of what?",
        "answers": [
            "technologies and ideas",
            "technologies and ideas",
            "technologies and ideas",
            "technologies and ideas",
            "technologies and ideas."
        ],
        "model_ans": "Christianity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Imperialism extends a country's power and what?",
        "answers": [
            "influence",
            "influence",
            "influence",
            "influence",
            "influence"
        ],
        "model_ans": "influence",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> influence </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "colonial rule would be considered what type of imperialism?",
        "answers": [
            "\"Formal imperialism\"",
            "formal",
            "\"Formal imperialism",
            "Formal imperialism",
            "Formal"
        ],
        "model_ans": "direct",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> direct </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "imperialism often divides countries by using which technique?",
        "answers": [
            "othering",
            "othering",
            "othering",
            "othering",
            "othering"
        ],
        "model_ans": "colonialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> colonialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Informal imperialism is still dominant; however, less what?",
        "answers": [
            "direct",
            "direct",
            "direct",
            "direct",
            "direct"
        ],
        "model_ans": "formal\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " formal\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "A forced trade agreement between two countries would be an example of what?",
        "answers": [
            "\"informal\" imperialism",
            "Informal rule",
            "informal\" imperialism",
            "imperialism"
        ],
        "model_ans": "Bilateral trade agreement",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bilateral trade agreement </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "colonial rule, or physical occupation of a territory is an example of what kind of imperialism?",
        "answers": [
            "\"formal\"",
            "formal",
            "formal",
            "formal",
            "formal"
        ],
        "model_ans": "direct",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> direct </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Some have generalized the meaning of the word imperialism down to general-purpose what?",
        "answers": [
            "aggressiveness",
            "aggressiveness",
            "aggressiveness",
            "aggressiveness",
            "aggressiveness"
        ],
        "model_ans": "imperialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> imperialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which is more costly, formal, or informal imperialism?",
        "answers": [
            "informal",
            "Informal rule is generally less costly",
            "Informal rule",
            "formal",
            "formal"
        ],
        "model_ans": "formal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> formal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What subtle tool can be used in an informal imperialistic situation to expand a controlled area?",
        "answers": [
            "ownership of private industries",
            "technological superiority",
            "technological superiority",
            "ownership of private industries",
            "technological superiority,"
        ],
        "model_ans": "Diplomacy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Diplomacy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The amount of land a country controls is its greatest what?",
        "answers": [
            "distinction",
            "distinction",
            "distinction",
            "distinction",
            "distinction"
        ],
        "model_ans": "asset",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> asset </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Western Imperialism divided the globe according to which theory?",
        "answers": [
            "the world systems theory",
            "world systems theory",
            "world systems theory.",
            "world systems theory"
        ],
        "model_ans": "Mercator",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mercator </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who suggested that imperialism was the \"highest\" form of capitalism?",
        "answers": [
            "Lenin",
            "Lenin",
            "Lenin"
        ],
        "model_ans": "Lenin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lenin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "One country's authority over a number of others would constitute the original country as what?",
        "answers": [
            "empires",
            "empires"
        ],
        "model_ans": "empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Most imperialism was carried out using which method of transport?",
        "answers": [
            "seaborne",
            "land",
            "sea and trade routes",
            "sea"
        ],
        "model_ans": "ships",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ships </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Imperialism is confused with what other term?",
        "answers": [
            "colonialism",
            "colonialism",
            "colonialism",
            "colonialism",
            "colonialism"
        ],
        "model_ans": "Colonialism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Colonialism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does colonialism lack that imperialism has?",
        "answers": [
            "political focus",
            "political focus",
            "political focus",
            "political focus",
            "ideological"
        ],
        "model_ans": "direct control",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> direct control </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Colonialism as a policy is caused by financial and what other reasons?",
        "answers": [
            "ideological",
            "ideological",
            "ideological",
            "commercial"
        ],
        "model_ans": "ideological",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> ideological </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who besides the Russians are often left out of the colonialism debat?",
        "answers": [
            "Ottoman",
            "Ottoman",
            "Ottoman",
            "Ottoman",
            "Ottoman"
        ],
        "model_ans": "French",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> French </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Imperialism and colonialism both assert a states dominance over what?",
        "answers": [
            "person or group of people",
            "a person or group of people",
            "a person or group of people",
            "person or group of people"
        ],
        "model_ans": "other territories",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> other territories </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Political advantage is an attribute of which state policies?",
        "answers": [
            "Imperialism and colonialism",
            "Imperialism and colonialism",
            "Imperialism and colonialism",
            "Imperialism and colonialism"
        ],
        "model_ans": "Government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Colonialism often means a country doing what?",
        "answers": [
            "taking physical control of another",
            "a conquest over an area",
            "the process of a country taking physical control of another",
            "dominating areas",
            "country taking physical control of another"
        ],
        "model_ans": "colonizing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> colonizing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How would one create an empire by means of Imperialism?",
        "answers": [
            "conquering the other state's lands",
            "conquering the other state's lands and therefore increasing its own dominance",
            "by conquering the other state's lands",
            "political and monetary dominance"
        ],
        "model_ans": "Through conquest, colonization, and exploitation of resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Through conquest, colonization, and exploitation of resources </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what do conquering people pass down to native populations?",
        "answers": [
            "characteristics",
            "characteristics of the conquering peoples",
            "characteristics of the conquering peoples",
            "the characteristics of the conquering peoples",
            "characteristics"
        ],
        "model_ans": "culture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> culture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is colonialism's core meaning?",
        "answers": [
            "exploitation",
            "the exploitation of the valuable assets and supplies",
            "the exploitation of the valuable assets and supplies of the nation that was conquered",
            "exploitation of the valuable assets and supplies of the nation that was conquered and the conquering nation then gaining the benefits",
            "exploitation of the valuable assets and supplies of the nation that was conquered"
        ],
        "model_ans": "The policy of a nation seeking to extend or maintain its control over other territories",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The policy of a nation seeking to extend or maintain its control over other territories </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the most controversial aspect of imperialism?",
        "answers": [
            "empire-building",
            "defense and justification of empire-building",
            "is the defense and justification of empire-building based on seemingly rational grounds",
            "defense and justification of empire-building based on seemingly rational grounds",
            "defense and justification of empire-building"
        ],
        "model_ans": "Colonialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Colonialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": " J. A. Hobson wanted which races to develop the world?",
        "answers": [
            "highest 'social efficiency'",
            "highest 'social efficiency'",
            "the races of highest 'social efficiency'\"",
            "of highest 'social efficiency",
            "races of highest 'social efficiency'\""
        ],
        "model_ans": "white",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> white </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Friedrich Ratzel thought what was needed for a state to survive?",
        "answers": [
            "imperialism",
            "imperialism",
            "imperialism",
            "imperialism",
            "imperialism"
        ],
        "model_ans": "Lebensraum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lebensraum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which theory justifies imperialism in part?",
        "answers": [
            "theory of races",
            "Social Darwinism",
            "Social Darwinism",
            "Social Darwinism"
        ],
        "model_ans": "Social Darwinism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social Darwinism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In Latin America what is the most revered skin color?",
        "answers": [
            "whiteness",
            "whiteness",
            "whiteness",
            "whiteness",
            "whiteness"
        ],
        "model_ans": "White",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> White </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was Friedrich Ratzel born?",
        "answers": [
            "Germany",
            "Germany",
            "Germany",
            "Germany",
            "Germany"
        ],
        "model_ans": "Leipzig",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leipzig </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was Halford Mackinder born?",
        "answers": [
            "Britain",
            "Britain",
            "Britain",
            "Britain",
            "Britain"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Halford Mackinder and Friedrich Ratzel where what kind of geographers?",
        "answers": [
            "Political",
            "Political",
            "Political",
            "Political",
            "Political"
        ],
        "model_ans": "Halford Mackinder was a British geographer, and Friedrich Ratzel was a German geographer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Halford Mackinder was a British geographer, and Friedrich Ratzel was a German geographer </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Friedrich Ratzel thought imperialism was what for the country?",
        "answers": [
            "geographical societies in Europe",
            "necessary for a state\u2019s survival",
            "survival",
            "necessary",
            "necessary"
        ],
        "model_ans": "a means of expansion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a means of expansion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How would the geographical societies in Europe support certain travelers?",
        "answers": [
            "fund",
            "fund travelers who would come back with tales of their discoveries",
            "fund travelers",
            "able to fund travelers",
            "fund"
        ],
        "model_ans": "By providing maps, guides, and other resources",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By providing maps, guides, and other resources </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which theory suggested people in the tropics were uncivilized?",
        "answers": [
            "environmental determinism",
            "environmental determinism",
            "environmental determinism",
            "environmental determinism",
            "environmental determinism"
        ],
        "model_ans": "Social Darwinism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social Darwinism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "According to Ellen Churchill Semple what type of climate was necessary for humans to become fully human?",
        "answers": [
            "temperate",
            "temperate zone",
            "the temperate zone",
            "temperate zone",
            "temperate"
        ],
        "model_ans": "temperate",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> temperate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which book by Edward Said portrayed the east as being the \"others?\"",
        "answers": [
            "Orientalism",
            "Orientalism",
            "Orientalism",
            "Orientalism",
            "Orientalism"
        ],
        "model_ans": "Orientalism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Orientalism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "According to certain Geographical theories what type of human does a tropical climate produce?",
        "answers": [
            "uncivilized",
            "uncivilized",
            "fully human",
            "uncivilized people",
            "uncivilized"
        ],
        "model_ans": "Negroid",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Negroid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By justification certain racial and geographical theories, Europe thought of itself as what?",
        "answers": [
            "superior",
            "superior",
            "the superior and the norm",
            "superior",
            "superior"
        ],
        "model_ans": "superior",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> superior </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Imperialism is most often associated with which sovereignty?",
        "answers": [
            "the British Empire",
            "Terra nullius",
            "the British Empire",
            "British Empire",
            "British"
        ],
        "model_ans": "European",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What law justified British imperialism?",
        "answers": [
            "Terra nullius",
            "Terra nullius",
            "Terra nullius",
            "Terra nullius"
        ],
        "model_ans": "The Doctrine of Discovery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Doctrine of Discovery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were the native inhabitants of Australia called?",
        "answers": [
            "Aboriginal",
            "Aboriginal",
            "Aboriginal inhabitants",
            "Aboriginal"
        ],
        "model_ans": "Aboriginal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aboriginal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Great Britain colonize Australia?",
        "answers": [
            "the eighteenth century",
            "eighteenth century",
            "eighteenth century",
            "eighteenth century",
            "eighteenth century,"
        ],
        "model_ans": "1788\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1788\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Terra Nullius is a Latin expression meaning what in English?",
        "answers": [
            "empty land",
            "empty land",
            "empty land",
            "empty land",
            "'empty land'"
        ],
        "model_ans": "\"No man's land\"",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> \"No man's land\" </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Orientalism refers to how the West developed a what of the East?",
        "answers": [
            "an imaginative geography",
            "imaginative geography",
            "imaginative geography",
            "imaginative geography",
            "imaginative geography"
        ],
        "model_ans": "image",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> image </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Early Western texts referencing the East describe the people as being what?",
        "answers": [
            "irrational and backward",
            "them",
            "as irrational and backward",
            "irrational and backward",
            "irrational and backward"
        ],
        "model_ans": "barbarians",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> barbarians </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The West saw the East as what?",
        "answers": [
            "inferior",
            "irrational and backward",
            "its inferior",
            "irrational and backward",
            "inferior"
        ],
        "model_ans": "barbarian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> barbarian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was used by the West to justify control over eastern territories?",
        "answers": [
            "Orientalism",
            "inferior",
            "Defining the East as a negative vision of itself",
            "Orientalism",
            "Orientalism"
        ],
        "model_ans": "Manifest Destiny",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manifest Destiny </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The West saw themselves as what compared to the east?",
        "answers": [
            "progressive",
            "rational and progressive",
            "rational and progressive",
            "rational and progressive"
        ],
        "model_ans": "superior",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> superior </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bassett focuses on what to illustrate his idea?",
        "answers": [
            "nineteenth-century maps",
            "nineteenth-century maps",
            "the role of nineteenth-century maps",
            "the role of nineteenth-century maps",
            "the role of nineteenth-century maps during the \"scramble for Africa\""
        ],
        "model_ans": "bass",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> bass </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What provided an incentive to western empires to colonize Africa?",
        "answers": [
            "blank spaces on contemporary maps",
            "fill in blank spaces on contemporary maps",
            "maps",
            "maps",
            "blank space"
        ],
        "model_ans": "Gold",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gold </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were blank spaces used for on nineteenth-century maps?",
        "answers": [
            "unexplored territory",
            "unknown or unexplored territory",
            "unknown or unexplored territory",
            "to denote unknown or unexplored territory",
            "unknown or unexplored territory"
        ],
        "model_ans": "Unknown or unexplored territories",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Unknown or unexplored territories </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Basset analyze before coming to his conclusions?",
        "answers": [
            "nineteenth-century cartographic techniques",
            "nineteenth-century maps",
            "nineteenth-century cartographic techniques",
            "nineteenth-century maps",
            "role of nineteenth-century maps"
        ],
        "model_ans": "Data",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Data </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who besides the british colonized Africa?",
        "answers": [
            "French",
            "French",
            "French",
            "French",
            "French"
        ],
        "model_ans": "France, Germany, Italy, Portugal, Spain, Belgium, Netherlands",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France, Germany, Italy, Portugal, Spain, Belgium, Netherlands </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who used imperialism during their rule of the Mongol Empire?",
        "answers": [
            "Genghis Khan",
            "Genghis Khan",
            "Genghis Khan",
            "Genghis Khan",
            "Genghis Khan"
        ],
        "model_ans": "Mongols",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mongols </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "During which era did the Aztec and Incan empires thrive?",
        "answers": [
            "the pre-Columbian era",
            "pre-Columbian",
            "pre-Columbian era",
            "pre-Columbian",
            "pre-Columbian"
        ],
        "model_ans": "Pre-Columbian",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pre-Columbian </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "The Asante and Lunda Empires were in which region?",
        "answers": [
            "Sub-Saharan Africa",
            "Sub-Saharan Africa",
            "Sub-Saharan Africa",
            "Sub-Saharan Africa"
        ],
        "model_ans": "Central Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Central Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many Muslim empires have used imperialism?",
        "answers": [
            "dozens",
            "dozens",
            "dozens",
            "dozens",
            "dozens"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which is older the British Empire or the Ethiopian Empire?",
        "answers": [
            "Ethiopian Empire",
            "the Ethiopian Empire",
            "Ethiopian",
            "Ethiopian"
        ],
        "model_ans": "British Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When imperialism impacts social norms of a state, what is it called?",
        "answers": [
            "Cultural imperialism",
            "Cultural imperialism",
            "Cultural imperialism",
            "Cultural imperialism",
            "Cultural imperialism"
        ],
        "model_ans": "Cultural Imperialism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cultural Imperialism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is Cultural Imperialism often referred to as?",
        "answers": [
            "soft power",
            "soft power",
            "soft power",
            "soft power",
            "soft power"
        ],
        "model_ans": "Cultural Hegemony",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cultural Hegemony </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which American show changed the views of Romanians during the cold war?",
        "answers": [
            "Dallas",
            "Dallas",
            "Dallas",
            "Dallas",
            "Dallas"
        ],
        "model_ans": "I Love Lucy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I Love Lucy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which historic empire used cultural imperialism to sway local elites?",
        "answers": [
            "Roman",
            "Roman",
            "Roman",
            "Roman",
            "Roman"
        ],
        "model_ans": "Roman Empire",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Roman Empire </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How do regimes fight against cultural imperialism?",
        "answers": [
            "bans",
            "bans on foreign popular culture, control of the internet and unauthorised satellite dishes",
            "bans on foreign popular culture, control of the internet and unauthorised satellite dishes",
            "bans"
        ],
        "model_ans": "By promoting their own culture and resisting foreign influences",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By promoting their own culture and resisting foreign influences </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the age of Imperialism begin?",
        "answers": [
            "around 1700",
            "around 1700",
            "1700",
            "around 1700",
            "1700"
        ],
        "model_ans": "15th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 15th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were European countries doing during the 1700's?",
        "answers": [
            "colonizing",
            "process of colonizing, influencing, and annexing other parts of the world",
            "colonizing, influencing, and annexing other parts of the world in order to gain political power",
            "colonizing, influencing, and annexing"
        ],
        "model_ans": "colonizing and trading",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> colonizing and trading </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many years have imperialistic practices existed?",
        "answers": [
            "thousands",
            "thousands",
            "thousands",
            "thousands",
            "thousands"
        ],
        "model_ans": "5000 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5000 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the age of imperialism end?",
        "answers": [
            "middle of the 20th century",
            "20th century",
            "20th century",
            "middle of the 20th century",
            "20th century,"
        ],
        "model_ans": "1945",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1945 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of the imperialistic policy in China?",
        "answers": [
            "Open Door Policy",
            "Open Door Policy",
            "Open Door Policy",
            "Open Door Policy",
            "Open Door Policy"
        ],
        "model_ans": "Qing dynasty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Qing dynasty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was John Gallagher born?",
        "answers": [
            "1919",
            "1919",
            "1919",
            "1919",
            "1919"
        ],
        "model_ans": "1984",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1984 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Ronald Robinson die?",
        "answers": [
            "1999",
            "1999",
            "1999",
            "1999",
            "1999"
        ],
        "model_ans": "1997",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1997 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What profession were Ronald Robinson and John Gallagher?",
        "answers": [
            "historians",
            "historians",
            "historians",
            "historians",
            "historians"
        ],
        "model_ans": "Historian",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Historian </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What grew on a global scale as a result of imperialism?",
        "answers": [
            "the world's economy",
            "economy",
            "economy",
            "world's economy",
            "world's economy"
        ],
        "model_ans": "Nationalism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nationalism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was made rich and prosperous prior to World War 1",
        "answers": [
            "many imperial powers",
            "imperial powers",
            "imperial powers",
            "imperial powers"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "European imperialism was focused on what?",
        "answers": [
            "economic growth",
            "economic growth",
            "economic growth",
            "economic growth",
            "economic growth"
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did European empires rely on to supply them with resources?",
        "answers": [
            "colonies",
            "collecting resources from colonies",
            "colonies",
            "colonies",
            "colonies"
        ],
        "model_ans": "colonies",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> colonies </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the colonization of India occur?",
        "answers": [
            "mid-18th century",
            "18th century",
            "mid-18th century",
            "mid-18th century",
            "mid-18th century"
        ],
        "model_ans": "1757",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1757 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Britain exploit in India?",
        "answers": [
            "the Mughal state",
            "Mughal state",
            "Mughal state",
            "Mughal state",
            "Mughal state"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What advancements besides military technology did Europe achieve?",
        "answers": [
            "communication",
            "communication",
            "communication",
            "communication",
            "communication"
        ],
        "model_ans": "Navigation, printing, and the Renaissance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Navigation, printing, and the Renaissance </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did European chemists make that could be used in warfare?",
        "answers": [
            "deadly explosives",
            "explosives",
            "explosives",
            "deadly explosives",
            "deadly explosives"
        ],
        "model_ans": "Mustard gas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mustard gas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was invented in 1880 that revolutionized warfare?",
        "answers": [
            "the machine gun",
            "machine gun",
            "machine gun",
            "machine gun",
            "machine gun"
        ],
        "model_ans": "Machine gun",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Machine gun </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What weapons were the Zulus using during the Anglo-Zulu War of 1879?",
        "answers": [
            "arrows, swords, and leather shields",
            "arrows, swords, and leather shields",
            "arrows, swords, and leather shields",
            "arrows, swords, and leather shields",
            "arrows, swords, and leather shields"
        ],
        "model_ans": "Assegai",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Assegai </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which region invented the machine gun?",
        "answers": [
            "European",
            "European",
            "European",
            "Europe"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Theories on imperialism use which country as a model?",
        "answers": [
            "British",
            "British",
            "British",
            "British"
        ],
        "model_ans": "Britain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Britain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the term imperialism first come to be used by its current definition?",
        "answers": [
            "in the late 1870s",
            "1870s",
            "1870s",
            "late 1870s",
            "1870s"
        ],
        "model_ans": "Late 19th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Late 19th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the idealized value of imperialism?",
        "answers": [
            "philanthropy",
            "idealism and philanthropy",
            "philanthropy",
            "idealism and philanthropy"
        ],
        "model_ans": "Progress",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Progress </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to Lenin why must capitalistic countries have an imperialistic policy?",
        "answers": [
            "to constantly expand investment",
            "to constantly expand investment",
            "to constantly expand investment, material resources and manpower",
            "need for capitalist economies to constantly expand investment, material resources and manpower",
            "need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion."
        ],
        "model_ans": "Because they must export capital to maintain their economy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Because they must export capital to maintain their economy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "some debate that there is a correlation between capitalism, imperialism, and what?",
        "answers": [
            "aristocracy",
            "aristocracy",
            "aristocracy",
            "aristocracy",
            "aristocracy"
        ],
        "model_ans": "colonialism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> colonialism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were Joseph Schumpeter and Norman Angell at their most prolific writing period?",
        "answers": [
            "before World War I",
            "World War I",
            "before World War I",
            "before World War I",
            "before World War I,"
        ],
        "model_ans": "1920s-1930s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920s-1930s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the military-political complex reflected upon within the scope of understanding imperialism?",
        "answers": [
            "the 1950s",
            "1950s",
            "1950s",
            "1950s",
            "1950s"
        ],
        "model_ans": "1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Hobson argued that imperialism was an international what?",
        "answers": [
            "disease",
            "disease",
            "disease",
            "disease",
            "disease"
        ],
        "model_ans": "phenomenon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> phenomenon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did Hobson argue to rid the world of imperialism?",
        "answers": [
            "taxation",
            "removing its economic foundation",
            "domestic social reforms",
            "removing its economic foundation",
            "removing its economic foundation."
        ],
        "model_ans": "He argued that imperialism was a form of exploitation and that it was necessary to rid the world of it in order to achieve true freedom and equality.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He argued that imperialism was a form of exploitation and that it was necessary to rid the world of it in order to achieve true freedom and equality. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What served as a justification for imposing imperialistic policies on certain peoples or regions?",
        "answers": [
            "environmental determinism",
            "environmental determinism",
            "environmental determinism",
            "environmental determinism",
            "environmental determinism"
        ],
        "model_ans": "Social Darwinism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Social Darwinism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was thought to decide a person's behavior?",
        "answers": [
            "the environment in which they lived",
            "environment in which they lived",
            "environment",
            "the environment in which they lived",
            "environment"
        ],
        "model_ans": "genes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> genes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Humans in tropical environments were considered what?",
        "answers": [
            "less civilized",
            "less civilized",
            "less civilized",
            "less civilized",
            "less civilized"
        ],
        "model_ans": "Endemic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Endemic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Europe first colonized the Americas, then Asia, but what continent was third?",
        "answers": [
            "Africa",
            "Africa",
            "Africa",
            "Africa",
            "Africa"
        ],
        "model_ans": "Africa\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Africa\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What were the two forms of environmental determinism?",
        "answers": [
            "orientalism and tropicality",
            "orientalism and tropicality",
            "orientalism and tropicality",
            "orientalism and tropicality",
            "orientalism and tropicality."
        ],
        "model_ans": "climatic and geographical",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> climatic and geographical </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who thought the world could be split into climatic zones?",
        "answers": [
            "geographic scholars",
            "geographic scholars",
            "geographic scholars",
            "geographic scholars",
            "geographic scholars"
        ],
        "model_ans": "Alexander von Humboldt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alexander von Humboldt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which regions have temperate climates?",
        "answers": [
            "Northern Europe and the Mid-Atlantic",
            "Northern Europe and the Mid-Atlantic",
            "Northern Europe and the Mid-Atlantic",
            "Mid-Atlantic",
            "Northern Europe and the Mid-Atlantic"
        ],
        "model_ans": "Europe, North America, parts of Asia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe, North America, parts of Asia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the the Europeans think the peoples in the tropics were in need of?",
        "answers": [
            "guidance",
            "guidance and intervention",
            "guidance and intervention",
            "guidance and intervention",
            "guidance"
        ],
        "model_ans": "Civilization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civilization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was a similar view about the Asian continent called?",
        "answers": [
            "orientalism",
            "orientalism",
            "orientalism",
            "orientalism",
            "orientalism"
        ],
        "model_ans": "Oriental",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oriental </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did the geographic scholars work for? ",
        "answers": [
            "colonizing empires",
            "colonizing empires",
            "colonizing empires",
            "colonizing empires",
            "colonizing empires"
        ],
        "model_ans": "University",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When is the earliest Britain had an imperialist policy?",
        "answers": [
            "the sixteenth century",
            "sixteenth century",
            "sixteenth century",
            "sixteenth century",
            "sixteenth century"
        ],
        "model_ans": "1583",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1583 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the British East India Company established?",
        "answers": [
            "1599",
            "1599",
            "1599",
            "1599",
            "1599"
        ],
        "model_ans": "1600\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1600\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who chartered the British East India Company?",
        "answers": [
            "Queen Elizabeth",
            "Queen Elizabeth",
            "Queen Elizabeth",
            "Queen Elizabeth",
            "Queen Elizabeth"
        ],
        "model_ans": "Queen Elizabeth I",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Elizabeth I </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What happened to the East India Trading Company in 1767?",
        "answers": [
            "exploitation",
            "political activity caused exploitation",
            "political activity caused exploitation",
            "exploitation",
            "exploitation"
        ],
        "model_ans": "It was dissolved",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It was dissolved </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which country had trading posts in India before Britain?",
        "answers": [
            "the Portuguese",
            "Portuguese",
            "Portuguese",
            "Portuguese",
            "Portuguese"
        ],
        "model_ans": "Portugal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Portugal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did France take control of Algeria?",
        "answers": [
            "1830",
            "1830",
            "1830",
            "1830",
            "1830"
        ],
        "model_ans": "1830\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1830\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did France begin in earnest to rebuild its global empire?",
        "answers": [
            "1850",
            "after 1850",
            "after 1850",
            "after 1850",
            "1850"
        ],
        "model_ans": "1945",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1945 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did France focus its efforts to rebuild its empire?",
        "answers": [
            "Africa",
            "North and West Africa",
            "North and West Africa",
            "North and West Africa, as well as South-East Asia, with other conquests in Central and East Africa, as well as the South Pacific",
            "North and West Africa, as well as South-East Asia,"
        ],
        "model_ans": "Indochina",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Indochina </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did French Republicans back building the French empire?",
        "answers": [
            "when Germany started to build her own",
            "Germany started to build her own colonial empire",
            "when Germany started to build her own colonial empire",
            "when Germany started to build her own colonial empire",
            "when Germany started to build her own colonial empire."
        ],
        "model_ans": "1799",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1799 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What religion did the French spread along with their imperialism? ",
        "answers": [
            "Catholicism",
            "Catholicism",
            "Catholicism",
            "Catholicism",
            "Catholicism"
        ],
        "model_ans": "Catholicism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Catholicism </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Jules Ferry thought that the \"higher races\" have a duty to what?",
        "answers": [
            "civilize the inferior",
            "civilize the inferior",
            "civilize the inferior",
            "to civilize the inferior",
            "civilize"
        ],
        "model_ans": "civilize",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> civilize </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did France offer that was rare by imperial standards?",
        "answers": [
            "assimilation",
            "Full citizenship rights",
            "assimilation",
            "assimilation",
            "Full citizenship rights"
        ],
        "model_ans": "a treaty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a treaty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did france differ from Britain in managing its colonies?",
        "answers": [
            "small numbers of settlers",
            "sent small numbers of settlers to its colonies",
            "sent small numbers of settlers to its colonies,",
            "sent small numbers of settlers to its colonies",
            "small numbers of settlers"
        ],
        "model_ans": "France used a more direct and authoritarian approach, while Britain used a more indirect and subtle approach",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France used a more direct and authoritarian approach, while Britain used a more indirect and subtle approach </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The French thought bringing what would uplift other regions?",
        "answers": [
            "Christianity and French culture",
            "Christianity",
            "Christianity and French culture",
            "Christianity and French culture"
        ],
        "model_ans": "Civilization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Civilization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did the French send a large number of settlers?",
        "answers": [
            "Algeria",
            "Algeria",
            "Algeria",
            "Algeria"
        ],
        "model_ans": "New France",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New France </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Charles de Gaulle and the Free French run operations during World War 2?",
        "answers": [
            "overseas colonies",
            "overseas colonies",
            "overseas colonies",
            "overseas colonies",
            "overseas colonies"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After 1945, what challenged the French empire?",
        "answers": [
            "anti-colonial movements",
            "anti-colonial movements",
            "anti-colonial movements",
            "anti-colonial movements",
            "anti-colonial movements"
        ],
        "model_ans": "Decolonization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Decolonization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did France lose a war in the 1950's?",
        "answers": [
            "Vietnam",
            "Vietnam",
            "Vietnam",
            "Vietnam",
            "Vietnam"
        ],
        "model_ans": "Indochina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Indochina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did France win a war in the 1950's",
        "answers": [
            "Algeria",
            "Algeria",
            "Algeria",
            "Algeria",
            "Algeria"
        ],
        "model_ans": "Indochina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Indochina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "By when did most of France's Colonies gain independence?",
        "answers": [
            "1960",
            "1960",
            "1960",
            "1960",
            "1960"
        ],
        "model_ans": "1960",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1960 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where were the Germanic tribes originally located?",
        "answers": [
            "Scandinavia",
            "Scandinavia and northern Europe",
            "Scandinavia and northern Europe",
            "Scandinavia and northern Europe",
            "Scandinavia and northern Europe,"
        ],
        "model_ans": "Northern Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Northern Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Germanic tribes claim territory in north and west Europe?",
        "answers": [
            "middle period of classical antiquity",
            "the middle period of classical antiquity",
            "the middle period of classical antiquity",
            "the middle period of classical antiquity",
            "middle period of classical antiquity"
        ],
        "model_ans": "5th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "By when did the Germanic tribes conquer the Celtic peoples?",
        "answers": [
            "800 CE",
            "in late antiquity",
            "late antiquity",
            "late antiquity",
            "by 800 CE"
        ],
        "model_ans": "5th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the only region in Europe not conquered by the Germanic tribes?",
        "answers": [
            "Muslim Iberia",
            "Muslim Iberia",
            "Muslim Iberia",
            "Muslim Iberia",
            "Muslim Iberia"
        ],
        "model_ans": "Greece",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Germany referred to which area more so than an actual country?",
        "answers": [
            "central Europe",
            "amorphous area of central Europe",
            "an amorphous area of central Europe",
            "central Europe",
            "amorphous area of central Europe."
        ],
        "model_ans": "Prussia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Prussia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Germany doesn't have an imperialistic past until when?",
        "answers": [
            "late 19th century",
            "late 19th century",
            "19th century",
            "late 19th century",
            "late 19th century."
        ],
        "model_ans": "1945\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1945\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Otto von Bismarck born?",
        "answers": [
            "1862",
            "1862",
            "1862",
            "1862",
            "1862"
        ],
        "model_ans": "1815\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1815\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the the second German empire founded?",
        "answers": [
            "after the Franco-German War",
            "after the Franco-German War",
            "after the Franco-German War",
            "after the Franco-German War",
            "after the Franco-German War,"
        ],
        "model_ans": "1871\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1871\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Germany's central interest?",
        "answers": [
            "Europe",
            "Europe",
            "Europe",
            "Europe",
            "Europe itself."
        ],
        "model_ans": "Economic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Economic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who caused the dissolution of the Holy Roman Empire?",
        "answers": [
            "Napoleon",
            "Napoleon",
            "the defeat of Napoleon",
            "Napoleon",
            "defeat of Napoleon"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Besides Africa, where did Germany have imperial interests?",
        "answers": [
            "the South Pacific",
            "South Pacific",
            "South Pacific",
            "South Pacific",
            "South Pacific"
        ],
        "model_ans": "Asia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Colonies were a sign of what amongst European countries?",
        "answers": [
            "prestige",
            "prestige",
            "prestige",
            "prestige"
        ],
        "model_ans": "Imperialism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Imperialism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the first German settlement?",
        "answers": [
            "New Guinea",
            "German New Guinea",
            "German New Guinea",
            "German New Guinea",
            "German New Guinea"
        ],
        "model_ans": "Germantown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Germantown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Germany found their first settlement?",
        "answers": [
            "1884",
            "1884",
            "1884",
            "1884",
            "1884"
        ],
        "model_ans": "13th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who influenced Bismark besides his neighbors?",
        "answers": [
            "Hamburg merchants and traders",
            "Hamburg merchants and traders",
            "Hamburg merchants and traders",
            "Hamburg merchants and traders"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the first Sino-Japanese War?",
        "answers": [
            "1894",
            "1894",
            "1894",
            "1894",
            "1894"
        ],
        "model_ans": "1894\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1894\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What happened as a result of the Russo-Japanese War?",
        "answers": [
            "Japan took part of Sakhalin Island",
            "Japan took part of Sakhalin Island from Russia",
            "Japan took part of Sakhalin Island from Russia",
            "Japan took part of Sakhalin Island from Russia",
            "Japan took part of Sakhalin Island from Russia"
        ],
        "model_ans": "Japan gained control of Manchuria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Japan gained control of Manchuria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which area of China did Japan conquer in 1931?",
        "answers": [
            "Manchuria",
            "Manchuria",
            "Manchuria",
            "Manchuria",
            "Manchuria"
        ],
        "model_ans": "Manchuria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manchuria </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which country did Japan force into an alliance?",
        "answers": [
            "Thailand",
            "Thailand",
            "Thailand",
            "Thailand",
            "Thailand"
        ],
        "model_ans": "Korea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Korea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who along with Russia supported post WW-II communist movements?",
        "answers": [
            "China",
            "People\u2019s Republic of China",
            "the People\u2019s Republic of China",
            "People\u2019s Republic of China",
            "People\u2019s Republic of China"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the Russian Policy \"Indigenization\" defunded?",
        "answers": [
            "1932",
            "1932",
            "1932",
            "1932",
            "1932"
        ],
        "model_ans": "1934",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1934 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who asserted Russia's right to \"self-determination?\"",
        "answers": [
            "Lenin",
            "Lenin",
            "Lenin",
            "Lenin",
            "Lenin"
        ],
        "model_ans": "Vladimir Putin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vladimir Putin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After WW-II where did Russia apply its old Tsarist regimes?",
        "answers": [
            "Eastern Europe",
            "Eastern Europe",
            "in areas its forces occupied in Eastern Europe",
            "1919\u201320",
            "Eastern Europe"
        ],
        "model_ans": "Eastern Europe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eastern Europe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who had established the Russian empire to its former glory prior to 1921?",
        "answers": [
            "Bolshevik leaders",
            "Bolshevik leaders",
            "Bolshevik leaders",
            "Bolshevik leaders"
        ],
        "model_ans": "Peter the Great",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Peter the Great </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Trotsky thought what was needed for a true Russian revolution.",
        "answers": [
            "a world revolution",
            "world revolution",
            "a world revolution",
            "a world revolution",
            "world revolution."
        ],
        "model_ans": "a world revolution",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> a world revolution </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who wrote that imperialism is the highest stage of capitalism?",
        "answers": [
            "Lenin",
            "Lenin",
            "Lenin",
            "Lenin",
            "Lenin"
        ],
        "model_ans": "Vladimir Lenin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vladimir Lenin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What policy did Stalin implement shortly after Lenin's Death?",
        "answers": [
            "socialism in one country",
            "socialism",
            "socialism",
            "socialism",
            "socialism in one country'"
        ],
        "model_ans": "Five-Year Plan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Five-Year Plan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the leader of Russia in the 1960's?",
        "answers": [
            "Nikita Khrushchev",
            "Nikita Khrushchev",
            "Nikita Khrushchev",
            "Nikita Khrushchev",
            "Khrushchev"
        ],
        "model_ans": "Nikita Khrushchev",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nikita Khrushchev </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who argued that the USSR had itself become an imperialist power?",
        "answers": [
            "Mao Zedong",
            "Mao Zedong",
            "Mao Zedong",
            "Mao Zedong",
            "Sultan Galiev and Vasyl Shakhrai"
        ],
        "model_ans": "Leon Trotsky",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leon Trotsky </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the first British empire based on?",
        "answers": [
            "mercantilism",
            "mercantilism",
            "mercantilism",
            "mercantilism",
            "mercantilism"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Great Britain lose its colonies in North America?",
        "answers": [
            "1776",
            "1776",
            "1776",
            "1776",
            "1776"
        ],
        "model_ans": "1776\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1776\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did the Spanish and Portuguese colonies gain their independance.",
        "answers": [
            "about 1820",
            "1820",
            "1820",
            "1820",
            "1820"
        ],
        "model_ans": "1826\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1826\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What policy gave Britain dominance in world trade?",
        "answers": [
            "free trade",
            "free trade",
            "free trade",
            "free trade",
            "free trade"
        ],
        "model_ans": "Mercantilism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mercantilism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the defeat of Napoleonic France?",
        "answers": [
            "1815",
            "1815",
            "1815",
            "1815",
            "1815"
        ],
        "model_ans": "1815\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1815\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "By the late 19th century, which country had the largest empire ever to exist in the world?",
        "answers": [
            "The British Empire",
            "British Empire",
            "The British",
            "British",
            "British"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kinds of sciences were Social Darwinism and theories of race?",
        "answers": [
            "pseudo-sciences",
            "pseudo-sciences",
            "pseudo-sciences",
            "British Empire",
            "pseudo"
        ],
        "model_ans": "Biology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Biology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In which continent besides Asia were major gains made by the British Empire in the late 19th century?",
        "answers": [
            "Middle East",
            "Middle East",
            "the Middle East",
            "Africa",
            "Middle East."
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Rudyard Kipling was an influential spokesman for what?",
        "answers": [
            "The British spirit of imperialism",
            "imperialism",
            "Social Darwinism",
            "imperialism"
        ],
        "model_ans": "British Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did the United States plan to subdue imperialistic tendencies? ",
        "answers": [
            "the Monroe Doctrine",
            "through policies",
            "policies such as the Monroe Doctrine",
            "policies such as the Monroe Doctrine",
            "Monroe Doctrine"
        ],
        "model_ans": "Through the Monroe Doctrine",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Through the Monroe Doctrine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the name of Theodore Roosevelt\u2019s policy of imperialism?",
        "answers": [
            "interventionism",
            ".",
            "interventionism",
            "interventionism",
            "interventionism"
        ],
        "model_ans": "Big Stick Policy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Big Stick Policy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Which country besides the Cuba did the United states try to annex in 1898?",
        "answers": [
            "the Philippines",
            "Philippines",
            "Philippines",
            "Philippines",
            "Philippines"
        ],
        "model_ans": "Puerto Rico",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Puerto Rico </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What caused the US public to condemn the occupation of the philippines?",
        "answers": [
            "a war erupted",
            "a war erupted",
            "war",
            "war",
            "war"
        ],
        "model_ans": "The Philippine-American War",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Philippine-American War </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did Smedley Butler call US foreign Policy?",
        "answers": [
            "a \"racket\"",
            "racket",
            "racket",
            "a \"racket\"",
            "racket"
        ],
        "model_ans": "War is a Racket",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> War is a Racket </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was the director of the American Geographical Society in 1914?",
        "answers": [
            "Isiah Bowman",
            "Isiah Bowman",
            "Isiah Bowman",
            "Isiah Bowman",
            "Isiah Bowman"
        ],
        "model_ans": "Isaiah Bowman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Isaiah Bowman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Isiah Bowman appointed to President Wilson's Inquiry?",
        "answers": [
            "1917",
            "1917",
            "1917",
            "1917",
            "1917"
        ],
        "model_ans": "1918",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1918 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who besides Woodrow Wilson himself had the idea for the inquiry?",
        "answers": [
            "American delegation from the Paris Peace Conference",
            "American delegation from the Paris Peace Conference",
            "the American delegation from the Paris Peace Conference",
            "American delegation from the Paris Peace Conference",
            "American delegation from the Paris Peace Conference"
        ],
        "model_ans": "Edward Mandell House",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edward Mandell House </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the premise of Woodrow Wilson's inquiry?",
        "answers": [
            "U.S authorship of a 'new world'",
            "allow for U.S authorship of a 'new world' which was to be characterized by geographical order",
            "allow for U.S authorship of a 'new world' which was to be characterized by geographical order",
            "allow for U.S authorship of a 'new world'",
            "U.S authorship of a 'new world'"
        ],
        "model_ans": "The Inquiry",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Inquiry </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Isiah Bowman nick name, as known by the public.",
        "answers": [
            "Wilson's geographer",
            "Wilson's geographer",
            "Wilson's geographer",
            "Wilson's geographer",
            "Wilson's geographer."
        ],
        "model_ans": "Ike",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ike </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Some people describe what between individuals or groups as imperialism or colonialism?",
        "answers": [
            "internal strife",
            "internal strife",
            "internal strife",
            "internal strife",
            "internal strife"
        ],
        "model_ans": "power",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> power </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the US expansion Westward could be viewed as what type of colonialism?",
        "answers": [
            "\"internal colonialism\"",
            "internal colonialism",
            "internal colonialism",
            "internal colonialism",
            "internal"
        ],
        "model_ans": "Internal",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Internal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Africans were brought into the United States during the slave trade?",
        "answers": [
            "12 to 15 million",
            "12 to 15 million",
            "12 to 15 million",
            "12 to 15 million",
            "12 to 15 million"
        ],
        "model_ans": "12 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who does Edward Said say is being attacked by US imperialism?",
        "answers": [
            "the contemporary Orient",
            "the contemporary Orient",
            "the contemporary Orient",
            "contemporary Orient",
            "contemporary Orient, \""
        ],
        "model_ans": "Palestine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Palestine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the Ottoman Empire fall?",
        "answers": [
            "1923",
            "1923",
            "1923",
            "1923",
            "1923"
        ],
        "model_ans": "1922\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1922\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who reigned over the Ottoman empire when it was at its most powerful.",
        "answers": [
            "Suleiman the Magnificent",
            "Suleiman the Magnificent",
            "Suleiman the Magnificent",
            "Suleiman the Magnificent",
            "Suleiman the Magnificent,"
        ],
        "model_ans": "Suleiman the Magnificent",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Suleiman the Magnificent </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many provinces did the Ottoman empire contain in the 17th century?",
        "answers": [
            "32",
            "32",
            "32",
            "32",
            "32"
        ],
        "model_ans": "29",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 29 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Ottoman empire controlled territory on three continents, Africa, Asia and which other?",
        "answers": [
            "Europe",
            "Europe",
            "Europe",
            "Europe",
            "Europe"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the Ottoman empire at its height?",
        "answers": [
            "During the 16th and 17th centuries",
            "17th century",
            "the 16th and 17th centuries",
            "16th and 17th centuries",
            "16th and 17th centuries"
        ],
        "model_ans": "16th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the capital of the Ottoman empire?",
        "answers": [
            "Istanbul",
            "Istanbul",
            "Istanbul",
            "Istanbul",
            "Istanbul"
        ],
        "model_ans": "Istanbul",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Istanbul </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who did the Ottoman empire ally with in WW I?",
        "answers": [
            "Germany",
            "Germany",
            "Germany",
            "Germany",
            "Germany"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Which country today is a remnant of the Ottoman empire?",
        "answers": [
            "Turkey",
            "Turkey",
            "Turkey",
            "Turkey",
            "Turkey"
        ],
        "model_ans": "Turkey",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turkey </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What ended Turkish imperial Ambitions?",
        "answers": [
            "World War I",
            "creation of modern Balkan and Middle Eastern states",
            "the creation of modern Balkan and Middle Eastern states",
            "creation of modern Balkan and Middle Eastern states",
            "creation of modern Balkan and Middle Eastern states"
        ],
        "model_ans": "World War I",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World War I </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the largest city of Poland?",
        "answers": [
            "Warsaw",
            "Warsaw",
            "Warsaw"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "On what river does Warsaw stand?",
        "answers": [
            "Vistula",
            "Vistula River",
            "Vistula"
        ],
        "model_ans": "Vistula",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vistula </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How far is Warsaw from the Baltic Sea?",
        "answers": [
            "roughly 260 kilometres",
            "260 kilometres",
            "260 kilometres"
        ],
        "model_ans": "10 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many residents does the greater metropolitan area have?",
        "answers": [
            "2.666 million",
            "2.666 million",
            "2.666 million"
        ],
        "model_ans": "1,000,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What rank for most populous city in the European Union does Warsaw hold?",
        "answers": [
            "9th",
            "9th",
            "9th"
        ],
        "model_ans": "5th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who ranked Warsaw as the 32nd most liveable city in the world?",
        "answers": [
            "Economist Intelligence Unit",
            "Economist Intelligence Unit",
            "Economist Intelligence Unit"
        ],
        "model_ans": "Mercer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mercer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Warsaw ranked as the 32nd most liveable city in the world?",
        "answers": [
            "2012",
            "2012",
            "2012"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Warsaw's economy characterized by?",
        "answers": [
            "wide variety of industries",
            "FMCG manufacturing, metal processing, steel and electronic manufacturing and food processing",
            "FMCG manufacturing"
        ],
        "model_ans": "Service-based",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Service-based </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What exchange in Warsaw is one of the most important for Central and Eastern Europe?",
        "answers": [
            "Stock",
            "Warsaw Stock Exchange",
            "Warsaw Stock Exchange"
        ],
        "model_ans": "Warsaw Stock Exchange",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Stock Exchange </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the name of the European Union agency for external border security?",
        "answers": [
            "Frontex",
            "Frontex",
            "Frontex"
        ],
        "model_ans": "Frontex",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Frontex </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When is the first reference in history to Warsaw?",
        "answers": [
            "1313",
            "1313",
            "1313"
        ],
        "model_ans": "1000 AD\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1000 AD\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What city served as Poland's capital in 1313?",
        "answers": [
            "Krak\u00f3w",
            "Krak\u00f3w",
            "Krak\u00f3w"
        ],
        "model_ans": "Krakow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Krakow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Warsaw become the capital of the Kingdom of Poland?",
        "answers": [
            "1596",
            "1596",
            "1596"
        ],
        "model_ans": "1596\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1596\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who moved his court from Krak\u00f3w to Warsaw in 1596?",
        "answers": [
            "King Sigismund III Vasa",
            "King Sigismund III Vasa",
            "King Sigismund III Vasa"
        ],
        "model_ans": "Sigismund III Vasa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sigismund III Vasa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did Warsaw gain the title of the \"Phoenix City\"?",
        "answers": [
            "survived many wars, conflicts and invasions",
            "it has survived many wars, conflicts and invasions",
            "because it has survived many wars, conflicts and invasions throughout its long history"
        ],
        "model_ans": "Warsaw was rebuilt after World War II",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw was rebuilt after World War II </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What archdiocese is Warsaw the seat of?",
        "answers": [
            "Roman Catholic",
            "Roman Catholic",
            "Roman Catholic"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another notable university in Warsaw after the University of Warsaw?",
        "answers": [
            "Polish Academy of Sciences",
            "Polish Academy of Sciences",
            "Polish Academy of Sciences"
        ],
        "model_ans": "Warsaw School of Economics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw School of Economics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Warsaw's Old Town listed as in 1980?",
        "answers": [
            "a UNESCO World Heritage Site",
            "UNESCO World Heritage Site",
            "UNESCO World Heritage Site"
        ],
        "model_ans": "UNESCO World Heritage Site",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO World Heritage Site </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "King Sigimund's Column is an example of what kind of attraction in Warsaw?",
        "answers": [
            "architectural",
            "architectural",
            "architectural"
        ],
        "model_ans": "Monument",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Monument </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a quarter of Warsaw filled with?",
        "answers": [
            "luxurious parks and royal gardens",
            "luxurious parks and royal gardens",
            "luxurious parks and royal gardens"
        ],
        "model_ans": "water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is Warsaw's name in the Polish language?",
        "answers": [
            "Warszawa",
            "Warszawa",
            "Warszawa"
        ],
        "model_ans": "Warszawa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warszawa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does Warszawa mean in Polish?",
        "answers": [
            "belonging to Warsz",
            "belonging to Warsz",
            "belonging to Warsz"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Warsz?",
        "answers": [
            "12th/13th-century nobleman",
            "shortened form of the masculine name of Slavic origin Warcis\u0142aw",
            "nobleman"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Warsz own?",
        "answers": [
            "a village",
            "village"
        ],
        "model_ans": "Warsz owned a record label",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warsz owned a record label </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the full official city name of Warsaw?",
        "answers": [
            "miasto sto\u0142eczne Warszawa",
            "miasto sto\u0142eczne Warszawa",
            "miasto sto\u0142eczne Warszawa"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What city, raided by clans and dukes, preceded the founding of Warszowa?",
        "answers": [
            "Jazd\u00f3w",
            "Jazd\u00f3w",
            "Jazd\u00f3w"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was Boleslaw II of Masovia?",
        "answers": [
            "The Prince of P\u0142ock",
            "Prince of P\u0142ock",
            "Prince of P\u0142ock"
        ],
        "model_ans": "Boleslaw II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boleslaw II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the settlement which would become Warsaw established?",
        "answers": [
            "1300",
            "1300",
            "1300"
        ],
        "model_ans": "13th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what year did Warszowa become the official capital of the Masovian Duchy?",
        "answers": [
            "1413",
            "1413",
            "1413"
        ],
        "model_ans": "Warszawa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warszawa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Masovian Duchy reincorporated into the Polish Crown?",
        "answers": [
            "1526",
            "1526",
            "1526"
        ],
        "model_ans": "1526\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1526\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Warsaw serve as the seat for in 1529?",
        "answers": [
            "General Sejm",
            "General Sejm",
            "General Sejm"
        ],
        "model_ans": "Poland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the General Sejm make Warsaw it's permanent seat?",
        "answers": [
            "1569",
            "1569",
            "1569"
        ],
        "model_ans": "1596\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1596\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Warsaw Confederation formally establish in 1573?",
        "answers": [
            "religious freedom",
            "religious freedom in the Polish\u2013Lithuanian Commonwealth",
            "religious freedom"
        ],
        "model_ans": "religious tolerance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> religious tolerance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did Warsaw become the capital of the Commonwealth?",
        "answers": [
            "Due to its central location",
            "its central location",
            "central location"
        ],
        "model_ans": "Warsaw was the capital of the Polish-Lithuanian Commonwealth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw was the capital of the Polish-Lithuanian Commonwealth </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year did King Sigismund III Vasa move his court to Warsaw?",
        "answers": [
            "1596",
            "1596",
            "1596"
        ],
        "model_ans": "1596\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1596\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long was Warsaw the capital of the Polish-Lithuanian Commonwealth?",
        "answers": [
            "until 1796",
            "until 1796"
        ],
        "model_ans": "1795\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1795\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What kingdom annexed Warsaw in 1796?",
        "answers": [
            "Prussia",
            "Kingdom of Prussia",
            "Prussia"
        ],
        "model_ans": "Prussia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prussia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Whose army liberated Warsaw in 1806?",
        "answers": [
            "Napoleon's",
            "Napoleon's",
            "Napoleon's"
        ],
        "model_ans": "Napoleon's army",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon's army </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Warsaw become the center of the Congress Poland?",
        "answers": [
            "1815",
            "1815",
            "1815"
        ],
        "model_ans": "1815\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1815\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the Royal University of Warsaw established?",
        "answers": [
            "1816",
            "1816",
            "1816"
        ],
        "model_ans": "1816\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1816\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long was Warsaw occupied by Germany?",
        "answers": [
            "from 4 August 1915 until November 1918",
            "4 August 1915 until November 1918",
            "from 4 August 1915 until November 1918"
        ],
        "model_ans": "4 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Article 12 of the Allied Armistice terms require Germany to withdraw from?",
        "answers": [
            "areas controlled by Russia in 1914",
            "areas controlled by Russia in 1914",
            "areas controlled by Russia"
        ],
        "model_ans": "Alsace-Lorraine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alsace-Lorraine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who set up what became the Second Polish Republic?",
        "answers": [
            "underground leader Pi\u0142sudski",
            "Pi\u0142sudski",
            "Pi\u0142sudski"
        ],
        "model_ans": "J\u00f3zef Pi\u0142sudski",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> J\u00f3zef Pi\u0142sudski </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was the Polish-Bolshevik war fought?",
        "answers": [
            "1920",
            "1920",
            "1920"
        ],
        "model_ans": "1919-1921\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1919-1921\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What army did Warsaw successfully defend itself against?",
        "answers": [
            "the Red Army",
            "Red Army",
            "Red Army"
        ],
        "model_ans": "Nazi Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nazi Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did Germany invade Poland and in doing so start World War II?",
        "answers": [
            "September 1939",
            "1 September 1939",
            "1 September 1939"
        ],
        "model_ans": "1 September 1939\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1 September 1939\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was Warsaw under the administration of when it came under the rule of the General Goverment?",
        "answers": [
            "a German Nazi colonial administration",
            "German Nazi",
            "German Nazi colonial administration"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of Warsaw's population was Jewish?",
        "answers": [
            "some 30% of the city",
            "30%",
            "30%"
        ],
        "model_ans": "30% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "30% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Hitler order the annihilation of the Warsaw Ghetto?",
        "answers": [
            "April 1943",
            "19 April 1943",
            "19 April 1943"
        ],
        "model_ans": "1943\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1943\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long were the fighters of the Warsaw Ghetto Uprising able to hold out?",
        "answers": [
            "almost a month",
            "almost a month",
            "almost a month"
        ],
        "model_ans": "27 days",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 27 days </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What army was pushing deep into Polish territory to pursue the Germans in 1944?",
        "answers": [
            "the Red Army",
            "Red Army",
            "e Red Army"
        ],
        "model_ans": "Soviet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Soviet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why did the exiled Polish government in London order the underground Home Army to seize control of Warsaw prior to the arrival of the Red Army?",
        "answers": [
            "Stalin was hostile to the idea of an independent Poland",
            "Stalin was hostile to the idea of an independent Poland",
            "Stalin was hostile to the idea of an independent Poland"
        ],
        "model_ans": "To prevent the Soviet Union from taking control of the city",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To prevent the Soviet Union from taking control of the city </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Warsaw Uprising begin?",
        "answers": [
            "August 1944",
            "the Red Army was nearing the city",
            "1 August 1944"
        ],
        "model_ans": "1944\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1944\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many days did the Warsaw Uprising last?",
        "answers": [
            "63 days",
            "63",
            "63 days"
        ],
        "model_ans": "63 days\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "63 days\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the estimated death toll for Polish civilians? ",
        "answers": [
            "between 150,000 and 200,000",
            "between 150,000 and 200,000",
            "between 150,000 and 200,000"
        ],
        "model_ans": "2 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What campaign did the Communist regime initiate after WWII?",
        "answers": [
            "\"Bricks for Warsaw\"",
            "Bricks for Warsaw",
            "Bricks for Warsaw"
        ],
        "model_ans": "Land Reform",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Land Reform </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of housing was erected in Warsaw as part of the Bricks for Warsaw process?",
        "answers": [
            "prefabricated",
            "prefabricated",
            "prefabricated"
        ],
        "model_ans": "residential",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> residential </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were the structures built by the Soviets typical of?",
        "answers": [
            "an Eastern Bloc city",
            "an Eastern Bloc city"
        ],
        "model_ans": "Brutalist architecture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brutalist architecture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What building was a gift from the Soviet Union?",
        "answers": [
            "Palace of Culture and Science",
            "Palace of Culture and Science",
            "Palace of Culture and Science"
        ],
        "model_ans": "The United Nations Headquarters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The United Nations Headquarters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What list was Warsaw's Old Town inscribed onto in 1980?",
        "answers": [
            "UNESCO's World Heritage list",
            "UNESCO's World Heritage",
            "UNESCO's World Heritage"
        ],
        "model_ans": "UNESCO World Heritage List",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO World Heritage List </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What pope as a native of Poland?",
        "answers": [
            "John Paul II",
            "John Paul II",
            "John Paul II"
        ],
        "model_ans": "John Paul II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Paul II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did John Paul II's visits in 1979 and 1983 encourage?",
        "answers": [
            "growing anti-communist fervor",
            "anti-communist fervor",
            "growing anti-communist fervor"
        ],
        "model_ans": "the Polish Solidarity movement",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the Polish Solidarity movement </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long had John Paul II been the pope in 1979?",
        "answers": [
            "less than a year",
            "less than a year",
            "less than a year"
        ],
        "model_ans": "16 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did John Paul II celebrate Mass in Warsaw?",
        "answers": [
            "Victory Square",
            "Victory Square",
            "1979"
        ],
        "model_ans": "St. John's Archcathedral",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> St. John's Archcathedral </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the Polish citizens understand the subtext of John Paul II's words to be?",
        "answers": [
            "incentive for the democratic changes",
            "incentive for the democratic changes",
            "democratic changes"
        ],
        "model_ans": "The Pope's words were seen as a call to unity and reconciliation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Pope's words were seen as a call to unity and reconciliation </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many kilometers is Warsaw from the Carpathian Mountains?",
        "answers": [
            "about 300",
            "300",
            "300"
        ],
        "model_ans": "300 km",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 300 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many miles east of Berlin is Warsaw?",
        "answers": [
            "325",
            "325",
            "325"
        ],
        "model_ans": "250 miles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 250 miles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What river does Warsaw straddle?",
        "answers": [
            "Vistula River",
            "Vistula",
            "Vistula"
        ],
        "model_ans": "Vistula",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vistula </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How high is the highest point in Warsaw?",
        "answers": [
            "452.8 ft",
            "115.7 metres",
            "115.7 metres"
        ],
        "model_ans": "120 meters\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "120 meters\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the lowest point of Warsaw located?",
        "answers": [
            "at the right bank of the Vistula",
            "at the right bank of the Vistula, by the eastern border of Warsaw",
            "by the eastern border"
        ],
        "model_ans": "82 meters below sea level",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 82 meters below sea level </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many geomorphologic formations is Warsaw on?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What formation has an asymmetrical pattern of different terraces?",
        "answers": [
            "Vistula Valley",
            "geomorphologic",
            "Vistula Valley"
        ],
        "model_ans": "Delta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Delta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the axis of Warsaw which divides it into two parts?",
        "answers": [
            "Vistula River",
            "Vistula River",
            "Vistula River"
        ],
        "model_ans": "N-S",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> N-S </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which plateau is the left part of Warsaw on?",
        "answers": [
            "moraine",
            "moraine",
            "moraine"
        ],
        "model_ans": "Vistula",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vistula </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the edge of the moraine plateau called?",
        "answers": [
            "Warsaw Escarpment",
            "Warsaw Escarpment",
            "Warsaw Escarpment"
        ],
        "model_ans": "Rim",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rim </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What plateau has groups of clay pits?",
        "answers": [
            "moraine",
            "moraine",
            "moraine"
        ],
        "model_ans": "Lune",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lune </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the highest level of the Vistula plateau contain?",
        "answers": [
            "former flooded terraces",
            "former flooded terraces",
            "peat swamps or small ponds"
        ],
        "model_ans": "Krakow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Krakow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the currently flooded terrace still have visible?",
        "answers": [
            "valleys",
            "valleys and ground depressions",
            "valleys"
        ],
        "model_ans": "foundation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> foundation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where can Aeolian sand with a number of dunes be found?",
        "answers": [
            "plain Vistula terraces",
            "highest terrace",
            "highest terrace"
        ],
        "model_ans": "Sahara Desert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sahara Desert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of forested areas can be found on the highest terrace?",
        "answers": [
            "pine",
            "pine",
            "pine"
        ],
        "model_ans": "Temperate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Temperate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does Warsaw's mixture of architectural styles reflect?",
        "answers": [
            "turbulent history of the city",
            "turbulent history of the city and country",
            "turbulent history of the city"
        ],
        "model_ans": "History",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> History </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Warsaw completely razed to the ground by bombing raids?",
        "answers": [
            "During the Second World War",
            "Second World War",
            "During the Second World War"
        ],
        "model_ans": "1944",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1944 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Warsaw start to rebuild?",
        "answers": [
            "After liberation",
            "After liberation",
            "After liberation"
        ],
        "model_ans": "1945\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1945\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What building from the 19th century was destroyed between the 1950s and 1960s?",
        "answers": [
            "Leopold Kronenberg Palace",
            "Leopold Kronenberg Palace",
            "Leopold Kronenberg Palace"
        ],
        "model_ans": "The Berlin Wall",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Berlin Wall </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What style were the mass constructed residential blocks designed in?",
        "answers": [
            "typical of Eastern bloc countries",
            "basic design typical of Eastern bloc countries",
            "design typical of Eastern bloc countries"
        ],
        "model_ans": "Brutalist",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brutalist </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of architecture is represented in the majestic churches?",
        "answers": [
            "Gothic",
            "Gothic",
            "Gothic"
        ],
        "model_ans": "Gothic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was St. John's Cathedral constructed?",
        "answers": [
            "14th century",
            "14th century",
            "14th century"
        ],
        "model_ans": "1845",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1845 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is St. John's Cathedral an example of, stylistically?",
        "answers": [
            "Masovian gothic",
            "Gothic architecture",
            "Masovian gothic"
        ],
        "model_ans": "Gothic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "The house of the Baryczko merchant family is a notable example of what type of architecture?",
        "answers": [
            "Renaissance",
            "Renaissance",
            "Renaissance"
        ],
        "model_ans": "Baroque",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Baroque </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Royal Castle the most interesting example of?",
        "answers": [
            "mannerist architecture",
            "mannerist architecture",
            "mannerist"
        ],
        "model_ans": "Baroque architecture",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Baroque architecture </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did building activity in the palaces and churches take place in the later decades of?",
        "answers": [
            "17th century",
            "17th century",
            "17th century."
        ],
        "model_ans": "16th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did building activity occur on St. Kazimierz Church?",
        "answers": [
            "1688\u20131692",
            "1677\u20131683",
            "1688\u20131692"
        ],
        "model_ans": "15th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 15th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of architecture is the Palace of Four Windows an impressive example of?",
        "answers": [
            "rococo",
            "rococo",
            "rococo"
        ],
        "model_ans": "Gothic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gothic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is being described when simplicity of geometrical forms are teamed with inspiration from the Roman period?",
        "answers": [
            "neoclassical architecture",
            "neoclassical architecture",
            "neoclassical architecture"
        ],
        "model_ans": "Art Deco",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Art Deco </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the Palace on the Water rebuilt?",
        "answers": [
            "1775\u20131795",
            "1696",
            "1775\u20131795"
        ],
        "model_ans": "1633",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1633 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "The Kronenberg Palace had been an exceptional example of what type of architecture?",
        "answers": [
            "bourgeois",
            "bourgeois",
            "bourgeois"
        ],
        "model_ans": "Baroque",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Baroque </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why aren't the examples of bouregois architecture visible today?",
        "answers": [
            "not restored by the communist authorities",
            "were not restored",
            "not restored by the communist authorities after the war"
        ],
        "model_ans": "Many examples of bourgeois architecture have been destroyed or altered over time due to various factors such as war, urban renewal, and natural disasters.",
        "model_confidence": "unsure</confidence",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Many examples of bourgeois architecture have been destroyed or altered over time due to various factors such as war, urban renewal, and natural disasters. </answer>\n<confidence>unsure</confidence</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What style was the Warsaw Philharmony edifice built in?",
        "answers": [
            "socialist realism",
            "socialist realism",
            "socialist realism"
        ],
        "model_ans": "Art Nouveau",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Art Nouveau </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What building is the most interesting of the late 19th-century architecture?",
        "answers": [
            "Warsaw University of Technology building",
            "Warsaw University of Technology building",
            "Warsaw University of Technology"
        ],
        "model_ans": "The Eiffel Tower",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Eiffel Tower </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were the Saxon Palace and Br\u00fchl Palace in prewar Warsaw?",
        "answers": [
            "the most distinctive buildings",
            "the most distinctive buildings",
            "most distinctive buildings"
        ],
        "model_ans": "Royal residences",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Royal residences </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What commemorates Warsaw's heroic history?",
        "answers": [
            "many places",
            "many places"
        ],
        "model_ans": "Warsaw Uprising Museum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Uprising Museum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the name of the infamous German Gestapo prison?",
        "answers": [
            "Pawiak",
            "Pawiak",
            "Pawiak"
        ],
        "model_ans": "Gestapo headquarters",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gestapo headquarters </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What fortification was built in the 19th century after the defeat of the November Uprising?",
        "answers": [
            "The Warsaw Citadel",
            "Warsaw Citadel",
            "The Warsaw Citadel"
        ],
        "model_ans": "Warsaw Citadel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Citadel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who does the statue of Little Insurgent commemorate?",
        "answers": [
            "children",
            "children who served as messengers and frontline troops in the Warsaw Uprising",
            "children"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What monument is in memory of the largest insurrection of WWII?",
        "answers": [
            "Warsaw Uprising Monument",
            "Warsaw Uprising Monument",
            "Warsaw Uprising Monument"
        ],
        "model_ans": "Warsaw Uprising Monument",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Warsaw Uprising Monument </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What garden was formally only for royalty?",
        "answers": [
            "The Saxon Garden",
            "Saxon Garden",
            "The Saxon Garden"
        ],
        "model_ans": "Versailles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Versailles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Over how many species of trees can be found in the Saxon Garden?",
        "answers": [
            "100",
            "over 100",
            "100"
        ],
        "model_ans": "150",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 150 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Which end of the Saxon Garden is the Tom of the Unknown Soldier located at?",
        "answers": [
            "east end",
            "east",
            "east"
        ],
        "model_ans": "East",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> East </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is a popular strolling destination for the Varsovians?",
        "answers": [
            "Krasi\u0144ski Palace Garden",
            "Krasi\u0144ski Palace Garden",
            "Krasi\u0144ski Palace Garden"
        ],
        "model_ans": "Lazienki Park",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lazienki Park </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What park covers an area of 76 ha.?",
        "answers": [
            "\u0141azienki",
            "\u0141azienki Park",
            "\u0141azienki Park"
        ],
        "model_ans": "Hyde Park",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hyde Park </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of space in Warsaw are the Botanic Garden and University Library garden?",
        "answers": [
            "green",
            "green",
            "green"
        ],
        "model_ans": "green",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> green </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where is a palm house with subtropic plants from all over the world on display?",
        "answers": [
            "New Orangery",
            "New Orangery",
            "New Orangery"
        ],
        "model_ans": "Kew Gardens",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kew Gardens </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the first horse racetrack located?",
        "answers": [
            "Pole Mokotowskie",
            "Mokot\u00f3w",
            "Pole Mokotowskie"
        ],
        "model_ans": "Ancient Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ancient Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What park is close to John Lennon street?",
        "answers": [
            "Park Ujazdowski",
            "Park Ujazdowski",
            "Park Ujazdowski"
        ],
        "model_ans": "Central Park",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Central Park </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was a zoological garden established in the Praga Park?",
        "answers": [
            "1927",
            "1927",
            "1927"
        ],
        "model_ans": "1928",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1928 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why is Warsaw's flora very rich in species?",
        "answers": [
            "location of Warsaw",
            "location of Warsaw",
            "location"
        ],
        "model_ans": "due to its location at the crossroads of Europe",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> due to its location at the crossroads of Europe </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is Bielany Forest located?",
        "answers": [
            "within the borders of Warsaw",
            "Warsaw",
            "within the borders of Warsaw"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the Bielany Forest the last remnant of?",
        "answers": [
            "Masovian Primeval Forest",
            "Masovian Primeval Forest",
            "Masovian Primeval Forest"
        ],
        "model_ans": "Primeval Forest",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Primeval Forest </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What forest is by Warsaw's southern border?",
        "answers": [
            "Kabaty",
            "Kabaty Forest",
            "Kabaty"
        ],
        "model_ans": "Bia\u0142owie\u017ca Forest",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bia\u0142owie\u017ca Forest </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many botanical gardens does Warsaw have?",
        "answers": [
            "two",
            "two",
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many natural reserves are in Warsaw?",
        "answers": [
            "13",
            "13",
            "13"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How far from Warsaw does the Vistula river's environment change noticeably? ",
        "answers": [
            "15 kilometres",
            "15 kilometres",
            "About 15 kilometres"
        ],
        "model_ans": "100 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What animals does the Vistula river's ecosystem include?",
        "answers": [
            "otter, beaver and hundreds of bird species",
            "otter, beaver and hundreds of bird species",
            "otter, beaver and hundreds of bird species."
        ],
        "model_ans": "fish, birds, mammals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fish, birds, mammals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many lakes are there in Warsaw?",
        "answers": [
            "several",
            "several",
            "several"
        ],
        "model_ans": "9",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why are the small lakes in the parks emptied before winter?",
        "answers": [
            "to clean them",
            "clean them",
            "to clean them of plants and sediments"
        ],
        "model_ans": "To prevent freezing and cracking of the lake's surface",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To prevent freezing and cracking of the lake's surface </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Warsaw the most diverse of in Poland?",
        "answers": [
            "city",
            "Demographically",
            "city"
        ],
        "model_ans": "city",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> city </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was there a significant minority of in Warsaw?",
        "answers": [
            "Jewish",
            "Jewish",
            "Jewish"
        ],
        "model_ans": "Jews",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jews</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What percentage of the population of Warsaw was Jewish in 1897?",
        "answers": [
            "around 34%",
            "34",
            "34%"
        ],
        "model_ans": "30%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many of Warsaw's inhabitants spoke Polish in 1933?",
        "answers": [
            "833,500",
            "833,500",
            "833,500"
        ],
        "model_ans": "1,000,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is most of Warsaw's modern growth based on?",
        "answers": [
            "migration and urbanisation",
            "internal migration and urbanisation",
            "internal migration and urbanisation."
        ],
        "model_ans": "Steel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Steel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people lived in Warsaw in 1939?",
        "answers": [
            "1,300,000",
            "1,300,000",
            "1,300,000"
        ],
        "model_ans": "1,306,000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,306,000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What had the number of people living in Warsaw declined to by 1945?",
        "answers": [
            "420,000",
            "420,000",
            "420,000"
        ],
        "model_ans": "1/3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1/3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did the Warsaw area enlargement take place?",
        "answers": [
            "1951",
            "1951",
            "1951"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What conviction did many Poles have regarding how the Varsovians thought of themselves?",
        "answers": [
            "as better",
            "thought of themselves as better",
            "better"
        ],
        "model_ans": "Varsovians",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Varsovians </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are there no longer limitations on since 1990?",
        "answers": [
            "residency registration",
            "residency registration",
            "residency registration"
        ],
        "model_ans": "Credit limits",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Credit limits </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of city has Warsaw been for as long as it's been a city?",
        "answers": [
            "multi-cultural",
            "multi-cultural city",
            "multi-cultural"
        ],
        "model_ans": "Capital",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Capital </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Warsaw's population in 1901?",
        "answers": [
            "711,988",
            "711,988",
            "711,988"
        ],
        "model_ans": "1,242,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,242,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Of Warsaw's inhabitants in 1901, what percentage was Catholic?",
        "answers": [
            "56.2%",
            "35.7",
            "56.2%"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What percentage of Warsaw's population was Protestant in 1901?",
        "answers": [
            "2.8%",
            "2.8",
            "2.8%"
        ],
        "model_ans": "10%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were most of the places of religious worship destroyed in Warsaw?",
        "answers": [
            "1944",
            "1944",
            "1944"
        ],
        "model_ans": "During World War II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> During World War II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the basic unit of territorial division in Poland?",
        "answers": [
            "a commune",
            "commune",
            "commune"
        ],
        "model_ans": "Gmina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gmina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the second level of territorial division in Poland?",
        "answers": [
            "counties or powiats",
            "counties or powiats",
            "counties or powiats"
        ],
        "model_ans": "voivodeship",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> voivodeship </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what districts are the registration numbers for cars all of the same type?",
        "answers": [
            "Krak\u00f3w",
            "Krak\u00f3w"
        ],
        "model_ans": "London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who in Warsaw has the power of legislative action?",
        "answers": [
            "Warsaw City Council",
            "Warsaw City Council",
            "Warsaw City Council"
        ],
        "model_ans": "Sejm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sejm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many members are on the Warsaw City Counil?",
        "answers": [
            "60",
            "60",
            "60"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How often are elections for the counsel held?",
        "answers": [
            "every four years",
            "four years",
            "every four years."
        ],
        "model_ans": "Every 4 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Every 4 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the City Council divide itself into?",
        "answers": [
            "committees",
            "committees",
            "committees"
        ],
        "model_ans": "committees",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> committees </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many days does the Council have to override the mayor's veto?",
        "answers": [
            "30 days",
            "30",
            "30"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the mayor of Warsaw called?",
        "answers": [
            "President",
            "President",
            "President"
        ],
        "model_ans": "Mayor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mayor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was the first Warsaw President?",
        "answers": [
            "Jan Andrzej Menich",
            "Jan Andrzej Menich",
            "Jan Andrzej Menich"
        ],
        "model_ans": "Stanis\u0142aw Ma\u0142achowski",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stanis\u0142aw Ma\u0142achowski </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Menich serve as President?",
        "answers": [
            "1695\u20131696",
            "1695\u20131696",
            "1695\u20131696"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who has elected the President of Warsaw since 1990?",
        "answers": [
            "the City council",
            "City council",
            "City council"
        ],
        "model_ans": "Polish people",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Polish people </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What district of Warsaw chose the President between 1994 and 1999?",
        "answers": [
            "Centrum",
            "Centrum",
            "Centrum"
        ],
        "model_ans": "Urszula Durska",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Urszula Durska </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the city centre of Warsaw called in Polish?",
        "answers": [
            "\u015ar\u00f3dmie\u015bcie",
            "\u015ar\u00f3dmie\u015bcie",
            "\u015ar\u00f3dmie\u015bcie"
        ],
        "model_ans": "\u015ar\u00f3dmie\u015bcie",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> \u015ar\u00f3dmie\u015bcie </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many companies were registered in Warsaw in 2006?",
        "answers": [
            "304,016",
            "304,016"
        ],
        "model_ans": "12,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Warsaw ranked the 7th greatest of?",
        "answers": [
            "emerging market",
            "emerging market",
            "emerging market"
        ],
        "model_ans": "cities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much of Poland's national income does Warsaw produce?",
        "answers": [
            "12%",
            "12%",
            "12%"
        ],
        "model_ans": "20%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the total nominal GDP of Warsaw in 2010?",
        "answers": [
            "191.766 billion PLN",
            "191.766 billion PLN",
            "191.766 billion PLN"
        ],
        "model_ans": "143 billion USD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 143 billion USD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Warsaw's first stock exchange established?",
        "answers": [
            "1817",
            "1817",
            "1817"
        ],
        "model_ans": "1817\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1817\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What brought Warsaw's stock exchange to a stop?",
        "answers": [
            "World War II",
            "World War II",
            "World War II."
        ],
        "model_ans": "World War II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> World War II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When was Warsaw's stock exchange brought back to life?",
        "answers": [
            "April 1991",
            "April 1991",
            "April 1991"
        ],
        "model_ans": "1991",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1991 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many companies were listed on the WSE on August 2009?",
        "answers": [
            "374",
            "374",
            "374"
        ],
        "model_ans": "350",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 350 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Whose former headquarters was the WSE located in until 2000?",
        "answers": [
            "Polish United Workers' Party",
            "Polish United Workers' Party",
            "Polish United Workers' Party"
        ],
        "model_ans": "Warsaw Stock Exchange",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Stock Exchange </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the FSO Car Factory founded?",
        "answers": [
            "1951",
            "1951",
            "1951"
        ],
        "model_ans": "1958",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1958 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What car is licensed by the FSO Car Factory and built in Egypt?",
        "answers": [
            "Polonez",
            "125p",
            "Polonez"
        ],
        "model_ans": "FSO",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> FSO </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What South Korean car manufacturer purchased the factor in 1995?",
        "answers": [
            "Daewoo",
            "Daewoo",
            "Daewoo"
        ],
        "model_ans": "Hyundai",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hyundai </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who bought the factory in 2005?",
        "answers": [
            "AvtoZAZ",
            "AvtoZAZ",
            "AvtoZAZ"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did the license to build this type of car expire in 2011?",
        "answers": [
            "Chevrolet Aveo",
            "Aveo",
            "Aveo"
        ],
        "model_ans": "Toyota",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Toyota </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What year was the University of Warsaw established?",
        "answers": [
            "1816",
            "1816",
            "1816"
        ],
        "model_ans": "1816\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1816\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the second academic school of technology in Poland?",
        "answers": [
            "Warsaw University of Technology",
            "Warsaw University of Technology",
            "Warsaw University of Technology"
        ],
        "model_ans": "Warsaw University of Technology",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw University of Technology </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How many professors does the Warsaw University of Technology employ?",
        "answers": [
            "2,000",
            "2,000",
            "2,000"
        ],
        "model_ans": "over 1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> over 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the largest medical school in Poland?",
        "answers": [
            "Medical University of Warsaw",
            "National Defence University",
            "Medical University of Warsaw"
        ],
        "model_ans": "Medical University of Warsaw",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medical University of Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is one of the largest music schools in Europe?",
        "answers": [
            "Fryderyk Chopin University of Music",
            "Fryderyk Chopin University of Music",
            "Fryderyk Chopin University of Music"
        ],
        "model_ans": "Berklee College of Music",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Berklee College of Music </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the University Library founded?",
        "answers": [
            "1816",
            "1816",
            "1816"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many items is the University Library home to?",
        "answers": [
            "over two million",
            "over two million",
            "over two million"
        ],
        "model_ans": "1 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What profession does Zbigniew Badowski have?",
        "answers": [
            "architects",
            "architects",
            "architects"
        ],
        "model_ans": "Doctor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doctor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who designed the garden for the University Library?",
        "answers": [
            "Irena Bajerska",
            "Irena Bajerska",
            "Irena Bajerska"
        ],
        "model_ans": "Landscape architects",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Landscape architects </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much area does the University Library garden cover?",
        "answers": [
            "10,000 m2",
            "more than 10,000 m2",
            "10,000 m2"
        ],
        "model_ans": "1,000 square meters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 square meters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What suffered considerably for Warsaw when it had an Eastern Bloc economy?",
        "answers": [
            "infrastructure",
            "infrastructure",
            "infrastructure"
        ],
        "model_ans": "Poland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was a major success, especially in rebuilding Warsaw?",
        "answers": [
            "Three-Year Plan",
            "Three-Year Plan",
            "Three-Year Plan"
        ],
        "model_ans": "UNESCO",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why has Warsaw seen many improvements over the past decade?",
        "answers": [
            "solid economic growth",
            "solid economic growth",
            "economic growth"
        ],
        "model_ans": "Warsaw has seen many improvements over the past decade due to its efforts to modernize its infrastructure, improve public transportation, and revitalize its historic center.",
        "model_confidence": "uns",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw has seen many improvements over the past decade due to its efforts to modernize its infrastructure, improve public transportation, and revitalize its historic center. </answer>\n<confidence>uns</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Warsaw's sidewalks and sanitation facilities are some examples of things which have what?",
        "answers": [
            "improved markedly",
            "improved markedly",
            "improved markedly"
        ],
        "model_ans": "infrastructure",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> infrastructure </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where are some of the best medical facilities in East-Central Europe located?",
        "answers": [
            "Warsaw",
            "Warsaw",
            "Warsaw"
        ],
        "model_ans": "Prague, Czech Republic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Prague, Czech Republic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the highest reference hospital in all of Poland?",
        "answers": [
            "Children's Memorial Health Institute",
            "Children's Memorial Health Institute",
            "Children's Memorial Health Institute"
        ],
        "model_ans": "Medical University of Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medical University of Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is one of the largest and most modern oncological institutions in Europe?",
        "answers": [
            "Maria Sk\u0142odowska-Curie Institute of Oncology",
            "Maria Sk\u0142odowska-Curie Institute of Oncology",
            "Maria Sk\u0142odowska-Curie Institute of Oncology"
        ],
        "model_ans": "University College London Hospitals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> University College London Hospitals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many beds does the Maria Sklodowska-Curie Institute of Oncology have?",
        "answers": [
            "700",
            "700",
            "700"
        ],
        "model_ans": "200",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What has the infrastructure done a lot of over the past years?",
        "answers": [
            "developed",
            "developed",
            "developed"
        ],
        "model_ans": "construction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> construction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of venue is the Teatr Wielki?",
        "answers": [
            "musical",
            "musical",
            "musical"
        ],
        "model_ans": "Opera House",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Opera House </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does Warsaw host many of?",
        "answers": [
            "events and festivals",
            "events and festivals",
            "events and festivals"
        ],
        "model_ans": "cultural events",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cultural events </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is the Congress Hall located?",
        "answers": [
            "in the Palace of Culture and Science",
            "Palace of Culture and Science",
            "Palace of Culture and Science"
        ],
        "model_ans": "Berlin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Berlin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where is the Jazz Jamboree hosted?",
        "answers": [
            "Warsaw",
            "Warsaw",
            "Warsaw"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Warsaw Summer Jazz Days is one of the many what hosted by Warsaw?",
        "answers": [
            "festivals",
            "events"
        ],
        "model_ans": "Jazz",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jazz</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the Saxon Garden in Polish?",
        "answers": [
            "Ogr\u00f3d Saski",
            "Ogr\u00f3d Saski",
            "Ogr\u00f3d Saski"
        ],
        "model_ans": "Ogrody Saskie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ogrody Saskie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the Summer Theatre located?",
        "answers": [
            "Saxon Garden",
            "the Saxon Garden",
            "Saxon Garden"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long was the Summer Theatre in operation?",
        "answers": [
            "1870 to 1939",
            "1870 to 1939",
            "1870 to 1939"
        ],
        "model_ans": "1950-1960",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950-1960 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Warsaw's first literary cabaret?",
        "answers": [
            "Momus",
            "Momus",
            "Momus"
        ],
        "model_ans": "Queridos Amigos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Queridos Amigos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What theatre was the best example of \"Polish monumental theatre\"?",
        "answers": [
            "Wojciech Bogus\u0142awski Theatre",
            "Wojciech Bogus\u0142awski Theatre",
            "Wojciech Bogus\u0142awski Theatre"
        ],
        "model_ans": "Teatr Wielki",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Teatr Wielki </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the polish word for wreaths?",
        "answers": [
            "Wianki",
            "Wianki",
            "Wianki"
        ],
        "model_ans": "wianki",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wianki </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How man people gather along the banks of the Vistula for the Wianki festival?",
        "answers": [
            "thousands",
            "thousands",
            "thousands"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is the Wianki festival held?",
        "answers": [
            "Midsummer\u2019s Night",
            "Midsummer\u2019s Night",
            "Midsummer\u2019s Night"
        ],
        "model_ans": "June 24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What will maidens be able to predict by floating their wreaths down the Vistula?",
        "answers": [
            "when they would be married",
            "when they would be married, and to whom",
            "when they would be married,"
        ],
        "model_ans": "The future",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The future </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of flower is sought on Midsummer's Eve?",
        "answers": [
            "the fern",
            "fern",
            "fern"
        ],
        "model_ans": "Wildflowers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wildflowers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the world's first Museum of Posters have one of the largest collections of in the world?",
        "answers": [
            "art posters",
            "art posters",
            "art posters"
        ],
        "model_ans": "posters",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> posters </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many museums are in Warsaw?",
        "answers": [
            "60",
            "60",
            "60"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Warsaw's National Museum is one of the most what?",
        "answers": [
            "prestigious",
            "prestigious",
            "prestigious"
        ],
        "model_ans": "important",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> important </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the National Museum boast having from Adolf Hitler's private collection?",
        "answers": [
            "some paintings",
            "paintings",
            "paintings"
        ],
        "model_ans": "Art",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Art </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the Museum of the Polish Army portray the history of?",
        "answers": [
            "arms",
            "history of arms",
            "arms"
        ],
        "model_ans": "Poland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where can a tribute to the fall of Warsaw be found?",
        "answers": [
            "Warsaw Uprising Museum",
            "Warsaw Uprising Museum",
            "Warsaw Uprising Museum"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What museum preserves the memory of the crime?",
        "answers": [
            "Katy\u0144",
            "Katy\u0144 Museum",
            "Katy\u0144 Museum"
        ],
        "model_ans": "Museum of Crime",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Museum of Crime </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of theatre is the Warsaw Fotoplastikon?",
        "answers": [
            "stereoscopic",
            "stereoscopic theatre",
            "stereoscopic"
        ],
        "model_ans": "Cinematograph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cinematograph </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where in Warsaw are patriotic and political objects connected with Poland's struggles for Independence found?",
        "answers": [
            "Museum of Independence",
            "Museum of Independence",
            "Museum of Independence"
        ],
        "model_ans": "Warsaw Uprising Museum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Uprising Museum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many rooms does the Warsaw Historical Museum have?",
        "answers": [
            "60",
            "60",
            "60"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What castle currently houses the Centre for Contemporary Art?",
        "answers": [
            "Royal Ujazd\u00f3w Castle",
            "Royal Ujazd\u00f3w Castle",
            "Royal Ujazd\u00f3w"
        ],
        "model_ans": "Castle of Kromeriz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Castle of Kromeriz </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many projects does the Centre currently realize a year?",
        "answers": [
            "about 500",
            "500",
            "about 500"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the oldest exhibition site in Warsaw?",
        "answers": [
            "Zach\u0119ta National Gallery of Art",
            "Zach\u0119ta National Gallery of Art",
            "Zach\u0119ta National Gallery of Art"
        ],
        "model_ans": "Warsaw Uprising Museum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw Uprising Museum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the Zach\u0119ta National Gallery of Art organize exhibitions of art from?",
        "answers": [
            "Polish and international artists",
            "modern art by Polish and international artists",
            "Polish and international artists a"
        ],
        "model_ans": "Poland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When is the Warsaw Gallery Weekend held?",
        "answers": [
            "last weekend of September",
            "last weekend of September",
            "last weekend of September"
        ],
        "model_ans": "September",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who won the Ekstraklasa Championship in 2000?",
        "answers": [
            "Polonia Warsaw",
            "Polonia Warsaw",
            "Polonia Warsaw"
        ],
        "model_ans": "Wis\u0142a Krak\u00f3w",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wis\u0142a Krak\u00f3w </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Polonia Warsaw win the country's championship prior to 2000?",
        "answers": [
            "1946",
            "1946",
            "1946"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many times has Polonia won the cup?",
        "answers": [
            "twice",
            "twice",
            "twice"
        ],
        "model_ans": "0",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 0 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where is Polonia's home venue located?",
        "answers": [
            "at Konwiktorska Street",
            "Konwiktorska Street",
            "Konwiktorska Street"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why was Polonia relegated from the country's top flight in 2013?",
        "answers": [
            "disastrous financial situation",
            "their disastrous financial situation",
            "disastrous financial situation."
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is polish for \"mermaid\"?",
        "answers": [
            "syrenka",
            "syrenka",
            "syrenka"
        ],
        "model_ans": "syrenka",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> syrenka </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is Warsaw's symbol?",
        "answers": [
            "The mermaid",
            "mermaid",
            "The mermaid"
        ],
        "model_ans": "Mermaid",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Mermaid </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long has the imagery of the mermaid been used by Warsaw?",
        "answers": [
            "since at least the mid-14th century",
            "mid-14th century",
            "at least the mid-14th century"
        ],
        "model_ans": "200 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When is the oldest armed seal of Warsaw from?",
        "answers": [
            "1390",
            "1390",
            "1390"
        ],
        "model_ans": "14th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does the sea monster with a female upper body hold in its claws?",
        "answers": [
            "a sword",
            "sword",
            "sword"
        ],
        "model_ans": "a pearl",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a pearl </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Artur Oppman give to the world?",
        "answers": [
            "legend",
            "The best-known legend",
            "legend"
        ],
        "model_ans": "Jazz",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jazz</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did two of Triton's daughters set out on a journey through?",
        "answers": [
            "depths of the oceans and seas",
            "depths of the oceans and seas",
            "depths of the oceans and seas"
        ],
        "model_ans": "sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did one of Triton's daughters decide she wanted to hang out and stay?",
        "answers": [
            "coast of Denmark",
            "coast of Denmark",
            "coast of Denmark"
        ],
        "model_ans": "Under the sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Under the sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "A mermaid stopped to rest on the sandy beach by what village?",
        "answers": [
            "Warszowa",
            "village of Warszowa",
            "Warszowa"
        ],
        "model_ans": "Atlantis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Atlantis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did a greedy merchant do to the mermaid?",
        "answers": [
            "captured",
            "captured the mermaid",
            "captured"
        ],
        "model_ans": "He sold her to the sea witch",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He sold her to the sea witch </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was one of the most famous people born in Warsaw?",
        "answers": [
            "Maria Sk\u0142odowska-Curie",
            "Maria Sk\u0142odowska-Curie",
            "Maria Sk\u0142odowska-Curie"
        ],
        "model_ans": "Fr\u00e9d\u00e9ric Chopin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fr\u00e9d\u00e9ric Chopin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was Maria Curie the first female recipient of?",
        "answers": [
            "Nobel Prize",
            "Nobel Prize",
            "Nobel Prize"
        ],
        "model_ans": "Nobel Prize",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nobel Prize </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who was Fr\u00e9d\u00e9ric Chopin?",
        "answers": [
            "Famous musicians",
            "musicians",
            "Famous musicians"
        ],
        "model_ans": "Polish composer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Polish composer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How old was Chopin when he moved to Warsaw with his family?",
        "answers": [
            "seven months old",
            "seven months old",
            "seven months old"
        ],
        "model_ans": "1\n<confidence> unsure </confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What year was Casimir Pulaski born in Warsaw?",
        "answers": [
            "1745",
            "1745",
            "1745"
        ],
        "model_ans": "1745\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1745\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was the famous artist Tamara de Lempicka born?",
        "answers": [
            "Warsaw",
            "Warsaw",
            "Warsaw"
        ],
        "model_ans": "Warsaw",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warsaw </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When did Tamara marry a lawyer?",
        "answers": [
            "1916",
            "1916",
            "1916"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Lempicka represent better than anyone else?",
        "answers": [
            "the Art Deco style",
            "Art Deco style in painting and art",
            "Art Deco style"
        ],
        "model_ans": "Art",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Art </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What profession was Nathan Alterman?",
        "answers": [
            "poet",
            "poet",
            "poet"
        ],
        "model_ans": "Poet",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Poet </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who loved Warsaw so much that he kept putting it in his novels?",
        "answers": [
            "Isaac Bashevis Singer",
            "Isaac Bashevis Singer",
            "Isaac Bashevis Singer"
        ],
        "model_ans": "Joseph Conrad",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Conrad </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the French and Indian War?",
        "answers": [
            "1754\u20131763",
            "1754\u20131763",
            "1754\u20131763",
            "1754\u20131763",
            "1754\u20131763"
        ],
        "model_ans": "1754-1763\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1754-1763\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who fought in the French and Indian war?",
        "answers": [
            "colonies of British America and New France",
            "colonies of British America and New France",
            "British America and New France",
            "British America and New France",
            "the colonies of British America and New France"
        ],
        "model_ans": "France and Britain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France and Britain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many people were in French North American Colonies?",
        "answers": [
            "roughly 60,000 European settlers",
            "60,000",
            "60,000",
            "60,000",
            "60,000 European settlers"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many people were in British North American Colonies?",
        "answers": [
            "2 million",
            "2 million",
            "2 million",
            "2 million",
            "2 million"
        ],
        "model_ans": "2 million",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was war fought?",
        "answers": [
            "primarily along the frontiers between New France and the British colonies",
            "between New France and the British colonies",
            "frontiers between New France and the British colonies",
            "along the frontiers",
            "Virginia in the South to Nova Scotia in the North"
        ],
        "model_ans": "Various locations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Various locations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did war start?",
        "answers": [
            "dispute over control of the confluence of the Allegheny and Monongahela rivers, called the Forks of the Ohio",
            "dispute over control of the confluence of the Allegheny and Monongahela rivers",
            "dispute over control of the confluence of the Allegheny and Monongahela rivers",
            "dispute over control",
            "a dispute over control of the confluence of the Allegheny and Monongahela rivers"
        ],
        "model_ans": "War has started in various ways throughout history, including territorial disputes, ideological conflicts, and economic rivalries.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> War has started in various ways throughout history, including territorial disputes, ideological conflicts, and economic rivalries. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did violence start in war?",
        "answers": [
            "Battle of Jumonville Glen in May 1754,",
            "May 1754",
            "May 1754",
            "May 1754",
            "May 1754"
        ],
        "model_ans": "ancient times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ancient times </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did colonial governors meet with General Edward Braddock about attack on the french?",
        "answers": [
            "1755",
            "1755",
            "1755",
            "1755",
            "1755"
        ],
        "model_ans": "1755",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1755 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How successful was initial effort by Braddock?",
        "answers": [
            "disaster; he was defeated in the Battle of the Monongahela",
            "disaster",
            "was a disaster",
            "he was defeated",
            "None succeeded"
        ],
        "model_ans": "Not successful",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not successful </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did British operation fail in 1755, 56, 57?",
        "answers": [
            "combination of poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies",
            "poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies",
            "a combination of poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies",
            "poor management, internal divisions, and effective Canadian scouts",
            "a combination of poor management, internal divisions, and effective Canadian scouts"
        ],
        "model_ans": "Not enough information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not enough information </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1755 what fort did British capture?",
        "answers": [
            "Fort Beaus\u00e9jour",
            "Fort Beaus\u00e9jour",
            "Fort Beaus\u00e9jour",
            "Fort Beaus\u00e9jour",
            "Fort Beaus\u00e9jour"
        ],
        "model_ans": "Louisbourg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louisbourg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What order did British make of French?",
        "answers": [
            "expulsion of the Acadians",
            "expulsion of the Acadians",
            "deportation",
            "expulsion",
            "deportation"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who increased British military resources in colonies?",
        "answers": [
            "William Pitt",
            "William Pitt",
            "William Pitt",
            "William Pitt",
            "William Pitt"
        ],
        "model_ans": "Winston Churchill",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Winston Churchill </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much resources were French placing in North America?",
        "answers": [
            "unwilling to risk large convoys to aid the limited forces it had in New France",
            "limited forces",
            "significantly increased",
            "France was unwilling to risk large convoys to aid the limited forces it had in New France"
        ],
        "model_ans": "100 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was France concentraing efforts?",
        "answers": [
            "against Prussia and its allies in the European theatre of the war.",
            "Prussia",
            "against Prussia and its allies",
            "European theatre",
            "Prussia"
        ],
        "model_ans": "Verdun",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Verdun </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where were British defeated in Canada?",
        "answers": [
            "Sainte Foy in Quebec",
            "Sainte Foy",
            "Sainte Foy in Quebec",
            "Sainte Foy",
            "Sainte Foy"
        ],
        "model_ans": "Quebec",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What territory was ceded to Britain?",
        "answers": [
            "territory east of the Mississippi to Great Britain",
            "France",
            "territory east of the Mississippi",
            "east of the Mississippi",
            "territory east of the Mississippi"
        ],
        "model_ans": "Hong Kong",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hong Kong </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What land was ceded to Spain?",
        "answers": [
            "French Louisiana west of the Mississippi River (including New Orleans) to its ally Spain",
            "French Louisiana",
            "French Louisiana west of the Mississippi River (including New Orleans)",
            "Louisiana west of the Mississippi River",
            "French Louisiana west of the Mississippi River (including New Orleans)"
        ],
        "model_ans": "Florida",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Florida </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the significance of British win?",
        "answers": [
            "confirming Britain's position as the dominant colonial power in eastern North America",
            "confirming Britain's position as the dominant colonial power in eastern North America",
            "confirming Britain's position as the dominant colonial power in eastern North America",
            "dominant colonial power",
            "confirming Britain's position as the dominant colonial power in eastern North America"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was King George's war?",
        "answers": [
            "1740s",
            "1740s",
            "1740s",
            "1740s",
            "1740s"
        ],
        "model_ans": "1744-1748\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1744-1748\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the confusion of the French and Indian war?",
        "answers": [
            "Indians fought on both sides of the conflict, and that this was part of the Seven Years' War",
            "Indians fought on both sides of the conflict",
            "obscures the fact that Indians fought on both sides of the conflict, and that this was part of the Seven Years' War",
            "Seven Years' War",
            "it obscures the fact that Indians fought on both sides of the conflict"
        ],
        "model_ans": "The French and Indian War was a conflict between the British and the French in North America, fought from 1754 to 1763.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The French and Indian War was a conflict between the British and the French in North America, fought from 1754 to 1763. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the Seven Years War?",
        "answers": [
            "much larger conflict between France and Great Britain",
            "conflict between France and Great Britain",
            "in King George's reign",
            "conflict between France and Great Britain",
            "a much larger conflict between France and Great Britain"
        ],
        "model_ans": "A global conflict fought between 1756 and 1763",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A global conflict fought between 1756 and 1763 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are other alternative names for French and Indian War?",
        "answers": [
            "Fourth Intercolonial War and the Great War for the Empire",
            "Fourth Intercolonial War and the Great War for the Empire",
            "Fourth Intercolonial War and the Great War for the Empire",
            "Fourth Intercolonial War and the Great War for the Empire",
            "the Fourth Intercolonial War and the Great War for the Empire"
        ],
        "model_ans": "Seven Years' War",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Seven Years' War </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What time framd does the Seven Years War cover?",
        "answers": [
            "declaration of war in 1756 to the signing of the peace treaty in 1763",
            "1756 to the signing of the peace treaty in 1763",
            "1756 to the signing of the peace treaty in 1763",
            "1756 to the signing of the peace treaty in 1763",
            "the official declaration of war in 1756 to the signing of the peace treaty in 1763"
        ],
        "model_ans": "1756-1763",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1756-1763 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How long did the fighting last in Seven Years War?",
        "answers": [
            "six years",
            "six years",
            "six years",
            "six years",
            "six years"
        ],
        "model_ans": "9 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was Montreal captured?",
        "answers": [
            "1760",
            "1760",
            "1760",
            "1760",
            "1760"
        ],
        "model_ans": "1760\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1760\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was first battle in 1754?",
        "answers": [
            "Battle of Jumonville Glen",
            "Battle of Jumonville Glen",
            "Jumonville Glen",
            "Battle of Jumonville Glen",
            "Battle of Jumonville Glen"
        ],
        "model_ans": "Battle of Fort Necessity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Battle of Fort Necessity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was French population in North America?",
        "answers": [
            "about 75,000",
            "75,000",
            "75,000",
            "75,000",
            "75,000"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where were French North Americans settled?",
        "answers": [
            "heavily concentrated along the St. Lawrence River valley, with some also in Acadia",
            "along the St. Lawrence River valley",
            "St. Lawrence River valley",
            "along the St. Lawrence River valley"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did French fur trappers travel?",
        "answers": [
            "St. Lawrence and Mississippi watersheds, did business with local tribes, and often married Indian women",
            "St. Lawrence and Mississippi watersheds",
            "throughout the St. Lawrence and Mississippi watersheds",
            "St. Lawrence and Mississippi",
            "the St. Lawrence and Mississippi watersheds"
        ],
        "model_ans": "North America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the ratio of British settler to French?",
        "answers": [
            "20 to 1",
            "20 to 1",
            "20 to 1",
            "20 to 1",
            "20 to 1"
        ],
        "model_ans": "3:1\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3:1\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did British settlers live?",
        "answers": [
            "from Nova Scotia and Newfoundland in the north, to Georgia in the south",
            "eastern coast of the continent",
            "eastern coast of the continent,",
            "eastern coast",
            "from Nova Scotia and Newfoundland in the north, to Georgia in the south"
        ],
        "model_ans": "America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where were populations centered in colonies?",
        "answers": [
            "along the coast, the settlements were growing into the interior",
            "along the coast",
            "along the coast",
            "along the coast",
            "along the coast"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In between French and British, what groups controlled land?",
        "answers": [
            "native tribes",
            "native tribes",
            "native tribes",
            "native tribes",
            "native tribes"
        ],
        "model_ans": "Spanish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What tribes were in Father Le Loutre's War?",
        "answers": [
            "Mi'kmaq and the Abenaki",
            "Mi'kmaq and the Abenaki",
            "the Mi'kmaq and the Abenaki",
            "Mi'kmaq and the Abenaki",
            "the Mi'kmaq and the Abenaki"
        ],
        "model_ans": "Mi'kmaq, Maliseet, and Beothuk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mi'kmaq, Maliseet, and Beothuk </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Iroquois Confederation control?",
        "answers": [
            "present-day Upstate New York and the Ohio Country",
            "present-day Upstate New York and the Ohio Country",
            "Upstate New York and the Ohio Country",
            "New York and the Ohio",
            "Upstate New York and the Ohio Country"
        ],
        "model_ans": "North America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What rule did some native live under?",
        "answers": [
            "Iroquois rule, and were limited by them in authority to make agreements",
            "Iroquois",
            "Iroquois",
            "Iroquois",
            "Iroquois"
        ],
        "model_ans": "The Great Law of Peace",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Great Law of Peace </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the Siouan-speaking tribes?",
        "answers": [
            "Catawba, Muskogee-speaking Creek and Choctaw",
            "Catawba",
            "Catawba",
            "Catawba",
            "Catawba"
        ],
        "model_ans": "The Siouan-speaking tribes include the Catawba, Santee, and Waxhaw tribes",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Siouan-speaking tribes include the Catawba, Santee, and Waxhaw tribes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What areas did French recruit natives from?",
        "answers": [
            "western portions of the Great Lakes region",
            "Great Lakes",
            "tribes in western portions of the Great Lakes region",
            "western portions of the Great Lakes",
            "western portions of the Great Lakes region"
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What tribes supported British?",
        "answers": [
            "Iroquois Six Nations, and also by the Cherokee",
            "Iroquois Six Nations, and also by the Cherokee",
            "Iroquois Six Nations, and also by the Cherokee",
            "Iroquois",
            "the Iroquois Six Nations"
        ],
        "model_ans": "Gurkhas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gurkhas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Frensh military presence at start of war?",
        "answers": [
            "no French regular army troops were stationed in North America",
            "no French regular army troops were stationed in North America",
            "no French regular army troops were stationed in North America,",
            "no French regular army",
            "no French regular army troops were stationed in North America"
        ],
        "model_ans": "France had a military presence in Europe, Africa, and Asia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France had a military presence in Europe, Africa, and Asia </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much British military was in North America at start of War?",
        "answers": [
            "few British troops",
            "few",
            "few",
            "not have any standing forces",
            "few British troops"
        ],
        "model_ans": "4,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was normal British defense?",
        "answers": [
            "mustered local militia companies, generally ill trained and available only for short periods, to deal with native threats, but did not have any standing forces.",
            "local militia companies",
            "local militia companies",
            "militia support",
            "local militia companies"
        ],
        "model_ans": "British Army",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British Army </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was extent of Celeron's expedition?",
        "answers": [
            "about 3,000 miles (4,800 km) between June and November 1749.",
            "about 3,000 miles",
            "3,000 miles",
            "3,000 miles",
            "3,000 miles"
        ],
        "model_ans": "Celeron's expedition was a French expedition that explored the Ohio River Valley in 1742.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Celeron's expedition was a French expedition that explored the Ohio River Valley in 1742. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was on Celeron's expedition?",
        "answers": [
            "200 Troupes de la marine and 30 Indians",
            "C\u00e9loron",
            "200 Troupes de la marine and 30 Indians",
            "200 Troupes de la marine and 30 Indians",
            "200 Troupes de la marine and 30 Indians"
        ],
        "model_ans": "Hernando Cort\u00e9s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hernando Cort\u00e9s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Celeron handle business on trip?",
        "answers": [
            "British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave.",
            "told them to leave",
            "Whenever he encountered British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave.",
            "buried lead plates",
            "Whenever he encountered British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Natives in Logstown take Celeron's information?",
        "answers": [
            "informed C\u00e9loron that they owned the Ohio Country and that they would trade with the British regardless of the French",
            "informed C\u00e9loron that they owned the Ohio Country and that they would trade with the British",
            "they owned the Ohio Country",
            "they owned the Ohio Country and that they would trade with the British regardless of the French"
        ],
        "model_ans": "They took it by force",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They took it by force </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Old Briton call home?",
        "answers": [
            "village of Pickawillany",
            "village of Pickawillany",
            "village of Pickawillany",
            "Pickawillany",
            "village of Pickawillany"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How did Celeron handle meeting with Old Briton?",
        "answers": [
            "threatened \"Old Briton\" with severe consequences if he continued to trade with the British",
            "C\u00e9loron threatened \"Old Briton\" with severe consequences",
            "threatened \"Old Briton\" with severe consequences",
            "threatened",
            "C\u00e9loron threatened \"Old Briton\""
        ],
        "model_ans": "I don't know",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I don't know </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Old Briton's response to Celeron?",
        "answers": [
            "ignored the warning.",
            "ignored the warning",
            "ignored the warning",
            "ignored the warning",
            "\"Old Briton\" ignored the warning"
        ],
        "model_ans": "Celeron",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Celeron </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Celeron feel about Native relations?",
        "answers": [
            "very badly disposed towards the French, and are entirely devoted to the English",
            "very badly disposed towards the French",
            "are very badly disposed towards the French, and are entirely devoted to the English",
            "what way they could be brought back",
            "very badly disposed towards the French"
        ],
        "model_ans": "Celeron was a French explorer who had a negative view of Native Americans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Celeron was a French explorer who had a negative view of Native Americans </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How were leaders back in Europe feeling about news from Celeron expedition?",
        "answers": [
            "proposing that action be taken",
            "each side proposing that action be taken",
            "proposing that action be taken",
            "each side proposing that action be taken"
        ],
        "model_ans": "There is no record of a Celeron expedition, so it is difficult to determine how leaders in Europe felt about it.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no record of a Celeron expedition, so it is difficult to determine how leaders in Europe felt about it. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did William Shirley feel about French advancement?",
        "answers": [
            "British colonists would not be safe as long as the French were present",
            "British colonists would not be safe",
            "British colonists would not be safe as long as the French were present",
            "British colonists would not be safe",
            "forceful"
        ],
        "model_ans": "He was opposed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He was opposed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did British government give land for development of Ohio Country?",
        "answers": [
            "1749",
            "1749",
            "1749",
            "1749",
            "1749"
        ],
        "model_ans": "1783",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1783 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was given land by British goovernment for development of Ohio Country?",
        "answers": [
            "Ohio Company of Virginia",
            "Ohio Company of Virginia",
            "Ohio Company of Virginia",
            "Ohio Company of Virginia",
            "Ohio Company"
        ],
        "model_ans": "American Indians",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> American Indians </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who explored Ohio territory in 1750?",
        "answers": [
            "Christopher Gist",
            "Christopher Gist",
            "Christopher Gist",
            "Christopher Gist",
            "Christopher Gist"
        ],
        "model_ans": "Robert de La Salle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robert de La Salle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What agreement was made for trade with natives and British?",
        "answers": [
            "Treaty of Logstown",
            "1752 Treaty of Logstown",
            "1752 Treaty of Logstown",
            "Treaty of Logstown",
            "Treaty of Logstown"
        ],
        "model_ans": "Treaty of Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "According to agreement between Iroquois and British, where was a strong house to be built?",
        "answers": [
            "mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)",
            "mouth of the Monongahela River",
            "mouth of the Monongahela River",
            "Pittsburgh, Pennsylvania",
            "the mouth of the Monongahela River"
        ],
        "model_ans": "Oswego",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oswego </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the North American portion of War of Austrian Succession?",
        "answers": [
            "King George's War",
            "King George's War",
            "King George's War",
            "King George's War"
        ],
        "model_ans": "Seven Years' War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Seven Years' War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the end of the War of the Austrian Succession?",
        "answers": [
            "1748 with the signing of the Treaty of Aix-la-Chapelle",
            "signing of the Treaty of Aix-la-Chapelle",
            "signing of the Treaty of Aix-la-Chapelle",
            "1748",
            "the Treaty of Aix-la-Chapelle"
        ],
        "model_ans": "Treaty of Paris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Treaty of Paris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What issues were not addressed in the Treaty of Aix-la-Chapelle?",
        "answers": [
            "conflicting territorial claims between British and French",
            "conflicting territorial claims between British and French colonies in North America",
            "conflicting territorial claims between British and French colonies in North America",
            "conflicting territorial claims",
            "The issues of conflicting territorial claims between British and French colonies"
        ],
        "model_ans": "The issues of the American Revolution were not addressed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The issues of the American Revolution were not addressed </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When a commission reached no decision, what happened?",
        "answers": [
            "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides",
            "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides",
            "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides.",
            "claimed by both sides",
            "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides"
        ],
        "model_ans": "The commission deadlocked",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The commission deadlocked </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What Governor in charge of New France died in 1752?",
        "answers": [
            "Marquis de la Jonqui\u00e8re",
            "Marquis de la Jonqui\u00e8re",
            "Marquis de la Jonqui\u00e8re",
            "Marquis de la Jonqui\u00e8re",
            "Marquis de la Jonqui\u00e8re"
        ],
        "model_ans": "Pierre de Rigaud de Vaudreuil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pierre de Rigaud de Vaudreuil </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many were in Langlades expedition?",
        "answers": [
            "300 men, including French-Canadians and warriors of the Ottawa",
            "300",
            "300 men",
            "300",
            "300 men"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Was was the plan for Langlades mission?",
        "answers": [
            "punish the Miami people of Pickawillany for not following C\u00e9loron's orders to cease trading with the British",
            "punish the Miami people of Pickawillany",
            "punish the Miami people of Pickawillany for not following C\u00e9loron's orders",
            "punish the Miami people",
            "to punish the Miami people of Pickawillany"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was result of French attack of trading centre?",
        "answers": [
            "capturing three traders and killing 14 people of the Miami nation, including Old Briton",
            "capturing three traders and killing 14 people of the Miami nation",
            "capturing three traders and killing 14 people of the Miami nation, including Old Briton",
            "capturing three traders and killing 14 people",
            "capturing three traders and killing 14 people of the Miami nation"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who took command of French in spring of 1753?",
        "answers": [
            "Paul Marin de la Malgue",
            "Paul Marin de la Malgue",
            "Paul Marin de la Malgue",
            "Paul Marin de la Malgue",
            "Paul Marin de la Malgue"
        ],
        "model_ans": "Louis XV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis XV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Marin build first fort?",
        "answers": [
            "Fort Presque Isle (near present-day Erie, Pennsylvania",
            "Fort Presque Isle",
            "near present-day Erie, Pennsylvania",
            "Fort Presque Isle",
            "near present-day Erie, Pennsylvania"
        ],
        "model_ans": "Venice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Venice </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was Marin's second fort constructed?",
        "answers": [
            "Fort Le Boeuf (present-day Waterford, Pennsylvania",
            "Fort Le Boeuf",
            "present-day Waterford, Pennsylvania",
            "Fort Le Boeuf",
            "present-day Waterford, Pennsylvania"
        ],
        "model_ans": "Fortaleza",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fortaleza </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Marin's orders?",
        "answers": [
            "protect the King's land in the Ohio Valley from the British",
            "protect the King's land in the Ohio Valley from the British",
            "to protect the King's land in the Ohio Valley from the British",
            "protect the King's land in the Ohio Valley",
            "he moved south, he drove off or captured British traders"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What native chief travelled to French fort and threatened Marin?",
        "answers": [
            "Tanaghrisson",
            "Tanaghrisson",
            "Tanaghrisson",
            "Tanaghrisson",
            "the Mingo"
        ],
        "model_ans": "Marin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Marin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was William Johnson's role in British military?",
        "answers": [
            "British Superintendent for Indian Affairs in the New York region and beyond",
            "British Superintendent for Indian Affairs",
            "British Superintendent for Indian Affairs in the New York region and beyond",
            "British Superintendent for Indian Affairs",
            "British Superintendent for Indian Affairs"
        ],
        "model_ans": "General",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> General </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was William Johnson's Iroquois name?",
        "answers": [
            "Warraghiggey, meaning \"He who does great things.\"",
            "Warraghiggey",
            "Warraghiggey",
            "Warraghiggey",
            "Warraghiggey"
        ],
        "model_ans": "Ganaado",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ganaado </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What title did Iroquois give Johnson?",
        "answers": [
            "colonel of the Iroquois",
            "He who does great things",
            "He who does great things.",
            "honorary member of the Iroquois Confederacy",
            "Warraghiggey"
        ],
        "model_ans": "Orenda",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Orenda </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was the speaker of the tribal council?",
        "answers": [
            "Mohawk Chief Hendrick",
            "Mohawk Chief Hendrick",
            "Mohawk Chief Hendrick",
            "Chief Hendrick",
            "Chief Hendrick"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Governon Robert Dinwiddie had an investment in what significan company?",
        "answers": [
            "Ohio Company",
            "Ohio Company",
            "Ohio Company,",
            "Ohio Company",
            "the Ohio Company"
        ],
        "model_ans": "Virginia Company",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virginia Company </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who did Dinwiddie order to address French in Virginia territory?",
        "answers": [
            "Major George Washington",
            "George Washington",
            "Major George Washington",
            "George Washington",
            "Major George Washington"
        ],
        "model_ans": "French",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was added to party as Washington went on the way?",
        "answers": [
            "Jacob Van Braam as an interpreter; Christopher Gist, a company surveyor working in the area; and a few Mingo led by Tanaghrisson",
            "Jacob Van Braam",
            "Jacob Van Braam",
            "Jacob Van Braam"
        ],
        "model_ans": "Jefferson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jefferson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did Washington reach Fort Le Boeuf?",
        "answers": [
            "December 12",
            "December 12",
            "December 12",
            "December 12",
            "December 12"
        ],
        "model_ans": "1753\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1753\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who invited Washington to dine with him?",
        "answers": [
            "Jacques Legardeur de Saint-Pierre",
            "Jacques Legardeur de Saint-Pierre",
            "Jacques Legardeur de Saint-Pierre",
            "Jacques Legardeur de Saint-Pierre",
            "Jacques Legardeur de Saint-Pierre"
        ],
        "model_ans": "Lafayette",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lafayette </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What letter did Washington present to  Saint-Pierre ?",
        "answers": [
            "Dinwiddie demanding an immediate French withdrawal from the Ohio Country",
            "Dinwiddie",
            "from Dinwiddie demanding an immediate French withdrawal from the Ohio Country",
            "immediate French withdrawal",
            "the letter from Dinwiddie"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Saint-Pierre respond to Washington?",
        "answers": [
            "As to the Summons you send me to retire, I do not think myself obliged to obey it.",
            "said, \"As to the Summons you send me to retire, I do not think myself obliged to obey it.\"",
            "\"As to the Summons you send me to retire, I do not think myself obliged to obey it.\"",
            "I do not think myself obliged to obey",
            "\"As to the Summons you send me to retire, I do not think myself obliged to obey it.\""
        ],
        "model_ans": "Saint-Pierre did not respond to Washington",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saint-Pierre did not respond to Washington </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did French feel they had right to Ohio claim?",
        "answers": [
            "France's claim to the region was superior to that of the British",
            "Sieur de La Salle had explored the Ohio Country nearly a century earlier",
            "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier.",
            "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country",
            "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier"
        ],
        "model_ans": "The French claimed the Ohio River Valley as part of their territory, and they believed they had the right to govern it due to their historical presence in the region.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The French claimed the Ohio River Valley as part of their territory, and they believed they had the right to govern it due to their historical presence in the region. </answer>\n<confidence</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many men did Duquesne send to relieve  Saint-Pierre ?",
        "answers": [
            "Contrec\u0153ur led 500 men south from Fort Venango on April 5, 1754",
            "40",
            "40",
            "additional French forces",
            "40 men"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did British begin to build fort under William Trent?",
        "answers": [
            "early months of 1754",
            "1754",
            "1754",
            "1754",
            "1754"
        ],
        "model_ans": "1673",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1673 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the fort that was being built to be named?",
        "answers": [
            "Fort Duquesne.",
            "Fort Duquesne",
            "Fort Duquesne",
            "Fort Duquesne",
            "Fort Duquesne"
        ],
        "model_ans": "Fort Sumter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fort Sumter </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Upon learning of a French scounting party in the area, what did Washington do?",
        "answers": [
            "with Tanaghrisson and his party, surprised the Canadians on May 28 in what became known as the Battle of Jumonville Glen",
            "killed many of the Canadians",
            "surprised the Canadians on May 28",
            "Battle of Jumonville Glen",
            "surprised the Canadians on May 28"
        ],
        "model_ans": "He ordered his troops to prepare for battle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He ordered his troops to prepare for battle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were casualties of battle?",
        "answers": [
            "killed many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville",
            "many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville",
            "Canadians, including their commanding officer",
            "many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why was Tanaghrisson supporting British efforts?",
        "answers": [
            "regain authority over his own people. They had been inclined to support the French, with whom they had long trading relationships",
            "gain the support of the British and regain authority over his own people",
            "had promised",
            "regain authority over his own people",
            "to gain the support of the British and regain authority over his own people"
        ],
        "model_ans": "He was a loyal ally",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He was a loyal ally </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the goal of Braddock's expedition?",
        "answers": [
            "dislodge the French",
            "dislodge the French",
            "dislodge the French",
            "dislodge the French"
        ],
        "model_ans": "To capture Fort Duquesne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To capture Fort Duquesne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When did French learn about Braddock's plans?",
        "answers": [
            "plans leaked to France well before Braddock's departure",
            "before Braddock's departure",
            "well before Braddock's departure for North America",
            "before Braddock's departure",
            "well before Braddock's departure for North America"
        ],
        "model_ans": "1755",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1755 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did King Louis XV respond to British plans?",
        "answers": [
            "dispatched six regiments to New France under the command of Baron Dieskau in 1755.",
            "dispatched six regiments to New France",
            "dispatched six regiments to New France under the command of Baron Dieskau in 1755",
            "six regiments to New France",
            "dispatched six regiments to New France"
        ],
        "model_ans": "He declared war",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He declared war </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What were British plans against French?",
        "answers": [
            "blockade French ports, sent out their fleet in February 1755",
            "blockade French ports",
            "blockade French ports",
            "blockade French ports",
            "blockade French ports"
        ],
        "model_ans": "Operation Overlord",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Operation Overlord </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What political response was convening in June/July 1754?",
        "answers": [
            "Albany Congress",
            "Albany Congress",
            "the opening of hostilities",
            "Albany Congress",
            "Albany Congress"
        ],
        "model_ans": "Albany Congress",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Albany Congress </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the goal of congress?",
        "answers": [
            "formalize a unified front in trade and negotiations with various Indians, since allegiance of the various tribes and nations was seen to be pivotal",
            "formalize a unified front in trade and negotiations with various Indians",
            "formalize a unified front in trade and negotiations with various Indians",
            "unified front in trade and negotiations with various Indians",
            "to formalize a unified front in trade and negotiations with various Indians"
        ],
        "model_ans": "To establish a federal government",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To establish a federal government </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Was the plan formalized?",
        "answers": [
            "The plan that the delegates agreed to was never ratified by the colonial legislatures nor approved of by the crown",
            "was never ratified",
            "never ratified",
            "never ratified",
            "The plan that the delegates agreed to was never ratified"
        ],
        "model_ans": "No",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the importance of the congress?",
        "answers": [
            "format of the congress and many specifics of the plan became the prototype for confederation during the War of Independence",
            "became the prototype for confederation during the War of Independence",
            "became the prototype for confederation during the War of Independence",
            "prototype for confederation",
            "became the prototype for confederation during the War of Independence"
        ],
        "model_ans": "The Congress was a significant event in the history of the United States, marking the drafting and ratification of the United States Constitution.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Congress was a significant event in the history of the United States, marking the drafting and ratification of the United States Constitution. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who went to Fort Dusquesne in June 1755?",
        "answers": [
            "Braddock (with George Washington as one of his aides) led about 1,500 army troops",
            "Braddock",
            "Braddock (with George Washington",
            "Braddock",
            "Braddock"
        ],
        "model_ans": "George Washington",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Washington </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How much success did this expedition with Braddock find?",
        "answers": [
            "The expedition was a disaster",
            "disaster",
            "was a disaster",
            "disaster",
            "The expedition was a disaster"
        ],
        "model_ans": "failed",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> failed </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many casualties did British get?",
        "answers": [
            "Approximately 1,000 British soldiers were killed or injured.",
            "Approximately 1,000",
            "1,000 British soldiers",
            "1,000",
            "1,000 British soldiers"
        ],
        "model_ans": "72",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 72 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What future Revolutionary key figures participated in this attack?",
        "answers": [
            "Washington and Thomas Gage",
            "George Washington",
            "Washington and Thomas Gage",
            "Washington and Thomas Gage",
            "George Washington"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whose activities were the French able to gain knowledge of?",
        "answers": [
            "Shirley and Johnson.",
            "British",
            "British war plans",
            "British war plans",
            "Shirley and Johnson"
        ],
        "model_ans": "German",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> German </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What difficulties was Shirly having?",
        "answers": [
            "efforts to fortify Oswego were bogged down in logistical difficulties, exacerbated by Shirley's inexperience",
            "logistical",
            "logistical difficulties",
            "logistical",
            "logistical"
        ],
        "model_ans": "Shirley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shirley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was Shirey going to be when Fort Oswego was to be attacked?",
        "answers": [
            "planned to attack Fort Niagara",
            "Fort Niagara",
            "Fort Niagara",
            "Fort Niagara"
        ],
        "model_ans": "Fort Niagara",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Fort Niagara </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Shirley leave at Oswego?",
        "answers": [
            "garrisons",
            "garrisons",
            "garrisons",
            "garrisons"
        ],
        "model_ans": "Shirley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shirley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who was New France's governor?",
        "answers": [
            "Marquis de Vaudreuil.",
            "Marquis de Vaudreuil",
            "the Marquis de Vaudreuil",
            "Marquis de Vaudreuil",
            "Marquis de Vaudreuil"
        ],
        "model_ans": "Louis de Buade",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louis de Buade </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How did Vaudreuil react when Johnson was seen as larger threat?",
        "answers": [
            "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric to meet that threat",
            "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric",
            "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric",
            "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric",
            "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric"
        ],
        "model_ans": "I couldn't find any reliable sources that provide information on this specific event",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I couldn't find any reliable sources that provide information on this specific event </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who won the battle of Lake George?",
        "answers": [
            "inconclusively, with both sides withdrawing from the field",
            "The battle ended inconclusively",
            "ended inconclusively",
            "both sides withdrawing from the field",
            "The battle ended inconclusively"
        ],
        "model_ans": "The British",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The British </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Johnson stop?",
        "answers": [
            "Fort William Henry",
            "Fort William Henry",
            "Fort William Henry",
            "Fort William Henry",
            "Fort William Henry"
        ],
        "model_ans": "Johnson stopped at the stop sign",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Johnson stopped at the stop sign </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was French withdrawal to?",
        "answers": [
            "Ticonderoga Point,",
            "Ticonderoga Point",
            "Ticonderoga Point",
            "Ticonderoga Point",
            "Ticonderoga Point"
        ],
        "model_ans": "Dien Bien Phu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dien Bien Phu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who captured Fort Beausejour?",
        "answers": [
            "Colonel Monckton",
            "Colonel Monckton",
            "Colonel Monckton",
            "Colonel Monckton",
            "British"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How were British able to cut supplies to Louisbourg?",
        "answers": [
            "deportation of the French-speaking Acadian population from the area.",
            "deportation of the French-speaking Acadian population from the area",
            "captured Fort Beaus\u00e9jour",
            "captured Fort Beaus\u00e9jour",
            "the deportation of the French-speaking Acadian population"
        ],
        "model_ans": "By sea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> By sea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What other clashes were involved in taking Louisbourg?",
        "answers": [
            "Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757",
            "Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757",
            "deportation of the French-speaking Acadian population from the area",
            "Petitcodiac in 1755 and at Bloody Creek",
            "Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "After Braddock died, who controlled North American British forces?",
        "answers": [
            "William Shirley",
            "William Shirley",
            "William Shirley",
            "William Shirley",
            "William Shirley"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what meeting did Shirley lay out plans for 1756?",
        "answers": [
            "Albany",
            "meeting in Albany in December 1755",
            "Albany",
            "Albany in December 1755",
            "a meeting in Albany"
        ],
        "model_ans": "I couldn't find the information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I couldn't find the information </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What proposed attacks did Shirley plan?",
        "answers": [
            "capture Niagara, Crown Point and Duquesne, he proposed attacks on Fort Frontenac on the north shore of Lake Ontario",
            "Fort Frontenac",
            "Fort Frontenac",
            "Fort Frontenac",
            "Fort Frontenac"
        ],
        "model_ans": "Shirley planned to attack the United States",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shirley planned to attack the United States </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was Shirley planning an expedition?",
        "answers": [
            "through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec",
            "wilderness of the Maine district and down the Chaudi\u00e8re River",
            "the wilderness of the Maine district",
            "Maine",
            "the wilderness of the Maine district and down the Chaudi\u00e8re River"
        ],
        "model_ans": "Africa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who was appointed as second in command to Lor Loudoun in 1756?",
        "answers": [
            "Major General James Abercrombie",
            "Lord Loudoun",
            "Major General James Abercrombie",
            "Major General James Abercrombie",
            "Major General James Abercrombie"
        ],
        "model_ans": "John Campbell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Campbell </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who led New France reinforcements in 1756?",
        "answers": [
            "Major General Louis-Joseph de Montcalm",
            "Major General Louis-Joseph de Montcalm",
            "Lord Loudoun",
            "Major General Louis-Joseph de Montcalm",
            "Major General Louis-Joseph de Montcalm"
        ],
        "model_ans": "Louis-Joseph de Montcalm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis-Joseph de Montcalm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did England formally declare war on France?",
        "answers": [
            "May 18, 1756",
            "May 18, 1756",
            "May 18, 1756",
            "May 18, 1756",
            "May 18, 1756"
        ],
        "model_ans": "1337",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1337 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was there a weakness in British supply chain?",
        "answers": [
            "Oneida Carry",
            "Oneida Carry",
            "forts Shirley had erected at the Oneida Carry",
            "Oneida Carry",
            "Oneida Carry"
        ],
        "model_ans": "Dunkirk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dunkirk </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the attack on the British weakness?",
        "answers": [
            "Battle of Fort Bull",
            "Battle of Fort Bull",
            "Battle of Fort Bull",
            "Battle of Fort Bull",
            "March Battle of Fort Bull"
        ],
        "model_ans": "Pearl Harbor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pearl Harbor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How much gun powder was destroyed in attack?",
        "answers": [
            "45,000 pounds",
            "45,000 pounds",
            "45,000 pounds",
            "45,000 pounds",
            "45,000 pounds"
        ],
        "model_ans": "1,000 pounds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 pounds </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What plans of the British did this attach on Oneida Carry set back?",
        "answers": [
            "hopes for campaigns on Lake Ontario, and endangered the Oswego garrison",
            "campaigns on Lake Ontario, and endangered the Oswego garrison",
            "campaigns on Lake Ontario",
            "campaigns on Lake Ontario",
            "hopes for campaigns on Lake Ontario"
        ],
        "model_ans": "The British plans were to attack the Oneida Carry set back",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The British plans were to attack the Oneida Carry set back </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who refused to act until Loudoun approved plans?",
        "answers": [
            "Abercrombie",
            "Abercrombie",
            "Abercrombie",
            "Abercrombie",
            "Abercrombie"
        ],
        "model_ans": "Fairfax",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fairfax </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Montcalm move his heaquarter to show strategic advancement?",
        "answers": [
            "Ticonderoga",
            "Ticonderoga",
            "Ticonderoga",
            "Ticonderoga",
            "Ticonderoga"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did Moncalm slip away to attack, left largely unprotected?",
        "answers": [
            "Oswego",
            "Oswego",
            "Oswego",
            "Oswego",
            "Oswego"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What disagreement did Montcalm and Indians have?",
        "answers": [
            "disposition of prisoners' personal effects",
            "the disposition of prisoners' personal effects",
            "about the disposition of prisoners' personal effects",
            "disposition of prisoners' personal effects",
            "the disposition of prisoners' personal effects"
        ],
        "model_ans": "The French and Indian War",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The French and Indian War </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was Loudoun's plans for 1757?",
        "answers": [
            "attack on New France's capital, Quebec",
            "an attack on New France's capital, Quebec",
            "an attack on New France's capital, Quebec",
            "one major operation",
            "an attack on New France's capital, Quebec"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was the purpose of Loudoun's troops at Fort Henry?",
        "answers": [
            "to distract Montcalm",
            "distract Montcalm",
            "distract Montcalm",
            "distract Montcalm",
            "to distract Montcalm"
        ],
        "model_ans": "To capture the fort",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To capture the fort </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who ordered Loudoun to attack Louisbourg?",
        "answers": [
            "William Pitt",
            "William Pitt",
            "William Pitt",
            "William Pitt",
            "William Pitt"
        ],
        "model_ans": "Louisbourg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louisbourg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Given the strength of French forces at Louisbourg, what did Loudoun do?",
        "answers": [
            "returned to New York amid news that a massacre had occurred at Fort William Henry.",
            "returned to New York",
            "returned to New York",
            "returned to New York",
            "returned to New York"
        ],
        "model_ans": "He besieged the fortress",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He besieged the fortress </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What troops attacked Fort William Henry in early 1757?",
        "answers": [
            "French irregular forces (Canadian scouts and Indians)",
            "French irregular forces",
            "French irregular forces",
            "French irregular forces",
            "French irregular forces"
        ],
        "model_ans": "French",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "On what lake did troops attack fort willima henry in winter?",
        "answers": [
            "Lake George",
            "Lake George",
            "Lake George",
            "Lake George",
            "Lake George"
        ],
        "model_ans": "Lake Erie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Erie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "During withdrawal from Fort William Henry, what did some Indian allies of French do?",
        "answers": [
            "attacked the British column, killing and capturing several hundred men, women, children, and slaves.",
            "attacked the British column",
            "attacked the British column",
            "attacked the British",
            "attacked the British column"
        ],
        "model_ans": "They killed and scalped many of the retreating British soldiers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> They killed and scalped many of the retreating British soldiers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What was causing New France to have issues with resupplying?",
        "answers": [
            "British blockade of the French coastline limited French shipping.",
            "British blockade of the French coastline",
            "British blockade of the French coastline",
            "British blockade of the French coastline",
            "British blockade"
        ],
        "model_ans": "The British blockade",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The British blockade </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What other reason caused poor supply of New France from a difficult winter?",
        "answers": [
            "poor harvest",
            "allegedly corrupt machinations of Fran\u00e7ois Bigot",
            "poor harvest in 1757",
            "poor harvest in 1757",
            "a poor harvest"
        ],
        "model_ans": "The Great Fire of London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Great Fire of London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where was Montcalm focusing the defense for New France?",
        "answers": [
            "St. Lawrence, with primary defenses at Carillon, Quebec, and Louisbourg,",
            "St. Lawrence",
            "St. Lawrence",
            "St. Lawrence",
            "the defense of the St. Lawrence"
        ],
        "model_ans": "Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What led to Newcastle's fall from power as military advisor?",
        "answers": [
            "British failures in North America, combined with other failures in the European theater",
            "British failures in North America, combined with other failures in the European theater",
            "British failures in North America, combined with other failures in the Europe",
            "failures in North America",
            "British failures in North America"
        ],
        "model_ans": "The rise of the Roman Empire",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The rise of the Roman Empire </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who did Abercrombie replace as commander in chief?",
        "answers": [
            "Loudoun",
            "Duke of Cumberland",
            "Loudoun",
            "Pitt",
            "Newcastle"
        ],
        "model_ans": "George Washington",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> George Washington </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Pitt's plan called for what attacks?",
        "answers": [
            "three major offensive actions involving large numbers of regular troops",
            "three major offensive actions",
            "three major offensive actions",
            "three major offensive actions",
            "three major offensive actions"
        ],
        "model_ans": "Pearl Harbor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pearl Harbor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many of the Pitt's planned expeditions were successful?",
        "answers": [
            "Two of the expeditions were successful, with Fort Duquesne and Louisbourg",
            "Two",
            "Two",
            "Two",
            "Two"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many Frenchman won Battle of Carillon?",
        "answers": [
            "3,600",
            "3,60",
            "3,600",
            "3,600",
            "3,600"
        ],
        "model_ans": "1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many troops were defeated for British in BAttle of Carillon?",
        "answers": [
            "18,000 regulars, militia and Native American allies",
            "18,000",
            "18,000",
            "18,000",
            "18,000"
        ],
        "model_ans": "1,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What success did Abercrombie gain out of the defeat at Carillon?",
        "answers": [
            "sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac",
            "successfully destroyed Fort Frontenac",
            "destroyed Fort Frontenac",
            "destroyed Fort Frontenac",
            "destroyed Fort Frontenac"
        ],
        "model_ans": "None",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What impact did this loss have on Abercrombie?",
        "answers": [
            "recalled and replaced by Jeffery Amherst, victor at Louisbourg.",
            "Abercrombie was recalled and replaced",
            "was recalled and replaced by Jeffery Amherst",
            "recalled and replaced",
            "Abercrombie was recalled and replaced by Jeffery Amherst,"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In 1758 what was duc de Choiseul's plan for focused military efforts?",
        "answers": [
            "invasion of Britain, to draw British resources away from North America and the European mainland",
            "invasion of Britain",
            "an invasion of Britain",
            "invasion of Britain",
            "an invasion of Britain"
        ],
        "model_ans": "He planned to focus on the Austrian army",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He planned to focus on the Austrian army </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How successful was the French revised efforts?",
        "answers": [
            "The invasion failed both militarily and politically, as Pitt again planned significant campaigns against New France",
            "failed",
            "invasion failed",
            "failed",
            "The invasion failed both militarily and politically"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What naval battles did France lose in 1759?",
        "answers": [
            "Lagos and Quiberon Bay.",
            "battles at Lagos and Quiberon Bay",
            "Lagos and Quiberon Bay",
            "Lagos and Quiberon Bay",
            "Lagos and Quiberon Bay"
        ],
        "model_ans": "Battle of Quebec, Battle of Lagos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Battle of Quebec, Battle of Lagos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who defeated Montcalm at Quebec?",
        "answers": [
            "James Wolfe",
            "James Wolfe",
            "James Wolfe",
            "James Wolfe",
            "James Wolfe"
        ],
        "model_ans": "British",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the significance of victory at Forth Niagara for British?",
        "answers": [
            "cut off the French frontier forts further to the west and south",
            "successfully cut off the French frontier forts further to the west and south",
            "cut off the French frontier forts",
            "cut off the French frontier forts",
            "successfully cut off the French frontier forts"
        ],
        "model_ans": "It was a decisive victory in the War of 1812",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> It was a decisive victory in the War of 1812 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What battle outside Quebec City did British lose in 1760?",
        "answers": [
            "Battle of Sainte-Foy",
            "Battle of Sainte-Foy",
            "Sainte-Foy",
            "Battle of Sainte-Foy",
            "Battle of Sainte-Foy"
        ],
        "model_ans": "Battle of Quebec",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Battle of Quebec </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What victory at thwarted efforts of French relief ships.",
        "answers": [
            "naval Battle of the Restigouche",
            "Battle of the Restigouche",
            "Battle of the Restigouche",
            "Battle of the Restigouche",
            "Battle of the Restigouche"
        ],
        "model_ans": "Battle of the Nile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Battle of the Nile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In Sept 1760 who negotiated a capitulation from Montreal?",
        "answers": [
            "Governor Vaudreuil",
            "Governor Vaudreuil",
            "Governor Vaudreuil",
            "Governor Vaudreuil",
            "Governor Vaudreuil"
        ],
        "model_ans": "General Amherst",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Amherst </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What were requests made to British?",
        "answers": [
            "freedom to continue worshiping in their Roman Catholic tradition, continued ownership of their property,",
            "French residents who chose to remain in the colony would be given freedom",
            "continue worshiping in their Roman Catholic tradition, continued ownership of their property, and the right to remain undisturbed",
            "French residents who chose to remain in the colony would be given freedom"
        ],
        "model_ans": "requests made to British",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> requests made to British </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What British General negotiated at Montreal?",
        "answers": [
            "General Amherst.",
            "General Amherst",
            "General Amherst",
            "Amherst",
            "Amherst"
        ],
        "model_ans": "General Brock",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Brock </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the North American French and Indian War end?",
        "answers": [
            "signing of the Treaty of Paris on 10 February 1763",
            "10 February 1763",
            "10 February 1763",
            "10 February 1763",
            "10 February 1763"
        ],
        "model_ans": "1763\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1763\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the European portion of the Seven Years War complete?",
        "answers": [
            "Treaty of Hubertusburg on 15 February 1763",
            "15 February 1763",
            "15 February 1763",
            "15 February 1763",
            "15 February 1763"
        ],
        "model_ans": "1763\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1763\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What choice did French have for surrendering land?",
        "answers": [
            "continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique",
            "surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique",
            "either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique,",
            "its continental North American possessions east of the Mississippi or the Caribbean islands",
            "surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique"
        ],
        "model_ans": "Alsace-Lorraine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alsace-Lorraine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Why did France choose to give up continental lands?",
        "answers": [
            "value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent",
            "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent",
            "They viewed the economic value of the Caribbean islands' sugar cane to be greater",
            "value of the Caribbean islands' sugar",
            "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent"
        ],
        "model_ans": "France gave up its continental lands in the Treaty of Versailles in 1783, which ended the American Revolutionary War.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> France gave up its continental lands in the Treaty of Versailles in 1783, which ended the American Revolutionary War. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many French colonists were gained by British?",
        "answers": [
            "80,000",
            "80,000",
            "80,000",
            "80,000",
            "80,000"
        ],
        "model_ans": "7,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7,000 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When was the deportation of Acadians?",
        "answers": [
            "1755",
            "1755",
            "1755",
            "1755",
            "1755"
        ],
        "model_ans": "1755\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1755\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did British resettle many Acadians?",
        "answers": [
            "throughout its North American provinces",
            "throughout its North American provinces",
            "North American provinces",
            "North American provinces",
            "its North American provinces"
        ],
        "model_ans": "Nova Scotia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nova Scotia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Although some Acadians went to France and other destiantions, what North American city did many move to?",
        "answers": [
            "New Orleans",
            "New Orleans",
            "New Orleans",
            "New Orleans",
            "New Orleans"
        ],
        "model_ans": "Louisiana",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louisiana </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who issued the Royal Proclamation of 1763?",
        "answers": [
            "King George III",
            "King George III",
            "King George III",
            "King George III",
            "King George III"
        ],
        "model_ans": "King George III",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> King George III </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the objective of Royal Proclamation of 1763?",
        "answers": [
            "outlined the division and administration of the newly conquered territory",
            "outlined the division and administration of the newly conquered territory",
            "division and administration of the newly conquered territory",
            "division and administration",
            "the division and administration of the newly conquered territory"
        ],
        "model_ans": "To establish boundaries between British colonies and Native American territories",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> To establish boundaries between British colonies and Native American territories </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What lands were reserved for natives?",
        "answers": [
            "west of the Appalachian Mountains",
            "lands west of the Appalachian Mountains",
            "west of the Appalachian Mountains",
            "west of the Appalachian Mountains",
            "west of the Appalachian Mountains"
        ],
        "model_ans": "Native American reservations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Native American reservations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did the loss mean to France?",
        "answers": [
            "disappearance of a strong ally and counterweight to British expansion, leading to their ultimate dispossession",
            "disappearance of a strong ally and counterweight to British expansion",
            "elimination of French power",
            "."
        ],
        "model_ans": "The loss of Alsace-Lorraine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The loss of Alsace-Lorraine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What made Ohio Country vulnerable?",
        "answers": [
            "military roads to the area by Braddock and Forbes",
            "construction of military roads to the area by Braddock and Forbes",
            "the construction of military roads to the area",
            "military roads to the area",
            "the construction of military roads"
        ],
        "model_ans": "French and Indian War",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French and Indian War </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was Spanish takeover of Louisiana Territory complete?",
        "answers": [
            "1769",
            "1769",
            "1769",
            "1769",
            "1769"
        ],
        "model_ans": "1762\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1762\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What natives were displaced by British takeover in Florida?",
        "answers": [
            "Choctaw and the Creek",
            "tribes that did not want to do business with the British",
            "Choctaw and the Creek",
            "Choctaw and the Creek"
        ],
        "model_ans": "Timucua",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Timucua </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where did many Spanish Catholic move after British takeover in Florida?",
        "answers": [
            "Most went to Cuba,",
            "Most went to Cuba",
            "Cuba",
            "Cuba",
            "Cuba"
        ],
        "model_ans": "Cuba",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cuba </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What concept did philosophers in antiquity use to study simple machines?",
        "answers": [
            "force",
            "force",
            "the concept of force",
            "the concept of force",
            "force",
            "force"
        ],
        "model_ans": "Mechanism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mechanism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was the belief that maintaining motion required force?",
        "answers": [
            "fundamental error",
            "A fundamental error",
            "A fundamental error",
            "A fundamental error",
            "A fundamental error",
            "A fundamental error"
        ],
        "model_ans": "Aristotelian concept of inertia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Aristotelian concept of inertia </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who had mathmatical insite?",
        "answers": [
            "Sir Isaac Newton",
            "Sir Isaac Newton",
            "Sir Isaac Newton",
            "Sir Isaac Newton",
            "Sir Isaac Newton",
            "Sir Isaac Newton"
        ],
        "model_ans": "Isaac Newton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isaac Newton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How long did it take to improve on Sir Isaac Newton's laws of motion?",
        "answers": [
            "nearly three hundred years",
            "nearly three hundred years",
            "nearly three hundred years",
            "nearly three hundred years",
            "nearly three hundred years",
            "three hundred years"
        ],
        "model_ans": "200 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 200 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who develped the theory of relativity?",
        "answers": [
            "Einstein",
            "Einstein",
            "Einstein",
            "Einstein",
            "Einstein",
            "Einstein"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What has partical physics made to describe sub-atomic forces?",
        "answers": [
            "Standard Model",
            "Standard Model",
            "Standard Model",
            "Standard Model",
            "a Standard Model",
            "a Standard Model"
        ],
        "model_ans": "Quantum Field Theory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantum Field Theory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the exchanged particles predicted by the standard Model?",
        "answers": [
            "gauge bosons",
            "gauge bosons",
            "gauge bosons",
            "gauge bosons",
            "gauge bosons",
            "gauge bosons"
        ],
        "model_ans": "photons, gluons, W and Z bosons, and Higgs bosons",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> photons, gluons, W and Z bosons, and Higgs bosons </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the strongest main interaction?",
        "answers": [
            "strong",
            "strong",
            "strong,",
            "strong",
            "strong",
            "strong, electromagnetic"
        ],
        "model_ans": "Strong nuclear force",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Strong nuclear force </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the weakest main interaction?",
        "answers": [
            "gravitational",
            "gravitational",
            "gravitational",
            "gravitational",
            "gravitational",
            "gravitational"
        ],
        "model_ans": "Weak nuclear force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Weak nuclear force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are weak and electromatic forces expressions of?",
        "answers": [
            "electroweak interaction",
            "a more fundamental electroweak interaction",
            "more fundamental electroweak interaction.",
            "a more fundamental electroweak interaction",
            "fundamental electroweak interaction."
        ],
        "model_ans": "Weak and electromatic forces are expressions of the fundamental forces of nature, specifically the weak nuclear force and electromagnetism.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Weak and electromatic forces are expressions of the fundamental forces of nature, specifically the weak nuclear force and electromagnetism. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who provided a philosophical discussion of force?",
        "answers": [
            "Aristotle",
            "Aristotle",
            "Aristotle",
            "Aristotle",
            "Aristotle",
            "Aristotle"
        ],
        "model_ans": "Aristotle",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aristotle </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the concept of force an integral part of?",
        "answers": [
            "Aristotelian cosmology",
            "Aristotelian cosmology",
            "Aristotelian cosmology",
            "Aristotelian cosmology",
            "cosmology",
            "Aristotelian cosmology"
        ],
        "model_ans": "Physics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many elements did Aristotle believe the terrestrial sphere to be made up of?",
        "answers": [
            "four",
            "four",
            "four",
            "four",
            "four",
            "four"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where did Aristotle believe the natural place for earth and water elements?",
        "answers": [
            "on the ground",
            "ground",
            "heavy bodies to fall",
            "on the ground",
            "on the ground",
            "on the ground"
        ],
        "model_ans": "The center of the universe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The center of the universe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What did Aristotle refer to forced motion as?",
        "answers": [
            "unnatural",
            "unnatural",
            "natural motion",
            "unnatural",
            "continued application of a force",
            "unnatural"
        ],
        "model_ans": "natural motion",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> natural motion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "When were the shortcomings of Aristotle's physics overcome?",
        "answers": [
            "17th century",
            "17th century",
            "17th century",
            "the 17th century",
            "17th century",
            "17th century"
        ],
        "model_ans": "17th century",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 17th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Whose work  corrected Aristotle's physics in the seventeenth century?",
        "answers": [
            "Galileo Galilei",
            "Galileo Galilei",
            "Galileo Galilei",
            "Galileo Galilei,",
            "Galileo Galilei",
            "Galileo Galilei"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What did objects in forced motion contain according to the late Medieval idea that influence Aristotle?",
        "answers": [
            "impetus",
            "innate force of impetus",
            "gravity",
            "an innate force of impetus",
            "innate force of impetus",
            "innate force of impetus"
        ],
        "model_ans": "a potential for motion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a potential for motion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who experimented by rolling stones and canonballs down a steep incline?",
        "answers": [
            "Galileo",
            "Galileo",
            "Galileo Galilei",
            "Galileo",
            "Galileo",
            "Galileo"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What force acted on bodies to retard their velocity?",
        "answers": [
            "friction",
            "friction",
            "gravity",
            "friction",
            "friction",
            "force"
        ],
        "model_ans": "Friction",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Friction </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Whose First Law of Motion says that unless acted upon be forces, objects would continue to move at a constant velocity?",
        "answers": [
            "Newton",
            "Newton's",
            "Newton's",
            "Newton's",
            "Newton's"
        ],
        "model_ans": "Newton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What insight of Galileo was associated with constant velocity?",
        "answers": [
            "lack of net force",
            "lack of net force",
            "constant velocity was associated with a lack of net force",
            "constant velocity was associated with a lack of net force",
            "lack of net force"
        ],
        "model_ans": "Inertia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Inertia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who proposed that innate intertial is the natural state of objects?",
        "answers": [
            "Newton",
            "Newton",
            "Newton",
            "Newton",
            "Newton"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What law connects relative velocities with inertia?",
        "answers": [
            "Newton's First",
            "first law",
            "Newton's First Law",
            "First Law",
            "Newton's First Law"
        ],
        "model_ans": "Newton's second law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's second law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the laws of physics of Galileo, in reference to objest in motion and rest?",
        "answers": [
            "the same",
            "a Galilean transformation",
            "Galilean transformation",
            "the laws of physics are the same in every inertial frame of reference",
            "the same in every inertial frame of reference"
        ],
        "model_ans": "Galileo's laws of motion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo's laws of motion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What doesn't change from being at rest to movement at a constant velocity?",
        "answers": [
            "laws of physics",
            "the laws of physics",
            "the laws of physics",
            "the laws of physics",
            "the laws of physics"
        ],
        "model_ans": "its speed",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> its speed </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What path does a ball thrown up and down in a moving vehicle take when seen by an outside observer? ",
        "answers": [
            "parabolic",
            "parabolic path",
            "a curving parabolic path",
            "curving parabolic path",
            "curving parabolic path"
        ],
        "model_ans": "a parabola",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a parabola </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What sate are things inside of a moving vehicle as seen by a  person inside the vehicle?",
        "answers": [
            "at rest",
            "at rest",
            "rest",
            "the vehicle and everything inside of it is at rest:"
        ],
        "model_ans": "stationary",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> stationary </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What applies to equally to constant velocity motion as it does to rest.",
        "answers": [
            "Inertia",
            "Inertia",
            "Inertia",
            "Inertia",
            "Inertia"
        ],
        "model_ans": "inertia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inertia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What concept explains why objects continue in constant motion?",
        "answers": [
            "inertia",
            "inertia",
            "inertia",
            "inertia",
            "inertia"
        ],
        "model_ans": "inertia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inertia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What makes day length constant on Earth?",
        "answers": [
            "rotational inertia of planet",
            "rotational inertia of planet Earth",
            "rotational inertia",
            "rotational inertia",
            "The rotational inertia of planet Earth"
        ],
        "model_ans": "Earth's tilt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Earth's tilt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who explained that inertial reference frames equaled reference frames subject to constant acceleration?",
        "answers": [
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What do astronaughts experience while in free-fall?",
        "answers": [
            "weightlessness",
            "weightlessness",
            "weightlessness",
            "weightlessness",
            "weightlessness"
        ],
        "model_ans": "Weightlessness",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Weightlessness </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What was the basis mentioned for the develpment of the general theory of relativity?",
        "answers": [
            "principle of equivalence",
            "principle of equivalence",
            "principle of equivalence",
            "principle of equivalence",
            "principle of equivalence"
        ],
        "model_ans": "Gravitational redshift",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gravitational redshift </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What describes the proportionality of acceleration to force and mass?",
        "answers": [
            "Newton's Second Law",
            "Newton's Second Law",
            "Newton's Second Law",
            "Newton's Second Law",
            "Newton's Second Law"
        ],
        "model_ans": "Newton's second law",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's second law </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kind of measurements define accelerlations?",
        "answers": [
            "kinematic",
            "kinematic measurements",
            "kinematic",
            "kinematic",
            "kinematic"
        ],
        "model_ans": "meters per second squared",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> meters per second squared </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has an equivalence between mass and space-time?",
        "answers": [
            "General relativity",
            "General relativity",
            "General relativity",
            "General relativity",
            "General relativity"
        ],
        "model_ans": "Gravity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gravity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is missing a theory on quantum gravity?",
        "answers": [
            "General relativity",
            "coherent theory of quantum gravity",
            "General relativity",
            "General relativity"
        ],
        "model_ans": "String theory",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> String theory </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In Newton's second law, what are the units of mass and force in relation to microscales?",
        "answers": [
            "fixed",
            "an equality",
            "fixed",
            "fixed",
            "unclear"
        ],
        "model_ans": "kg",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> kg </answer> <answer> N </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When forces are from the presence of differnet objects, what law gives symmetry?",
        "answers": [
            "Newton's Third",
            "Newton's Third Law",
            "Newton's Third Law",
            "Newton's Third Law",
            "Newton's Third Law"
        ],
        "model_ans": "Newton's third law",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's third law </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What law staes that forces are interactions between bodies?",
        "answers": [
            "Newton's Third",
            "The third law",
            "The third law",
            "Newton's Third Law",
            "Newton's Third Law"
        ],
        "model_ans": "Newton's Third Law",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's Third Law </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kind of force does not exist under Newton's third law?",
        "answers": [
            "unidirectional",
            "unidirectional force",
            "unidirectional force",
            "unidirectional",
            "unidirectional force"
        ],
        "model_ans": "Gravity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gravity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the equality of forces between two objects exerting force on each other??",
        "answers": [
            "magnitude",
            "action-reaction",
            "the action-reaction law",
            "equal in magnitude"
        ],
        "model_ans": "Action",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Action </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What experiences acceleration when external force is applied to a system?",
        "answers": [
            "center of mass",
            "center of mass",
            "the center of mass",
            "the center of mass",
            "the center of mass"
        ],
        "model_ans": "Objects",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Objects </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what kind of system of particles are there no unbalanced iinternal forces?",
        "answers": [
            "closed",
            "closed system",
            "closed system of particles",
            "a closed system of particles",
            "a closed system"
        ],
        "model_ans": "Closed",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Closed </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the magnitude of force divided by when external force is added?",
        "answers": [
            "mass of the system",
            "mass of the system",
            "the mass of the system",
            "the mass of the system",
            "mass of the system"
        ],
        "model_ans": "acceleration",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> acceleration </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does pushing and pulling perceptions provide for describing forces?",
        "answers": [
            "intuitive understanding",
            "an intuitive understanding",
            "an intuitive understanding",
            "intuitive understanding",
            "an intuitive understanding"
        ],
        "model_ans": "A way to describe forces in terms of their direction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A way to describe forces in terms of their direction </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is used to quantify the intuitive undestanding of forces?",
        "answers": [
            "standard measurement scale",
            "precise operational definitions",
            "precise operational definitions",
            "precise operational definitions",
            "precise operational definitions"
        ],
        "model_ans": "Newton's laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What offers a conceptual definition of force?",
        "answers": [
            "Newtonian mechanics",
            "Newtonian mechanics",
            "Newtonian mechanics",
            "Newtonian mechanics",
            "Newtonian mechanics"
        ],
        "model_ans": "Physics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are laboratory measurements of forces determined?",
        "answers": [
            "experimentation",
            "Through experimentation",
            "Through experimentation",
            "Through experimentation",
            "experimentation"
        ],
        "model_ans": "By using instruments such as spring balances, force plates, and dynamometers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By using instruments such as spring balances, force plates, and dynamometers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How are forces classified with regard to push and pull strengt?",
        "answers": [
            "vector quantities",
            "vector quantities",
            "vector quantities",
            "\"vector quantities\"",
            "dependent upon how strong"
        ],
        "model_ans": "Forces are classified as either contact forces or non-contact forces",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Forces are classified as either contact forces or non-contact forces </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What physical quantities do not have direction?",
        "answers": [
            "denoted scalar quantities",
            "scalar quantities",
            "denoted scalar quantities",
            "scalar quantities",
            "scalar quantities"
        ],
        "model_ans": "scalar quantities",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> scalar quantities </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How do you avoid problems when determining forces involved on an object from two or more sources?",
        "answers": [
            "Associating forces with vectors",
            "Associating forces with vectors",
            "Associating forces with vectors",
            "Associating forces with vectors",
            "know both the magnitude and the direction of both forces to calculate the result"
        ],
        "model_ans": "By considering the relative magnitudes of the forces and the direction of the forces, and by using the principle of superposition to combine the forces.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By considering the relative magnitudes of the forces and the direction of the forces, and by using the principle of superposition to combine the forces.</answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If you do not know both magnitude and direction of two forces on an object, what would you call that situation?",
        "answers": [
            "ambiguous",
            "ambiguous",
            "ambiguous",
            "ambiguous",
            "ambiguous"
        ],
        "model_ans": "Unknown forces",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Unknown forces </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How do you determine the acceleration of a rope when two people are pulling it?",
        "answers": [
            "Associating forces with vectors",
            "Associating forces with vectors",
            "adding the two force magnitudes or subtracting one from the other",
            "knowing the direction of the forces",
            "it is impossible"
        ],
        "model_ans": "By using the concept of Newton's second law of motion, F = ma, where F is the force applied by each person, m is the mass of the rope, and a is</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> By using the concept of Newton's second law of motion, F = ma, where F is the force applied by each person, m is the mass of the rope, and a is</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what conditions were forces first measured historically?",
        "answers": [
            "static equilibrium",
            "static equilibrium",
            "conditions of static equilibrium",
            "static equilibrium",
            "static equilibrium"
        ],
        "model_ans": "By Galileo Galilei in 1592",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> By Galileo Galilei in 1592 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do forces have with regard to additive quantities?",
        "answers": [
            "magnitude and direction",
            "magnitude and direction",
            "magnitude and direction",
            "magnitude and direction",
            "magnitude and direction"
        ],
        "model_ans": "scalar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> scalar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the resultant force called when two forces act on a particle?",
        "answers": [
            "net force",
            "net force",
            "the resultant (also called the net force)",
            "net force",
            "net force"
        ],
        "model_ans": "net force",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> net force </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "When forces are acting on an extended body, what do you need to account for motion effects?",
        "answers": [
            "respective lines of application",
            "respective lines of application",
            "their respective lines of application",
            "their respective lines of application",
            "their effects on the motion of the body"
        ],
        "model_ans": "Inertia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Inertia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What geometric shape is used in equations to determine net force?",
        "answers": [
            "parallelogram",
            "parallelogram",
            "parallelogram",
            "parallelogram",
            "parallelogram"
        ],
        "model_ans": "Vector",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vector </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whwn forces are at right ngles to each other what can they be broken down to?",
        "answers": [
            "independent components",
            "independent components",
            "independent components",
            "independent components"
        ],
        "model_ans": "Pythagorean theorem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pythagorean theorem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "If a force is pointing horizontally to the northeast, how many forces can you split the force into?",
        "answers": [
            "two",
            "two",
            "two",
            "two"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do you get when you figure the sum of forces with vector addition?",
        "answers": [
            "the original force",
            "the original force",
            "the original force",
            "the original force"
        ],
        "model_ans": "Resultant force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Resultant force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are the independant components of a vector sum that has been determined by scalar addition of individual vectors?",
        "answers": [
            "orthogonal",
            "uniquely determined",
            "orthogonal components",
            "orthogonal components"
        ],
        "model_ans": "scalar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> scalar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can orthogonal forces be when there are three components with two at right angles to each other?",
        "answers": [
            "three-dimensional",
            "three-dimensional",
            "three-dimensional",
            "three-dimensional"
        ],
        "model_ans": "In-plane and out-of-plane forces",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In-plane and out-of-plane forces </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can keep an object from moving when it is being pushed on a surface?",
        "answers": [
            "static friction",
            "static friction",
            "friction",
            "static friction",
            "applied force"
        ],
        "model_ans": "Friction",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Friction </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is generated between a surface and an object that is being pushed?",
        "answers": [
            "static friction",
            "static friction",
            "static friction",
            "static friction",
            "static friction"
        ],
        "model_ans": "friction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> friction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Static friction balances what force when there is no movement of an object on a surface?",
        "answers": [
            "applied",
            "applied force",
            "applied force",
            "applied force",
            "applied"
        ],
        "model_ans": "normal force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> normal force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What makes static friction go up or down in responce to contact characteristics between an object and the surface it is on?",
        "answers": [
            "applied force",
            "applied force",
            "applied force",
            "applied force",
            "applied force"
        ],
        "model_ans": "Microscopic irregularities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Microscopic irregularities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can scales and spring balances measure between two forces by using static equilibrium?",
        "answers": [
            "forces",
            "static equilibrium",
            "forces",
            "force of gravity",
            "forces"
        ],
        "model_ans": "equal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> equal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What force acts on an object suspended on a spring scale in addition to gravity?",
        "answers": [
            "spring reaction force",
            "spring reaction force",
            "the force of gravity",
            "spring reaction",
            "spring reaction force"
        ],
        "model_ans": "tension",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> tension </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What equals the spring reaction force on an object suspended on a spring reaction scale? ",
        "answers": [
            "gravity",
            "object's weight",
            "spring reaction force",
            "the object's weight",
            "the object's weight"
        ],
        "model_ans": "weight",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> weight </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Objects of constant density are proportional to volume by what force to define standard weights?.",
        "answers": [
            "gravity",
            "gravity",
            "the force of gravity",
            "force of gravity",
            "the force of gravity"
        ],
        "model_ans": "Gravity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gravity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who expounded the Three Laws of Motion?",
        "answers": [
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton"
        ],
        "model_ans": "Isaac Newton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isaac Newton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who first described dynamic equilibrium?",
        "answers": [
            "Galileo",
            "Galileo",
            "Galileo",
            "Galileo",
            "Galileo"
        ],
        "model_ans": "Jean-Baptiste Dumas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Baptiste Dumas</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What does motion at a constant velocity equal?",
        "answers": [
            "rest",
            "rest",
            "rest",
            "rest",
            "rest"
        ],
        "model_ans": "zero acceleration",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> zero acceleration </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who had the idea of a natural state for objects at rest?",
        "answers": [
            "Galileo",
            "Aristotle's",
            "Aristotle",
            "Aristotle",
            "Aristotle's"
        ],
        "model_ans": "Aristotle",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aristotle </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Where will a canonball dropped from the crow's nest of a ship land according to Aristotle?",
        "answers": [
            "behind the foot of the mast",
            "straight down",
            "behind the foot of the mast",
            "behind the foot of the mast",
            "behind the foot of the mast of a moving ship"
        ],
        "model_ans": "at the foot of the mast",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> at the foot of the mast </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does a canonball dropped from the crow's nest of a ship actually land?",
        "answers": [
            "foot of the mast",
            "the foot of the mast",
            "at the foot of the mast",
            "at the foot of the mast",
            "at the foot of the mast"
        ],
        "model_ans": "Water",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What occurs when traveling across a surface at a constant velocity with regard to friction?",
        "answers": [
            "dynamic equilibrium",
            "dynamic equilibrium",
            "dynamic equilibrium",
            "dynamic equilibrium",
            "dynamic equilibrium"
        ],
        "model_ans": "No friction occurs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> No friction occurs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What directly opposes the force applied to move an object across a surface?",
        "answers": [
            "kinetic friction force",
            "kinetic friction force",
            "kinetic friction force",
            "kinetic friction",
            "kinetic friction force"
        ],
        "model_ans": "Friction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Friction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What has to accounted for that causes no net force being the cause of constant velocity motion?",
        "answers": [
            "kinetic friction",
            "object started with a non-zero velocity",
            "kinetic friction",
            "kinetic friction"
        ],
        "model_ans": "Newton's First Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's First Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who thought that applied force caused movement of an object regardless of non-zero velocity?",
        "answers": [
            "Aristotle",
            "Aristotle",
            "Aristotle",
            "Aristotle",
            "Aristotle"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What equation currently decribes the physics of force.",
        "answers": [
            "Schr\u00f6dinger",
            "Newtonian equations",
            "the Schr\u00f6dinger equation",
            "Schr\u00f6dinger",
            "Schr\u00f6dinger equation"
        ],
        "model_ans": "F = ma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> F = ma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What equation desribed the physics of force before the current Schrodinger equation?",
        "answers": [
            "Newtonian",
            "Newtonian equations",
            "Newtonian equations.",
            "Newtonian",
            "Newtonian equations"
        ],
        "model_ans": "Newton's laws",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton's laws </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How are the forces derived from fields treated similarly to?",
        "answers": [
            "classical position variables",
            "classical position variables",
            "classical position variables",
            "classical position variables",
            "classical position variables"
        ],
        "model_ans": "charges",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> charges </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What type of measurements result under Schrodinger equations when using operators instead of Newtonian variables?",
        "answers": [
            "quantized",
            "operators",
            "quantized",
            "quantized",
            "quantized"
        ],
        "model_ans": "wave functions",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wave functions </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What notion keeps it's meaning through both Netonian and Schrodinger physics equations?",
        "answers": [
            "force",
            "force",
            "force",
            "force",
            "The notion \"force\""
        ],
        "model_ans": "Time",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Time </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the intrisic angular variable called when particles act upon one another?",
        "answers": [
            "spin",
            "spin",
            "spin",
            "spin",
            "the \"spin"
        ],
        "model_ans": "Azimuth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Azimuth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the principle about relating spin and space variables?",
        "answers": [
            "Pauli",
            "Pauli principle",
            "Pauli principle",
            "Pauli",
            "Pauli"
        ],
        "model_ans": "Pauli's exclusion principle",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Pauli's exclusion principle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What value does the seperating into fermions and bosons depend?",
        "answers": [
            "spin",
            "value of the spin",
            "the value of the spin",
            "the spin",
            "value of the spin,"
        ],
        "model_ans": "spin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> spin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "If the apparant force of two fermions is attractive, what is the spin function?",
        "answers": [
            "antiparallel",
            "antiparallel spins",
            "antisymmetric",
            "antiparallel",
            "antiparallel"
        ],
        "model_ans": "singlet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> singlet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "If the apparant force of two fermions is repulsive, what is the spin function?",
        "answers": [
            "parallel",
            "antisymmetric",
            "symmetric",
            "parallel",
            "symmetric"
        ],
        "model_ans": "antisymmetric",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> antisymmetric </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How are the particle forces and accelerations explained as by gauge bosons exchange?",
        "answers": [
            "mathematical by-product",
            "mathematical by-product of exchange",
            "a mathematical by-product of exchange of momentum",
            "mathematical by-product of exchange"
        ],
        "model_ans": "The particle forces and accelerations are explained as by gauge bosons exchange through the process of quantum field theory.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The particle forces and accelerations are explained as by gauge bosons exchange through the process of quantum field theory. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the redundant concept coming from momentum conservation?",
        "answers": [
            "force",
            "4-momentum in relativity and momentum of virtual particles in quantum electrodynamics",
            "force"
        ],
        "model_ans": "Energy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Energy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is more fundamental than force in quanton field theory?",
        "answers": [
            "conservation of momentum",
            "conservation of momentum",
            "conservation of momentum",
            "the currently known fundamental forces"
        ],
        "model_ans": "energy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> energy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What diagrams are used to simplify particle interactions on a fundamental level?",
        "answers": [
            "Feynman",
            "Feynman diagrams",
            "Feynman"
        ],
        "model_ans": "Feynman diagrams",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Feynman diagrams </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Matter particles are shown as what kind of lines in a Feynman diagram?",
        "answers": [
            "straight",
            "straight line",
            "straight",
            "straight"
        ],
        "model_ans": "solid lines",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> solid lines </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many interactions are all of the universal forces based on?",
        "answers": [
            "four",
            "four",
            "four",
            "four"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What nuclear forces only act at short distances?",
        "answers": [
            "strong and weak",
            "strong and weak forces",
            "strong and weak",
            "strong and weak forces"
        ],
        "model_ans": "Strong",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Strong </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What force acts between electric charges?",
        "answers": [
            "electromagnetic",
            "electromagnetic force",
            "electromagnetic"
        ],
        "model_ans": "Electric force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do gravitational forces act between?",
        "answers": [
            "masses",
            "masses",
            "masses",
            "masses"
        ],
        "model_ans": "masses",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> masses </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What prohibits atoms from passing through each other?",
        "answers": [
            "Pauli exclusion principle",
            "the Pauli exclusion principle",
            "the Pauli exclusion principle",
            "Pauli exclusion principle"
        ],
        "model_ans": "Electromagnetic forces",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Electromagnetic forces </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who formed the universal theory of gravitation?",
        "answers": [
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton"
        ],
        "model_ans": "Isaac Newton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isaac Newton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "In what century was quantum mechanics made? ",
        "answers": [
            "20th",
            "the 20th century",
            "20th",
            "20th"
        ],
        "model_ans": "20th",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 20th </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What kind of self-consistent models are physicists trying to make that would create a theory of everything?",
        "answers": [
            "unification",
            "unification models",
            "unification",
            "unification"
        ],
        "model_ans": "String theory",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> String theory </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What type of physics model did Einstein fail to make?",
        "answers": [
            "self-consistent unification",
            "self-consistent unification models",
            "self-consistent unification",
            "self-consistent unification models that would combine all four fundamental interactions"
        ],
        "model_ans": "Quantum Mechanics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quantum Mechanics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who identified gravity as a force?",
        "answers": [
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton",
            "Isaac Newton"
        ],
        "model_ans": "Sir Isaac Newton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sir Isaac Newton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who came up with the concept that falling objects fell at the same speed regardless of weight?",
        "answers": [
            "Galileo",
            "Galileo",
            "Galileo",
            "Galileo"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How fast do objects fall on Earth?",
        "answers": [
            "about 9.81 meters per second squared",
            "about 9.81 meters per second squared",
            "about 9.81 meters per second",
            "9.81 meters per second"
        ],
        "model_ans": "9.8 meters per second squared (m/s^2)\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "9.8 meters per second squared (m/s^2)\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Where was the measurment for the standard gravity on Earth taken?",
        "answers": [
            "sea level",
            "sea level",
            "sea level",
            "from sea level"
        ],
        "model_ans": "Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is an object's mass proportional to at the surface of the Earth?",
        "answers": [
            "force of gravity",
            "the force of gravity on an object",
            "force of gravity",
            "force of gravity"
        ],
        "model_ans": "its volume",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> its volume </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How might gravity effects be observed differently according to Newton?",
        "answers": [
            "at larger distances.",
            "at larger distances",
            "at larger distances",
            "at larger distances"
        ],
        "model_ans": "Newton's law of universal gravitation states that every point mass attracts every other point mass by a force acting along the line intersecting both points.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Newton's law of universal gravitation states that every point mass attracts every other point mass by a force acting along the line intersecting both points. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What could be attributed to gravity acceleration around the Earth?",
        "answers": [
            "the Moon",
            "the mass () and the radius () of the Earth",
            "force of gravity",
            "the same force of gravity if the acceleration due to gravity decreased as an inverse square law."
        ],
        "model_ans": "9.8 m/s^2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 9.8 m/s^2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is gravitational acceleration proportional to?",
        "answers": [
            "mass",
            "the mass of the attracting body",
            "the mass of the attracting body",
            "the mass of the attracting body"
        ],
        "model_ans": "mass",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mass </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is included along with gravitational acceration, and mass of the Earth in a formula about rotation about the Earth?",
        "answers": [
            "radius () of the Earth",
            "the radius () of the Earth",
            "radius"
        ],
        "model_ans": "radius",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> radius </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is used to figure the relative strengh of gravity?",
        "answers": [
            "Newton's Universal Gravitation Constant,",
            "dimensional constant",
            "a dimensional constant",
            "a dimensional constant"
        ],
        "model_ans": "Gravitational constant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gravitational constant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who made the first to measure value of the Newton Universal Gravitation Constant?",
        "answers": [
            "Henry Cavendish",
            "Henry Cavendish",
            "Henry Cavendish",
            "Henry Cavendish"
        ],
        "model_ans": "Newton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When was the first measurement of the value of the Newton Universal Gravitation Constant?",
        "answers": [
            "1798",
            "1798",
            "1798",
            "1798"
        ],
        "model_ans": "1687",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1687 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who figured out that his law of gravity had to be universal?",
        "answers": [
            "Newton",
            "Newton",
            "Newton",
            "Newton"
        ],
        "model_ans": "Galileo Galilei",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Galileo Galilei </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What planet seemed to buck Newton's gravitational laws?",
        "answers": [
            "Mercury",
            "Mercury",
            "Mercury",
            "Mercury"
        ],
        "model_ans": "Jupiter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jupiter</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What planet did astrophysisist predict to explain the problems with Mercury?",
        "answers": [
            "Vulcan",
            "Vulcan",
            "Vulcan",
            "Vulcan"
        ],
        "model_ans": "Venus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Venus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What theory accounted for the Mercury problem?",
        "answers": [
            "theory of general relativity",
            "theory of general relativity (GR)",
            "general relativity",
            "general relativity"
        ],
        "model_ans": "Einstein's theory of general relativity",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Einstein's theory of general relativity </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who came up with the theory of relativity?",
        "answers": [
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "Who first showed that Newton's Theory of Gravity was not as correct as another theory?",
        "answers": [
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein",
            "Albert Einstein"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What theory best explains gravity?",
        "answers": [
            "general relativity",
            "general relativity",
            "general relativity",
            "general relativity"
        ],
        "model_ans": "General Relativity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Relativity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What space-time path is seen as a curved line in space?",
        "answers": [
            "ballistic trajectory",
            "path between two space-time events",
            "straight lines",
            "the shortest space-time path between two space-time events."
        ],
        "model_ans": "geodesic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> geodesic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the derivative of an object's changing momentum called?",
        "answers": [
            "gravitational force",
            "gravitational force",
            "gravitational force",
            "gravitational force"
        ],
        "model_ans": "Force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what sense must you be observing the curvature of space-time?",
        "answers": [
            "global",
            "a global sense",
            "in space",
            "the perspective of the object"
        ],
        "model_ans": "With a telescope",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> With a telescope </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the law named that defines a charge moving through a magnetic field?",
        "answers": [
            "Lorentz's Law",
            "Lorentz's Law",
            "Lorentz's Law",
            "Lorentz's Law"
        ],
        "model_ans": "Lorentz force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lorentz force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is  the time rate of change of electric charge?",
        "answers": [
            "electric current",
            "electric current",
            "electric current",
            "electric current"
        ],
        "model_ans": "Electric current",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric current </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What magnetic and electric force acts on a charge?",
        "answers": [
            "unified electromagnetic",
            "unified electromagnetic force",
            "electromagnetic",
            "unified electromagnetic force"
        ],
        "model_ans": "Lorentz force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lorentz force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Whatare the electrostatic and magnetic force awritten as the sum of?",
        "answers": [
            "electrostatic force",
            "the electrostatic force (due to the electric field) and the magnetic force (due to the magnetic field).",
            "electrostatic force (due to the electric field) and the magnetic force",
            "the electrostatic force (due to the electric field) and the magnetic force"
        ],
        "model_ans": "Coulomb's Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coulomb's Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Who first fully explained the origins of magnetic and electric fields?",
        "answers": [
            "James Clerk Maxwell",
            "James Clerk Maxwell",
            "James Clerk Maxwell",
            "James Clerk Maxwell"
        ],
        "model_ans": "Andr\u00e9-Marie Amp\u00e8re",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andr\u00e9-Marie Amp\u00e8re </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "When did the origins of magnetic and electric fields occur?",
        "answers": [
            "1864",
            "1864",
            "1864",
            "1864"
        ],
        "model_ans": "1831",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1831 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many scalar equations were formed into a set by James Maxwell?",
        "answers": [
            "20",
            "20",
            "20",
            "20"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "How many vector equations did Heaviside and Gibbs reformilate Maxwell's 20 scalar equtions into?",
        "answers": [
            "4",
            "4",
            "4",
            "4"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Who discovered that magnetic and electric could self-generate?",
        "answers": [
            "Maxwell",
            "James Clerk Maxwell",
            "Maxwell",
            "Maxwell"
        ],
        "model_ans": "Michael Faraday",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Faraday </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was dificult to reconcile the photoelectric effect and the missing ultraviolet catastrophe?",
        "answers": [
            "electromagnetic theory",
            "electromagnetic theory",
            "electromagnetic theory",
            "electromagnetic theory"
        ],
        "model_ans": "Planck's constant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Planck's constant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What was used to create a new electromagnetic theory to reconcile the troubles with electromagnetic theory as it used to stand?",
        "answers": [
            "quantum mechanics",
            "quantum mechanics",
            "quantum mechanics",
            "the work of leading theoretical physicists"
        ],
        "model_ans": "Maxwell's equations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maxwell's equations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did electromagnetic theory  finally lead to?",
        "answers": [
            "quantum electrodynamics",
            "quantum electrodynamics (or QED)",
            "quantum electrodynamics",
            "quantum electrodynamics"
        ],
        "model_ans": "Wireless communication",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wireless communication </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What are the wave-particles called that mediate all electromagnetic phenomena?",
        "answers": [
            "photons",
            "photons",
            "photons",
            "photons"
        ],
        "model_ans": "photons",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> photons </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is QED short for?",
        "answers": [
            "quantum electrodynamics",
            "quantum electrodynamics",
            "quantum electrodynamics",
            "quantum electrodynamics"
        ],
        "model_ans": "Quantum Electrodynamics",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantum Electrodynamics </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is often misunderstood as the cause of matter rigidity?",
        "answers": [
            "repulsion of like charges",
            "repulsion of like charges under the influence of the electromagnetic force",
            "repulsion of like charges",
            "the repulsion of like charges under the influence of the electromagnetic force"
        ],
        "model_ans": "Atomic structure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Atomic structure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What actually causes rigidity in matter?",
        "answers": [
            "the Pauli exclusion principle",
            "the Pauli exclusion principle",
            "Pauli exclusion principle",
            "Pauli exclusion principle"
        ],
        "model_ans": "Atomic bonds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atomic bonds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is needed to pack electrons densely together?",
        "answers": [
            "energy",
            "energy",
            "energy",
            "energy"
        ],
        "model_ans": "pressure",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pressure </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How is the Pauli exclusion priciple manifested in the macro world?",
        "answers": [
            "as a structural force",
            "as a structural force",
            "a structural force",
            "macroscopically as a structural force"
        ],
        "model_ans": "The Pauli exclusion principle is not directly applicable to macroscopic objects, as it is a quantum mechanical principle that describes the behavior of fermions at the atomic and subatomic level. </</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Pauli exclusion principle is not directly applicable to macroscopic objects, as it is a quantum mechanical principle that describes the behavior of fermions at the atomic and subatomic level. </</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does stong force act upon?",
        "answers": [
            "elementary particles",
            "elementary particles",
            "elementary particles",
            "elementary particles"
        ],
        "model_ans": "particles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> particles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can be seen between hadrons?",
        "answers": [
            "residual of the force",
            "residual of the force",
            "nucleons in atomic nuclei",
            "a residual of the force"
        ],
        "model_ans": "Quarks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quarks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the force between nucleons?",
        "answers": [
            "nuclear",
            "nuclear force.",
            "nuclear",
            "nuclear force"
        ],
        "model_ans": "Strong nuclear force",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Strong nuclear force </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "How are nuclear forces transmitted?",
        "answers": [
            "as gluons",
            "as gluons",
            "as gluons",
            "as gluons"
        ],
        "model_ans": "through particles called gluons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> through particles called gluons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the term for the lack of obsevable free quarks?",
        "answers": [
            "color confinement",
            "color confinement",
            "color confinement",
            "color confinement"
        ],
        "model_ans": "confinement",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> confinement </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What does the W and Z boson exchange create?",
        "answers": [
            "weak force",
            "weak force",
            "weak force",
            "weak force"
        ],
        "model_ans": "mass",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mass </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the observable effect of W and Z boson exchange?",
        "answers": [
            "beta decay",
            "beta decay (of neutrons in atomic nuclei)",
            "beta decay",
            "beta decay"
        ],
        "model_ans": "Weak nuclear force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Weak nuclear force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the effect of beta decay?",
        "answers": [
            "radioactivity",
            "radioactivity",
            "radioactivity",
            "radioactivity"
        ],
        "model_ans": "Radioactive decay",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Radioactive decay </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How many times less is the strenght of the weak field compared to the strong?",
        "answers": [
            "1013",
            "1013",
            "1013",
            "1013"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "At what temperature do weak and electromagnetic forces appear the same?",
        "answers": [
            "approximately 1015 kelvins",
            "in excess of approximately 1015 kelvins",
            "1015 kelvins",
            "in excess of approximately 1015 kelvins"
        ],
        "model_ans": "10^15 Kelvin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10^15 Kelvin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the repulsive force of close range atom interaction?",
        "answers": [
            "normal force",
            "normal force",
            "normal force",
            "normal force"
        ],
        "model_ans": "Van der Waals force",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Van der Waals force </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What occurs when electron clouds overlap from different atoms?",
        "answers": [
            "Pauli repulsion",
            "Pauli repulsion",
            "Pauli repulsion",
            "Pauli repulsion"
        ],
        "model_ans": "Chemical Bonding",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chemical Bonding </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What causes Pauli repulsion?",
        "answers": [
            "fermionic nature of electrons",
            "fermionic nature of electrons",
            "fermionic nature of electrons",
            "fermionic nature of electrons"
        ],
        "model_ans": "Electrons",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electrons </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the force that causes rigid strength in structures?",
        "answers": [
            "normal",
            "normal force",
            "normal force",
            "normal force"
        ],
        "model_ans": "Tensile strength",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tensile strength </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What can be used to model tension forces?",
        "answers": [
            "ideal strings",
            "ideal strings that are massless",
            "ideal strings that are massless",
            "ideal strings that are massless, frictionless, unbreakable, and unstretchable"
        ],
        "model_ans": "Springs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Springs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What do you use to let idea strings switch direction?",
        "answers": [
            "ideal pulleys",
            "ideal pulleys",
            "ideal pulleys",
            "ideal pulleys"
        ],
        "model_ans": "pivot",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pivot </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "In what way do idea strings transmit tesion forces?",
        "answers": [
            "action-reaction pairs",
            "instantaneously in action-reaction pairs",
            "in action-reaction pairs",
            "instantaneously in action-reaction pairs"
        ],
        "model_ans": "I am not sure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am not sure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the final effect of adding more and more idea strings to a load?",
        "answers": [
            "conservation of mechanical energy",
            "conservation of mechanical energy",
            "the tension force on a load can be multiplied",
            "tension force on a load can be multiplied"
        ],
        "model_ans": "The load becomes more complex and difficult to manage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The load becomes more complex and difficult to manage </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What can increase the tension force on a load?",
        "answers": [
            "movable pulleys",
            "connecting the same string multiple times to the same object through the use of a set-up that uses movable pulleys,",
            "every string",
            "connecting the same string multiple times to the same object through the use of a set-up that uses movable pulleys"
        ],
        "model_ans": "Increasing the force applied to the load",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Increasing the force applied to the load </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What did Newton's mechanics affect?",
        "answers": [
            "idealized point particles",
            "idealized point particles rather than three-dimensional objects",
            "idealized point particles",
            "idealized point particles"
        ],
        "model_ans": "Physics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What didn't Newton's mechanics affext?",
        "answers": [
            "three-dimensional objects",
            "three-dimensional objects",
            "three-dimensional objects"
        ],
        "model_ans": "Quantum Mechanics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantum Mechanics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what kind of fluid are pressure differences caused by direction of forces over gradients?",
        "answers": [
            "extended",
            "extended",
            "extended"
        ],
        "model_ans": "fluid",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fluid </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What may a force on one part of an object affect?",
        "answers": [
            "other parts",
            "other parts of an object",
            "other parts of an object",
            "other parts of an object"
        ],
        "model_ans": "other parts",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> other parts </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What does matter actually have that Newtonian mechanics doesn't address?",
        "answers": [
            "extended structure",
            "extended structure",
            "extended structure",
            "extended structure and forces that act on one part of an object might affect other parts of an object"
        ],
        "model_ans": "Quantum properties",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quantum properties </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What causes strain in structures?",
        "answers": [
            "stress tensor",
            "stress tensor",
            "deformations",
            "The stress tensor"
        ],
        "model_ans": "Load",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Load </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is used to calculate cross section area in the volume of an object?",
        "answers": [
            "pressure terms",
            "stress tensor",
            "pressure terms associated with forces that act normal to the cross-sectional area (the matrix diagonals of the tensor) as well as shear terms"
        ],
        "model_ans": "Pi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What are associated with normal forces?",
        "answers": [
            "pressure terms",
            "matrix diagonals of the tensor)",
            "pressure terms"
        ],
        "model_ans": "surfaces",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> surfaces </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What includes pressure terms when calculating area in volume?",
        "answers": [
            "formalism",
            "the relevant cross-sectional area for the volume for which the stress-tensor is being calculated",
            "formalism",
            "This formalism"
        ],
        "model_ans": "Volume",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Volume </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the force equivalent of torque compared to angular momentum?",
        "answers": [
            "rotational equivalent for position",
            "rotation",
            "rotational inertia",
            "angle is the rotational equivalent for position"
        ],
        "model_ans": "moment",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> moment </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What would change the rotational inertia of a body under Newton's First Law of Motion?",
        "answers": [
            "unbalanced torque",
            "unbalanced torque",
            "unbalanced torque",
            "an unbalanced torque"
        ],
        "model_ans": "mass",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mass </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "To calculate instant angular acceleration of a rigid body what would you use?",
        "answers": [
            "Newton's Second Law of Motion",
            "Newton's Second Law of Motion",
            "Newton's Second Law of Motion",
            "Newton's Second Law of Motion"
        ],
        "model_ans": "Euler's rotation equations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Euler's rotation equations </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "Where does centripetal force go?",
        "answers": [
            "toward the center of the curving path",
            "center of the curving path.",
            "the center of the curving path",
            "directed toward the center of the curving path"
        ],
        "model_ans": "center",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> center </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "How do centripetal forces act in relation to vectors of velocity?",
        "answers": [
            "perpendicular",
            "perpendicular",
            "perpendicular",
            "perpendicular"
        ],
        "model_ans": "Centripetal forces act perpendicular to the velocity vector",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Centripetal forces act perpendicular to the velocity vector </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What force changes an objects direction of travel?",
        "answers": [
            "centripetal",
            "unbalanced centripetal force",
            "unbalanced centripetal force",
            "centripetal"
        ],
        "model_ans": "Gravity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gravity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is another word for centripetal force?",
        "answers": [
            "radial",
            "radial (centripetal) force",
            "radial",
            "radial"
        ],
        "model_ans": "centrifugal force",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> centrifugal force </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is resposible for speeding up or slowing down an object?",
        "answers": [
            "tangential force",
            "tangential force",
            "tangential force",
            "tangential force"
        ],
        "model_ans": "Force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the only form potential energy can change into?",
        "answers": [
            "kinetic",
            "kinetic",
            "kinetic",
            "kinetic"
        ],
        "model_ans": "Kinetic energy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kinetic energy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "What is the only form kinetic energy can change into?",
        "answers": [
            "potential",
            "potential",
            "potential",
            "potential"
        ],
        "model_ans": "thermal energy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> thermal energy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is preserved in a closed system of forces when acted upon?",
        "answers": [
            "net mechanical energy",
            "net mechanical energy",
            "net mechanical energy",
            "net mechanical energy"
        ],
        "model_ans": "momentum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> momentum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the force between two locations related to?",
        "answers": [
            "difference in potential energy",
            "the difference in potential energy",
            "the difference in potential energy",
            "the difference in potential energy between two different locations in space"
        ],
        "model_ans": "gravity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gravity </answer> <confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the force called rgarding a potential field between two locations?",
        "answers": [
            "artifact",
            "artifact of the potential field",
            "an artifact"
        ],
        "model_ans": "gravitational force",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gravitational force </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is sometimes impossible to model?",
        "answers": [
            "forces",
            "forces as being due to gradient of potentials",
            "forces",
            "forces as being due to gradient of potentials"
        ],
        "model_ans": "Chaos",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chaos </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Why are some forces due to that are impossible to model?",
        "answers": [
            "gradient of potentials",
            "macrophysical considerations that yield forces as arising from a macroscopic statistical average of microstates",
            "gradient of potentials.",
            "gradient of potentials"
        ],
        "model_ans": "Quantum mechanics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Quantum mechanics </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What do electrostatic gradiient potentials create?",
        "answers": [
            "friction",
            "friction",
            "friction",
            "friction"
        ],
        "model_ans": "Electric fields",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electric fields </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "Tension, compression, and drag are what kind of forces?",
        "answers": [
            "Nonconservative",
            "Nonconservative forces other than friction",
            "Nonconservative",
            "Nonconservative forces"
        ],
        "model_ans": "external forces",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> external forces </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "In what treatment are nonconservative and conservative forces described?",
        "answers": [
            "statistical mechanics",
            "statistical mechanics",
            "detailed",
            "detailed treatment with statistical mechanics"
        ],
        "model_ans": "Newtonian mechanics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newtonian mechanics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What changes macroscopic closed system energies?",
        "answers": [
            "nonconservative forces",
            "internal energies of the system",
            "nonconservative forces",
            "nonconservative forces"
        ],
        "model_ans": "Heat",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heat </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the exchange of heat associated with?",
        "answers": [
            "nonconservative forces",
            "nonconservative forces",
            "nonconservative forces",
            "nonconservative forces"
        ],
        "model_ans": "Temperature",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Temperature </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the law of thermodynamics associated with closed system heat exchange?",
        "answers": [
            "Second",
            "Second law of thermodynamics",
            "Second law",
            "Second"
        ],
        "model_ans": "Zeroth Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zeroth Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What makes energy changes in a closed system?",
        "answers": [
            "nonconservative forces",
            "nonconservative forces",
            "nonconservative forces",
            "nonconservative forces"
        ],
        "model_ans": "heat",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> heat </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the metric term less used than the Newton?",
        "answers": [
            "kilogram-force",
            "pound-force",
            "kilogram-force (kgf)",
            "kilogram-force",
            "the kilogram-force ("
        ],
        "model_ans": "dyne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dyne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is the kilogram-force sometimes reffered to as?",
        "answers": [
            "kilopond",
            "kilopond",
            "kilopond",
            "kilopond",
            "kilopond"
        ],
        "model_ans": "Newton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "What is a very seldom used unit of mass in the metric system?",
        "answers": [
            "slug",
            "metric slug",
            "metric slug",
            "metric slug",
            "the metric slug"
        ],
        "model_ans": "Ton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What seldom used term of a unit of force equal to 1000 pound s of force?",
        "answers": [
            "kip",
            "kip",
            "kip",
            "kip",
            "kip"
        ],
        "model_ans": "Kilonewton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kilonewton </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "What is the seldom used force unit equal to one thousand newtons?",
        "answers": [
            "sth\u00e8ne",
            "sth\u00e8ne",
            "sth\u00e8ne",
            "sth\u00e8ne",
            "sth\u00e8ne"
        ],
        "model_ans": "kilonewton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> kilonewton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "total_sample": 5928,
        "correct_sample": 949,
        "accuracy": 0.1600877192982456,
        "refusal": 3208,
        "refusal_rate": 0.5411605937921727,
        "answer_sample": 2720,
        "answer_rate": 0.45883940620782726,
        "un_c_match_sample": 312,
        "un_c_match_rate": 0.05263157894736842,
        "I": 2083,
        "C": 637,
        "AED": 0.6782716052296636
    }
]