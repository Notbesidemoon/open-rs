[
    {
        "question": "when was the last time anyone was on the moon",
        "answers": [
            "14 December 1972 UTC",
            "December 1972"
        ],
        "model_ans": "December 1972",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> December 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote he ain't heavy he's my brother lyrics",
        "answers": [
            "Bobby Scott",
            "Bob Russell"
        ],
        "model_ans": "Bob Russell",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Bob Russell</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many seasons of the bastard executioner are there",
        "answers": [
            "one",
            "one season"
        ],
        "model_ans": "1\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the eagles win last super bowl",
        "answers": [
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won last year's ncaa women's basketball",
        "answers": [
            "South Carolina"
        ],
        "model_ans": "Baylor Lady Bears",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Baylor Lady Bears </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the isle of wight become an island",
        "answers": [
            "During the last Ice Age"
        ],
        "model_ans": "12,000 years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12,000 years ago </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "love yourself by justin bieber is about who",
        "answers": [
            "Rihanna"
        ],
        "model_ans": "Justin Bieber",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Justin Bieber </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the ruler of england in 1616",
        "answers": [
            "James I"
        ],
        "model_ans": "James I",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James I </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the hot coffee mod in san andreas",
        "answers": [
            "a normally inaccessible mini-game"
        ],
        "model_ans": "Grand Theft Auto: San Andreas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Grand Theft Auto: San Andreas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the maximum data rate for the 802.11a standard select one",
        "answers": [
            "54\u00a0Mbit/s"
        ],
        "model_ans": "54 Mbps",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>54 Mbps</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which state is located in the centre of india",
        "answers": [
            "Chhattisgarh",
            "Madhya Pradesh"
        ],
        "model_ans": "Madhya Pradesh",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Madhya Pradesh </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang i ran all the way home",
        "answers": [
            "The Impalas"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the last name wallace come from",
        "answers": [
            "a Scottish surname"
        ],
        "model_ans": "Scotland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the actor that played ben stone on law and order",
        "answers": [
            "Michael Moriarty"
        ],
        "model_ans": "Michael Moriarty",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Moriarty </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does the voice of nala in the lion king",
        "answers": [
            "Niketa Calame",
            "Sally Dworsky",
            "Moira Kelly",
            "Laura Williams"
        ],
        "model_ans": "Moira Kelly",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Moira Kelly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays gram on the young and the restless",
        "answers": [
            "Max Shippee"
        ],
        "model_ans": "Hunter King",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hunter King </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the oath that new citizens take",
        "answers": [
            "United States Oath of Allegiance"
        ],
        "model_ans": "The Oath of Allegiance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Oath of Allegiance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is under the mask of darth vader",
        "answers": [
            "Anakin Skywalker"
        ],
        "model_ans": "Anakin Skywalker",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anakin Skywalker </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who had a baby at 100 in the bible",
        "answers": [
            "Sarah",
            "Abraham"
        ],
        "model_ans": "Sarah",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sarah </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what age do you need to be to buy a bb gun",
        "answers": [
            "18"
        ],
        "model_ans": "18",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 18 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ethiopia flight 961 crashes in to the sea",
        "answers": [
            "23 November 1996"
        ],
        "model_ans": "Indian Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Indian Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was percy jackson and the olympians filmed",
        "answers": [
            "Vancouver",
            "Mission, British Columbia"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons of vampire diaries r there",
        "answers": [
            "eight",
            "8"
        ],
        "model_ans": "8\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "8\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes are there in dragon ball z",
        "answers": [
            "291 episodes",
            "291"
        ],
        "model_ans": "291\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "291\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays auggie in the movie the wonder",
        "answers": [
            "Jacob Tremblay"
        ],
        "model_ans": "Jacob Tremblay",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jacob Tremblay </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the first australian prime minister elected",
        "answers": [
            "Sir Edmund Barton",
            "1901"
        ],
        "model_ans": "1901\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1901\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays matthew on anne with an e",
        "answers": [
            "R. H. Thomson"
        ],
        "model_ans": "Ben Rosenfield",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ben Rosenfield </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl in green day 21 guns",
        "answers": [
            "Lisa Stelly"
        ],
        "model_ans": "Billie Joe Armstrong's daughter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Billie Joe Armstrong's daughter </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays joker in batman the dark knight",
        "answers": [
            "Ledger"
        ],
        "model_ans": "Heath Ledger",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heath Ledger </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the south asian association for regional co-operation (saarc) formed",
        "answers": [
            "December 1985",
            "8 December 1985"
        ],
        "model_ans": "1985\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1985\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first hunger games book published",
        "answers": [
            "September 14, 2008",
            "2008"
        ],
        "model_ans": "2008\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2008\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did bette midler portray in the rose",
        "answers": [
            "Mary Rose Foster"
        ],
        "model_ans": "Mary Delgado",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mary Delgado </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the lead singer of depeche mode",
        "answers": [
            "David Gahan"
        ],
        "model_ans": "Dave Gahan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dave Gahan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the butchers in the slaughterhouse cases live",
        "answers": [
            "New Orleans"
        ],
        "model_ans": "Providence",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Providence </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who developed the concept of total quality management",
        "answers": [
            "W. Edwards Deming"
        ],
        "model_ans": "Deming",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deming </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote cant get you out of my head lyrics",
        "answers": [
            "Cathy Dennis and Rob Davis",
            "Rob Davis",
            "Cathy Dennis"
        ],
        "model_ans": "Kylie Minogue",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kylie Minogue </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does no game no life anime end",
        "answers": [
            "the Elkia Federation",
            "the sixth volume"
        ],
        "model_ans": "The anime has not ended yet, it is still ongoing",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The anime has not ended yet, it is still ongoing </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did taylor swift's first album release",
        "answers": [
            "October 24, 2006",
            "2005"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the three fifty shades of grey books",
        "answers": [
            "Fifty Shades of Grey",
            "Fifty Shades Darker",
            "Fifty Shades Freed"
        ],
        "model_ans": "Fifty Shades of Grey, Fifty Shades Darker, Fifty Shades Freed",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fifty Shades of Grey, Fifty Shades Darker, Fifty Shades Freed </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the power (judicial) to make decisions in courts of law",
        "answers": [
            "judges"
        ],
        "model_ans": "Judges",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Judges</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are the ranks in the us navy",
        "answers": [
            "E-8s senior chief petty officer",
            "E-9s master chief petty officer"
        ],
        "model_ans": "Enlisted: Seaman Recruit, Seaman Apprentice, Seaman, Petty Officer Third Class, Petty Officer Second Class, Petty Officer First Class, Chief Petty Officer, Senior Chief Petty Officer, Master Chief Petty Officer, Command Master Chief</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enlisted: Seaman Recruit, Seaman Apprentice, Seaman, Petty Officer Third Class, Petty Officer Second Class, Petty Officer First Class, Chief Petty Officer, Senior Chief Petty Officer, Master Chief Petty Officer, Command Master Chief</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "i was a great islamic scholar and mathematician who died in 1131 ce",
        "answers": [
            "Omar Khayyam"
        ],
        "model_ans": "Ibn Yunus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ibn Yunus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the coach for the ottawa senators",
        "answers": [
            "Guy Boucher"
        ],
        "model_ans": "DJ Smith",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> DJ Smith </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "last episode of what happens to my family",
        "answers": [
            "53"
        ],
        "model_ans": "The Last Episode of \"What Happens to My Family\" aired on May 31, 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Last Episode of \"What Happens to My Family\" aired on May 31, 2019 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the last time the vikings were in the nfc championship",
        "answers": [
            "1976",
            "2017/18"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the colors of the netherlands flag",
        "answers": [
            "blue",
            "white",
            "red"
        ],
        "model_ans": "red, white, blue",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> red, white, blue </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is lord's prayer found in bible",
        "answers": [
            "in the Gospel of Luke"
        ],
        "model_ans": "Matthew 6:9-13",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matthew 6:9-13 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time oklahoma won a national championship in football",
        "answers": [
            "2003",
            "2000"
        ],
        "model_ans": "2000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "location of the ten commandments in the bible",
        "answers": [
            "Exodus",
            "Deuteronomy"
        ],
        "model_ans": "Exodus 20:1-17",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exodus 20:1-17 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did the allies go after north africa",
        "answers": [
            "Italy",
            "the Italian Campaign"
        ],
        "model_ans": "Sicily",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sicily </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of veronica in english",
        "answers": [
            "she who brings victory"
        ],
        "model_ans": "means \"true image\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> means \"true image\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the main artery which takes blood from the heart to the body",
        "answers": [
            "The aorta",
            "aorta"
        ],
        "model_ans": "aorta",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> aorta </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played solomon in little house on the prairie",
        "answers": [
            "Todd Bridges"
        ],
        "model_ans": "Jonathan Gilbert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jonathan Gilbert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does eric end up with in that 70s show",
        "answers": [
            "Donna"
        ],
        "model_ans": "Donna Pinciotti",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Donna Pinciotti </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "an object that moves around an external axis is said to be",
        "answers": [
            "revolution or orbital revolution",
            "orbit"
        ],
        "model_ans": "rotating",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rotating </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "architectural elements forming rib vaults eg wells cathedral",
        "answers": [
            "an armature of piped masonry",
            "barrel vaults",
            "two to three barrel vaults"
        ],
        "model_ans": "ribs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ribs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the song good morning good morning",
        "answers": [
            "Gene Kelly",
            "Donald O'Connor",
            "Judy Garland",
            "Debbie Reynolds",
            "Mickey Rooney"
        ],
        "model_ans": "The Beatles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Beatles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote papa got a brand new bag",
        "answers": [
            "James Brown"
        ],
        "model_ans": "James Brown",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>James Brown</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does a roadrunner live in the desert",
        "answers": [
            "mountainous shrubland",
            "arid lowland"
        ],
        "model_ans": "Sonoran Desert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sonoran Desert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote it's a long long way to pasadena",
        "answers": [
            "John Young",
            "Harry Vanda",
            "David Hemmings",
            "George Young"
        ],
        "model_ans": "John Green",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Green </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the dog's name on tom and jerry",
        "answers": [
            "Spike"
        ],
        "model_ans": "Jerry",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jerry</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are nominated for president of india 2017",
        "answers": [
            "Meira Kumar",
            "Ram Nath Kovind"
        ],
        "model_ans": "Ram Nath Kovind",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ram Nath Kovind </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the path train stop in newark",
        "answers": [
            "Newark Penn Station"
        ],
        "model_ans": "Newark Penn Station",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Newark Penn Station </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does route 66 start on the west coast",
        "answers": [
            "in Santa Monica"
        ],
        "model_ans": "Santa Monica",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Santa Monica </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the first wife on sister wives",
        "answers": [
            "Meri"
        ],
        "model_ans": "Meri Brown",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Meri Brown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did houston go to the american league",
        "answers": [
            "2013"
        ],
        "model_ans": "2013\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2013\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they stop cigarette advertising on television",
        "answers": [
            "January 2, 1971",
            "1970"
        ],
        "model_ans": "1971",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1971 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "coldplay song i will try to fix you",
        "answers": [
            "\"Fix You\""
        ],
        "model_ans": "Fix You",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fix You </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "points on a sphere or angles in a circle are measured in units called",
        "answers": [
            "radians"
        ],
        "model_ans": "radians",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> radians </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the oligodynamic effect is a phenomenon that describes",
        "answers": [
            "a biocidal effect of metals"
        ],
        "model_ans": "the toxic effects of certain metals on microorganisms",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the toxic effects of certain metals on microorganisms </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the white witch live in narnia",
        "answers": [
            "her castle"
        ],
        "model_ans": "Charn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many games in a row have the uconn women's basketball team won",
        "answers": [
            "111 straight wins",
            "111",
            "90"
        ],
        "model_ans": "111",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 111 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "is there a name for the at symbol",
        "answers": [
            "commercial at",
            "at symbol",
            "at sign"
        ],
        "model_ans": "at sign",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> at sign </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings the theme song for the tv show cops",
        "answers": [
            "Inner Circle",
            "Jamaican reggae band Inner Circle"
        ],
        "model_ans": "The TV show \"Cops\" does not have a theme song, it is an instrumental score.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The TV show \"Cops\" does not have a theme song, it is an instrumental score.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was corporal punishment banned in south africa",
        "answers": [
            "1997"
        ],
        "model_ans": "2005\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2005\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays captain phasma in star wars the force awakens",
        "answers": [
            "Gwendoline Christie"
        ],
        "model_ans": "Gwendoline Christie",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gwendoline Christie </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings she's like the wind lyrics",
        "answers": [
            "Wendy Fraser",
            "Patrick Swayze"
        ],
        "model_ans": "Dustin O'Halloran",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Dustin O'Halloran</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did marathon change its name to snickers",
        "answers": [
            "19 July 1990"
        ],
        "model_ans": "1990",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1990 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who captained the first european ship to sail around the tip of africa",
        "answers": [
            "Bartolomeu Dias"
        ],
        "model_ans": "Bartolomeu Dias",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bartolomeu Dias </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who ordered the forbidden city to be built",
        "answers": [
            "Zhu Di"
        ],
        "model_ans": "Emperor Yongle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Emperor Yongle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang let me tell you about the birds and the bees",
        "answers": [
            "Jewel Akens"
        ],
        "model_ans": "Bobby Day",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bobby Day</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the power to approve or veto legislation constitution",
        "answers": [
            "the President"
        ],
        "model_ans": "President",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> President </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons of the rugrats are there",
        "answers": [
            "9 seasons",
            "9"
        ],
        "model_ans": "9\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "9\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the minister of local government in zimbabwe",
        "answers": [
            "Hon July Moyo"
        ],
        "model_ans": "July Moyo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July Moyo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the initial effect of the transition from command to market economies in eastern europe",
        "answers": [
            "Inequality of opportunity"
        ],
        "model_ans": "economic growth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> economic growth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did toyota start making cars in the us",
        "answers": [
            "by the early 1980s",
            "1984"
        ],
        "model_ans": "1957",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1957 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many pieces in a terry's chocolate orange",
        "answers": [
            "six",
            "20"
        ],
        "model_ans": "20\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "20\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the saint of killers on preacher",
        "answers": [
            "Graham McTavish"
        ],
        "model_ans": "Dominic Cooper",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dominic Cooper </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the royal proclamation of 1763 end",
        "answers": [
            "the American Revolutionary War",
            "with the American Revolutionary War",
            "1783"
        ],
        "model_ans": "1763",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1763 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is playing the halftime show at super bowl 2016",
        "answers": [
            "Beyonc\u00e9",
            "Coldplay",
            "Bruno Mars"
        ],
        "model_ans": "Bruno Mars",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bruno Mars</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "jonny cash one piece at a time car",
        "answers": [
            "Cadillac"
        ],
        "model_ans": "Johnny Cash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Cash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the minimum wage in france per hour",
        "answers": [
            "11.16",
            "\u20ac9.88 per hour."
        ],
        "model_ans": "10.03 \u20ac\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "10.03 \u20ac\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "describe the three phases of the normal blood clotting process",
        "answers": [
            "blood coagulation",
            "vasoconstriction,"
        ],
        "model_ans": "<phase> Intrinsic pathway: This phase begins when blood vessels are injured, causing platelets to aggregate and form a platelet plug. </phase>\n<phase> Extrinsic pathway: This phase is triggered by the release of</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> \n<phase> Intrinsic pathway: This phase begins when blood vessels are injured, causing platelets to aggregate and form a platelet plug. </phase>\n<phase> Extrinsic pathway: This phase is triggered by the release of</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did amnesia the dark descent come out",
        "answers": [
            "8 September 2010"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the oldest street in the philippines",
        "answers": [
            "Cebu City",
            "Colon Street"
        ],
        "model_ans": "Calle Real",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Calle Real </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the tibia and fibula bone located",
        "answers": [
            "leg"
        ],
        "model_ans": "lower leg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lower leg </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played bat masterson in the tv series",
        "answers": [
            "Gene Barry"
        ],
        "model_ans": "Gene Barry",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gene Barry </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings sugar sugar you are my candy girl",
        "answers": [
            "the Archies"
        ],
        "model_ans": "Billy Field",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Billy Field</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "types of skiing in the winter olympics 2018",
        "answers": [
            "Slalom",
            "Downhill",
            "Super-G",
            "Giant slalom",
            "Slalom \u2013 (SC)"
        ],
        "model_ans": "Alpine skiing, Cross-country skiing, Freestyle skiing, Nordic combined, Ski jumping, Snowboarding",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alpine skiing, Cross-country skiing, Freestyle skiing, Nordic combined, Ski jumping, Snowboarding </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays noah newman on the young and the restless",
        "answers": [
            "Robert Gillespie Adamson IV"
        ],
        "model_ans": "Rory Gibson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rory Gibson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the most games in nfl 2017",
        "answers": [
            "Dallas Cowboys"
        ],
        "model_ans": "Pittsburgh Steelers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pittsburgh Steelers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "under article 1 what is the minimum age required to serve in the house of representatives",
        "answers": [
            "25",
            "25 years old"
        ],
        "model_ans": "25\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "25\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most catches in nfl history",
        "answers": [
            "Jerry Rice"
        ],
        "model_ans": "Jerry Rice",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jerry Rice </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the dlc for rainbow six siege come out",
        "answers": [
            "January 2018"
        ],
        "model_ans": "Ubisoft has not officially announced a release date for the DLC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ubisoft has not officially announced a release date for the DLC </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the great wall of china built to defend against",
        "answers": [
            "nomads from Inner Asia",
            "nomads from Inner Asia."
        ],
        "model_ans": "nomadic tribes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nomadic tribes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the last name galvez come from",
        "answers": [
            "Spanish surname",
            "Spanish"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who opens the church of the holy sepulchre",
        "answers": [
            "the Sunni Muslim family",
            "the Nusaybah family"
        ],
        "model_ans": "Helena",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Helena </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does season 5 of the blacklist resume",
        "answers": [
            "January\u00a031,\u00a02018"
        ],
        "model_ans": "October 21, 2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 21, 2021 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the chinese dragons are protectors of how many seas diggy",
        "answers": [
            "Four Seas",
            "Four"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much money did it cost to make gta v",
        "answers": [
            "137"
        ],
        "model_ans": "265 million dollars\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "265 million dollars\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the angle of the tower of pisa",
        "answers": [
            "about 3.99 degrees",
            "3.99 degrees",
            "at about 3.99 degrees"
        ],
        "model_ans": "3.97 degrees\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3.97 degrees\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the share of agriculture in indian economy",
        "answers": [
            "17.32%",
            "23%"
        ],
        "model_ans": "18%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 18% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does demetrius love in a midsummer night dream",
        "answers": [
            "Helena",
            "Hermia"
        ],
        "model_ans": "Helena",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Helena </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the movie varsity blues come out",
        "answers": [
            "1999",
            "January\u00a015,\u00a01999"
        ],
        "model_ans": "1999\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1999\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the champions league quarter finals start",
        "answers": [
            "16 March 2018",
            "3\u20134 April 2018"
        ],
        "model_ans": "The Champions League quarter-finals typically start in April, with the exact dates varying from year to year.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Champions League quarter-finals typically start in April, with the exact dates varying from year to year. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the famous scientist that ran the research lab moseley went to in manchester",
        "answers": [
            "Sir Ernest Rutherford"
        ],
        "model_ans": "J.J. Thomson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>J.J. Thomson</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do you get a cashiers check from",
        "answers": [
            "a bank",
            "bank"
        ],
        "model_ans": "Bank",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bank </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does stefan marry in the vampire diaries",
        "answers": [
            "Caroline Forbes"
        ],
        "model_ans": "Elena Gilbert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Elena Gilbert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of cc and bcc",
        "answers": [
            "Carbon copy",
            "Carbon copy to secondary recipients",
            "Blind carbon copy"
        ],
        "model_ans": "cc stands for carbon copy, and bcc stands for blind carbon copy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cc stands for carbon copy, and bcc stands for blind carbon copy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "hazels boyfriend in the fault in our stars",
        "answers": [
            "Augustus Waters"
        ],
        "model_ans": "Augustus Waters",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Augustus Waters </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the day of the dead end",
        "answers": [
            "November 2"
        ],
        "model_ans": "November 2nd",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> November 2nd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do you celebrate birthday if born on feb 29",
        "answers": [
            "February 29",
            "February 28",
            "March 1"
        ],
        "model_ans": "Leap Day",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leap Day </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does new york drinking water come from",
        "answers": [
            "the eastern Catskill Mountains"
        ],
        "model_ans": "New York City's drinking water comes from a combination of sources, including the Catskill Mountains, the Croton Watershed, and the Delaware River.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York City's drinking water comes from a combination of sources, including the Catskill Mountains, the Croton Watershed, and the Delaware River. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the citrus bowl held this year",
        "answers": [
            "Camping World Stadium"
        ],
        "model_ans": "Orlando",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Orlando </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what year does the quiet man take place",
        "answers": [
            "the 1920s",
            "In the 1920s"
        ],
        "model_ans": "1952",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1952 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many seasons of rules of engagement is there",
        "answers": [
            "7",
            "seven"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays alec ramsay in the black stallion",
        "answers": [
            "Kelly Reno"
        ],
        "model_ans": "Kelly Reno",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kelly Reno </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays dusty in the movie pure country",
        "answers": [
            "George Strait"
        ],
        "model_ans": "George Strait",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Strait </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many episodes of greys anatomy season 14",
        "answers": [
            "24",
            "24 episodes",
            "21"
        ],
        "model_ans": "24\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "24\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is currently serving as president of the senate",
        "answers": [
            "Orrin Hatch",
            "Patrick Leahy"
        ],
        "model_ans": "Kamala Harris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kamala Harris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what percentage of sunlight is captured by plants to convert it into food energy",
        "answers": [
            "45%",
            "3 to 6%"
        ],
        "model_ans": "3-6%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3-6% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of economic system was utilized in the soviet union",
        "answers": [
            "communism",
            "state ownership"
        ],
        "model_ans": "socialist",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> socialist </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many gold medals did australia win in the 2000 olympics",
        "answers": [
            "16"
        ],
        "model_ans": "58\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "58\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who started ww2 and how did it start",
        "answers": [
            "Nazi Germany"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the royal mint move to wales",
        "answers": [
            "1968",
            "the 1960s.",
            "17 December 1968",
            "the 1960s"
        ],
        "model_ans": "1980",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1980 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did bird is the word come out",
        "answers": [
            "1963"
        ],
        "model_ans": "2003",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2003 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how tall is the actor who plays hagrid in harry potter",
        "answers": [
            "6ft 1in"
        ],
        "model_ans": "6 feet 7 inches",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 feet 7 inches </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is opening for little mix glory days tour",
        "answers": [
            "Sheppard",
            "Zoe Badwi",
            "Louisa Johnson",
            "Bronnie",
            "The Vamps",
            "Ella Eyre",
            "Conor Maynard"
        ],
        "model_ans": "Anne-Marie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anne-Marie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who performed the first c section in 1794",
        "answers": [
            "Dr. Jesse Bennett"
        ],
        "model_ans": "Jean-Louis Baudelocque",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Louis Baudelocque </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who voices randy in f is for family",
        "answers": [
            "T.J. Miller"
        ],
        "model_ans": "Justin Roiland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Justin Roiland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bible verse taking the lord's name in vain",
        "answers": [
            "Exodus 20:7"
        ],
        "model_ans": "Exodus 20:7",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exodus 20:7 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who controlled the house and the senate in 2012",
        "answers": [
            "Republican",
            "Democratic"
        ],
        "model_ans": "Democratic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Democratic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when's the last time army won the army navy game",
        "answers": [
            "2017",
            "Army"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does thomas rhett's new album come out",
        "answers": [
            "September 8, 2017"
        ],
        "model_ans": "August 13, 2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 13, 2021 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the champions league final in 2016",
        "answers": [
            "Real Madrid"
        ],
        "model_ans": "Real Madrid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Real Madrid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the real killer in basic instinct 2",
        "answers": [
            "Catherine Tramell"
        ],
        "model_ans": "Catherine Tramell",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Catherine Tramell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of mickey mouse on mickey mouse clubhouse",
        "answers": [
            "Bret Iwan",
            "Wayne Allwine"
        ],
        "model_ans": "Wayne Allwine",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Wayne Allwine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last episode of vampire diaries aired",
        "answers": [
            "March\u00a010,\u00a02017",
            "March 10, 2017"
        ],
        "model_ans": "March 10, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 10, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the dewey decimal system come from",
        "answers": [
            "Melvil Dewey"
        ],
        "model_ans": "Dewey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dewey </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the jungle book story come from",
        "answers": [
            "English author Rudyard Kipling"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "derek and meredith get back together season 3",
        "answers": [
            "Staring at the Sun"
        ],
        "model_ans": "No",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did america declare war on in ww1",
        "answers": [
            "Austria-Hungary"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played zoe hart on hart of dixie",
        "answers": [
            "Rachel Sarah Bilson"
        ],
        "model_ans": "Jessica Lucas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jessica Lucas</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was tom hanks character name in castaway",
        "answers": [
            "Chuck Noland"
        ],
        "model_ans": "Chuck Noland",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chuck Noland </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what engine is in a holden v8 supercar",
        "answers": [
            "V8-engine"
        ],
        "model_ans": "Chevrolet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chevrolet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the sat become out of 1600",
        "answers": [
            "March 2016",
            "2014",
            "2016"
        ],
        "model_ans": "1600",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1600 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the minimum wage established in the united states",
        "answers": [
            "1938",
            "1933",
            "1912"
        ],
        "model_ans": "1938",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1938 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the rational dress society begin to work",
        "answers": [
            "1881"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the baby elephants name in jungle book",
        "answers": [
            "Hathi Jr."
        ],
        "model_ans": "Raja",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Raja </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is fe best absorbed in the body",
        "answers": [
            "in the duodenum",
            "the duodenum"
        ],
        "model_ans": "small intestine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> small intestine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the biggest selling female group of all time",
        "answers": [
            "Spice Girls"
        ],
        "model_ans": "Spice Girls",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Spice Girls </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "epidemiologists attempt to explain the link between health and variables such as",
        "answers": [
            "biological agents",
            "disease conditions in defined populations",
            "smoking",
            "stress",
            "chemicals",
            "alcohol"
        ],
        "model_ans": "lifestyle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lifestyle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the mens single ice skating 2018",
        "answers": [
            "Yuzuru Hanyu",
            "Javier Fern\u00e1ndez",
            "Shoma Uno"
        ],
        "model_ans": "Yuzuru Hanyu",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuzuru Hanyu </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the boy who played charlie in willy wonka",
        "answers": [
            "Peter Gardner[4] Ostrum",
            "Lowville, New York"
        ],
        "model_ans": "Jean-Pierre Franc",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Pierre Franc </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first session of the assam association held in1905",
        "answers": [
            "Guwahati"
        ],
        "model_ans": "Guwahati",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Guwahati </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played ice queen in chronicles of narnia",
        "answers": [
            "Tilda Swinton",
            "Laura Brent"
        ],
        "model_ans": "Tilda Swinton",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tilda Swinton </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is season 2 of jessica jones being released",
        "answers": [
            "March 8, 2018"
        ],
        "model_ans": "March 8, 2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 8, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was united nations convention on the rights of the child created",
        "answers": [
            "20 November 1989"
        ],
        "model_ans": "1989\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1989\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "swan lake the sleeping beauty and the nutcracker are three famous ballets by",
        "answers": [
            "Pyotr Ilyich Tchaikovsky"
        ],
        "model_ans": "Ballets by Tchaikovsky",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Ballets by Tchaikovsky</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of database is library literature and information science",
        "answers": [
            "bibliographic database",
            "bibliographic"
        ],
        "model_ans": "Bibliographic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bibliographic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the united states start using the death penalty",
        "answers": [
            "the beginning",
            "1608"
        ],
        "model_ans": "1608",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1608 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was coffee first made into a drink",
        "answers": [
            "15th century",
            "the 15th century"
        ],
        "model_ans": "15th century",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 15th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is jared on the bold and the beautiful",
        "answers": [
            "Andrew Collins"
        ],
        "model_ans": "Jared Zevon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jared Zevon </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote knock knock knocking on heavens door",
        "answers": [
            "Bob Dylan"
        ],
        "model_ans": "Bob Dylan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bob Dylan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the movie napoleon dynamite come out",
        "answers": [
            "June\u00a011,\u00a02004",
            "2004"
        ],
        "model_ans": "2004\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2004\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who starred in an officer and a gentleman",
        "answers": [
            "Richard Gere",
            "David Keith",
            "Louis Gossett Jr.",
            "Debra Winger",
            "Phillip J. Salmon"
        ],
        "model_ans": "Richard Gere",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Gere </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays chummy's mother in call the midwife",
        "answers": [
            "Cheryl Campbell"
        ],
        "model_ans": "Jennifer Kirby",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jennifer Kirby</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name two fibres which are made of proteins",
        "answers": [
            "feathers",
            "hair",
            "wool",
            "fur",
            "silk"
        ],
        "model_ans": "Keratin and Collagen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Keratin and Collagen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many super bowl games has the patriots played in",
        "answers": [
            "10",
            "ten",
            "ten times"
        ],
        "model_ans": "11",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 11 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do they put the tomb vampires in order to burn them during founders day",
        "answers": [
            "the Gilbert building"
        ],
        "model_ans": "The tomb vampires are burned during founders day in the city of New Orleans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The tomb vampires are burned during founders day in the city of New Orleans </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the king and queen of the netherlands",
        "answers": [
            "Queen M\u00e1xima of the Netherlands",
            "King Willem-Alexander"
        ],
        "model_ans": "Willem-Alexander",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Willem-Alexander </answer> <answer> M\u00e1xima </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is gall bladder situated in human body",
        "answers": [
            "beneath the liver"
        ],
        "model_ans": "under the liver",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> under the liver </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the current population of bora bora",
        "answers": [
            "10,605"
        ],
        "model_ans": "10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does tropic of cancer pass in india",
        "answers": [
            "Chhattisgarh",
            "West Bengal",
            "Gujarat",
            "State of Tripura",
            "Jharkhand",
            "State of Mizoram",
            "Madhya Pradesh",
            "Rajasthan"
        ],
        "model_ans": "Mumbai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mumbai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made the song falling in love with you",
        "answers": [
            "Hugo Peretti",
            "George David Weiss",
            "Elvis Presley",
            "Luigi Creatore"
        ],
        "model_ans": "william singe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> william singe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which is produced in plants of narora kakrapar tarapur",
        "answers": [
            "Atomic Power"
        ],
        "model_ans": "Nuclear Power Plants",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nuclear Power Plants </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the first book of percy jackson",
        "answers": [
            "The Lightning Thief"
        ],
        "model_ans": "The Lightning Thief",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Lightning Thief </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was originally cast to play indiana jones",
        "answers": [
            "Tom Selleck"
        ],
        "model_ans": "James Coburn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James Coburn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what proposition made the insurance commissioner an elected position",
        "answers": [
            "Proposition 103",
            "Proposition 103 in 1988"
        ],
        "model_ans": "Proposition 103",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Proposition 103 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played amy grant i i can only imagine",
        "answers": [
            "Nicole DuPort"
        ],
        "model_ans": "Amy Grant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amy Grant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the song only in my dreams",
        "answers": [
            "Debbie Gibson"
        ],
        "model_ans": "The Pretenders",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Pretenders </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who appoints the chair of the federal reserve system",
        "answers": [
            "President of the United States"
        ],
        "model_ans": "The President of the United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The President of the United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wins the next iron chef super chefs",
        "answers": [
            "Zakarian",
            "Geoffrey Zakarian"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does body temperature tend to be lowest",
        "answers": [
            "11 p.m. to 3 a.m."
        ],
        "model_ans": "around 4am",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 4am </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the whiskey ain't workin anymore",
        "answers": [
            "Dennis Locorriere",
            "Marty Stuart",
            "Travis Tritt",
            "Tim Passmore",
            "Travis Tritt and Marty Stuart"
        ],
        "model_ans": "Travis Tritt",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Travis Tritt </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what year is it for the jewish calendar",
        "answers": [
            "AM 5778",
            "5778"
        ],
        "model_ans": "5783\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5783\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "chief ministers of tamil nadu mentioned on wikipedia",
        "answers": [
            "Ramakrishna Ranga Rao",
            "Tanguturi Prakasam",
            "P. Subbarayan",
            "M. G. Ramachandran",
            "Janaki Ramachandran",
            "P. T. Rajan",
            "J. Jayalalithaa",
            "M. Karunanidhi",
            "A. Subbarayalu Reddiar",
            "C. N. Annadurai",
            "P. S. Kumaraswamy Raja",
            "K. Palaniswami",
            "O. Panneerselvam",
            "V.R. Nedunchezhiyan",
            "Raja of Panagal",
            "O. P. Ramaswamy Reddiyar",
            "Kurma Venkata Reddy Naidu",
            "B. Munuswamy Naidu",
            "C. Rajagopalachari"
        ],
        "model_ans": "M. Karunanidhi, J. Jayalalithaa, O. Panneerselvam, Edappadi K. Palaniswami",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> M. Karunanidhi, J. Jayalalithaa, O. Panneerselvam, Edappadi K. Palaniswami </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the function of a political action committee (pac)",
        "answers": [
            "pools campaign contributions from members"
        ],
        "model_ans": "To support political candidates and parties",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To support political candidates and parties </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most followers in the world on instagram",
        "answers": [
            "Instagram's own account",
            "Instagram"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of political system does el salvador have",
        "answers": [
            "a presidential representative democratic republic",
            "\"flawed democracy\"",
            "presidential representative democratic republic"
        ],
        "model_ans": "Presidential republic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Presidential republic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is simple squamous epithelium found in the body",
        "answers": [
            "alveoli",
            "outer layer of skin",
            "capillaries",
            "glomeruli"
        ],
        "model_ans": "lung, blood vessels, and lining of the heart",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> lung, blood vessels, and lining of the heart </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is president of india in present time",
        "answers": [
            "Ram Nath Kovind"
        ],
        "model_ans": "Ram Nath Kovind",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ram Nath Kovind </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what role does the president play in foreign affairs",
        "answers": [
            "negotiates treaties with foreign nations"
        ],
        "model_ans": "The President plays a crucial role in foreign affairs, as they are responsible for making key decisions regarding diplomacy, foreign policy, and international relations.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The President plays a crucial role in foreign affairs, as they are responsible for making key decisions regarding diplomacy, foreign policy, and international relations.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did ole miss beat alabama in football",
        "answers": [
            "October 3, 1970",
            "September 11, 1976",
            "October 13, 2001",
            "October 27, 1894",
            "October 18, 2003",
            "November 5, 1910",
            "October 8, 1988",
            "October 4, 2014",
            "September 19, 2015",
            "October 5, 1968"
        ],
        "model_ans": "2003\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2003\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what grade was arnold from hey arnold in",
        "answers": [
            "fourth"
        ],
        "model_ans": "4th grade\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4th grade\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who translated the play neel darpan into english",
        "answers": [
            "Michael Madhusudan Dutta",
            "Reverend J.Long"
        ],
        "model_ans": "Rabindranath Tagore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rabindranath Tagore </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the miz and maryse show start",
        "answers": [
            "2018"
        ],
        "model_ans": "8:00 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8:00 PM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what channel is celebrity big brother on in the usa",
        "answers": [
            "CBS",
            "on CBS"
        ],
        "model_ans": "CBS",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> CBS </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is on top of us capitol building",
        "answers": [
            "The Statue of Freedom"
        ],
        "model_ans": "Statue of Freedom",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Statue of Freedom </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who made the most free throws in nba history",
        "answers": [
            "Karl Malone"
        ],
        "model_ans": "Stephen Curry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stephen Curry </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the first president to be impeached",
        "answers": [
            "Andrew Johnson",
            "Johnson"
        ],
        "model_ans": "Andrew Johnson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Johnson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why does kerosene oil rise up in the wick of lantern",
        "answers": [
            "capillary action"
        ],
        "model_ans": "due to capillary action",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> due to capillary action </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the sims 4 toddlers come out",
        "answers": [
            "January 2017",
            "January 12, 2017",
            "the January 2017 patch"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes of season 5 of curse of oak island",
        "answers": [
            "18"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes of touching evil are there",
        "answers": [
            "16"
        ],
        "model_ans": "26",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 26 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "hyori bed and breakfast season 2 air date",
        "answers": [
            "February 4, 2018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "if a piece of music is perceived to have changed key then we say the piece has",
        "answers": [
            "transposed",
            "transposition"
        ],
        "model_ans": "modulated",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> modulated </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most gold medals in the winter olympics of all time",
        "answers": [
            "Norway"
        ],
        "model_ans": "Bj\u00f8rn D\u00e6hlie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bj\u00f8rn D\u00e6hlie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the song let me love you",
        "answers": [
            "DJ Snake featuring Justin Bieber",
            "Justin Bieber",
            "Singh H Spot"
        ],
        "model_ans": "Mario",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mario </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the fourth movie of the divergent series coming out",
        "answers": [
            "never made"
        ],
        "model_ans": "There is no official announcement about the release date of the fourth movie of the Divergent series",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official announcement about the release date of the fourth movie of the Divergent series </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the cast of don't tell mom the babysitter's dead",
        "answers": [
            "Kimmy Robertson",
            "Jeff Bollow",
            "John Getz",
            "Keith Coogan",
            "Joanna Cassidy",
            "Concetta Tomei",
            "Robert Hy Gorman",
            "David Duchovny",
            "Jayne Brook",
            "Eda Reiss Merin",
            "Christopher Pettiet",
            "Dan Castellaneta (voice)",
            "Josh Charles",
            "Danielle Harris",
            "Michael Kopelow",
            "Christina Applegate"
        ],
        "model_ans": "Christina Applegate, Joanna Cassidy, and Josh Charles",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Christina Applegate, Joanna Cassidy, and Josh Charles </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the outer layer of the skin that contains no blood or nerve supply is the",
        "answers": [
            "epidermis"
        ],
        "model_ans": "epidermis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> epidermis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the battle of the first battle of bull run",
        "answers": [
            "Confederate victory",
            "Confederate forces",
            "Confederate"
        ],
        "model_ans": "Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which country has the most coastline in the world",
        "answers": [
            "Canada"
        ],
        "model_ans": "Canada",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Canada </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won battle of the sexes tennis game",
        "answers": [
            "Billie Jean King"
        ],
        "model_ans": "Borg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Borg</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won in the brown vs board of education case",
        "answers": [
            "defendants"
        ],
        "model_ans": "Brown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "ganglion axons forming the optic nerve run to the",
        "answers": [
            "pretectal nucleus",
            "suprachiasmatic nucleus",
            "photoreceptor cells",
            "lateral geniculate nucleus",
            "optic chiasma"
        ],
        "model_ans": "brain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> brain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the word of wisdom become mandatory",
        "answers": [
            "February 1834"
        ],
        "model_ans": "1835",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1835 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "element named after fictional planet from which superman came",
        "answers": [
            "Kryptonite"
        ],
        "model_ans": "Krypton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Krypton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote and performed i can only imagine",
        "answers": [
            "Bart Millard",
            "Christian rock band MercyMe",
            "MercyMe"
        ],
        "model_ans": "TobyMac",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> TobyMac </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what are the active materials of a lead acid battery",
        "answers": [
            "Lead",
            "sulfuric acid",
            "Lead and lead dioxide",
            "lead dioxide"
        ],
        "model_ans": "Lead dioxide (PbO2) and sponge lead (Pb)",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lead dioxide (PbO2) and sponge lead (Pb)</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the roman name for a liberal arts education is known as",
        "answers": [
            "liberalia studia",
            "artes liberales"
        ],
        "model_ans": "liberalium artium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> liberalium artium </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings you're welcome in moana credits",
        "answers": [
            "Dwayne Johnson",
            "Lin-Manuel Miranda",
            "Jordan Fisher"
        ],
        "model_ans": "Lin-Manuel Miranda",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lin-Manuel Miranda </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who developed the central processing unit (cpu)",
        "answers": [
            "John von Neumann"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was kat slater's sisters in eastenders",
        "answers": [
            "Zoe",
            "Little Mo",
            "Lynne"
        ],
        "model_ans": "Zoe Slater",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zoe Slater </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is katie running from in safe haven",
        "answers": [
            "her abusive husband"
        ],
        "model_ans": "her past",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> her past </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they replace lead with graphite in pencils",
        "answers": [
            "never contained the element lead"
        ],
        "model_ans": "1822",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1822 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what started the war between us and japan",
        "answers": [
            "attack on Pearl Harbor"
        ],
        "model_ans": "Pearl Harbor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pearl Harbor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how old is the actress who plays phyllis on y&r",
        "answers": [
            "Gina Tognoni",
            "age\u00a044"
        ],
        "model_ans": "72",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 72 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the french declaration of the rights of man and of the citizen",
        "answers": [
            "General Lafayette",
            "Honor\u00e9 Mirabeau",
            "Lafayette",
            "Thomas Jefferson"
        ],
        "model_ans": "National Constituent Assembly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> National Constituent Assembly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does sam realize he is jim in ghost whisperer",
        "answers": [
            "Leap of Faith"
        ],
        "model_ans": "Season 5, Episode 13",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 5, Episode 13 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what size engine does a 2005 honda civic have",
        "answers": [
            "1169\u00a0cc"
        ],
        "model_ans": "1.7L",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.7L </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won college basketball player of the year",
        "answers": [
            "A'ja Wilson",
            "Jalen Brunson"
        ],
        "model_ans": "Anthony Davis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anthony Davis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a single period of precession of earth's axis is completed in about",
        "answers": [
            "approximately 26,000 years",
            "26,000 years"
        ],
        "model_ans": "26,000 years",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 26,000 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "locations for the film an englishman who went up a hill",
        "answers": [
            "Llanrhaeadr-ym-Mochnant",
            "Llansilin in Powys"
        ],
        "model_ans": "Wales",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wales </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "rizal finished all the chapters of the novel noli me tangere in",
        "answers": [
            "December 1886",
            "Spanish"
        ],
        "model_ans": "1896\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1896\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the superbowl national anthem in 2017",
        "answers": [
            "Luke Bryan"
        ],
        "model_ans": "Lady Gaga",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lady Gaga </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the singing in into the woods",
        "answers": [
            "the cast",
            "the cast members"
        ],
        "model_ans": "Idina Menzel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Idina Menzel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which country has won maximum number of gold medal in asian game 2014",
        "answers": [
            "China"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which country is the last member of saarc",
        "answers": [
            "Afghanistan"
        ],
        "model_ans": "Bhutan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bhutan</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays timon in lion king on broadway",
        "answers": [
            "Max Casella"
        ],
        "model_ans": "Adam Lambert",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Adam Lambert </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what caused the breakup of the democratic republican party",
        "answers": [
            "the disputed 1824 presidential election"
        ],
        "model_ans": "The party was dissolved in 1869",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The party was dissolved in 1869 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "most passing yards in nfl history in a game",
        "answers": [
            "Norm Van Brocklin",
            "554"
        ],
        "model_ans": "554 yards by Norm Van Brocklin\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "554 yards by Norm Van Brocklin\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the most college football national champions",
        "answers": [
            "Princeton"
        ],
        "model_ans": "Alabama",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alabama </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what languages are spoken in india the most",
        "answers": [
            "Bengali",
            "Telugu",
            "Marathi",
            "Hindi",
            "English"
        ],
        "model_ans": "Hindi, Bengali, Telugu, Marathi, Tamil",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hindi, Bengali, Telugu, Marathi, Tamil </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the hyena in lion king",
        "answers": [
            "Banzai",
            "Shenzi",
            "Ed"
        ],
        "model_ans": "Shenzi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shenzi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the meaning of the dragon boat festival",
        "answers": [
            "commemorating fealty and filial piety"
        ],
        "model_ans": "Dragon Boat Festival is a traditional Chinese holiday celebrated on the fifth day of the fifth month of the traditional Chinese calendar, which usually falls in late May or early June.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dragon Boat Festival is a traditional Chinese holiday celebrated on the fifth day of the fifth month of the traditional Chinese calendar, which usually falls in late May or early June. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the real name of saudi arabia",
        "answers": [
            "the Saudi Arab kingdom"
        ],
        "model_ans": "Saudi Arabia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saudi Arabia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the function of the pericardial sac",
        "answers": [
            "Lubricates the heart"
        ],
        "model_ans": "to protect the heart",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to protect the heart </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "chris cornell she's going to change the world",
        "answers": [
            "Can't Change Me"
        ],
        "model_ans": "Chris Cornell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chris Cornell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played the mad hatter in the batman tv show",
        "answers": [
            "Roddy McDowall",
            "David Wayne",
            "Benedict Samuel"
        ],
        "model_ans": "David Warner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Warner </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the colorado kid in rio bravo",
        "answers": [
            "Ricky Nelson"
        ],
        "model_ans": "Dean Stockwell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dean Stockwell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "other than water what else has hydrogen bonds",
        "answers": [
            "inorganic molecules such as water"
        ],
        "model_ans": "DNA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> DNA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was when we first met netflix filmed",
        "answers": [
            "New Orleans"
        ],
        "model_ans": "Toronto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toronto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the viceroy when the simon commission visited india",
        "answers": [
            "Lord Irwin"
        ],
        "model_ans": "Lord Chelmsford",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lord Chelmsford </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what category was hurricane charley when it hit florida",
        "answers": [
            "4",
            "Category 4",
            "Category\u00a04"
        ],
        "model_ans": "Category 4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " Category 4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the united states host the world cup",
        "answers": [
            "1994"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "is parallax more pronounced with nearby stars or with distant stars",
        "answers": [
            "nearby objects",
            "nearby"
        ],
        "model_ans": "nearby stars",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nearby stars </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the us not go to the olympics",
        "answers": [
            "The 1980 Summer Olympics",
            "1980"
        ],
        "model_ans": "1940",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1940 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "number 4 in roman numerals on clock faces",
        "answers": [
            "IV"
        ],
        "model_ans": "4\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "4\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last year the eagles went to the superbowl",
        "answers": [
            "following the 2017 season",
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the team that beat the eagles this season",
        "answers": [
            "Dallas Cowboys",
            "Seattle Seahawks",
            "Kansas City Chiefs"
        ],
        "model_ans": "San Francisco 49ers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Francisco 49ers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did lionel messi play his first game for barcelona",
        "answers": [
            "2002",
            "2001",
            "October 2004"
        ],
        "model_ans": "2004\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2004\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the super heavyweight gold medal at the 2000 olympics",
        "answers": [
            "Audley Harrison"
        ],
        "model_ans": "Audley Harrison",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Audley Harrison </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who turns into a bear in the hobbit",
        "answers": [
            "Beorn"
        ],
        "model_ans": "Bilbo Baggins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bilbo Baggins</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "batman the enemy with episode 5 release date",
        "answers": [
            "March\u00a027,\u00a02018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "yeh hai mohabbatein serial star cast real name",
        "answers": [
            "Divyanka Tripathi and Karan Patel"
        ],
        "model_ans": "Raman Kumar Bhalla (played by Karan Patel), Ishita Iyer (played by Divyanka Tripathi), Raman's mother Shobha (played by Anita Hassanandani), and others",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Raman Kumar Bhalla (played by Karan Patel), Ishita Iyer (played by Divyanka Tripathi), Raman's mother Shobha (played by Anita Hassanandani), and others </answer>\n<</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the slide placed on the microscope",
        "answers": [
            "stage",
            "on the microscope's stage"
        ],
        "model_ans": "on the stage",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> on the stage </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did mcgee became a regular on ncis",
        "answers": [
            "in season two",
            "season two"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who owns the crown plaza hotel in chicago illinois",
        "answers": [
            "InterContinental Hotels Group"
        ],
        "model_ans": "Hilton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hilton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time the eu was audited",
        "answers": [
            "1994"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the legend of heroes trails in the sky the 3rd vita",
        "answers": [
            "July 14, 2016"
        ],
        "model_ans": "Falcom",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Falcom </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was a series of unfortunate events published",
        "answers": [
            "September 1999"
        ],
        "model_ans": "2008\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2008\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who will win 2018 election in sri lanka",
        "answers": [
            "Sri Lanka Podujana Peramuna"
        ],
        "model_ans": "Maithripala Sirisena",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maithripala Sirisena </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name for the ch3coo- ion",
        "answers": [
            "polyatomic anion"
        ],
        "model_ans": "acetate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> acetate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of government did the ming dynasty have",
        "answers": [
            "imperial rule"
        ],
        "model_ans": "Imperial monarchy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Imperial monarchy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did us fight in world war 1",
        "answers": [
            "Germany",
            "Austria-Hungary"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was rosencrantz and guildenstern are dead written",
        "answers": [
            "1966"
        ],
        "model_ans": "1966\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1966\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "nuclear power plant that blew up in russia",
        "answers": [
            "Chernobyl Nuclear Power Plant",
            "Chernobyl",
            "the Chernobyl Nuclear Power Plant"
        ],
        "model_ans": "Chernobyl",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chernobyl </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang picking up pebbles and throwing them into the sea",
        "answers": [
            "Matt Flinders"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many breeds of pigs are there in the uk",
        "answers": [
            "---"
        ],
        "model_ans": "24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the battle of corinth take place",
        "answers": [
            "in Corinth, Mississippi",
            "Corinth, Mississippi"
        ],
        "model_ans": "Corinth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Corinth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the song i'll never forget you",
        "answers": [
            "Mariah Carey",
            "Zara Larsson and MNEK",
            "Noisettes"
        ],
        "model_ans": "J. Balvin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> J. Balvin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played shmuel in the boy in the striped pyjamas",
        "answers": [
            "Jack Scanlon"
        ],
        "model_ans": "Asa Butterfield",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asa Butterfield </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang rip it up and start again",
        "answers": [
            "Scottish post-punk band Orange Juice",
            "Orange Juice"
        ],
        "model_ans": "Pet Shop Boys",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pet Shop Boys </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the 4 types of nitrogenous bases",
        "answers": [
            "cytosine (C)",
            "adenine (A)",
            "uracil (U)",
            "thymine (T)",
            "guanine (G)"
        ],
        "model_ans": "Adenine, Guanine, Cytosine, Uracil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Adenine, Guanine, Cytosine, Uracil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are alkali metals located on the periodic table",
        "answers": [
            "in the s-block",
            "group 1"
        ],
        "model_ans": "Group 1",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Group 1 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the capital city of alabama located",
        "answers": [
            "Montgomery"
        ],
        "model_ans": "Montgomery",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montgomery </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what year did the us hockey team won the olympics",
        "answers": [
            "1960",
            "1960 and 1980",
            "1980"
        ],
        "model_ans": "1980\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1980\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the order of the netflix marvel shows",
        "answers": [
            "Marvel's Iron Fist",
            "Marvel's Daredevil",
            "Marvel's The Punisher",
            "Marvel's Jessica Jones",
            "Marvel's The Defenders",
            "Marvel's Luke Cage"
        ],
        "model_ans": "Iron Fist, Daredevil, Jessica Jones, Luke Cage, The Defenders, The Punisher, The Runaways, Cloak & Dagger, The Inhumans, The Gifted",
        "model_confidence": "unsure</confidence",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Iron Fist, Daredevil, Jessica Jones, Luke Cage, The Defenders, The Punisher, The Runaways, Cloak & Dagger, The Inhumans, The Gifted </answer>\n<confidence>unsure</confidence</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the broncos beat in the super bowl",
        "answers": [
            "Carolina Panthers",
            "Atlanta Falcons",
            "Green Bay Packers"
        ],
        "model_ans": "Atlanta Falcons",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Atlanta Falcons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who had created the second bank of the united states",
        "answers": [
            "President James Madison",
            "James Madison"
        ],
        "model_ans": "Alexander Hamilton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alexander Hamilton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the highest level of fluoride stored in the teeth",
        "answers": [
            "surface of the enamel"
        ],
        "model_ans": "Enamel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enamel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was as you like it first performed",
        "answers": [
            "1603"
        ],
        "model_ans": "1602",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1602 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the latest version of chrome released",
        "answers": [
            "2018-01-22"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made delhi as capital for the first time",
        "answers": [
            "the Pandavas"
        ],
        "model_ans": "Mughal Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mughal Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is tinker air force base named after",
        "answers": [
            "Major General Clarence L. Tinker"
        ],
        "model_ans": "Tinker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tinker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when were the winnie the pooh books written",
        "answers": [
            "1924",
            "1926",
            "1927",
            "1928"
        ],
        "model_ans": "1924\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1924\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is final season of game of thrones",
        "answers": [
            "The eighth",
            "eighth",
            "the eighth season"
        ],
        "model_ans": "season 8",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> season 8 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do new episodes of riverdale season 2 come out",
        "answers": [
            "February\u00a07,\u00a02018",
            "April\u00a018,\u00a02018",
            "October\u00a011,\u00a02017",
            "TBA",
            "January\u00a031,\u00a02018"
        ],
        "model_ans": "October 11, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 11, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is arachidonic acid found in the body",
        "answers": [
            "brain",
            "muscles",
            "liver"
        ],
        "model_ans": "fatty tissues",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fatty tissues </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most all ireland hurling medals",
        "answers": [
            "Henry Shefflin"
        ],
        "model_ans": "Henry Shefflin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry Shefflin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who hit the first home run in the houston astrodome",
        "answers": [
            "Mickey Mantle"
        ],
        "model_ans": "Rusty Staub",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rusty Staub </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the eagles play in the superbowl",
        "answers": [
            "February 6, 2005"
        ],
        "model_ans": "1980",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1980 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when will fairy tail final season be released",
        "answers": [
            "2018"
        ],
        "model_ans": "There is no official announcement about the release date of Fairy Tail's final season",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official announcement about the release date of Fairy Tail's final season </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did seat belts become law in ontario",
        "answers": [
            "January 1, 1976"
        ],
        "model_ans": "1978\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1978\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did response to state of the union start",
        "answers": [
            "in 1966",
            "1966"
        ],
        "model_ans": "1913",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1913 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does madea's family funeral come out",
        "answers": [
            "2018"
        ],
        "model_ans": "2006",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did canada get rid of the death penalty",
        "answers": [
            "July 14, 1976",
            "1976",
            "1998"
        ],
        "model_ans": "1976",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the new gotham season come out",
        "answers": [
            "September\u00a021,\u00a02017",
            "September 21, 2017"
        ],
        "model_ans": "October 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who lasted the longest in the royal rumble",
        "answers": [
            "Rey Mysterio"
        ],
        "model_ans": "Rey Mysterio",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Rey Mysterio </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "star wars episode ii attack of the clones characters",
        "answers": [
            "Chancellor Palpatine / Darth Sidious",
            "Anakin Skywalker",
            "Mace Windu",
            "Padm\u00e9 Amidala",
            "R2-D2",
            "Yoda",
            "Count Dooku / Darth Tyranus",
            "Obi-Wan Kenobi",
            "C-3PO"
        ],
        "model_ans": "Anakin Skywalker, Obi-Wan Kenobi, Padm\u00e9 Amidala, Mace Windu, Yoda",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anakin Skywalker, Obi-Wan Kenobi, Padm\u00e9 Amidala, Mace Windu, Yoda </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does hp mean in war and order",
        "answers": [
            "hit points or health points"
        ],
        "model_ans": "Heavy Pistol",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Heavy Pistol </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the owner of reading football club",
        "answers": [
            "Xiu Li Dai",
            "Dai Xiuli",
            "Dai Yongge",
            "Yongge Dai"
        ],
        "model_ans": "Dai Yongge",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Dai Yongge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is given credit for the gnu initiative",
        "answers": [
            "Richard Stallman"
        ],
        "model_ans": "GNU",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> GNU </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is edmund on days of our lives",
        "answers": [
            "Adam Caine"
        ],
        "model_ans": "Edmund",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edmund </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the nba create the 3 point line",
        "answers": [
            "the 1979\u201380 season",
            "1979\u201380 season"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is an example of a tricyclic antidepressant",
        "answers": [
            "Amineptine"
        ],
        "model_ans": "amitriptyline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> amitriptyline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the canadian pacific railway started and finished",
        "answers": [
            "between 1881 and 1885"
        ],
        "model_ans": "1881-1885",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1881-1885 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the creature on jeepers creepers 3",
        "answers": [
            "Jonathan Breck"
        ],
        "model_ans": "Jonathan Breck",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jonathan Breck </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays unis in she's the man",
        "answers": [
            "Emily Perkins"
        ],
        "model_ans": "Justin Long",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Justin Long </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the mom on what's eating gilbert grape",
        "answers": [
            "Darlene Cates"
        ],
        "model_ans": "Judy Davis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Judy Davis</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the fertile crescent is located between what two bodies of water",
        "answers": [
            "Tigris and Euphrates rivers",
            "Tigris",
            "Euphrates"
        ],
        "model_ans": "Tigris and Euphrates rivers",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tigris and Euphrates rivers </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what episode does goku give up against cell",
        "answers": [
            "165",
            "180"
        ],
        "model_ans": "Episode 194",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Episode 194 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "sri lanka belongs to which part of asia",
        "answers": [
            "South Asia"
        ],
        "model_ans": "South Asia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South Asia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the first nuclear power plant opened",
        "answers": [
            "December 20, 1951",
            "June 27, 1954",
            "On June 27, 1954",
            "the USSR",
            "December 2, 1942"
        ],
        "model_ans": "1951",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1951 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in nanny mcphee and the big bang",
        "answers": [
            "Ewan McGregor"
        ],
        "model_ans": "Colin Firth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Colin Firth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the taming ofthe shrew first performed",
        "answers": [
            "prior to June 1592"
        ],
        "model_ans": "1594\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1594\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many languages in harry potter translated into",
        "answers": [
            "over 74",
            "over 74 languages"
        ],
        "model_ans": "80",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time giants won superbowl",
        "answers": [
            "2011"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the co hosts on the real",
        "answers": [
            "Tamar Braxton",
            "Loni Love",
            "Adrienne Houghton",
            "Tamera Mowry-Housley",
            "Jeannie Mai"
        ],
        "model_ans": "Robin Roberts and George Stephanopoulos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robin Roberts and George Stephanopoulos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "to transplant a nucleus from one cell to another cell a scientist would use",
        "answers": [
            "somatic cell nuclear transfer"
        ],
        "model_ans": "microinjection",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> microinjection </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the golden state warriors win the finals",
        "answers": [
            "1947",
            "1975",
            "1956",
            "2015",
            "2017"
        ],
        "model_ans": "2015, 2017, 2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2015, 2017, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays general hux in the last jedi",
        "answers": [
            "Domhnall Gleeson"
        ],
        "model_ans": "Domhnall Gleeson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Domhnall Gleeson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who ran the fastest 40 yard dash in the nfl",
        "answers": [
            "Jakeem Grant",
            "John Ross"
        ],
        "model_ans": "John Ross",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John Ross </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time new zealand had an earthquake",
        "answers": [
            "11 Jul 2017"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the actor that plays dr. sean murphy",
        "answers": [
            "Freddie Highmore"
        ],
        "model_ans": "Omar Epps",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Omar Epps </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played gino in a place to call home",
        "answers": [
            "Aldo Mignone"
        ],
        "model_ans": "Damien Garvey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Damien Garvey </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the pirates of the caribbean in order",
        "answers": [
            "On Stranger Tides",
            "At World's End",
            "Dead Men Tell No Tales",
            "Dead Man's Chest"
        ],
        "model_ans": "1. The Curse of the Black Pearl, 2. Dead Man's Chest, 3. At World's End, 4. On Stranger Tides, 5. Dead Men Tell No Tales\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1. The Curse of the Black Pearl, 2. Dead Man's Chest, 3. At World's End, 4. On Stranger Tides, 5. Dead Men Tell No Tales\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does the pearl symbolize in the bible",
        "answers": [
            "the Kingdom of Heaven"
        ],
        "model_ans": "purity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> purity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what album is sacrifice by elton john on",
        "answers": [
            "Sleeping with the Past.",
            "Sleeping with the Past"
        ],
        "model_ans": "The Fox",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Fox </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who proved that cells come from other cells",
        "answers": [
            "Matthias Schleiden",
            "Robert Hooke",
            "Robert Remak",
            "Theodor Schwann",
            "Rudolf Virchow"
        ],
        "model_ans": "Matthias Jakob Schleiden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matthias Jakob Schleiden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who holds the world record for the most world records",
        "answers": [
            "Ashrita Furman"
        ],
        "model_ans": "Ashrita Furman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ashrita Furman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the designer in devil wears prada",
        "answers": [
            "Valentino Garavani"
        ],
        "model_ans": "Meryl Streep",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Meryl Streep </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does dividends go on cash flow statement",
        "answers": [
            "the financing activities section"
        ],
        "model_ans": "Operating Activities",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Operating Activities </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the 50th star added to the united states flag",
        "answers": [
            "1960"
        ],
        "model_ans": "August 21, 1960",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> August 21, 1960 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the ethnic background of the shib sibs",
        "answers": [
            "Japanese"
        ],
        "model_ans": "Asian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Asian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name the four major layers of the earth in order",
        "answers": [
            "a liquid outer core",
            "an outer silicate solid crust",
            "a highly viscous mantle",
            "a solid inner core"
        ],
        "model_ans": "Crust, Mantle, Outer Core, Inner Core",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Crust, Mantle, Outer Core, Inner Core </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how much for a passport in the philippines",
        "answers": [
            "$60 abroad",
            "\u20b1950"
        ],
        "model_ans": "1,200 PHP",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,200 PHP </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was mr.owen in and then there were none",
        "answers": [
            "Justice Lawrence John Wargrave"
        ],
        "model_ans": "Mr. Rogers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mr. Rogers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did gaurdians of the galaxy 2 come out",
        "answers": [
            "2017",
            "May\u00a05,\u00a02017"
        ],
        "model_ans": "May 5, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> May 5, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "kings and queens of england in the 1900s",
        "answers": [
            "George V",
            "George VI",
            "Edward VIII",
            "Elizabeth II",
            "Edward VII"
        ],
        "model_ans": "Edward VII, George V, Edward VIII, George VI",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edward VII, George V, Edward VIII, George VI </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who made the poppies at tower of london",
        "answers": [
            "Paul Cummins",
            "Tom Piper",
            "stage designer Tom Piper"
        ],
        "model_ans": "ceramic artist Paul Cummins",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> ceramic artist Paul Cummins </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what season does bart bass die in gossip girl",
        "answers": [
            ")"
        ],
        "model_ans": "Season 5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the first indian woman to be canonized as a saint",
        "answers": [
            "Saint Alphonsa"
        ],
        "model_ans": "Mother Teresa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mother Teresa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is in charge of ratifying treaties in the us",
        "answers": [
            "the Executive branch",
            "the President",
            "Senate",
            "the Senate"
        ],
        "model_ans": "The President",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The President </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the name of the first earthquake early warning system",
        "answers": [
            "1991",
            "The Mexican Seismic Alert System"
        ],
        "model_ans": "Japan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Japan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time the military drafted",
        "answers": [
            "1973",
            "1972",
            "December 1972"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes of corrie has there been",
        "answers": [
            "9,436"
        ],
        "model_ans": "over 10,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> over 10,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do primary ossification centers appear in an embryo",
        "answers": [
            "prenatal development"
        ],
        "model_ans": "around 6-8 weeks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 6-8 weeks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the biltmore house opened to the public",
        "answers": [
            "March 1930"
        ],
        "model_ans": "1930\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1930\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "most of new zealands land supports which economic activity",
        "answers": [
            "agriculture",
            "Pastoral farming"
        ],
        "model_ans": "agriculture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> agriculture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does hydrogen peroxide come from in the body",
        "answers": [
            "nearly all living cells"
        ],
        "model_ans": "Hydrogen peroxide is produced by the enzyme catalase in the body",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hydrogen peroxide is produced by the enzyme catalase in the body </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote old flames cant hold a candle to you",
        "answers": [
            "Pebe Sebert",
            "Pebe Sebert and Hugh Moffatt",
            "Patricia Rose Sebert",
            "Hugh Moffatt"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the killing of a sacred deer filmed",
        "answers": [
            "Cincinnati"
        ],
        "model_ans": "Dublin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dublin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays hannibal in silence of the lambs",
        "answers": [
            "Anthony Hopkins"
        ],
        "model_ans": "Jodie Foster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jodie Foster</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the dragon queen from game of thrones",
        "answers": [
            "Emilia Clarke"
        ],
        "model_ans": "Daenerys Targaryen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Daenerys Targaryen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the first ice age come out",
        "answers": [
            "2002",
            "March 15, 2002"
        ],
        "model_ans": "40 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the term social justice first used",
        "answers": [
            "the 1840s",
            "1840s"
        ],
        "model_ans": "1840",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1840 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the publishers clearing house sweepstakes drawing",
        "answers": [
            "just after the Super Bowl"
        ],
        "model_ans": "December 31st",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 31st </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the elephant man in the film",
        "answers": [
            "John Hurt"
        ],
        "model_ans": "John Hurt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Hurt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time the ducks won the stanley cup",
        "answers": [
            "(2006\u201307)",
            "2006\u201307"
        ],
        "model_ans": "2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do rory and paris go to college",
        "answers": [
            "Yale University",
            "Yale University,"
        ],
        "model_ans": "Yale",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yale </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the eurovision song contest the most times",
        "answers": [
            "Ireland's Johnny Logan",
            "Ireland"
        ],
        "model_ans": "Ireland",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ireland </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the director of taarak mehta ka ooltah chashmah",
        "answers": [
            "Malav Suresh Rajda",
            "Harshad Joshi"
        ],
        "model_ans": "Asit Kumar Modi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asit Kumar Modi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "genre of diary of a wimpy kid the getaway",
        "answers": [
            "Children's novel",
            "Graphic Novel"
        ],
        "model_ans": "Comedy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Comedy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the met office leaving the bbc",
        "answers": [
            "31 March 2018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is billy last name in where the red fern grows",
        "answers": [
            "Colman",
            "Billy Colman"
        ],
        "model_ans": "Billy Colman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Billy Colman</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did puerto rico belong to before the u.s",
        "answers": [
            "Ta\u00edno",
            "indigenous Ta\u00edno people",
            "Spain"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the population of st petersburg fl",
        "answers": [
            "260,999",
            "257,083"
        ],
        "model_ans": "265,098",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 265,098 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the study of media effects begin",
        "answers": [
            "1919",
            "1975"
        ],
        "model_ans": "1920s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays heather in beauty and the beast",
        "answers": [
            "Nicole Gale Anderson"
        ],
        "model_ans": "Emma Watson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Emma Watson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many customers does edf have in the uk",
        "answers": [
            "5.7 million customer accounts",
            "5.7 million"
        ],
        "model_ans": "12 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the formation of atp take place",
        "answers": [
            "plasma membrane in bacteria",
            "inner mitochondrial membrane",
            "thylakoid membrane",
            "mitochondrial membrane in eukaryotes"
        ],
        "model_ans": "Mitochondria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitochondria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is jack's mother in when calls the heart",
        "answers": [
            "Charlotte Thornton"
        ],
        "model_ans": "Elizabeth Thatcher",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elizabeth Thatcher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the head of the spanish inquisition",
        "answers": [
            "Grand Inquisitor",
            "Tom\u00e1s de Torquemada",
            "Dominican Tom\u00e1s de Torquemada"
        ],
        "model_ans": "Tomas de Torquemada",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tomas de Torquemada </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does istj mean in a personality test",
        "answers": [
            "Extroverted Thinking (Te)",
            "Extroverted Intuition (Ne)",
            "Introverted Sensing (Si)",
            "Introverted Feeling (Fi)"
        ],
        "model_ans": "Introverted, Sensing, Thinking, Judging",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Introverted, Sensing, Thinking, Judging </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons are there for lost girl",
        "answers": [
            "5",
            "five"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays artemisia in 300 rise of an empire",
        "answers": [
            "Caitlin Carmichael",
            "Eva Green",
            "Jade Chynoweth"
        ],
        "model_ans": "Eva Green",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eva Green </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the the regulatory reform (fire safety) order 2005 first come into effect",
        "answers": [
            "1 October 2006"
        ],
        "model_ans": "1 October 2006",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1 October 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the bill of rights come out",
        "answers": [
            "1689",
            "16 December 1689"
        ],
        "model_ans": "1791\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1791\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the east india company take control of india",
        "answers": [
            "in 1757",
            "1757",
            "1799",
            "1612"
        ],
        "model_ans": "1757",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1757 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was elected president in mexico in 2000",
        "answers": [
            "Vicente Fox"
        ],
        "model_ans": "Vicente Fox",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vicente Fox </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does season 6 of the next step start",
        "answers": [
            "2018"
        ],
        "model_ans": "August 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2022 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the sharks play in san jose",
        "answers": [
            "the SAP Center",
            "SAP Center",
            "SAP Center at San Jose"
        ],
        "model_ans": "SAP Center",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SAP Center </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "abbreviated name of the highest peak in tasmania",
        "answers": [
            "Mount Ossa"
        ],
        "model_ans": "MT",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> MT </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played alex cross in along came a spider",
        "answers": [
            "Morgan Freeman"
        ],
        "model_ans": "Morgan Freeman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Morgan Freeman</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most wins on around the horn",
        "answers": [
            "Woody Paige"
        ],
        "model_ans": "Max Kellerman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Max Kellerman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the main sources of economic growth in the us currently",
        "answers": [
            "pharmaceuticals",
            "heavy machinery",
            "telecommunications",
            "aircraft"
        ],
        "model_ans": "Technology, Healthcare, and E-commerce",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Technology, Healthcare, and E-commerce </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the australia's got talent judges",
        "answers": [
            "Kelly Osbourne",
            "Ian Dickson",
            "Ian \"Dicko\" Dickson",
            "Eddie Perfect",
            "Sophie Monk"
        ],
        "model_ans": "Shane Jacobson, Manu Feildel, Kelly Osbourne",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Shane Jacobson, Manu Feildel, Kelly Osbourne </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song i wanna be sedated",
        "answers": [
            "the Ramones"
        ],
        "model_ans": "The Ramones",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Ramones </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the setting of the book hoot",
        "answers": [
            "Florida"
        ],
        "model_ans": "Florida",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Florida </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is season 3 of grace and frankie being released",
        "answers": [
            "March\u00a024,\u00a02017"
        ],
        "model_ans": "Netflix has not officially announced a release date for Season 3 of Grace and Frankie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Netflix has not officially announced a release date for Season 3 of Grace and Frankie </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the sun represent on the uruguay flag",
        "answers": [
            "the May Revolution of 1810"
        ],
        "model_ans": "The sun represents the country's independence and sovereignty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The sun represents the country's independence and sovereignty </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was in charge of the revolutionary war",
        "answers": [
            "General George Washington",
            "the king"
        ],
        "model_ans": "George Washington",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Washington </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "why was hong kong important to the british empire",
        "answers": [
            "a centre for international trade"
        ],
        "model_ans": "Hong Kong was an important strategic location for the British Empire due to its proximity to China and its natural harbor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hong Kong was an important strategic location for the British Empire due to its proximity to China and its natural harbor </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what position did doug peterson play in the nfl",
        "answers": [
            "holder on placekicks",
            "quarterback"
        ],
        "model_ans": "Quarterback",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Quarterback </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is creatine phosphate found in the body",
        "answers": [
            "brain",
            "pancreas",
            "skeletal muscle and the brain",
            "muscle cells",
            "heart"
        ],
        "model_ans": "muscle tissue",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> muscle tissue </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "criminal minds what episode does jj find out she pregnant",
        "answers": [
            "in April 2011",
            "The Crossing"
        ],
        "model_ans": "Season 5 Episode 13",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 5 Episode 13 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was harry potter and the philosophers stone published",
        "answers": [
            "in 1997",
            "1997"
        ],
        "model_ans": "1997\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1997\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the twins in darling buds of may",
        "answers": [
            "Christina Giles",
            "Katherine Giles"
        ],
        "model_ans": "Patsy Kensit and Frances Barber",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Patsy Kensit and Frances Barber </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did skiing halfpipe become an olympic event",
        "answers": [
            "2014"
        ],
        "model_ans": "1998",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1998 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays at the prudential center in newark",
        "answers": [
            "Seton Hall Pirates",
            "New Jersey Devils"
        ],
        "model_ans": "New Jersey Devils",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Jersey Devils </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the first colony in north america located",
        "answers": [
            "Virginia"
        ],
        "model_ans": "Jamestown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jamestown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "during the first world war against which country germany did not fight",
        "answers": [
            "Austria-Hungary"
        ],
        "model_ans": "Italy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Italy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the minnesota vikings lose to in the super bowl",
        "answers": [
            "Pittsburgh Steelers",
            "Oakland Raiders",
            "Miami Dolphins",
            "Kansas City Chiefs"
        ],
        "model_ans": "New Orleans Saints",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New Orleans Saints </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the aztec ruler when the spanish arrived",
        "answers": [
            "Moctezuma II",
            "emperor Cuauhtemoc"
        ],
        "model_ans": "Moctezuma II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Moctezuma II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "product-market fit means being in a good market with a product that can satisfy that market",
        "answers": [
            "Mark Andreessen"
        ],
        "model_ans": "yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does bryce dallas howard play in the grinch",
        "answers": [
            "Surprised Who"
        ],
        "model_ans": "Donna Who",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Donna Who </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the robot on the orville show",
        "answers": [
            "Mark Jackson"
        ],
        "model_ans": "Mark Jackson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Mark Jackson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the group that officially elects the president of the united states is called",
        "answers": [
            "the U.S. Electoral College",
            "U.S. Electoral College"
        ],
        "model_ans": "Electoral College",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electoral College </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many wars held between india and pakistan",
        "answers": [
            "four"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the young and the restless first aired",
        "answers": [
            "March 26, 1973"
        ],
        "model_ans": "March 26, 1973",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 26, 1973 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the emperor name in star wars",
        "answers": [
            "Darth Sidious",
            "Sheev Palpatine"
        ],
        "model_ans": "Palpatine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Palpatine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has won 2017 women's singles korean open series badminton championship",
        "answers": [
            "P. V. Sindhu"
        ],
        "model_ans": "Tai Tzu-ying",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tai Tzu-ying </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the full form of cfc's",
        "answers": [
            "Chlorofluorocarbons"
        ],
        "model_ans": "ChloroFluoroCarbon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ChloroFluoroCarbon </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the most important battles in the revolutionary war",
        "answers": [
            "Philadelphia campaign",
            "Yorktown campaign",
            "Saratoga campaign",
            "Boston campaign",
            "Invasion of Quebec"
        ],
        "model_ans": "Saratoga, Yorktown",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saratoga, Yorktown </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does eric end up with in gossip girl",
        "answers": [
            "Jenny"
        ],
        "model_ans": "Serena van der Woodsen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Serena van der Woodsen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first temple built in jerusalem",
        "answers": [
            "the mid-10th century BCE"
        ],
        "model_ans": "1000 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1000 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the steel mills closed in youngstown ohio",
        "answers": [
            "September 19, 1977"
        ],
        "model_ans": "1977",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1977 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the jets won a playoff game",
        "answers": [
            "2010"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the song it ain't me",
        "answers": [
            "Selena Gomez",
            "American singer Selena Gomez"
        ],
        "model_ans": "Kygo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kygo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "is it marley and me or marley and i",
        "answers": [
            "Marley & Me"
        ],
        "model_ans": "Marley and Me",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marley and Me </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did vat change from 17.5 to 20",
        "answers": [
            "4 January 2011"
        ],
        "model_ans": "2008",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2008 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did seattle slew win the triple crown",
        "answers": [
            "1977",
            "in 1977"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings too much time on my hands lyrics",
        "answers": [
            "Tommy Shaw"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "nba record for most double doubles in a season",
        "answers": [
            "Tim Duncan"
        ],
        "model_ans": "Russell Westbrook",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Russell Westbrook </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is super bowl 2018 half time show",
        "answers": [
            "Justin Timberlake"
        ],
        "model_ans": "Juanes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Juanes</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "all the motor neurons that control the skeletal muscles are",
        "answers": [
            "efferent nerves",
            "Somatic motor neurons",
            "Somatic"
        ],
        "model_ans": "alpha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> alpha </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who became the king of ayodhya after ram",
        "answers": [
            "Kusha"
        ],
        "model_ans": "Bharata",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bharata </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote lyrics for phantom of the opera",
        "answers": [
            "Charles Hart",
            "Charles Hart and Richard Stilgoe",
            "Richard Stilgoe"
        ],
        "model_ans": "Charles Hart",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Charles Hart </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what album is help by the beatles on",
        "answers": [
            "Help!"
        ],
        "model_ans": "Help!",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Help! </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the king of england in 1756",
        "answers": [
            "George II"
        ],
        "model_ans": "George II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the left anterior descending artery located",
        "answers": [
            "the left coronary artery"
        ],
        "model_ans": "Left side of the heart",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Left side of the heart </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the head of the fbi report to",
        "answers": [
            "the Director of National Intelligence",
            "the Attorney General"
        ],
        "model_ans": "The Attorney General of the United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Attorney General of the United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings every light in the house is on",
        "answers": [
            "Trace Adkins"
        ],
        "model_ans": "Chicago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of the harp in ireland",
        "answers": [
            "the arms of Ireland"
        ],
        "model_ans": "Symbol of Ireland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Symbol of Ireland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote got this feeling in my body",
        "answers": [
            "Max Martin",
            "Johan Schuster",
            "Justin Timberlake"
        ],
        "model_ans": "The Human League",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Human League </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does like cage season 2 come out",
        "answers": [
            "June 22, 2018"
        ],
        "model_ans": "There is no information available about the release date of Like Cage Season 2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no information available about the release date of Like Cage Season 2 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did frank sinatra first sing new york new york",
        "answers": [
            "1980",
            "1979"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the salvation army's christmas collection kettle first introduced",
        "answers": [
            "San Francisco",
            "in San Francisco"
        ],
        "model_ans": "New York City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is jojo in horton hears a who",
        "answers": [
            "Jesse McCartney"
        ],
        "model_ans": "Horton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Horton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what song is played while raising the american flag",
        "answers": [
            "Reveille",
            "\"Reveille\""
        ],
        "model_ans": "The Star-Spangled Banner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Star-Spangled Banner </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "this poster was created to increase support for the war effort.the poster links food rationing to",
        "answers": [
            "aiding the war effort"
        ],
        "model_ans": "patriotism",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> patriotism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many countries does cadbury sell its products",
        "answers": [
            "more than 50 countries worldwide",
            "more than 50"
        ],
        "model_ans": "50",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did mcdonald's sell 1 million burgers",
        "answers": [
            "By 1965"
        ],
        "model_ans": "1955",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1955 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the power of supreme court in the philippines",
        "answers": [
            "Justices"
        ],
        "model_ans": "The Supreme Court of the Philippines has the power to interpret the Constitution, declare laws unconstitutional, and issue writs of certiorari, prohibition, mandamus, quo warranto, and habeas corpus.",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Supreme Court of the Philippines has the power to interpret the Constitution, declare laws unconstitutional, and issue writs of certiorari, prohibition, mandamus, quo warranto, and habeas corpus. </answer>\n<confidence></confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the last episode of adventure time air",
        "answers": [
            "TBA"
        ],
        "model_ans": "March 21, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 21, 2018 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the cast members of ncis new orleans",
        "answers": [
            "Zoe McLellan",
            "Lucas Black",
            "Daryl \"Chill\" Mitchell",
            "Shalita Grant",
            "Rob Kerkovich",
            "Vanessa Ferlito",
            "Daryl Mitchell",
            "Scott Bakula",
            "CCH Pounder"
        ],
        "model_ans": "Scott Bakula, Lucas Black, Vanessa Ferlito, CCH Pounder, Rob Kerkovich, Daryl Mitchell, and Necar Zadegan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Scott Bakula, Lucas Black, Vanessa Ferlito, CCH Pounder, Rob Kerkovich, Daryl Mitchell, and Necar Zadegan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what word is used to describe knowledge about the universe and method of obtaining that knowledge",
        "answers": [
            "epistemology",
            "Empiricism"
        ],
        "model_ans": "cosmology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cosmology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many paintings of sunflowers did van gogh paint",
        "answers": [
            "two"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the $1 000 bill discontinued",
        "answers": [
            "1969",
            "December 27, 1945",
            "July 14, 1969"
        ],
        "model_ans": "1969\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1969\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the population of prince edward island",
        "answers": [
            "142,907 residents",
            "142,907"
        ],
        "model_ans": "154,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 154,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many ceos of fortune 500 companies are female",
        "answers": [
            "32"
        ],
        "model_ans": "37",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 37 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the orinoco river located on a map",
        "answers": [
            "in South America"
        ],
        "model_ans": "South America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the debating club established in almora",
        "answers": [
            "1871 A.D.",
            "1871"
        ],
        "model_ans": "1920",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the boston red sox pitched a no-hitter",
        "answers": [
            "May 19, 2008"
        ],
        "model_ans": "August 31, 2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 31, 2007 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the french chef given credit for developing the classic kitchen\u200b brigade",
        "answers": [
            "Georges Auguste Escoffier"
        ],
        "model_ans": "Auguste Escoffier",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Auguste Escoffier </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the cannes film festival take place",
        "answers": [
            "Cannes, France",
            "usually in May"
        ],
        "model_ans": "May",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in pretty in pink",
        "answers": [
            "Harry Dean Stanton"
        ],
        "model_ans": "James M. Stephens",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James M. Stephens </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "unsaturated fats are comprised of lipids that contain",
        "answers": [
            "double bond",
            "at least one double bond"
        ],
        "model_ans": "one or more double bonds",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> one or more double bonds </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when do the new episodes of supernatural start",
        "answers": [
            "May\u00a010,\u00a02018"
        ],
        "model_ans": "October",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the award for best goalkeeper in football world cup 2006",
        "answers": [
            "Gianluigi Buffon"
        ],
        "model_ans": "Gianluigi Buffon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gianluigi Buffon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is upstream project in oil and gas",
        "answers": [
            "drilling exploratory wells"
        ],
        "model_ans": "upstream refers to the exploration and production of oil and gas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> upstream refers to the exploration and production of oil and gas </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "is a network connection device that can build tables that identify addresses on each network",
        "answers": [
            "routing table",
            "a router"
        ],
        "model_ans": "Router",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Router </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the era of the great mughals began with the accession of",
        "answers": [
            "Akbar the Great",
            "Babur"
        ],
        "model_ans": "Babur",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Babur</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the final episode of quantum leap",
        "answers": [
            "\"Mirror Image\""
        ],
        "model_ans": "All Good Things...",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> All Good Things... </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first election held in india",
        "answers": [
            "1951\u201352"
        ],
        "model_ans": "1919",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1919 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has been appointed as the election commissioner of india",
        "answers": [
            "Om Prakash Rawat"
        ],
        "model_ans": "Rajiv Kumar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rajiv Kumar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who discovered cells divide to make new cells",
        "answers": [
            "Hugo von Mohl",
            "German botanist Hugo von Mohl"
        ],
        "model_ans": "Matthias Jakob Schleiden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matthias Jakob Schleiden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does a brisket come from on a cow",
        "answers": [
            "the breast or lower chest",
            "breast or lower chest"
        ],
        "model_ans": "The brisket is a cut of beef that comes from the breast or lower chest area of a cow.",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The brisket is a cut of beef that comes from the breast or lower chest area of a cow. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the parts of a domain name called",
        "answers": [
            "subdomain",
            "top-level domain",
            "hostname"
        ],
        "model_ans": "subdomain, domain name, top-level domain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> subdomain, domain name, top-level domain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does april end up with on parks and rec",
        "answers": [
            "Andy",
            "Andy Dwyer"
        ],
        "model_ans": "Andy Dwyer",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Andy Dwyer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played tom in four weddings and a funeral",
        "answers": [
            "James Fleet"
        ],
        "model_ans": "Hugh Grant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hugh Grant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings don't take your guns to town",
        "answers": [
            "U2",
            "Johnny Cash"
        ],
        "model_ans": "Johnny Cash",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Cash </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did huntington's disease get its name",
        "answers": [
            "the physician George Huntington"
        ],
        "model_ans": "George Huntington",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Huntington </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time michigan won the championship",
        "answers": [
            "1989"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did deion sanders go in the hall of fame as",
        "answers": [
            "Cornerback"
        ],
        "model_ans": "Deion Sanders",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deion Sanders </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the leaders of the jehovah witnesses",
        "answers": [
            "Gerrit L\u00f6sch",
            "Kenneth Cook",
            "Mark Stephen Lett",
            "Mark Sanderson",
            "Anthony Morris III",
            "Samuel F. Herd",
            "David H. Splane",
            "Geoffrey Jackson"
        ],
        "model_ans": "Charles Taze Russell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Taze Russell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was originally cast as phoebe on charmed",
        "answers": [
            "Lori Rom"
        ],
        "model_ans": "Alyssa Milano",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alyssa Milano </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who turned out to be the mother on how i met your mother",
        "answers": [
            "Tracy McConnell"
        ],
        "model_ans": "Tracy McConnell",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tracy McConnell </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "animals that are active at dawn and dusk",
        "answers": [
            "Crepuscular",
            "crepuscular",
            "Crepuscular animals"
        ],
        "model_ans": "Nocturnal animals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nocturnal animals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "whos jack the ripper in gotham by gaslight",
        "answers": [
            "Jacob Packer"
        ],
        "model_ans": "Jack the Ripper",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack the Ripper</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do secondary xylem and phloem cells arise from",
        "answers": [
            "The vascular cambium",
            "the vascular cambium"
        ],
        "model_ans": "cambium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cambium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did johnny manziel play college football for",
        "answers": [
            "Texas A&M",
            "Texas A&M University",
            "Texas A&M Aggies"
        ],
        "model_ans": "Alabama",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alabama </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the christmas song mary did you know",
        "answers": [
            "Michael English"
        ],
        "model_ans": "Brendan Graham",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brendan Graham</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang gonna sit right down and write myself a letter",
        "answers": [
            "Fats Waller"
        ],
        "model_ans": "Bing Crosby",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bing Crosby</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who picks the players in the nfl draft",
        "answers": [
            "each team"
        ],
        "model_ans": "NFL teams",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NFL teams </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings got my mind set on you",
        "answers": [
            "James Ray",
            "George Harrison"
        ],
        "model_ans": "George Michael\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " George Michael\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the song here comes the boom come out",
        "answers": [
            "May 2002",
            "May\u00a014,\u00a02002"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song i think we're alone now",
        "answers": [
            "Tiffany",
            "Tommy James and the Shondells"
        ],
        "model_ans": "Tiffany",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tiffany </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did we first put a rover on mars",
        "answers": [
            "January 2004"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the members of the traveling wilburys group",
        "answers": [
            "Roy Orbison",
            "Jeff Lynne",
            "George Harrison",
            "Bob Dylan",
            "Tom Petty"
        ],
        "model_ans": "Tom Petty, Jeff Lynne, Roy Orbison, George Harrison, Bob Dylan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tom Petty, Jeff Lynne, Roy Orbison, George Harrison, Bob Dylan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won game 4 of the 2000 nba finals",
        "answers": [
            "Los Angeles Lakers"
        ],
        "model_ans": "Los Angeles Lakers",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles Lakers </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the highest peak in the ozarks",
        "answers": [
            "Lookout",
            "Buffalo Lookout"
        ],
        "model_ans": "Taum Sauk Mountain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taum Sauk Mountain </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the last episode of spongebob",
        "answers": [
            "\"Bottle Burglars\"",
            "The String"
        ],
        "model_ans": "Krabby Patty Creature Feature",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Krabby Patty Creature Feature </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last grand slam hit in the world series",
        "answers": [
            "2016"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does episode 29 of boruto come out",
        "answers": [
            "October 18, 2017"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the tv show in the heat of the night filmed",
        "answers": [
            "Decatur in Dekalb County",
            "Atlanta",
            "Covington, Georgia",
            "Hammond, Louisiana"
        ],
        "model_ans": "Warner Bros. Studios",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Warner Bros. Studios </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the judges on do you think you can dance",
        "answers": [
            "Nigel Lythgoe",
            "Mia Michaels",
            "Adam Shankman"
        ],
        "model_ans": "Nigel Lythgoe, Mary Murphy, and Adam Shankman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Nigel Lythgoe, Mary Murphy, and Adam Shankman </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the most common form of megalithic architecture in europe is",
        "answers": [
            "the portal tomb",
            "portal tomb"
        ],
        "model_ans": "Dolmen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dolmen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long was dark side of the moon number 1",
        "answers": [
            "a week",
            "42:49"
        ],
        "model_ans": "108 weeks\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "108 weeks\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the golden age of india took place during the rule of the",
        "answers": [
            "Chandragupta II",
            "Samudragupta",
            "Chandragupta I",
            "Gupta Empire",
            "Vishnu Gupta",
            "the Guptas",
            "Sri-Gupta"
        ],
        "model_ans": "Mauryan Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mauryan Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the origin of the name robinson",
        "answers": [
            "English language patronymic surname"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the first super bowl the eagles ever won",
        "answers": [
            "2017",
            "1948"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the best batting average in test cricket",
        "answers": [
            "Australia's Sir Donald Bradman",
            "Don Bradman",
            "Sir Donald Bradman"
        ],
        "model_ans": "Bradman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bradman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long has it been since eagles went to super bowl",
        "answers": [
            "2018"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who built the tower of london in 1066",
        "answers": [
            "William the Conqueror"
        ],
        "model_ans": "William the Conqueror",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William the Conqueror </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is fulda and what is its significance",
        "answers": [
            "Hesse, Germany",
            "on the river Fulda"
        ],
        "model_ans": "Fulda is a city located in the state of Hesse, Germany. It is known for its historic cathedral and its significance in the region's history and culture.",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Fulda is a city located in the state of Hesse, Germany. It is known for its historic cathedral and its significance in the region's history and culture. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who overthrew the mongols and established the ming dynasty",
        "answers": [
            "Zhu Yuanzhang"
        ],
        "model_ans": "Zhu Yuanzhang",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zhu Yuanzhang </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the first book made into a movie",
        "answers": [
            "1924"
        ],
        "model_ans": "1908\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1908\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did tim hortons open in the usa",
        "answers": [
            "1981"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the reaper invented by cyrus mccormick",
        "answers": [
            "1837",
            "1834"
        ],
        "model_ans": "1831",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1831 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the next scandal episode coming out",
        "answers": [
            "February\u00a01,\u00a02018"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote antigone and what are the dates of his birth and death",
        "answers": [
            "winter 406/5 BC",
            "c. 497/6",
            "Sophocles"
        ],
        "model_ans": "Sophocles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sophocles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what goes on the bottom of shepherd's pie",
        "answers": [
            "minced meat",
            "mashed potato"
        ],
        "model_ans": "Mashed potatoes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mashed potatoes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the ohio river and the mississippi river meet",
        "answers": [
            "Cairo, Illinois"
        ],
        "model_ans": "Cairo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cairo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many kilometers of great wall of china",
        "answers": [
            "8,850\u00a0km",
            "21,196\u00a0km"
        ],
        "model_ans": "13,170 km\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "13,170 km\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they start assigning social security numbers at birth",
        "answers": [
            "1990"
        ],
        "model_ans": "1936\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1936\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "under the federal unemployment tax act which party pays unemployment taxes",
        "answers": [
            "Employers",
            "the employer"
        ],
        "model_ans": "employer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> employer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what are the names of the hunger games",
        "answers": [
            "The Hunger Games"
        ],
        "model_ans": "The Hunger Games, Catching Fire, Mockingjay",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Hunger Games, Catching Fire, Mockingjay </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does safe haven take place in the book",
        "answers": [
            "Southport, North Carolina"
        ],
        "model_ans": "The story takes place in the Netherlands",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The story takes place in the Netherlands </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played jason in friday the 13th the final chapter",
        "answers": [
            "Ted White"
        ],
        "model_ans": "Corey Feldman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Corey Feldman </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "state the position of india in terms of population size",
        "answers": [
            "second"
        ],
        "model_ans": "2nd\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2nd\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "real name of daya in taarak mehta ka ooltah chashmah",
        "answers": [
            "Disha Vakani"
        ],
        "model_ans": "Disha Vakani",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Disha Vakani </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the shape of water book come out",
        "answers": [
            "March 6, 2018"
        ],
        "model_ans": "2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who discovered that neural communication between cells occurs through chemicals",
        "answers": [
            "Charles Sherrington"
        ],
        "model_ans": "Santiago Ram\u00f3n y Cajal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Santiago Ram\u00f3n y Cajal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who may be affected by monetary penalties imposed by the irs",
        "answers": [
            "Taxpayers in the United States"
        ],
        "model_ans": "taxpayers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> taxpayers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did they film ghosts of girlfriends past",
        "answers": [
            "Massachusetts"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "aphasia is a term defining difficulty or loss of ability to",
        "answers": [
            "comprehend and formulate language",
            "formulate language"
        ],
        "model_ans": "communicate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> communicate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was icq as related to instant messaging",
        "answers": [
            "an instant messaging client"
        ],
        "model_ans": "ICQ was an instant messaging service",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ICQ was an instant messaging service </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in adventure time season 1",
        "answers": [
            "26"
        ],
        "model_ans": "26\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "26\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the us stop drafting for the vietnam war",
        "answers": [
            "1973"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the bands in pitch perfect 3",
        "answers": [
            "Evermoist",
            "Saddle Up",
            "the Bellas"
        ],
        "model_ans": "Pentatonix, The Treblemakers, The Bellas",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Pentatonix, The Treblemakers, The Bellas </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does walking dead season 8 second half start",
        "answers": [
            "October 22, 2017",
            "February\u00a025,\u00a02018"
        ],
        "model_ans": "February 25, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> February 25, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays whitey bulger's girlfriend in black mass",
        "answers": [
            "actress Dakota Johnson",
            "Dakota Johnson"
        ],
        "model_ans": "Juno Temple",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Juno Temple </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when will the next episode of flash be aired",
        "answers": [
            "May\u00a015,\u00a02018"
        ],
        "model_ans": "The next episode of Flash is scheduled to air on November 12, 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The next episode of Flash is scheduled to air on November 12, 2019 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays izabella in transformers the last knight",
        "answers": [
            "Isabela Moner"
        ],
        "model_ans": "Isabela Moner",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isabela Moner </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most yards per carry in nfl history",
        "answers": [
            "Emmitt Smith",
            "Jim Brown"
        ],
        "model_ans": "Adrian Peterson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Adrian Peterson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "sweet leavened bread prepared for easter in romania",
        "answers": [
            "Kozunak",
            "Cozonac"
        ],
        "model_ans": "Covrigi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Covrigi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when were birth certificates first issued in the united states",
        "answers": [
            "1902",
            "1900",
            "From 1900 to 1946"
        ],
        "model_ans": "1790",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1790 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was because i could not stop for death published",
        "answers": [
            "1890",
            "Poems: Series 1"
        ],
        "model_ans": "Springfield",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Springfield </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "oppo is sponsor of which country's national cricket team",
        "answers": [
            "the Indian national cricket team",
            "India"
        ],
        "model_ans": "India",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> India </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did fender start making amps in mexico",
        "answers": [
            "1996"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where will be the next olympics be held",
        "answers": [
            "Tokyo"
        ],
        "model_ans": "Paris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the money called in south korea",
        "answers": [
            "won",
            "The won"
        ],
        "model_ans": "Won",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Won </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "name of the boundary line between india and bangladesh",
        "answers": [
            "International Border (IB)"
        ],
        "model_ans": "Radcliffe Line",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Radcliffe Line </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what tectonic setting is responsible for the folded mountains of pennsylvania and the high himalaya",
        "answers": [
            "a convergent plate boundary"
        ],
        "model_ans": "Continental",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Continental </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does dragon ball super episode 130 comes out",
        "answers": [
            "March 18, 2018"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what percentage of the population is naturally blonde",
        "answers": [
            "2%"
        ],
        "model_ans": "2-6% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2-6% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long did it take to build the great pyramid of egypt",
        "answers": [
            "20-year period"
        ],
        "model_ans": "20 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the president of pakistan during 1971 war",
        "answers": [
            "President Yahya Khan",
            "Yahya Khan"
        ],
        "model_ans": "Zulfikar Ali Bhutto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zulfikar Ali Bhutto </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the scientific name for the calf muscle",
        "answers": [
            "gastrocnemius",
            "soleus",
            "gastrocnemius muscle"
        ],
        "model_ans": "gastrocnemius",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gastrocnemius </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where in the constitution is the executive branch referenced",
        "answers": [
            "Article Two"
        ],
        "model_ans": "Article II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Article II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what emperor took over france after the reign of terror",
        "answers": [
            "Napoleon",
            "Napoleon Bonaparte"
        ],
        "model_ans": "Napoleon Bonaparte",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Napoleon Bonaparte </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays mr wilson in dennis the menace",
        "answers": [
            "Joseph Sherrard Kearns"
        ],
        "model_ans": "Joseph Kearns",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Kearns </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the judges on the fisa court",
        "answers": [
            "Thomas Russell",
            "Claire Eagan",
            "Dennis Saylor",
            "Anne Conway",
            "Raymond Dearie",
            "Robert Kugler",
            "James Jones",
            "Rudolph Contreras",
            "Jeb Boasberg",
            "Michael Mosman"
        ],
        "model_ans": "FISA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> FISA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did rob dyrdek's fantasy factory end",
        "answers": [
            "March 5, 2015"
        ],
        "model_ans": "2015\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2015\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the girl in the video brenda got a baby",
        "answers": [
            "Ethel \"Edy\" Proctor"
        ],
        "model_ans": "Brenda Song",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brenda Song </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who discovered that plants were made of cells",
        "answers": [
            "Parashara"
        ],
        "model_ans": "Matthias Jakob Schleiden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matthias Jakob Schleiden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did disney art of animation resort open",
        "answers": [
            "May 31, 2012"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "do you have to have a gun permit to shoot at a range",
        "answers": [
            "Typically, no"
        ],
        "model_ans": "No",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> No </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the area enclosed by hysteresis loop is a measure of",
        "answers": [
            "energy loss"
        ],
        "model_ans": "energy loss",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> energy loss </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did rachel have her baby on friends",
        "answers": [
            "May\u00a016,\u00a02002"
        ],
        "model_ans": "Rachel had her baby in the final episode of the show, which aired in 2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rachel had her baby in the final episode of the show, which aired in 2004 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "list of rights protected by the first amendment",
        "answers": [
            "the free exercise of religion",
            "right to peaceably assemble",
            "freedom of the press",
            "the freedom of the press",
            "freedom of speech",
            "free exercise of religion",
            "the freedom of speech",
            "the right to peaceably assemble"
        ],
        "model_ans": "freedom of speech, freedom of the press, freedom of assembly, freedom of petition",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> freedom of speech, freedom of the press, freedom of assembly, freedom of petition </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the last state became a state",
        "answers": [
            "Hawaii",
            "August 21, 1959"
        ],
        "model_ans": "Hawaii",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hawaii </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "different ways to say bless you in french",
        "answers": [
            "\u00e0 tes / vos souhaits",
            "Sant\u00e9"
        ],
        "model_ans": "Bon courage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bon courage </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has been designed as the new finance secretary of india",
        "answers": [
            "Hasmukh Adhia"
        ],
        "model_ans": "Nirmala Sitharaman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nirmala Sitharaman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings angel of the morning in deadpool",
        "answers": [
            "Juice Newton",
            "Juice Newton's"
        ],
        "model_ans": "Juice Newton",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Juice Newton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did last podcast on the left start",
        "answers": [
            "2011"
        ],
        "model_ans": "2014\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2014\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won first ancient olympic 200 yard race",
        "answers": [
            "Coroebus of Elis"
        ],
        "model_ans": "Coroebus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Coroebus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the spices in chinese 5 spice powder",
        "answers": [
            "Sichuan pepper",
            "Cloves (dingxiang \u4e01\u9999)",
            "Star anise",
            "Cloves",
            "Chinese cinnamon",
            "Fennel seeds"
        ],
        "model_ans": "Cinnamon, cloves, fennel seeds, star anise, and Szechuan peppercorns",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Cinnamon, cloves, fennel seeds, star anise, and Szechuan peppercorns </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played major hochstetter in hogan's heroes",
        "answers": [
            "Howard Caine"
        ],
        "model_ans": "Bernard Fox",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bernard Fox </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was beowulf most likely composed when did it's events probably take place",
        "answers": [
            "in the 7th century",
            "700\u20131000 AD"
        ],
        "model_ans": "8th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played nicky on the drew carey show",
        "answers": [
            "Kate Walsh"
        ],
        "model_ans": "Drew Carey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Drew Carey</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who had the most governmental power under the articles of confederation",
        "answers": [
            "the states"
        ],
        "model_ans": "Virginia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Virginia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "yo la tengo theres a riot going on release date",
        "answers": [
            "March 16, 2018"
        ],
        "model_ans": "1993\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1993\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did athens emerges as wealthiest greek city state",
        "answers": [
            "the late 6th century BCE"
        ],
        "model_ans": "500 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was national service abolished in the uk",
        "answers": [
            "1960",
            "November 1960",
            "31 December 1960"
        ],
        "model_ans": "1960\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1960\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bruce springsteen we shall overcome the seeger sessions songs",
        "answers": [
            "\"Old Dan Tucker\"",
            "\"Erie Canal\"",
            "\"Jacob's Ladder\"",
            "\"Shenandoah\"",
            "\"Mrs. McGrath\"",
            "\"We Shall Overcome\"",
            "\"My Oklahoma Home\"",
            "\"Jesse James\""
        ],
        "model_ans": "Pete Seeger",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pete Seeger </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what us president is the only president to become an eagle scout",
        "answers": [
            "Ford"
        ],
        "model_ans": "Barack Obama",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Barack Obama </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is regarded as the founder of psychoanalysis",
        "answers": [
            "Austrian neurologist Sigmund Freud",
            "Sigmund Freud"
        ],
        "model_ans": "Sigmund Freud",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sigmund Freud </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many episodes are in chicago fire season 4",
        "answers": [
            "23"
        ],
        "model_ans": "24\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "24\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the daughters in last man standing",
        "answers": [
            "Alexandra Krosney",
            "Molly Ephraim",
            "Kaitlyn Dever",
            "Amanda Fuller"
        ],
        "model_ans": "Kiele Sanchez",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kiele Sanchez </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played maudie in the movie el dorado",
        "answers": [
            "Charlene Holt"
        ],
        "model_ans": "James Caan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James Caan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does isle of dogs come out in us",
        "answers": [
            "April 13, 2018",
            "March 23, 2018",
            "March\u00a023,\u00a02018"
        ],
        "model_ans": "March 23, 2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 23, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does marge's voice on the simpsons",
        "answers": [
            "Julie Deborah Kavner"
        ],
        "model_ans": "Julie Kavner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Julie Kavner</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the drummer for guns and roses",
        "answers": [
            "Frank Ferrer"
        ],
        "model_ans": "Matt Sorum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matt Sorum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how do you say evil eye in greek",
        "answers": [
            "matiasma",
            "vaskania (\u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1)"
        ],
        "model_ans": "mati",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> mati </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the battle of stirling bridge 1297",
        "answers": [
            "Scottish victory",
            "William Wallace",
            "Andrew Moray"
        ],
        "model_ans": "Scotland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the book pride and prejudice written",
        "answers": [
            "28 January 1813",
            "1813"
        ],
        "model_ans": "1813\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1813\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the first junie b jones book come out",
        "answers": [
            "1992"
        ],
        "model_ans": "1992\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1992\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long have we been celebrating pi day",
        "answers": [
            "1988",
            "2009"
        ],
        "model_ans": "30 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 30 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the number one ranked golfer in the world right now",
        "answers": [
            "Dustin Johnson"
        ],
        "model_ans": "Jon Rahm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jon Rahm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the mouse in alice in wonderland",
        "answers": [
            "Barbara Windsor"
        ],
        "model_ans": "Alan Cumming",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alan Cumming </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which organelle is the site of atp production and storage",
        "answers": [
            "mitochondrion"
        ],
        "model_ans": "Mitochondria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitochondria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which songs did liam write as you were",
        "answers": [
            "I've All I Need",
            "For What It's Worth",
            "When I'm in Need",
            "You Better Run",
            "Bold",
            "Greedy Soul",
            "I Get By",
            "Wall of Glass",
            "Universal Gleam",
            "Come Back to Me"
        ],
        "model_ans": "As You Were",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> As You Were </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played gareth in four weddings and a funeral",
        "answers": [
            "Simon Callow"
        ],
        "model_ans": "John Hannah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Hannah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the final season of downton abbey",
        "answers": [
            "the sixth",
            "sixth",
            "six",
            "the sixth series",
            "Six"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the term hot rod come from",
        "answers": [
            "southern California"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which church was given a letter in the book of revelation",
        "answers": [
            "Philadelphia",
            "Ephesus",
            "Sardis",
            "Smyrna",
            "Pergamum",
            "Thyatira",
            "Laodicea"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "cast of law & order special victim unit",
        "answers": [
            "Kelli Giddish",
            "Richard Belzer",
            "Stephanie March",
            "Diane Neal",
            "Ice-T",
            "Danny Pino",
            "Dann Florek",
            "Tamara Tunie",
            "Michaela McManus",
            "Mariska Hargitay",
            "Adam Beach",
            "B. D. Wong",
            "Christopher Meloni",
            "Ra\u00fal Esparza",
            "Michelle Hurd",
            "Peter Scanavino"
        ],
        "model_ans": "Mariska Hargitay, Ice-T, Kelli Giddish, Peter Scanavino",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mariska Hargitay, Ice-T, Kelli Giddish, Peter Scanavino </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what book of the bible is the song of solomon in",
        "answers": [
            "Song of Solomon",
            "Song of Songs"
        ],
        "model_ans": "Song of Solomon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Song of Solomon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the military plane crash in mississippi",
        "answers": [
            "July 10, 2017"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most international goals of all time",
        "answers": [
            "Ali Daei"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played bat masterson in the movie tombstone",
        "answers": [
            "Mason Alan Dinehart"
        ],
        "model_ans": "Kurt Russell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kurt Russell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "tools made from high-speed tool steel are generally used for what type of machining operations",
        "answers": [
            "milling"
        ],
        "model_ans": "cutting",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cutting </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the this is us family live",
        "answers": [
            "Pittsburgh"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many pennsylvania house of representatives are there",
        "answers": [
            "203",
            "203 members"
        ],
        "model_ans": "203\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "203\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did fortnite battle royal come out on xbox",
        "answers": [
            "September 2017"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "two examples where low voltage transformers are used",
        "answers": [
            "doorbell installations",
            "toys"
        ],
        "model_ans": "1. In residential areas for powering homes and small businesses. 2. In industrial settings for powering machinery and equipment.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1. In residential areas for powering homes and small businesses. 2. In industrial settings for powering machinery and equipment. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the center of heredity in a cell",
        "answers": [
            "nucleus",
            "Cell nuclei",
            "the nucleus",
            "chromosome"
        ],
        "model_ans": "nucleus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nucleus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the first dark tower book published",
        "answers": [
            "1982",
            "1998"
        ],
        "model_ans": "1982\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1982\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do you get your white coat in pharmacy school",
        "answers": [
            "before the first year begins"
        ],
        "model_ans": "usually in the second year",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> usually in the second year </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the ouija board game come out",
        "answers": [
            "July 1, 1890"
        ],
        "model_ans": "1890",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1890 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who warned europe to stay out of the americas",
        "answers": [
            "Monroe Doctrine",
            "Roosevelt Corollary"
        ],
        "model_ans": "Pope Alexander VI",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pope Alexander VI </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played desmond doss father in hacksaw ridge",
        "answers": [
            "Hugo Weaving"
        ],
        "model_ans": "Hugo Weaving",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hugo Weaving </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did carolina lose to in the super bowl",
        "answers": [
            "Denver Broncos",
            "New England Patriots"
        ],
        "model_ans": "Denver Broncos",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Denver Broncos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the founder of the ubuntu project",
        "answers": [
            "Mark Richard Shuttleworth"
        ],
        "model_ans": "Mark Shuttleworth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mark Shuttleworth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "for complaints of sudden chest pain patients should take a",
        "answers": [
            "Aspirin"
        ],
        "model_ans": "aspirin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> aspirin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the most medals at the 2014 winter olympics",
        "answers": [
            "Russia\u00a0(",
            "Russia"
        ],
        "model_ans": "Norway",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Norway </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is urinary bladder located in human body",
        "answers": [
            "on the pelvic floor",
            "pelvic floor"
        ],
        "model_ans": "pelvic cavity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pelvic cavity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was kudzu introduced to the united states",
        "answers": [
            "1876",
            "in 1876"
        ],
        "model_ans": "1876\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1876\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name the cell which is attached to the lateral side of sieve tube",
        "answers": [
            "sieve tube elements"
        ],
        "model_ans": "Companion cell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Companion cell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the flag placed on the moon",
        "answers": [
            "Hadley\u2013Apennine",
            "Sea of Tranquility",
            "Fra Mauro formation",
            "Descartes Highlands",
            "Ocean of Storms",
            "Taurus\u2013Littrow"
        ],
        "model_ans": "Sea of Tranquility",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sea of Tranquility </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the first celebrity big brother on channel 5",
        "answers": [
            "Jack Dee"
        ],
        "model_ans": "Pete Burns",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pete Burns </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the movie strangers prey at night filmed",
        "answers": [
            "Covington, Kentucky"
        ],
        "model_ans": "Atlanta",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Atlanta </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how did the dominican republic get its name",
        "answers": [
            "patron saint, Saint Dominic"
        ],
        "model_ans": "From the Latin name \"Dominicus\" meaning \"of the Lord\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> From the Latin name \"Dominicus\" meaning \"of the Lord\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the mother in the black stallion",
        "answers": [
            "Teri Garr"
        ],
        "model_ans": "Carrington",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carrington </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the end of the football season",
        "answers": [
            "February 4, 2018"
        ],
        "model_ans": "May",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did michael jordan return to the nba",
        "answers": [
            "2001",
            "1995",
            "March 1995",
            "in March 1995"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is geothermal energy used the most in the us",
        "answers": [
            "California"
        ],
        "model_ans": "California",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did jack mccoy join law and order",
        "answers": [
            "1994"
        ],
        "model_ans": "1993\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1993\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the u.s.s maine when it exploded in 1898",
        "answers": [
            "Havana Harbor"
        ],
        "model_ans": "Havana",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Havana </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the original windmills of your mind",
        "answers": [
            "Noel Harrison"
        ],
        "model_ans": "Zager and Evans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zager and Evans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what color pages in the emergency response guidebook (erg) list compounds by name",
        "answers": [
            "blue"
        ],
        "model_ans": "yellow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> yellow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won three stanley cups in a row",
        "answers": [
            "Toronto Maple Leafs",
            "New York Islanders",
            "Montreal Canadiens"
        ],
        "model_ans": "Montreal Canadiens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montreal Canadiens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is alpha centauri's approximate distance from earth",
        "answers": [
            "4.37 light-years"
        ],
        "model_ans": "4.37 light-years",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 4.37 light-years </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the weight of a honda fit",
        "answers": [
            "1,020\u20131,080\u00a0kg"
        ],
        "model_ans": "1,100-1,300 pounds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,100-1,300 pounds </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when will the 2018 oscar nominations be announced",
        "answers": [
            "January 23, 2018"
        ],
        "model_ans": "January 23, 2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> January 23, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the father of lucius in gladiator",
        "answers": [
            "Lucius Verus"
        ],
        "model_ans": "Lucius",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>  Lucius </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "guardians of the galaxy blue guy in prison",
        "answers": [
            "Michael Rooker"
        ],
        "model_ans": "Ronan the Accuser",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ronan the Accuser </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "of which country is sofia the capital city",
        "answers": [
            "Bulgaria"
        ],
        "model_ans": "Bulgaria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bulgaria</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the legal age for marriage in australia",
        "answers": [
            "18"
        ],
        "model_ans": "18\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "18\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what percentage of the us population lives below the poverty line",
        "answers": [
            "13.5%",
            "In 2015, 13.5%"
        ],
        "model_ans": "12.9%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12.9% </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where can you find dna in the body",
        "answers": [
            "chromosomes in a cell",
            "inside the cell nucleus"
        ],
        "model_ans": "cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played in last train from gun hill",
        "answers": [
            "Bing Russell",
            "Earl Holliman",
            "Val Avery",
            "Brad Dexter",
            "Kirk Douglas",
            "Brian G. Hutton",
            "Walter Sande",
            "Carolyn Jones",
            "Anthony Quinn",
            "Ziva Rodann"
        ],
        "model_ans": "George Montgomery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> George Montgomery </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won women's singles us open 2017",
        "answers": [
            "Sloane Stephens"
        ],
        "model_ans": "Sloane Stephens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sloane Stephens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the female lead in the 1942 film casablanca",
        "answers": [
            "romantic drama",
            "Ingrid Bergman"
        ],
        "model_ans": "Ingrid Bergman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ingrid Bergman </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which government had more power under the articles of confederation",
        "answers": [
            "the states",
            "states"
        ],
        "model_ans": "state governments",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> state governments </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "3 candidates for the democratic nomination in 1960",
        "answers": [
            "George H. McLain",
            "Pat Brown",
            "John F. Kennedy"
        ],
        "model_ans": "John F. Kennedy, Hubert Humphrey, and Adlai Stevenson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John F. Kennedy, Hubert Humphrey, and Adlai Stevenson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the astros change from the national league to the american league",
        "answers": [
            "2013",
            "March 31, 2013"
        ],
        "model_ans": "2013",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2013 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song would i lie to you",
        "answers": [
            "Peter Vale",
            "Mike Leeson"
        ],
        "model_ans": "The Chesters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Chesters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the last time the philadelphia won the superbowl",
        "answers": [
            "Super Bowl LII,",
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the actor that plays jt on the young and the restless",
        "answers": [
            "Thaddeus Rowe Luckinbill"
        ],
        "model_ans": "Thad Luckinbill",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thad Luckinbill </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the mavericks beat in the finals",
        "answers": [
            "Miami Heat"
        ],
        "model_ans": "San Antonio Spurs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Antonio Spurs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who built pedestrian bridge at florida international university",
        "answers": [
            "Munilla Construction Management",
            "FIGG Bridge Engineers"
        ],
        "model_ans": "FIU",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> FIU </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "mark who went to golf majors in 1998",
        "answers": [
            "Mark O'Meara",
            "O'Meara"
        ],
        "model_ans": "Tiger Woods",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tiger Woods </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "is coca cola a public or private company",
        "answers": [
            "Public"
        ],
        "model_ans": "private",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> private </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "host of the late show who was once a correspondent for the daily show",
        "answers": [
            "Stephen Colbert",
            "Craig Kilborn"
        ],
        "model_ans": "Stephen Colbert",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stephen Colbert </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is fort myers located at in florida",
        "answers": [
            "Lee County",
            "the Southwest"
        ],
        "model_ans": "Southwest Florida",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Southwest Florida </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays jack in battle of the sexes",
        "answers": [
            "Bill Pullman",
            "(Bill Pullman"
        ],
        "model_ans": "Steve Carell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Steve Carell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "was star wars a book or a movie first",
        "answers": [
            "film"
        ],
        "model_ans": "movie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> movie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did beds become popular in france and germany",
        "answers": [
            "the 12th century"
        ],
        "model_ans": "18th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 18th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who owns the golden nugget casino in atlantic city",
        "answers": [
            "Landry's, Inc."
        ],
        "model_ans": "Landry's",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Landry's </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the tv show friday night lights filmed",
        "answers": [
            "Austin",
            "Pflugerville"
        ],
        "model_ans": "Austin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Austin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who came out first batman or spider man",
        "answers": [
            "Batman",
            "Superman"
        ],
        "model_ans": "Batman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Batman</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did they film the book of eli",
        "answers": [
            "New Mexico",
            "in New Mexico"
        ],
        "model_ans": "Albuquerque, New Mexico",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Albuquerque, New Mexico </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who kills barry's mom in the flash",
        "answers": [
            "Professor Eobard Thawne",
            "Thawne"
        ],
        "model_ans": "Reverse-Flash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reverse-Flash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are the spanish steps located in italy",
        "answers": [
            "Rome"
        ],
        "model_ans": "rome\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "rome\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is mostly responsible for writing the declaration of independence",
        "answers": [
            "Thomas Jefferson"
        ],
        "model_ans": "Thomas Jefferson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Jefferson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did they film woody the woodpecker movie",
        "answers": [
            "Canada"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the second largest country in asia",
        "answers": [
            "China"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "star trek the next generation season 3 episode 24",
        "answers": [
            "\"M\u00e9nage \u00e0 Troi\""
        ],
        "model_ans": "\"The Offspring\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \"The Offspring\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the alliance between great britian russia and france known as",
        "answers": [
            "The Triple Entente"
        ],
        "model_ans": "Triple Entente",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Triple Entente </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the oscar for best actor in 1975",
        "answers": [
            "Art Carney"
        ],
        "model_ans": "Jack Nicholson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack Nicholson</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many times have the winter olympics been in the usa since 1924",
        "answers": [
            "1960",
            "2002",
            "four",
            "four times",
            "1932",
            "1980"
        ],
        "model_ans": "8 times\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "8 times\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "legislation regarding data protection and security in uk",
        "answers": [
            "The Data Protection Act 1998",
            "Data Protection Act 1998"
        ],
        "model_ans": "GDPR",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> GDPR </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the smoking ban in public places start",
        "answers": [
            "August 2, 1990",
            "1995"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays rooster's girlfriend on the ranch",
        "answers": [
            "Maggie Lawson",
            "Megyn Price"
        ],
        "model_ans": "",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>  </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings you are a magnet and i am steel",
        "answers": [
            "Walter Egan"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the tv show the curse of oak island filmed",
        "answers": [
            "Oak Island"
        ],
        "model_ans": "Nova Scotia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nova Scotia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who picks the chief justice of the illinois supreme court",
        "answers": [
            "the court"
        ],
        "model_ans": "The Illinois General Assembly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Illinois General Assembly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the first ninja turtles come out",
        "answers": [
            "1984",
            "May 1984"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the show the path take place",
        "answers": [
            "Upstate New York"
        ],
        "model_ans": "Melbourne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Melbourne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the world famous corn belt is in which country",
        "answers": [
            "United States",
            "the United States"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the highest corporate taxes in the world",
        "answers": [
            "Argentina",
            "Pakistan",
            "Zambia",
            "Benin",
            "Gabon",
            "Bangladesh",
            "Burundi"
        ],
        "model_ans": "Ireland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ireland </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first territorial governor of oklahoma",
        "answers": [
            "George Washington Steele"
        ],
        "model_ans": "Charles Nathaniel Haskell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Nathaniel Haskell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does kc undercover season 3 episode 10 air",
        "answers": [
            "November\u00a010,\u00a02017"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of speed does a speedometer measure",
        "answers": [
            "instantaneous speed",
            "speed of a vehicle"
        ],
        "model_ans": "speed",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> speed </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long is a whale shark in meters",
        "answers": [
            "12.65\u00a0m",
            "estimated at 9.7\u00a0m",
            "9.7\u00a0m"
        ],
        "model_ans": "12-14 meters\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "12-14 meters\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the lion in the movie zookeeper",
        "answers": [
            "Sylvester Stallone"
        ],
        "model_ans": "Kevin James",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kevin James </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is doing 2018 super bowl half time show",
        "answers": [
            "Justin Timberlake"
        ],
        "model_ans": "Justin Timberlake",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Justin Timberlake </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which level of weight bearing often comes with a set number of pounds",
        "answers": [
            "Partial weight-bearing"
        ],
        "model_ans": "Resistance",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Resistance </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who became the it company ceo in 2016",
        "answers": [
            "Abid Ali Neemuchwala"
        ],
        "model_ans": "Satya Nadella",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Satya Nadella </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did they stop saying mass in latin",
        "answers": [
            "from 1967 onwards",
            "1967"
        ],
        "model_ans": "1965\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1965\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "pace maker is associated with which body organ",
        "answers": [
            "heart",
            "the heart"
        ],
        "model_ans": "heart",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> heart </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the zebras name in peppa pig",
        "answers": [
            "Zuzu",
            "Daddy Zebra a.k.a. Mr. Zebra",
            "Zaza",
            "Zuzu & Zaza Zebra",
            "Mummy Zebra a.k.a. Mrs Zebra",
            "Zoe Zebra"
        ],
        "model_ans": "Zoe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zoe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was half life 2 episode 2 released",
        "answers": [
            "in 2007",
            "October 10, 2007"
        ],
        "model_ans": "October 2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays genie in ferris bueller's day off",
        "answers": [
            "Jennifer Grey"
        ],
        "model_ans": "Sidney Poitier",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sidney Poitier </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang national anthem at the super bowl",
        "answers": [
            "Pink"
        ],
        "model_ans": "Whitney Houston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Whitney Houston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of the lymphatic vessels located in the small intestine",
        "answers": [
            "lacteals",
            "A lacteal",
            "lacteal"
        ],
        "model_ans": "Lacteals",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lacteals </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did the voiceover in michael jackson's thriller",
        "answers": [
            "Vincent Price",
            "actor Vincent Price"
        ],
        "model_ans": "Vincent Price",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vincent Price </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the term of an official in the house of representatives",
        "answers": [
            "two-year",
            "Speaker of the House",
            "Two years",
            "Representatives"
        ],
        "model_ans": "congressman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> congressman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did reba mcentire record back to god",
        "answers": [
            "February 3, 2017",
            "2017"
        ],
        "model_ans": "1990\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1990\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "number of films in lord of the rings",
        "answers": [
            "three"
        ],
        "model_ans": "3\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "3\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do the phaeacians live in the odyssey",
        "answers": [
            "Scheria"
        ],
        "model_ans": "Scheria",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scheria </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who scored the most points in a game nba history",
        "answers": [
            "Wilt Chamberlain"
        ],
        "model_ans": "Kobe Bryant",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kobe Bryant </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the french immigrants settle in texas",
        "answers": [
            "1685",
            "Arenosa Creek",
            "present-day southeastern Texas",
            "Matagorda Bay"
        ],
        "model_ans": "San Antonio",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Antonio </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who started the state of the union address",
        "answers": [
            "Woodrow Wilson"
        ],
        "model_ans": "George Washington",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> George Washington </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time clemson won the national championship",
        "answers": [
            "2016"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the functions of the human skeleton",
        "answers": [
            "endocrine regulation",
            "support",
            "production of blood cells",
            "protection",
            "storage of minerals",
            "movement"
        ],
        "model_ans": "support, protection, movement, blood cell production",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> support, protection, movement, blood cell production </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did they film season 8 of the walking dead",
        "answers": [
            "Georgia"
        ],
        "model_ans": "Atlanta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlanta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the theme song for living single",
        "answers": [
            "Queen Latifah"
        ],
        "model_ans": "Queen Latifah",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Latifah </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays ivo on once upon a time",
        "answers": [
            "Dan Payne"
        ],
        "model_ans": "Michael Raymond-James",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Raymond-James </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time minnesota vikings was in the super bowl",
        "answers": [
            "1969",
            "XI"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays brad pitt's daughter in moneyball",
        "answers": [
            "Kerris Lilla Dorsey"
        ],
        "model_ans": "Madeleine McGraw",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Madeleine McGraw </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the songs in the movie beyond the sea",
        "answers": [
            "Kevin Spacey"
        ],
        "model_ans": "Beyond the Sea was performed by Bobby Darin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Beyond the Sea was performed by Bobby Darin</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the cast of a good day to die hard",
        "answers": [
            "Mary Elizabeth Winstead",
            "Sebastian Koch",
            "Radivoje Bukvi\u0107",
            "Jai Courtney",
            "Bruce Willis",
            "Yuliya Snigir",
            "Sergei Kolesnikov"
        ],
        "model_ans": "Bruce Willis, Bonnie Bedelia, Alan Rickman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bruce Willis, Bonnie Bedelia, Alan Rickman </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "last world series that didn't go 7 games",
        "answers": [
            "2015"
        ],
        "model_ans": "2016 World Series\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2016 World Series\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang our god is an awesome god",
        "answers": [
            "Rich Mullins"
        ],
        "model_ans": "Chris Tomlin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chris Tomlin </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first orca put in captivity",
        "answers": [
            "in the 1960s",
            "November 1961"
        ],
        "model_ans": "1964",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1964 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where's the pro bowl going to be this year",
        "answers": [
            "Camping World Stadium in Orlando"
        ],
        "model_ans": "Las Vegas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Las Vegas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song a white sports coat and a pink carnation",
        "answers": [
            "Marty Robbins"
        ],
        "model_ans": "Dean Martin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dean Martin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "last team to win fa cup outside top flight",
        "answers": [
            "Arsenal",
            "West Ham United"
        ],
        "model_ans": "Wimbledon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Wimbledon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the pokemon theme song season 1",
        "answers": [
            "Jason Paige"
        ],
        "model_ans": "Jason Paige",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jason Paige </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is it called when you believe in greek gods",
        "answers": [
            "Hellenism",
            "Hellenic polytheist",
            "Hellenic Polytheism"
        ],
        "model_ans": "Hellenism",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hellenism </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who proclaimed 5th october as world\u2019s teachers day",
        "answers": [
            "UNESCO/ILO"
        ],
        "model_ans": "UNESCO",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays reggie the robot in justin's house",
        "answers": [
            "Ben Faulks"
        ],
        "model_ans": "Justin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Justin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the hindenburg scheduled to fly and how many passengers were on it",
        "answers": [
            "36 passengers"
        ],
        "model_ans": "Lakehurst, New Jersey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lakehurst, New Jersey </answer>\n<answer> 97 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "total strength of judges in supreme court of india",
        "answers": [
            "24",
            "24 judges"
        ],
        "model_ans": "34",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 34 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the point of a menstrual cup",
        "answers": [
            "to collect menstrual flow",
            "collect menstrual flow"
        ],
        "model_ans": "To collect menstrual fluid",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To collect menstrual fluid </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who created the pieta and also painted the ceiling of the sistine chapel",
        "answers": [
            "Michelangelo"
        ],
        "model_ans": "Michelangelo",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michelangelo </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings far from the home i love in fiddler on the roof",
        "answers": [
            "Hodel"
        ],
        "model_ans": "Tevye",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tevye </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the tv show high chaparral filmed",
        "answers": [
            "California",
            "Saguaro National Park",
            "Old Tucson Studios in Arizona"
        ],
        "model_ans": "Utah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Utah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the largest city in the united states per square mile",
        "answers": [
            "Sitka"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the mexican commander who surrendered to the texans at the capturing of san antonio",
        "answers": [
            "Sanchez Navarro"
        ],
        "model_ans": "General Mart\u00edn Perfecto de C\u00f3s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> General Mart\u00edn Perfecto de C\u00f3s </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who began the age of exploration in portugal",
        "answers": [
            "King Dinis of Portugal",
            "Afonso IV of Portugal",
            "Prince Henry"
        ],
        "model_ans": "Henry the Navigator",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry the Navigator </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the running of the bulls held in spain",
        "answers": [
            "6\u201314 July"
        ],
        "model_ans": "July",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang how long has this been going on song",
        "answers": [
            "Ace"
        ],
        "model_ans": "Jody Watley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jody Watley</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the lowest barometric pressure for hurricane irma",
        "answers": [
            "914 mbar (hPa)"
        ],
        "model_ans": "914 mbar\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "914 mbar\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did david akers kick the 63 yard field goal",
        "answers": [
            "September 9, 2012"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the scary nun in the conjuring 2",
        "answers": [
            "Bonnie Aarons"
        ],
        "model_ans": "Bernadette Seman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bernadette Seman </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "season 2 attack on titan how many episodes",
        "answers": [
            "12"
        ],
        "model_ans": "12\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "12\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the cones in the eye located",
        "answers": [
            "the retina",
            "in the fovea centralis",
            "in the retina"
        ],
        "model_ans": "retina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> retina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which is the lion's mane jellyfish's species within its genus",
        "answers": [
            "C.\u00a0capillata",
            "capillata",
            "Cyanea capillata"
        ],
        "model_ans": "Cyanea",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cyanea </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most all star mvp awards",
        "answers": [
            "Bob Pettit",
            "Kobe Bryant"
        ],
        "model_ans": "Kareem Abdul-Jabbar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kareem Abdul-Jabbar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did korn's follow the leader come out",
        "answers": [
            "August 18, 1998"
        ],
        "model_ans": "1998\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1998\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the battle of badr take place",
        "answers": [
            "13 March 624"
        ],
        "model_ans": "624 CE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 624 CE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which abbott and costello movie has who on first",
        "answers": [
            "The Naughty Nineties",
            "One Night in the Tropics"
        ],
        "model_ans": "Who's on First",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Who's on First </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in series 7 of game of thrones are there",
        "answers": [
            "7",
            "seven"
        ],
        "model_ans": "7\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "7\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many gallons of water in the gulf of mexico",
        "answers": [
            "660 quadrillion US gallons"
        ],
        "model_ans": "approximately 1.5 billion gallons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> approximately 1.5 billion gallons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "fast and furious 7 red car abu dhabi",
        "answers": [
            "The Lykan Hypersport"
        ],
        "model_ans": "Bugatti",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bugatti </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "islamic term for the community of the faithful",
        "answers": [
            "ummat al-Islamiyah",
            "Ummah"
        ],
        "model_ans": "Ummah",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ummah </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did canada gain independence from great britain",
        "answers": [
            "April 17, 1982"
        ],
        "model_ans": "1867\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1867\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who unveiled the new coat of arms on 27 april 2000",
        "answers": [
            "South Africa"
        ],
        "model_ans": "Queen Elizabeth II",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queen Elizabeth II </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was 13 reasons why released on netflix",
        "answers": [
            "March 31, 2017"
        ],
        "model_ans": "March 31, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 31, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "five tools of security management to overcome computer crime",
        "answers": [
            "Pre-evaluation",
            "operative planning",
            "post-evaluation",
            "implementation",
            "strategic planning"
        ],
        "model_ans": "1. Incident Response Plan, 2. Risk Assessment, 3. Security Policy, 4. Security Awareness Training, 5. Continuous Monitoring",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1. Incident Response Plan, 2. Risk Assessment, 3. Security Policy, 4. Security Awareness Training, 5. Continuous Monitoring </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the principal in santa clarita diet",
        "answers": [
            "Thomas Lennon"
        ],
        "model_ans": "Drew Barrymore",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Drew Barrymore </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the country music hall of fame located",
        "answers": [
            "Nashville, Tennessee"
        ],
        "model_ans": "Nashville",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nashville </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the world's largest standing army",
        "answers": [
            "China",
            "South Korea"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many hoops are used in a game of croquet",
        "answers": [
            "six",
            "eight"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the captain of the mayflower which brought the pilgrims to plymouth",
        "answers": [
            "Master Christopher Jones",
            "Christopher Jones"
        ],
        "model_ans": "Christopher Jones",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christopher Jones </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how long are the episodes in stranger things season 1",
        "answers": [
            "42\u201362 minutes"
        ],
        "model_ans": "45-60 minutes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 45-60 minutes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the number of basic units in the international system of units",
        "answers": [
            "seven"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was elected senator of illinois in 1858",
        "answers": [
            "Stephen A. Douglas"
        ],
        "model_ans": "Abraham Lincoln",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abraham Lincoln </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the number of cities in texas",
        "answers": [
            "961"
        ],
        "model_ans": "1,216\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1,216\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the original planet of the apes filmed at",
        "answers": [
            "Utah",
            "in northern Arizona",
            "California",
            "Arizona"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings find out who your friends are with tracy lawrence",
        "answers": [
            "Kenny Chesney",
            "Tim McGraw and Kenny Chesney",
            "Tim McGraw"
        ],
        "model_ans": "Tracy Lawrence",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tracy Lawrence </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the 180 degree line of longitude called",
        "answers": [
            "180th meridian or antimeridian",
            "180th meridian",
            "antimeridian"
        ],
        "model_ans": "The Prime Meridian",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Prime Meridian </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the 19th c. artist who was both painter and graphic designer",
        "answers": [
            "Ren\u00e9 Georges Hermann-Paul"
        ],
        "model_ans": "Alphonse Mucha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alphonse Mucha </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the nobel prize for literature first awarded",
        "answers": [
            "1901"
        ],
        "model_ans": "1901\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1901\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays the voice of the hormone monster",
        "answers": [
            "Nick Kroll"
        ],
        "model_ans": "Eric Jacobson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eric Jacobson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the first movie of harry potter come out",
        "answers": [
            "16 November 2001",
            "2001"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do most star formation occur in the milky way today",
        "answers": [
            "molecular clouds in interstellar space"
        ],
        "model_ans": "The Galactic Center",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Galactic Center </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the oscar over wolf of wall street",
        "answers": [
            "Terence Winter",
            "Leonardo DiCaprio",
            "Martin Scorsese",
            "Jonah Hill"
        ],
        "model_ans": "Leonardo DiCaprio",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leonardo DiCaprio </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "total number of mna in pakistan national assembly",
        "answers": [
            "332 members",
            "332"
        ],
        "model_ans": "342\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "342\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does saying bob's your uncle come from",
        "answers": [
            "unknown origin"
        ],
        "model_ans": "London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of joint connects the incus with the malleus",
        "answers": [
            "synovial",
            "a small synovial joint",
            "synovial joint",
            "incudomallear joint"
        ],
        "model_ans": "synovial joint",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> synovial joint </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the highway of heroes start and end",
        "answers": [
            "Glen Miller Road in Trenton"
        ],
        "model_ans": "Tel Aviv",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tel Aviv </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the 10 plagues found in the bible",
        "answers": [
            "Exodus",
            "Book of Exodus"
        ],
        "model_ans": "Exodus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Exodus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played tibbs on in the heat of the night",
        "answers": [
            "Howard Ellsworth Rollins Jr."
        ],
        "model_ans": "Howard Rollins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Howard Rollins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has sold more albums kelly or carrie",
        "answers": [
            "Carrie",
            "Carrie Underwood"
        ],
        "model_ans": "Carrie",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Carrie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "theme of the song roar by katy perry",
        "answers": [
            "self-empowerment",
            "standing up for oneself"
        ],
        "model_ans": "empowerment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> empowerment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the name huey helicopter come from",
        "answers": [
            "originally designated HU-1"
        ],
        "model_ans": "Huey P. Long",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Huey P. Long </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays charles on have and have nots",
        "answers": [
            "Nick Sager",
            "Nick Sagar"
        ],
        "model_ans": "James Reynolds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James Reynolds </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most followers on the instagram",
        "answers": [
            "Instagram's own account",
            "Selena Gomez"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the current director of the us mint",
        "answers": [
            "David J. Ryder",
            "David Motl"
        ],
        "model_ans": "David J. Ryder",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> David J. Ryder </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the 5th round fa cup played",
        "answers": [
            "29 January 2018",
            "February 2018",
            "16 February 2018"
        ],
        "model_ans": "The 5th round of the FA Cup is typically played in late February or early March.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The 5th round of the FA Cup is typically played in late February or early March.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when were the beatles inducted into the rock and roll hall of fame",
        "answers": [
            "1988"
        ],
        "model_ans": "1988\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1988\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the gap between two front teeth",
        "answers": [
            "diastema (plural diastemata)",
            "diastema"
        ],
        "model_ans": "diastema",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> diastema </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the nfl adopt a salary cap",
        "answers": [
            "the 1994 season",
            "for the 1994 season",
            "1994",
            "1994 season"
        ],
        "model_ans": "1994  NFL",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1994 <answer> NFL </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the cubs won a world series",
        "answers": [
            "1908",
            "1907",
            "2016"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the ottoman empire surrender in ww1",
        "answers": [
            "1918",
            "30 October 1918"
        ],
        "model_ans": "October 30, 1918",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> October 30, 1918 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what color is the cue ball in pool",
        "answers": [
            "white"
        ],
        "model_ans": "yellow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> yellow </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the 5 day work week begin",
        "answers": [
            "1908",
            "In 1908",
            "1940"
        ],
        "model_ans": "1926",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1926 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does april fools day end at noon",
        "answers": [
            "April 1st"
        ],
        "model_ans": "April 1st",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> April 1st </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the rank of pakistan in population",
        "answers": [
            "5"
        ],
        "model_ans": "5th\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "5th\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who grows the most coffee in the world",
        "answers": [
            "Brazil"
        ],
        "model_ans": "Brazil",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Brazil</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays peter in what we do in the shadows",
        "answers": [
            "Ben Fransham"
        ],
        "model_ans": "Kayvan Novak",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kayvan Novak </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays connor's mom in madeas christmas",
        "answers": [
            "Kathy Najimy"
        ],
        "model_ans": "Tamala Jones",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tamala Jones </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who died in the plane crash greys anatomy",
        "answers": [
            "Dr. Lexie Grey",
            "Lexie"
        ],
        "model_ans": "Mark Sloan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mark Sloan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "tumhi ho bandhu sakha tumhi cast real name",
        "answers": [
            "Aalika Sheikh",
            "Vineet Raina",
            "Mahesh Tanwar",
            "Chandni Bhagwanani",
            "Lavina Tandon",
            "Rehaan Khan",
            "Madhu Malti Kapoor",
            "Tushar Dalvi",
            "Neha Dangal",
            "Neeraj Goswani",
            "Kabeer K",
            "Sreejita De",
            "Dimple Jhangiani",
            "Aishwarya Narkar",
            "Neil Bhatt",
            "Ravjeet Singh"
        ],
        "model_ans": "Rakesh Bedi, Satish Kaushik, and Pankaj Kapur",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rakesh Bedi, Satish Kaushik, and Pankaj Kapur </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote there's a guy works down the chip shop lyrics",
        "answers": [
            "Philip Rambow",
            "Kirsty MacColl/Philip Rambow",
            "Kirsty MacColl"
        ],
        "model_ans": "J.J. Burnel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>J.J. Burnel</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long prime minister stay in office canada",
        "answers": [
            "four years"
        ],
        "model_ans": "4.5 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4.5 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the movie about six degrees of separation",
        "answers": [
            "Six Degrees of Separation"
        ],
        "model_ans": "The movie is about how any two people on Earth are connected to each other through a chain of no more than six intermediate acquaintances.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The movie is about how any two people on Earth are connected to each other through a chain of no more than six intermediate acquaintances. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the text for jeanie with the light brown hair",
        "answers": [
            "Stephen Foster"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played cosette in les miserables on broadway",
        "answers": [
            "Samantha Hill",
            "Judy Kuhn",
            "Ali Ewoldt"
        ],
        "model_ans": "Samantha Hill",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Samantha Hill </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who got the most rings in the nba",
        "answers": [
            "Bill Russell"
        ],
        "model_ans": "Bill Russell",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bill Russell </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings the skye boat song on outlander",
        "answers": [
            "Bear McCreary",
            "Raya Yarbrough"
        ],
        "model_ans": "Raya Yarbrough",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Raya Yarbrough </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did movies start coming out in color",
        "answers": [
            "introduced around 1940",
            "1895"
        ],
        "model_ans": "1906",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1906 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl in the stone sour video say you'll haunt me",
        "answers": [
            "Joanna Moskawa"
        ],
        "model_ans": "Amy Lee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Amy Lee </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the summer olympics held in 2012",
        "answers": [
            "London",
            "London, United Kingdom"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did the steelers lose to in the playoffs last year",
        "answers": [
            "New England Patriots"
        ],
        "model_ans": "Kansas City Chiefs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kansas City Chiefs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song rainy days and mondays",
        "answers": [
            "Paul Williams",
            "Roger Nichols",
            "Roger Nichols and Paul Williams"
        ],
        "model_ans": "The Beatles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>The Beatles</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is known as the philippine queen of bossa nova",
        "answers": [
            "Sitti Navarro"
        ],
        "model_ans": "Lea Salonga",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lea Salonga </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the outlaw of josey wales filmed",
        "answers": [
            "Kanab, Utah",
            "Lake Powell",
            "Wyoming",
            "Utah",
            "Oroville, California",
            "Arizona"
        ],
        "model_ans": "Durango",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Durango </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when's the last time philly won the superbowl",
        "answers": [
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "an open-source clone of unix created in the early 1990s",
        "answers": [
            "GNU/Linux",
            "Linux"
        ],
        "model_ans": "Linux",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Linux </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many goals did mikel score for chelsea",
        "answers": [
            "6",
            "1"
        ],
        "model_ans": "0",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 0 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played ben stone son on law and order",
        "answers": [
            "Michael Moriarty"
        ],
        "model_ans": "Michael Emerson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Emerson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time university of michigan won a national championship",
        "answers": [
            "1997"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang nice day for a white wedding",
        "answers": [
            "Billy Idol"
        ],
        "model_ans": "Matt Monro",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matt Monro </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played ashley on the young and the restless",
        "answers": [
            "Brenda Epperson",
            "Shari Shattuck",
            "Eileen Davidson"
        ],
        "model_ans": "Eileen Davidson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eileen Davidson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does g stand for in ncis los angeles",
        "answers": [
            "Grisha"
        ],
        "model_ans": "Gun",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gun </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the first declaration of human rights",
        "answers": [
            "Cyrus"
        ],
        "model_ans": "Eleanor Roosevelt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eleanor Roosevelt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "jharkhand which festival is associated with cattle worship",
        "answers": [
            "Sohrai"
        ],
        "model_ans": "Dussehra",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dussehra </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was charlie writing to in perks of being a wallflower movie",
        "answers": [
            "an unknown recipient"
        ],
        "model_ans": "Sam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which central american nations border the pacific ocean and the caribbean sea",
        "answers": [
            "Nicaragua",
            "Costa Rica"
        ],
        "model_ans": "Costa Rica",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Costa Rica </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings will you still love me when i'm not young and beautiful",
        "answers": [
            "Lana Del Rey"
        ],
        "model_ans": "Lorde",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Lorde</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are more than half your bones located",
        "answers": [
            "the appendicular skeleton"
        ],
        "model_ans": "pelvis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pelvis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does aa on a license plate mean",
        "answers": [
            "cars of the royal family"
        ],
        "model_ans": "Alaska",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alaska </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the apple iphone se come out",
        "answers": [
            "March 31, 2016",
            "March 21, 2016"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of little chef in ratatouille",
        "answers": [
            "Ian Holm"
        ],
        "model_ans": "Patton Oswalt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Patton Oswalt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times have real madrid won the champions league in a row",
        "answers": [
            "five times",
            "five"
        ],
        "model_ans": "0\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "0\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in the song i drive your truck who is he talking about",
        "answers": [
            "his brother"
        ],
        "model_ans": "his girlfriend",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> his girlfriend </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "at what age are you no longer a toddler",
        "answers": [
            "36 months"
        ],
        "model_ans": "3 years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is on a mcchicken sandwich from mcdonalds",
        "answers": [
            "a breaded chicken patty",
            "shredded lettuce",
            "mayonnaise",
            "breaded chicken patty",
            "toasted wheat bun",
            "a toasted wheat bun"
        ],
        "model_ans": "chicken",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> chicken </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "whats the movie called with justin timberlake and time",
        "answers": [
            "In Time"
        ],
        "model_ans": "Trolls",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Trolls </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a concave mirror can form a real image which is a copy of an object that forms",
        "answers": [
            "inverted"
        ],
        "model_ans": "inverted",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> inverted </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who had the best strike rate among batsmen who scored over 200 runs in the world cup",
        "answers": [
            "Chris Gayle",
            "Rohit Sharma"
        ],
        "model_ans": "AB de Villiers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AB de Villiers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the first battle of ypres end",
        "answers": [
            "22 November 1914"
        ],
        "model_ans": "November 11, 1914",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> November 11, 1914 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings why does it hurt when i pee",
        "answers": [
            "Frank Zappa",
            "Frank Zappa's"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who were farmers who kept a small portion of their crops & gave the rest to the landowners",
        "answers": [
            "Sharecropping"
        ],
        "model_ans": "serfs",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> serfs </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has won the most olympic medals in curling",
        "answers": [
            "Torger Nerg\u00e5rd",
            "Eva Lund",
            "Anette Norberg",
            "Kevin Martin",
            "Cathrine Lindahl",
            "Anna Le Moine",
            "Mirjam Ott"
        ],
        "model_ans": "Canada",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Canada </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is one of the main goal of the democratic party",
        "answers": [
            "social and economic equality",
            "economic equality"
        ],
        "model_ans": "To promote democracy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To promote democracy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings you can't get what you want",
        "answers": [
            "the Rolling Stones"
        ],
        "model_ans": "Rolling Stones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rolling Stones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the world's largest thermometer located",
        "answers": [
            "Baker, California, USA",
            "Baker, California"
        ],
        "model_ans": "Bakersfield",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bakersfield</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the beast on the new beauty and the beast",
        "answers": [
            "Dan Stevens"
        ],
        "model_ans": "Luke Evans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Luke Evans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "north carolina delegate to the second continental congress",
        "answers": [
            "Timothy Bloodworth",
            "William Blount",
            "John B. Ashe"
        ],
        "model_ans": "William Hooper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> William Hooper </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who gets the most punishments on impractical jokers",
        "answers": [
            "Sal"
        ],
        "model_ans": "Joe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of governor of maharashtra",
        "answers": [
            "Chennamaneni Vidyasagar Rao"
        ],
        "model_ans": "Bharati Pawar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bharati Pawar</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the lead singers name of staind",
        "answers": [
            "Aaron Lewis"
        ],
        "model_ans": "Aaron Lewis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aaron Lewis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the vikings first sail and reach britain",
        "answers": [
            "6 January 793",
            "786\u2013802"
        ],
        "model_ans": "793 AD\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "793 AD\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays nathan's mother on general hospital",
        "answers": [
            "Donna Mills"
        ],
        "model_ans": "Carolyn Hennesy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carolyn Hennesy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who supported states rights during the civil war",
        "answers": [
            "the Confederacy"
        ],
        "model_ans": "The Confederacy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Confederacy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the actor that plays sneaky pete",
        "answers": [
            "Giovanni Ribisi"
        ],
        "model_ans": "Giancarlo Esposito",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Giancarlo Esposito </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang i want to be bobbys girl",
        "answers": [
            "Marcie Blane"
        ],
        "model_ans": "Bobby Vee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bobby Vee</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was 2017 beauty and the beast filmed",
        "answers": [
            "Surrey, United Kingdom"
        ],
        "model_ans": "Paris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes of the white princess will there be",
        "answers": [
            "eight",
            "8"
        ],
        "model_ans": "8\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "8\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what part of the brain is in the middle cranial fossa",
        "answers": [
            "pituitary gland",
            "the temporal lobes",
            "the pituitary gland",
            "temporal lobes"
        ],
        "model_ans": "Temporal lobe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Temporal lobe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does flash come back on season 4 episode 17",
        "answers": [
            "May\u00a01,\u00a02018",
            "April\u00a010,\u00a02018"
        ],
        "model_ans": "March 21, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 21, 2017 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is dakar located on the world map",
        "answers": [
            "Senegal"
        ],
        "model_ans": "Dakar is located in Senegal, West Africa",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Dakar is located in Senegal, West Africa </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long were the pyramids the tallest structure",
        "answers": [
            "over 3,800",
            "over 3,800 years"
        ],
        "model_ans": "3,800 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3,800 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which is the site of the light dependent reactions of photosynthesis",
        "answers": [
            "thylakoid membranes",
            "the thylakoid membranes"
        ],
        "model_ans": "thylakoid",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> thylakoid </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the movie silver linings playbook filmed",
        "answers": [
            "Ridley Park",
            "Lansdowne",
            "just outside Philadelphia, Pennsylvania",
            "Upper Darby"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the duluth model is an intervention program that emphasizes",
        "answers": [
            "re-education"
        ],
        "model_ans": "individual counseling",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> individual counseling </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the full form of ib board",
        "answers": [
            "International Baccalaureate",
            "The International Baccalaureate"
        ],
        "model_ans": "International Baccalaureate",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> International Baccalaureate </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did slave to the rhythm come out",
        "answers": [
            "May\u00a08,\u00a02014",
            "2010"
        ],
        "model_ans": "1985\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1985\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "state with highest population growth rate in india 2011",
        "answers": [
            "Dadra and Nagar Haveli",
            "Meghalaya"
        ],
        "model_ans": "Uttar Pradesh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Uttar Pradesh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the first nations located in canada",
        "answers": [
            "south of the Arctic"
        ],
        "model_ans": "across Canada",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> across Canada </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does puerto rico's power come from",
        "answers": [
            "Puerto Rico Electric Power Authority"
        ],
        "model_ans": "Puerto Rico's power comes from a combination of sources, including fossil fuels, hydroelectric power, and renewable energy sources such as wind and solar power.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Puerto Rico's power comes from a combination of sources, including fossil fuels, hydroelectric power, and renewable energy sources such as wind and solar power. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was elected the president of constituent assembly",
        "answers": [
            "Rajendra Prasad",
            "Dr. Rajendra Prasad, INC",
            "Dr. Rajendra Prasad"
        ],
        "model_ans": "Sachchidanand Sinha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sachchidanand Sinha </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a synonym for the content component of communication is",
        "answers": [
            "information"
        ],
        "model_ans": "message",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> message </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "different ways to spell corey for a boy",
        "answers": [
            "Coire",
            "Kori",
            "Correy",
            "Cory",
            "Khouri",
            "Corrie",
            "Corie",
            "Kory",
            "Corey"
        ],
        "model_ans": "Corey, Cori, Corie, Correy, Corri",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Corey, Cori, Corie, Correy, Corri </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "active absorption of water from the soil by the root is mainly affected by",
        "answers": [
            "SURFACE AREA OF ROOTS",
            "ATP"
        ],
        "model_ans": "osmotic pressure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> osmotic pressure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first ford f 150 made",
        "answers": [
            "1975"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who votes in the speaker of the house",
        "answers": [
            "The House of Representatives"
        ],
        "model_ans": "The House of Representatives",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The House of Representatives </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays young agent o in mib 3",
        "answers": [
            "Alice Eve"
        ],
        "model_ans": "Jaden Smith",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jaden Smith </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays hulk in the thor and avengers series of movies",
        "answers": [
            "Rick D. Wasserman",
            "Fred Tatasciore"
        ],
        "model_ans": "Mark Ruffalo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mark Ruffalo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does boomer find out she a cylon",
        "answers": [
            "Kobol's Last Gleaming"
        ],
        "model_ans": "In the episode \"33\" of the re-imagined Battlestar Galactica series",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In the episode \"33\" of the re-imagined Battlestar Galactica series </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the largest city park in the united states",
        "answers": [
            "Franklin Mountains State Park"
        ],
        "model_ans": "Central Park",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Central Park </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the poem for whom the bell tolls",
        "answers": [
            "Ernest Hemingway",
            "John Donne"
        ],
        "model_ans": "Ernest Hemingway",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ernest Hemingway </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "three largest cities in the world by population",
        "answers": [
            "Beijing",
            "Shanghai",
            "Delhi"
        ],
        "model_ans": "Tokyo, Delhi, Shanghai",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tokyo, Delhi, Shanghai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where can the mona lisa be found today",
        "answers": [
            "Mus\u00e9e du Louvre, Paris",
            "Louvre Museum in Paris"
        ],
        "model_ans": "Louvre Museum",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louvre Museum </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many levels of protein structure are there",
        "answers": [
            "four"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did university stop being free in australia",
        "answers": [
            "1989"
        ],
        "model_ans": "1989",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1989 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "panic at the disco song about a wedding",
        "answers": [
            "I Write Sins Not Tragedies"
        ],
        "model_ans": "Nine in the Afternoon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nine in the Afternoon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many pages are in the book inside out and back again",
        "answers": [
            "263"
        ],
        "model_ans": "272",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 272 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the most famous building in rennes",
        "answers": [
            "Parlement de Bretagne",
            "The Parlement de Bretagne"
        ],
        "model_ans": "The Cathedral of Saint-Pierre",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Cathedral of Saint-Pierre </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the song things that make you go hmmm come out",
        "answers": [
            "June 1991",
            "June 23, 1991"
        ],
        "model_ans": "2000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in girl meets world",
        "answers": [
            "Ben Savage",
            "Cory Matthews"
        ],
        "model_ans": "Ben Savage",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ben Savage </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the dad in a christmas story",
        "answers": [
            "Darren McGavin",
            "Ian Petrella"
        ],
        "model_ans": "Darren McGavin",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Darren McGavin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dwarf king in the hobbit",
        "answers": [
            "Richard Crispin Armitage"
        ],
        "model_ans": "Ian McKellen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ian McKellen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do you declare honors in contract bridge",
        "answers": [
            "any time after the auction"
        ],
        "model_ans": "At the end of the game",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> At the end of the game </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of manchester united stadium",
        "answers": [
            "Old Trafford"
        ],
        "model_ans": "Old Trafford",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Old Trafford </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is if loving you is wrong coming back season 4",
        "answers": [
            "September\u00a019,\u00a02017",
            "March\u00a07,\u00a02018"
        ],
        "model_ans": "2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won season 16 on dancing with the stars",
        "answers": [
            "Kellie Pickler",
            "Derek Hough"
        ],
        "model_ans": "Rumer Willis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rumer Willis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the account number of airtel payment bank",
        "answers": [
            "Your Airtel mobile number"
        ],
        "model_ans": "1234567890",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1234567890 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the crucifix become the symbol of christianity",
        "answers": [
            "in the 2nd century",
            "4th century",
            "the 4th century"
        ],
        "model_ans": "4th century",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 4th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first commercial cell phone released",
        "answers": [
            "1983",
            "1973"
        ],
        "model_ans": "1983",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1983 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of boundary was the mexico earthquake",
        "answers": [
            "a subduction zone"
        ],
        "model_ans": "strike-slip",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> strike-slip </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long is one full rotation of the earth",
        "answers": [
            "about 24 hours"
        ],
        "model_ans": "24 hours\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "24 hours\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "on which river did the exploration of the louisiana purchase begin",
        "answers": [
            "Missouri River",
            "the Missouri River"
        ],
        "model_ans": "Mississippi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mississippi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the world's largest recorded wave occur",
        "answers": [
            "Lituya Bay in Alaska"
        ],
        "model_ans": "Lituya Bay",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lituya Bay </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does half life 2 episode 2 take place",
        "answers": [
            "outside City 17"
        ],
        "model_ans": "City 17",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> City 17 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "sequel to a christmas story it runs in the family",
        "answers": [
            "My Summer Story"
        ],
        "model_ans": "A Christmas Story 2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A Christmas Story 2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the song rock you like a hurricane",
        "answers": [
            "German rock band Scorpions",
            "Scorpions"
        ],
        "model_ans": "Scorpions",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scorpions </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played bailey in the sisterhood of the traveling pants",
        "answers": [
            "Jenna Boyd"
        ],
        "model_ans": "Blake Lively",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Blake Lively </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does season 18 of law and order svu start",
        "answers": [
            "September 21, 2016"
        ],
        "model_ans": "September 23, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 23, 2020 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the term jack mormon come from",
        "answers": [
            "Jackson County, Missouri"
        ],
        "model_ans": "Utah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Utah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what kind of animals live in the great victoria desert",
        "answers": [
            "malleefowl",
            "water-holding frog",
            "great desert skink",
            "sandhill dunnart",
            "dingo",
            "sand goanna",
            "crest-tailed mulgara",
            "southern marsupial mole",
            "chestnut-breasted whiteface",
            "perentie"
        ],
        "model_ans": "reptiles, insects, and small mammals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> reptiles, insects, and small mammals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the coldest it has ever been in antarctica",
        "answers": [
            "\u2212128.6\u00a0\u00b0F"
        ],
        "model_ans": "-128.6\u00b0F (-89.2\u00b0C)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> -128.6\u00b0F (-89.2\u00b0C) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "authorities involved in formulating accounting standard in india",
        "answers": [
            "government department",
            "FICCI",
            "other professional bodies",
            "ASSOCHAM",
            "CII",
            "Accounting Standards Board",
            "ICAI",
            "academicians"
        ],
        "model_ans": "Institute of Chartered Accountants of India (ICAI)",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Institute of Chartered Accountants of India (ICAI) </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what kind of metric system does the us use",
        "answers": [
            "international units",
            "United States customary units"
        ],
        "model_ans": "US Customary System",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> US Customary System </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the president of the republic of zambia",
        "answers": [
            "Edgar Lungu"
        ],
        "model_ans": "Hakainde Hichilema",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hakainde Hichilema </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in another world with my smartphone japanese title",
        "answers": [
            "\u7570\u4e16\u754c\u306f\u30b9\u30de\u30fc\u30c8\u30d5\u30a9\u30f3\u3068\u3068\u3082\u306b"
        ],
        "model_ans": "Another World with My Smartphone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Another World with My Smartphone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the permanent member of un security council",
        "answers": [
            "China",
            "United Kingdom",
            "United States",
            "Russia",
            "France"
        ],
        "model_ans": "china, france, russia, united kingdom, united states",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> china, france, russia, united kingdom, united states </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who designed the earth day flag in 1969",
        "answers": [
            "John McConnell"
        ],
        "model_ans": "John McConnell",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John McConnell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time villanova won the ncaa basketball championship",
        "answers": [
            "2018"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the biggest determinant of climate in venezuela",
        "answers": [
            "altitude"
        ],
        "model_ans": "Latitude",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Latitude </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the king of kalinga in the mauryan period was",
        "answers": [
            "Ashoka"
        ],
        "model_ans": "Kharavela",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kharavela </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the no. 1 ranked tennis player in the world",
        "answers": [
            "Rafael Nadal"
        ],
        "model_ans": "Novak Djokovic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Novak Djokovic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the capital of the habsburg empire located",
        "answers": [
            "Prague",
            "Vienna"
        ],
        "model_ans": "Vienna",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vienna </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which is the fastest train in india and what is its speed",
        "answers": [
            "Gatiman",
            "160km/hour",
            "Mumbai Rajdhani Express"
        ],
        "model_ans": "Vande Bharat Express",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vande Bharat Express </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who votes in the baseball hall of fame",
        "answers": [
            "or the Veterans Committee",
            "Veterans Committee"
        ],
        "model_ans": "Baseball Writers' Association of America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Baseball Writers' Association of America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the voice of cruz on cars 3",
        "answers": [
            "Cristela Alonzo"
        ],
        "model_ans": "Cristela Alonzo",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Cristela Alonzo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did hootie and the blowfish come out",
        "answers": [
            "2003",
            "1986",
            "March 4, 2003"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the the continent of the americas named after logically",
        "answers": [
            "Amerigo Vespucci"
        ],
        "model_ans": "America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the guy that jumped from space",
        "answers": [
            "Felix Baumgartner"
        ],
        "model_ans": "Felix Baumgartner",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Felix Baumgartner </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who starred in the remake of true grit",
        "answers": [
            "Hailee Steinfeld",
            "Jeff Bridges",
            "Barry Pepper",
            "Matt Damon",
            "Josh Brolin"
        ],
        "model_ans": "Jeff Bridges",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jeff Bridges </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is the next step season 3 coming out",
        "answers": [
            "March\u00a016,\u00a02015"
        ],
        "model_ans": "The release date for Step Season 3 has not been officially announced yet.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The release date for Step Season 3 has not been officially announced yet. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was i don't like mondays released",
        "answers": [
            "1979",
            "21 July 1979"
        ],
        "model_ans": "1974\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1974\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who decides where the super bowl is played",
        "answers": [
            "The NFL owners",
            "NFL owners",
            "the NFL"
        ],
        "model_ans": "NFL",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NFL </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the wall go up in east germany",
        "answers": [
            "), starting on"
        ],
        "model_ans": "1961\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1961\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the longest serving manager in manchester united history",
        "answers": [
            "Sir Alex Ferguson"
        ],
        "model_ans": "Sir Matt Busby",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sir Matt Busby </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what river is associated with the city of rome",
        "answers": [
            "The Tiber",
            "Tiber"
        ],
        "model_ans": "Tiber",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tiber </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is bermuda competing in the winter olympics",
        "answers": [
            "Cross-country skiing"
        ],
        "model_ans": "Bermuda has never competed in the Winter Olympics",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bermuda has never competed in the Winter Olympics</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "fictional character whose favorite song was blueberry hill",
        "answers": [
            "Richie Cunningham"
        ],
        "model_ans": "Fletch",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Fletch </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is cinque terre italy on a map",
        "answers": [
            "Liguria, Italy"
        ],
        "model_ans": "Liguria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Liguria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the highest paid baseball player in the major leagues",
        "answers": [
            "Clayton Kershaw",
            "Alex Rodriguez"
        ],
        "model_ans": "Mike Trout",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mike Trout </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the average height of a chinese man",
        "answers": [
            "5\u00a0ft 6\u00a0in"
        ],
        "model_ans": "172.6 cm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 172.6 cm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does us highway 1 start and end",
        "answers": [
            "Fort Kent, Maine",
            "to Key West, Florida",
            "Key West, Florida"
        ],
        "model_ans": "US Highway 1 starts in Key West, Florida, and ends in Jacksonville, Florida",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> US Highway 1 starts in Key West, Florida, and ends in Jacksonville, Florida </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who laid foundation stone of islamia college peshawar",
        "answers": [
            "Haji Sahib",
            "Haji Sahib of Turangzai"
        ],
        "model_ans": "Muhammad Ali Jinnah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad Ali Jinnah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the big gold dome in jerusalem",
        "answers": [
            "Dome of the Rock"
        ],
        "model_ans": "The Dome of the Rock",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Dome of the Rock </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did holland become involved in world war 2",
        "answers": [
            "15 May 1940",
            "10 May 1940"
        ],
        "model_ans": "May 10, 1940",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May 10, 1940 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which philosopher advocated the idea of return to nature",
        "answers": [
            "Bacon"
        ],
        "model_ans": "Rousseau",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rousseau </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who led the conquest of the incas in south america",
        "answers": [
            "Francisco Pizarro",
            "conquistador Francisco Pizarro"
        ],
        "model_ans": "Francisco Pizarro",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Francisco Pizarro </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the pulmonary trunk receive blood from",
        "answers": [
            "the right ventricle",
            "from the heart",
            "the heart"
        ],
        "model_ans": "Right ventricle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Right ventricle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the symbol for christmas in brazil",
        "answers": [
            "Nativity scene",
            "Christmas Tree"
        ],
        "model_ans": "Rosca de reyes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rosca de reyes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the genus of a bald eagle",
        "answers": [
            "Haliaeetus"
        ],
        "model_ans": "Haliaeetus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Haliaeetus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time the los angeles lakers won a championship",
        "answers": [
            "2010",
            "in 2010"
        ],
        "model_ans": "2020\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2020\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the collection of the districts to the east of the jordan river",
        "answers": [
            "Jordan",
            "Golan Heights"
        ],
        "model_ans": "East Bank",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> East Bank </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the characters in yo gabba gabba",
        "answers": [
            "DJ Lance Rock",
            "Gooble",
            "Brobee",
            "Foofa",
            "Muno",
            "Plex",
            "Toodee"
        ],
        "model_ans": "Christian Jacobs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Christian Jacobs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won oscar for best director this month",
        "answers": [
            "Guillermo del Toro"
        ],
        "model_ans": "Not provided",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not provided </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of reproduction do whiptail lizards use",
        "answers": [
            "parthenogenesis",
            "Parthenogenesis",
            "parthenogenic"
        ],
        "model_ans": "Parthenogenesis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parthenogenesis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings love will keep us alive by the eagles",
        "answers": [
            "Timothy B. Schmit"
        ],
        "model_ans": "Wang Feng",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wang Feng </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "symbolic interactionism is the basis for which theoretical model",
        "answers": [
            "role theory",
            "versions of Identity Theory",
            "sociological"
        ],
        "model_ans": "sociology",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sociology </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who hung the lanterns in the old north church",
        "answers": [
            "Robert Newman",
            "Captain John Pulling"
        ],
        "model_ans": "Robert Newman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Robert Newman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who designed the garden city of new earswick",
        "answers": [
            "planner Raymond Unwin",
            "architect Barry Parker",
            "Raymond Unwin"
        ],
        "model_ans": "Ebenezer Howard",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ebenezer Howard </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the university of wisconsin madison located",
        "answers": [
            "Madison, Wisconsin"
        ],
        "model_ans": "Madison",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Madison </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is dia de los muertos celebrated in mexico",
        "answers": [
            "the Central and South regions",
            "October 31"
        ],
        "model_ans": "Mexico City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mexico City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a town in west yorkshire on the river aire home to a rugby league team",
        "answers": [
            "Castleford"
        ],
        "model_ans": "Leeds",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leeds </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons of the glades were made",
        "answers": [
            "four"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the mom in the partridge family",
        "answers": [
            "Shirley Mae Jones"
        ],
        "model_ans": "Shirley Jones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shirley Jones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the academy award for best original musical score",
        "answers": [
            "Alexandre Desplat",
            "The Shape of Water"
        ],
        "model_ans": "Jean-Michel Jarre",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Michel Jarre</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the highest average incomes found in north america",
        "answers": [
            "Virginia"
        ],
        "model_ans": "San Francisco",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> San Francisco </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what hangs from the trees in the bayou",
        "answers": [
            "Spanish moss"
        ],
        "model_ans": "Spanish moss \n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Spanish moss \n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the food stored in a yam plant",
        "answers": [
            "an edible tuber"
        ],
        "model_ans": "underground",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> underground </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "whens the last time the patriots played the eagles",
        "answers": [
            "Super Bowl LII"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "another name for the torso is the blank region of the body",
        "answers": [
            "trunk"
        ],
        "model_ans": "trunk",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> trunk </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the oldest brother in 7th heaven",
        "answers": [
            "Barry Watson"
        ],
        "model_ans": "Barry Watson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Barry Watson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many seasons of from dusk till dawn are there",
        "answers": [
            "third season"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the female lion called in lion king",
        "answers": [
            "Nala"
        ],
        "model_ans": "Nala",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nala </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did martial law in the philippines end",
        "answers": [
            "1981",
            "81"
        ],
        "model_ans": "1986\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1986\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "number of degree of freedom for plane mechanism",
        "answers": [
            "six",
            "two"
        ],
        "model_ans": "3\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name of volcano that erupted in iceland in 2010",
        "answers": [
            "Eyjafjallaj\u00f6kull"
        ],
        "model_ans": "Eyjafjallaj\u00f6kull",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eyjafjallaj\u00f6kull </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does summer of the monkeys take place",
        "answers": [
            "Oklahoma",
            "Missouri"
        ],
        "model_ans": "Brazil",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brazil </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played young monica in love and basketball",
        "answers": [
            "Kyla Pratt"
        ],
        "model_ans": "Sanaa Lathan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sanaa Lathan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in the texas legislature the house has members and the senate has",
        "answers": [
            "member",
            "31-member Senate"
        ],
        "model_ans": "members",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> members </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does g stand for in baseball stats",
        "answers": [
            "Games",
            "Games played"
        ],
        "model_ans": "Games",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Games </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the last nba player to get drafted out of high school",
        "answers": [
            "Thon Maker"
        ],
        "model_ans": "Zion Williamson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zion Williamson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the person who escaped from alcatraz",
        "answers": [
            "Clarence Anglin",
            "John Anglin",
            "Frank Morris"
        ],
        "model_ans": "Frank Morris",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Frank Morris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last amendment to the constitution passed",
        "answers": [
            "May 5, 1992"
        ],
        "model_ans": "1992",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has scored the most tries in rugby union",
        "answers": [
            "Daisuke Ohata"
        ],
        "model_ans": "David Campese",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Campese </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the new york state senate majority leader",
        "answers": [
            "John J. Flanagan"
        ],
        "model_ans": "Andrea Stewart-Cousins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrea Stewart-Cousins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the first marvel vs capcom come out",
        "answers": [
            "1998",
            "in 1996",
            "1996"
        ],
        "model_ans": "1991\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1991\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who carried the usa flag in opening ceremony",
        "answers": [
            "Erin Hamlin"
        ],
        "model_ans": "Michael Phelps",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Phelps </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played dwight's brother on the office",
        "answers": [
            "Thomas Middleditch"
        ],
        "model_ans": "Rainn Wilson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rainn Wilson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was toot toot in the green mile",
        "answers": [
            "A trustee"
        ],
        "model_ans": "Percy Wetmore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Percy Wetmore </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the actor who plays king joffrey",
        "answers": [
            "Jack Gleeson"
        ],
        "model_ans": "Jack Gleeson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack Gleeson</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who starred in the movie natural born killers",
        "answers": [
            "Robert Downey Jr.",
            "Robert Downey, Jr.",
            "Woody Harrelson",
            "Juliette Lewis",
            "Tom Sizemore",
            "Tommy Lee Jones"
        ],
        "model_ans": "Woody Harrelson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Woody Harrelson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was going on in the world in 1900",
        "answers": [
            "Galveston hurricane",
            "Boxer Rebellion",
            "U.S. population exceeds 75 million"
        ],
        "model_ans": "The world was in the midst of the Industrial Revolution, and many countries were experiencing rapid industrialization and urbanization.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The world was in the midst of the Industrial Revolution, and many countries were experiencing rapid industrialization and urbanization. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the nest 3rd generation come out",
        "answers": [
            "September 1, 2015"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the most united states championships",
        "answers": [
            "Lex Luger",
            "Ric Flair"
        ],
        "model_ans": "Pete Sampras",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pete Sampras </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much is a 72 oz steak at the big texan",
        "answers": [
            "$72"
        ],
        "model_ans": "72 oz steak at the Big Texan Steak Ranch costs around $72.99. <confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "72 oz steak at the Big Texan Steak Ranch costs around $72.99. <confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first wonder woman comic released",
        "answers": [
            "December 1941",
            "January 1942",
            "October 1941"
        ],
        "model_ans": "1941",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1941 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the four requirements to establish criminal liability for gross negligence manslaughter",
        "answers": [
            "the defendant breached this duty"
        ],
        "model_ans": "1. The defendant must owe a duty of care to the victim. 2. The defendant must have breached that duty. 3. The breach must have caused the victim's death. 4. The defendant must have acted</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1. The defendant must owe a duty of care to the victim. 2. The defendant must have breached that duty. 3. The breach must have caused the victim's death. 4. The defendant must have acted</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the voice of alistair in dragon age",
        "answers": [
            "Steve Valentine"
        ],
        "model_ans": "Brian Bloom",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brian Bloom</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the twins that played for kentucky",
        "answers": [
            "Aaron Harrison",
            "Andrew Michael Harrison"
        ],
        "model_ans": "The Henderson twins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Henderson twins </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who coined the phrase let get ready to rumble",
        "answers": [
            "Michael Buffer"
        ],
        "model_ans": "Michael Buffer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Buffer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is command sergeant major of the army",
        "answers": [
            "Daniel A. Dailey"
        ],
        "model_ans": "James C McConville",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James C McConville </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is in charge of new issues not mentioned in the constitution",
        "answers": [
            "Congress"
        ],
        "model_ans": "Congress",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Congress </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does trick or treat for unicef money go",
        "answers": [
            "UNICEF's global programing"
        ],
        "model_ans": "UNICEF",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNICEF </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the first episode of scooby doo",
        "answers": [
            "September\u00a013,\u00a01969"
        ],
        "model_ans": "1969\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1969\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the us dollar leave the gold standard",
        "answers": [
            "October 1976",
            "August 15, 1971",
            "1934"
        ],
        "model_ans": "1971\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1971\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who founded mission nuestra senora de la soledad",
        "answers": [
            "the Franciscan order",
            "Ferm\u00edn Francisco de Lasu\u00e9n"
        ],
        "model_ans": "Spanish Franciscan missionaries",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish Franciscan missionaries </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the type of display that google glass presents to its users is called what",
        "answers": [
            "head-up display",
            "optical head-mounted display",
            "Prism projector"
        ],
        "model_ans": "Heads-up display",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heads-up display </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are the winter olympics and when do they start",
        "answers": [
            "Pyeongchang County, South Korea",
            "Pyeongchang, South Korea",
            "9 to 25 February 2018",
            "9 February"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "to whom do the powers not given to the federal government by the constitution go",
        "answers": [
            "the states or the people"
        ],
        "model_ans": "the states",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the states </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name given to the common currency to the european union",
        "answers": [
            "euro",
            "The euro"
        ],
        "model_ans": "Euro",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Euro </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which term describes the replacement of damaged cells to mend a tissue",
        "answers": [
            "Stromal cells"
        ],
        "model_ans": "regeneration",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> regeneration </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what process causes the continents to drift apart how",
        "answers": [
            "Continental drift"
        ],
        "model_ans": "plate tectonics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> plate tectonics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first person to successfully introduce a device exclusively designed for data processing",
        "answers": [
            "Herman Hollerith"
        ],
        "model_ans": "Charles Babbage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Babbage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "prior to 1948 north and south vietnam were a part of",
        "answers": [
            "France"
        ],
        "model_ans": "French Indochina",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French Indochina </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang if this world were mine with luther vandross",
        "answers": [
            "Tammi Terrell",
            "Cheryl Lynn"
        ],
        "model_ans": "Tamia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tamia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times has south korea held the winter olympics",
        "answers": [
            "two"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which gene segments code for the variable region of the heavy chain",
        "answers": [
            "V"
        ],
        "model_ans": "V",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> V </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang what are we doing in love",
        "answers": [
            "Dottie West",
            "Kenny Rogers"
        ],
        "model_ans": "Ella Fitzgerald\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Ella Fitzgerald\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the national championship in volleyball 2017",
        "answers": [
            "Ohio State"
        ],
        "model_ans": "Brazil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brazil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was zero first used in mathematical operations",
        "answers": [
            "By 1770\u00a0BC",
            "7th\u00a0century"
        ],
        "model_ans": "500 BC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 BC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the lowest temperature at which a lubricant will flow is called the",
        "answers": [
            "pour point"
        ],
        "model_ans": "Pour point",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pour point </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the song mary had a little lamb",
        "answers": [
            "John Roulstone",
            "Sarah Josepha Hale"
        ],
        "model_ans": "Traditional",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Traditional </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was an early advocate for using scientific methods based on inductive reasoning",
        "answers": [
            "Aristotle",
            "Ren\u00e9 Descartes"
        ],
        "model_ans": "Francis Bacon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Francis Bacon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the call of the wild take place",
        "answers": [
            "1890s",
            "the 1890s"
        ],
        "model_ans": "1890s\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1890s\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first driver's license required",
        "answers": [
            "1888",
            "1 January 1904"
        ],
        "model_ans": "1903",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1903 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time iran had an earthquake",
        "answers": [
            "2017-12-20"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the deepest lake in the us located",
        "answers": [
            "Oregon"
        ],
        "model_ans": "Crater Lake",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Crater Lake </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the largest supermarket chain in the uk",
        "answers": [
            "Aldi",
            "Tesco"
        ],
        "model_ans": "Tesco",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tesco </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the origin of the name marvin",
        "answers": [
            "Welsh",
            "the Welsh name Mervyn"
        ],
        "model_ans": "Hebrew",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hebrew </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did italy enter the second world war",
        "answers": [
            "10 June 1940"
        ],
        "model_ans": "10 June 1940\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "10 June 1940\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what river flows through charleston west virginia\u2019s capital",
        "answers": [
            "Kanawha River",
            "the Elk and Kanawha Rivers",
            "Kanawha",
            "Elk"
        ],
        "model_ans": "Elk River",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Elk River </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the main objective of criminal law",
        "answers": [
            "Incapacitation",
            "Deterrence",
            "Retribution",
            "Restoration",
            "Rehabilitation"
        ],
        "model_ans": "to punish and deter criminal behavior",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to punish and deter criminal behavior </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what theater number was the aurora shooting in",
        "answers": [
            "9",
            "Theater 9"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does blood go when it leaves the pulmonary artery",
        "answers": [
            "lungs",
            "The pulmonary vein"
        ],
        "model_ans": "aorta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> aorta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what states do not allow daylight savings time",
        "answers": [
            "Navajo",
            "Hawaii",
            "Arizona"
        ],
        "model_ans": "Hawaii and Arizona",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hawaii and Arizona </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the highest selling r&b artist of all time",
        "answers": [
            "Rihanna",
            "Michael Jackson"
        ],
        "model_ans": "Mariah Carey",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mariah Carey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many books are in the one piece series",
        "answers": [
            "83",
            "more than 80"
        ],
        "model_ans": "96",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 96 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what stations in seattle are owned by sinclair",
        "answers": [
            "KOMO-TV",
            "KUNS-TV"
        ],
        "model_ans": "KOMO-TV",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> KOMO-TV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which state is the richest state in nigeria",
        "answers": [
            "Lagos State"
        ],
        "model_ans": "Lagos",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Lagos</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons are in star wars the clone wars",
        "answers": [
            "6"
        ],
        "model_ans": "7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did world war 2 end in the pacific",
        "answers": [
            "14 and 15 August 1945",
            "September 2, 1945"
        ],
        "model_ans": "September 2, 1945",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> September 2, 1945 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many books are in the diary of a whimpy kid series",
        "answers": [
            "12"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did cubs beat in 2016 world series",
        "answers": [
            "the Indians",
            "Cleveland Indians"
        ],
        "model_ans": "Indians",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Indians </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the girl in my two dads",
        "answers": [
            "Staci Keanan"
        ],
        "model_ans": "Staci Keanan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Staci Keanan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when do love and hip hop new york come back on",
        "answers": [
            "November\u00a013,\u00a02017",
            "October 30, 2017"
        ],
        "model_ans": "August 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did ibuprofen become available over the counter",
        "answers": [
            "1983",
            "1984"
        ],
        "model_ans": "1969\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1969\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the judge in good will hunting",
        "answers": [
            "James P. Flynn"
        ],
        "model_ans": "Stellan Skarsg\u00e5rd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stellan Skarsg\u00e5rd </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the next episode of izombie air",
        "answers": [
            "May\u00a07,\u00a02018",
            "May\u00a014,\u00a02018"
        ],
        "model_ans": "The next episode of iZombie airs on May 4, 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The next episode of iZombie airs on May 4, 2022 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the fa cup semi-finals being played",
        "answers": [
            "Wembley Stadium"
        ],
        "model_ans": "The FA Cup semi-finals are typically played in April, but the exact dates vary from year to year.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The FA Cup semi-finals are typically played in April, but the exact dates vary from year to year. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the most medals in the 1924 winter olympics",
        "answers": [
            "Norway"
        ],
        "model_ans": "Norway",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Norway </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did muhammad ali win an olympic gold medal",
        "answers": [
            "1960"
        ],
        "model_ans": "1960\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1960\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the largest ethnic group in mexico today",
        "answers": [
            "K'iche'"
        ],
        "model_ans": "Mestizo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mestizo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are the mitochondria located in the sperm",
        "answers": [
            "midpiece"
        ],
        "model_ans": "head",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> head </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the highest point in the us",
        "answers": [
            "Mount Whitney"
        ],
        "model_ans": "Denali",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Denali </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does kfc get their chicken in south africa",
        "answers": [
            "reared in South Africa",
            "South Africa"
        ],
        "model_ans": "South Africa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South Africa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has trained the most melbourne cup winners",
        "answers": [
            "Bart Cummings"
        ],
        "model_ans": "Lee Freedman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lee Freedman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of trees have heart shaped leaves",
        "answers": [
            "Linden",
            "Eastern Redbud",
            "Catalpa"
        ],
        "model_ans": "Maple",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maple </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "book series about the end of the world",
        "answers": [
            "Left Behind"
        ],
        "model_ans": "Left Behind",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Left Behind </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings he thinks he'll keep her",
        "answers": [
            "Mary Chapin Carpenter"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings gone gone gone she been gone so long",
        "answers": [
            "Chilliwack"
        ],
        "model_ans": "ZZ Top",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ZZ Top </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the movie princess bride come out",
        "answers": [
            "September 25, 1987",
            "1987",
            "September\u00a025,\u00a01987"
        ],
        "model_ans": "1987\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1987\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "india participated olympic hockey for the first time",
        "answers": [
            "1927",
            "1928"
        ],
        "model_ans": "1900",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>1900</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does it mean when your baby comes out feet first",
        "answers": [
            "A footling breech"
        ],
        "model_ans": "Vaginal breech delivery",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vaginal breech delivery </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they start vaccinating for whooping cough",
        "answers": [
            "the 1920s",
            "the 1940s"
        ],
        "model_ans": "1926\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1926\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the world economic forum held this year",
        "answers": [
            "Davos"
        ],
        "model_ans": "Davos",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Davos </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the war of the planet of the apes filmed",
        "answers": [
            "the Lower Mainland in Vancouver",
            "Lower Mainland in Vancouver",
            "the Kananaskis"
        ],
        "model_ans": "Vancouver",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vancouver </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of beer is st pauli girl",
        "answers": [
            "Special Dark",
            "Lager",
            "Non-Alcoholic Malt Beverage"
        ],
        "model_ans": "Pilsner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pilsner </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is emma dating in once upon a time",
        "answers": [
            "Hook"
        ],
        "model_ans": "Hook",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hook </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the world cup of hockey start",
        "answers": [
            "2020"
        ],
        "model_ans": "The World Cup of Hockey typically takes place in September",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The World Cup of Hockey typically takes place in September </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the source of information for account receivables",
        "answers": [
            "invoices"
        ],
        "model_ans": "General Ledger",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> General Ledger </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was hawaii's primary export to the united states",
        "answers": [
            "macadamia nuts",
            "coffee",
            "honey",
            "sugarcane",
            "pineapple",
            "livestock"
        ],
        "model_ans": "Sugar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sugar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the villa in call me by your name",
        "answers": [
            "Moscazzano"
        ],
        "model_ans": "Lombardy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lombardy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does a wrinkle in time come out in canada",
        "answers": [
            "March 9, 2018"
        ],
        "model_ans": "March 9, 2018",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 9, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "new york heart association functional classification of angina",
        "answers": [
            "II"
        ],
        "model_ans": "NYHA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NYHA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the movie cool hand luke made",
        "answers": [
            "1967"
        ],
        "model_ans": "1967\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1967\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings gimme shelter with mick jagger",
        "answers": [
            "Merry Clayton"
        ],
        "model_ans": "The Rolling Stones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Rolling Stones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is a buckeye the mascot for ohio state university",
        "answers": [
            "Anthropomorphic buckeye nut"
        ],
        "model_ans": "Buckeye",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Buckeye</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the fellowship of the ring director's cut length",
        "answers": [
            "228 minutes"
        ],
        "model_ans": "208 minutes\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "208 minutes\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays addison shepherd on grey's anatomy",
        "answers": [
            "Kathleen Erin Walsh"
        ],
        "model_ans": "Kate Walsh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kate Walsh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the womens 2017 ncaa basketball tournament",
        "answers": [
            "South Carolina"
        ],
        "model_ans": "South Carolina Gamecocks",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> South Carolina Gamecocks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did canada sign the un declaration of indigenous rights",
        "answers": [
            "May 2016",
            "12 November 2010"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "distance from one side of a bridge to the other crossword",
        "answers": [
            "span"
        ],
        "model_ans": "span",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> span </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the cuban revolt against spain was led by",
        "answers": [
            "M\u00e1ximo Gomez",
            "Antonio Maceo",
            "Jos\u00e9 Mart\u00ed"
        ],
        "model_ans": "Jos\u00e9 Mart\u00ed",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jos\u00e9 Mart\u00ed </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did sweet caroline start at red sox games",
        "answers": [
            "1997",
            "at least 1997"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the adrenal gland produce that is necessary for the sympathetic nervous system to function",
        "answers": [
            "epinephrine"
        ],
        "model_ans": "adrenaline",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> adrenaline </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "colby chees is named after a town in what state",
        "answers": [
            "Wisconsin"
        ],
        "model_ans": "Wisconsin",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Wisconsin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does season 8 of hawaii five o premiere",
        "answers": [
            "September 29, 2017"
        ],
        "model_ans": "September 2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what happens when iron reacts with oxygen and water",
        "answers": [
            "Rust"
        ],
        "model_ans": "Rust forms\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Rust forms\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the first train run in england",
        "answers": [
            "1560s",
            "As early as 1671",
            "1830",
            "1804"
        ],
        "model_ans": "1825\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1825\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many ammendments to the constitution have there been",
        "answers": [
            "Twenty-seven",
            "Thirty-three"
        ],
        "model_ans": "27\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "27\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang it must have been love but its over now",
        "answers": [
            "Roxette"
        ],
        "model_ans": "Taylor Dayne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taylor Dayne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the first computer game in 1962 and what was the name of the game",
        "answers": [
            "Spacewar!",
            "Steve Russell",
            "Wayne Wiitanen",
            "Martin Graetz"
        ],
        "model_ans": "Steve Russell",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Steve Russell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the original spirit in the sky",
        "answers": [
            "Norman Greenbaum"
        ],
        "model_ans": "Ray Charles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ray Charles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "internet based test of english as a foreign language test",
        "answers": [
            "TOEFL"
        ],
        "model_ans": "IELTS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IELTS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays rachel on jessie punch dumped love",
        "answers": [
            "Isabella Palmieri"
        ],
        "model_ans": "Jennifer Aniston",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jennifer Aniston</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is season 8 for game of thrones",
        "answers": [
            "2019",
            "in 2019"
        ],
        "model_ans": "April 2019",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> April 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are considered to be the founding fathers",
        "answers": [
            "George Washington",
            "Benjamin Franklin",
            "John Adams",
            "Alexander Hamilton",
            "John Jay",
            "James Madison",
            "Thomas Jefferson"
        ],
        "model_ans": "George Washington, John Adams, Thomas Jefferson, James Madison, James Monroe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Washington, John Adams, Thomas Jefferson, James Madison, James Monroe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many players on the line of scrimmage in american football",
        "answers": [
            "at least seven players",
            "at least seven",
            "seven"
        ],
        "model_ans": "11\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "11\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who holds the record for most everest summits",
        "answers": [
            "Kami Rita",
            "Phurba Tashi Sherpa",
            "Apa Sherpa",
            "Phurba Tashi",
            "Kami Rita Sherpa"
        ],
        "model_ans": "Kami Rita",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kami Rita </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the director of nightmare before christmas",
        "answers": [
            "Henry Selick"
        ],
        "model_ans": "Henry Selick",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Henry Selick </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the four main types of precipitation",
        "answers": [
            "sleet",
            "hail",
            "graupel",
            "snow",
            "drizzle",
            "rain"
        ],
        "model_ans": "Rain, Snow, Hail, Sleet",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rain, Snow, Hail, Sleet </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the 11th prime minister of canada",
        "answers": [
            "R. B. Bennett",
            "Arthur Meighen"
        ],
        "model_ans": "Jean Chr\u00e9tien",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean Chr\u00e9tien </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is hallmark channel home and family filmed",
        "answers": [
            "Los Angeles, California"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which term means the study of the nature and causes of disease",
        "answers": [
            "pathology"
        ],
        "model_ans": "Pathology",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pathology </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where are the next two winter olympics going to be held",
        "answers": [
            "Beijing",
            "TBD"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the poorest county in the state of florida",
        "answers": [
            "Union"
        ],
        "model_ans": "Liberty County",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Liberty County </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i can't take my eyes off of you",
        "answers": [
            "Frankie Valli"
        ],
        "model_ans": "Andy Williams",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Andy Williams </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays colin on young and the restless",
        "answers": [
            "Tristan Rogers"
        ],
        "model_ans": "Thom Bierdz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thom Bierdz </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many indian astronauts have gone to space",
        "answers": [
            "2"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the width of a cricket bat",
        "answers": [
            "no more than 4.25 inches"
        ],
        "model_ans": "4 inches",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 inches </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "why did ric flair go back to wcw",
        "answers": [
            "February 1993"
        ],
        "model_ans": "He returned to WCW in 1993 after a brief stint in the WWF, reportedly due to a disagreement over his contract",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He returned to WCW in 1993 after a brief stint in the WWF, reportedly due to a disagreement over his contract </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays manny in diary of a wimpy kid",
        "answers": [
            "Connor and Owen Fielding",
            "Wyatt and Dylan Walters"
        ],
        "model_ans": "Robert Capron",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robert Capron </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the light reaction of photosynthesis occur",
        "answers": [
            "on the thylakoid membranes"
        ],
        "model_ans": "thylakoid",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> thylakoid </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most super bowls in nfl history",
        "answers": [
            "Pittsburgh Steelers",
            "The Pittsburgh Steelers"
        ],
        "model_ans": "New England Patriots",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New England Patriots </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has appeared in the most royal rumbles",
        "answers": [
            "Shawn Michaels"
        ],
        "model_ans": "Edge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did they film the game of thrones",
        "answers": [
            "Croatia",
            "Iceland",
            "Canada",
            "Spain",
            "Morocco",
            "Malta",
            "Scotland",
            "United States",
            "Northern Ireland"
        ],
        "model_ans": "Dubrovnik",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dubrovnik </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the last name taylor originate from",
        "answers": [
            "Old French"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "american horror story freak show girl kidnapped by clown",
        "answers": [
            "Bonnie Lipton"
        ],
        "model_ans": "Twisty",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Twisty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the most mvp awards in the nba",
        "answers": [
            "Kareem Abdul-Jabbar"
        ],
        "model_ans": "Kareem Abdul-Jabbar",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kareem Abdul-Jabbar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays sven in the santa clarita diet",
        "answers": [
            "Leo Howard"
        ],
        "model_ans": "Timothy Olyphant",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Timothy Olyphant </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the current cruiserweight champion in wwe",
        "answers": [
            "Cedric Alexander",
            "Cedric Alexander,"
        ],
        "model_ans": "Drew Gulak",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Drew Gulak </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did corbin dance with on dancing with the stars",
        "answers": [
            "Karina Smirnoff"
        ],
        "model_ans": "Karina Smirnoff",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Karina Smirnoff </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who abolished the monarchy and declared france a republic",
        "answers": [
            "Convention",
            "France's Legislative Assembly"
        ],
        "model_ans": "National Convention",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> National Convention </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays harley quinn in the lego batman movie",
        "answers": [
            "Jenny Slate"
        ],
        "model_ans": "Jenny Slate",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jenny Slate </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many different kinds of pokemon cards are there",
        "answers": [
            "eleven"
        ],
        "model_ans": "100",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is australia's location in the world and region",
        "answers": [
            "Oceania"
        ],
        "model_ans": "Oceania",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oceania </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "batman and robin episode only fools and horses",
        "answers": [
            "\"Heroes and Villains\""
        ],
        "model_ans": "Only Fools and Horses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Only Fools and Horses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the 30 man royal rumble match",
        "answers": [
            "Shinsuke Nakamura",
            "Randy Orton"
        ],
        "model_ans": "Edge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the supreme justice of the supreme court",
        "answers": [
            "John Roberts"
        ],
        "model_ans": "John Roberts",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Roberts </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the most common blood type in sweden",
        "answers": [
            "A+",
            "AB+"
        ],
        "model_ans": "O",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> O </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does a heart rate of 131 mean",
        "answers": [
            "Tachycardia",
            "tachycardia in adults"
        ],
        "model_ans": "131 beats per minute",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 131 beats per minute </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the government change the retirement age",
        "answers": [
            "2015"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how oxygenated blood returns to the heart from the lungs",
        "answers": [
            "pulmonary circulation"
        ],
        "model_ans": "pulmonary veins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pulmonary veins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has won the most f1 grand prix",
        "answers": [
            "Michael Schumacher"
        ],
        "model_ans": "Lewis Hamilton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lewis Hamilton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many games does a team have to win for the world series",
        "answers": [
            "best-of-seven"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the log flume closed at alton towers",
        "answers": [
            "10\u00a0October\u00a02015",
            "2015"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what happens when an air mass is pushed up and over a mountain range",
        "answers": [
            "Orographic lift"
        ],
        "model_ans": "it cools and condenses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> it cools and condenses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the last name hansen come from",
        "answers": [
            "Norway",
            "the Faroe Islands",
            "Scandinavian",
            "Denmark"
        ],
        "model_ans": "Denmark",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Denmark </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who said life is like a bowl of cherries",
        "answers": [
            "Lew Brown"
        ],
        "model_ans": "Johnny Mercer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Mercer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long is the famous suspension bridge in san francisco and what is it called",
        "answers": [
            "one-mile-wide",
            "Golden Gate Bridge"
        ],
        "model_ans": "The Golden Gate Bridge",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Golden Gate Bridge </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "name a food you might eat on thanksgiving",
        "answers": [
            "a large roasted turkey",
            "turkey"
        ],
        "model_ans": "turkey",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> turkey </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did sierra nevada brewery open in asheville",
        "answers": [
            "early 2014",
            "January 2012",
            "2014"
        ],
        "model_ans": "1996",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1996 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who said have you no sense of decency",
        "answers": [
            "Joseph Nye Welch"
        ],
        "model_ans": "Joseph McCarthy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joseph McCarthy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the chicago bears quarterback last year",
        "answers": [
            "Matt Barkley",
            "Jay Cutler (5)",
            "Matt Barkley (6)",
            "Brian Hoyer",
            "Jay Cutler",
            "Brian Hoyer (5)"
        ],
        "model_ans": "Mitchell Trubisky",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitchell Trubisky </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the dallas cowboys win their last playoff game",
        "answers": [
            "2014",
            "2016"
        ],
        "model_ans": "2021\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2021\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which animal is the carrier of the h1n1 virus",
        "answers": [
            "Pig",
            "pigs"
        ],
        "model_ans": "pig",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pig </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did the ancestors of the domestic goat originate",
        "answers": [
            "Iran"
        ],
        "model_ans": "The Middle East",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Middle East </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in season 4 of last ship",
        "answers": [
            "10"
        ],
        "model_ans": "13\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "13\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does part 5 of jojo take place",
        "answers": [
            "The manga begins in 2001",
            "2001"
        ],
        "model_ans": "2011\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2011\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the washington redskins based out of",
        "answers": [
            "the Washington metropolitan area",
            "FedExField in Landover, Maryland"
        ],
        "model_ans": "Washington",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Washington </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the highest base on the ph scale",
        "answers": [
            "greater than 14"
        ],
        "model_ans": "14\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "14\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the love meaning of the song",
        "answers": [
            "lament on various worldwide problems"
        ],
        "model_ans": "love",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> love </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played marius in the movie les miserables",
        "answers": [
            "Eddie Redmayne"
        ],
        "model_ans": "Hugh Jackman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hugh Jackman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the strictly come dancing results show recorded",
        "answers": [
            "Saturday",
            "Sunday night"
        ],
        "model_ans": "The results show is recorded live",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The results show is recorded live </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played chaka on land of the lost tv show",
        "answers": [
            "Phillip Paley"
        ],
        "model_ans": "Kevin Heffernan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kevin Heffernan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the first home video security system",
        "answers": [
            "her husband Albert Brown",
            "Marie Van Brittan Brown"
        ],
        "model_ans": "ADT",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ADT </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did sussex split into east and west",
        "answers": [
            "1832",
            "1889"
        ],
        "model_ans": "1066\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1066\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sold the most records elvis or the beatles",
        "answers": [
            "The Beatles"
        ],
        "model_ans": "The Beatles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Beatles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does a bull shark tooth look like",
        "answers": [
            "needle-like teeth",
            "needle-like"
        ],
        "model_ans": "Bull shark teeth are triangular in shape with a distinctive rounded tip and a rough surface",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bull shark teeth are triangular in shape with a distinctive rounded tip and a rough surface </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bosnia and herzegovina croatia macedonia and slovenia all used to be parts of",
        "answers": [
            "Yugoslavia"
        ],
        "model_ans": "Yugoslavia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yugoslavia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many quarterbacks have a receiving touchdown in the superbowl",
        "answers": [
            "1"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what act did parliament pass after the boston tea party",
        "answers": [
            "The Intolerable Acts",
            "Intolerable Acts",
            "the Coercive Acts"
        ],
        "model_ans": "Coercive Acts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Coercive Acts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons of johnny bravo are there",
        "answers": [
            "four"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the sweetness of fruit come from",
        "answers": [
            "Fructose, or fruit sugar",
            "Fructose"
        ],
        "model_ans": "fructose",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fructose </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays drew's boyfriend on the night shift",
        "answers": [
            "Rick"
        ],
        "model_ans": "Hunter Parrish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hunter Parrish </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does kubo and the two strings release",
        "answers": [
            "August 19, 2016",
            "August\u00a019,\u00a02016"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays nikko in the wizard of oz",
        "answers": [
            "Patrick Walshe"
        ],
        "model_ans": "Nikko",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nikko </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is a e8 in the marine corps",
        "answers": [
            "Master sergeant",
            "First sergeant"
        ],
        "model_ans": "Eighth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eighth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who stole the mona lisa from the louvre in 1911",
        "answers": [
            "Vincenzo Peruggia"
        ],
        "model_ans": "Vincenzo Peruggia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vincenzo Peruggia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang the them song for as told by ginger",
        "answers": [
            "Melissa Disney",
            "R&B artist Macy Gray",
            "Macy Gray",
            "Cree Summer"
        ],
        "model_ans": "Krystal Keith",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Krystal Keith </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does brooklyn nine nine season 5 episode 12",
        "answers": [
            "March\u00a018,\u00a02018"
        ],
        "model_ans": "January 10, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 10, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is going to host the 2018 winter olympics",
        "answers": [
            "South Korea",
            "Pyeongchang County, South Korea"
        ],
        "model_ans": "Pyeongchang",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pyeongchang </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which came first the walking dead comic or show",
        "answers": [
            "comic book",
            "comic"
        ],
        "model_ans": "comic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> comic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played john clark sr on nypd blue",
        "answers": [
            "Joe Spano"
        ],
        "model_ans": "David Caruso",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Caruso </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played peter benton's sister on er",
        "answers": [
            "Jackie Robbins"
        ],
        "model_ans": "Maura Tierney",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maura Tierney </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the protien made in the cell",
        "answers": [
            "in the cell nucleus",
            "cell nucleus"
        ],
        "model_ans": "Ribosomes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ribosomes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is given credit for inventing the aqua lung",
        "answers": [
            "Jacques Cousteau",
            "engineer \u00c9mile Gagnan",
            "\u00c9mile Gagnan"
        ],
        "model_ans": "Jean Piccard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Piccard</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the 1st battle of bull run",
        "answers": [
            "Confederate victory",
            "Confederate forces",
            "Confederate"
        ],
        "model_ans": "Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the voice of john smith in pocahontas",
        "answers": [
            "Mel Gibson"
        ],
        "model_ans": "Mel Gibson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mel Gibson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "computer based models of real life situation are called",
        "answers": [
            "Computer simulation",
            "Computer simulations"
        ],
        "model_ans": "Simulations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Simulations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many inches is the iphone 5s screen",
        "answers": [
            "4\u00a0in",
            "4-inch screen size"
        ],
        "model_ans": "4 inches\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4 inches\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "5 cities with the highest population in europe",
        "answers": [
            "London",
            "Saint Petersburg",
            "Berlin",
            "Moscow",
            "Istanbul"
        ],
        "model_ans": "London, Moscow, Istanbul, Berlin, Paris",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> London, Moscow, Istanbul, Berlin, Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the valley of the dolls based on",
        "answers": [
            "Dean Martin",
            "Judy Garland",
            "Ethel Merman",
            "Carole Landis"
        ],
        "model_ans": "Jean Harlow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Harlow</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the movie the post begin filming",
        "answers": [
            "May 2017",
            "May 30, 2017"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl who played in the grinch",
        "answers": [
            "Taylor Michel Momsen"
        ],
        "model_ans": "Taylor Momsen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taylor Momsen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who took over the dutch colony in north america",
        "answers": [
            "England",
            "English"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the theme song for mission impossible",
        "answers": [
            "Lalo Schifrin",
            "Argentine composer Lalo Schifrin"
        ],
        "model_ans": "Lalo Schifrin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lalo Schifrin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the theme to last of the mohicans",
        "answers": [
            "Dougie MacLean"
        ],
        "model_ans": "Trevor Jones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trevor Jones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did day light savings start in the us",
        "answers": [
            "March 31, 1918",
            "1918",
            "March 19, 1918",
            "March\u00a011"
        ],
        "model_ans": "1918",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1918 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the m number mean on a pint glass",
        "answers": [
            "imperial fluid ounces",
            "the manufacturing company or site"
        ],
        "model_ans": "M is the measurement of the glass's diameter in millimeters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> M is the measurement of the glass's diameter in millimeters </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is beijing located on the world map",
        "answers": [
            "northern China",
            "in northern China"
        ],
        "model_ans": "Asia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does mexico play in the winter olympics",
        "answers": [
            "9 to 25 February 2018"
        ],
        "model_ans": "Mexico has never participated in the Winter Olympics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mexico has never participated in the Winter Olympics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who dies in the lost city of z",
        "answers": [
            "Manley"
        ],
        "model_ans": "Percy Fawcett",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Percy Fawcett </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the black panther movie soundtrack come out",
        "answers": [
            "February 9, 2018",
            "February 16, 2018"
        ],
        "model_ans": "February 1, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> February 1, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the letter j introduced to the alphabet",
        "answers": [
            "in Middle High German",
            "1524"
        ],
        "model_ans": "around 1500 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 1500 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what flag is red and has a gold star",
        "answers": [
            "flag of Vietnam",
            "Vietnam",
            "The flag of Vietnam"
        ],
        "model_ans": "Flag of Chile",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Flag of Chile </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who expanded the palace of versailles to its present size",
        "answers": [
            "Louis XIV",
            "Louis XV"
        ],
        "model_ans": "Louis XIV",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis XIV </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time the vikings made the superbowl",
        "answers": [
            "in the 1970s"
        ],
        "model_ans": "never",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> never </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do we find out luke and leia are siblings",
        "answers": [
            "Return of the Jedi",
            "In Return of the Jedi"
        ],
        "model_ans": "Return of the Jedi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Return of the Jedi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the uk and us become allies",
        "answers": [
            "Since 1940",
            "1940"
        ],
        "model_ans": "1778",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1778 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song going to kansas city",
        "answers": [
            "Jerry Leiber and Mike Stoller",
            "Jerry Leiber",
            "Mike Stoller"
        ],
        "model_ans": "Jerry Leiber",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Jerry Leiber</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the battle of issus take place",
        "answers": [
            "southern Anatolia",
            "in southern Anatolia"
        ],
        "model_ans": "Issus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Issus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of the muslim dress",
        "answers": [
            "hijab"
        ],
        "model_ans": "Hijab",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hijab </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the new saw 8 come out",
        "answers": [
            "October 27, 2017"
        ],
        "model_ans": "October 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 2022 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when were cigarette ads banned from tv uk",
        "answers": [
            "1 August 1965"
        ],
        "model_ans": "1991",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1991 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the transtheoretical model of behavior change",
        "answers": [
            "colleagues",
            "Carlo Di Clemente"
        ],
        "model_ans": "James Prochaska",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Prochaska </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who recorded i can't help falling in love with you",
        "answers": [
            "Elvis Presley"
        ],
        "model_ans": "Elvis Presley",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Elvis Presley </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did india win their first cricket match",
        "answers": [
            "1952"
        ],
        "model_ans": "25 January 1932",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 25 January 1932 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which term is used to identify having official power to act",
        "answers": [
            "authority",
            "Authority"
        ],
        "model_ans": "authority",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> authority </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does grey's anatomy come back on in march",
        "answers": [
            "March\u00a01,\u00a02018"
        ],
        "model_ans": "March 30, 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 30, 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was president when the panama canal was built",
        "answers": [
            "Theodore Roosevelt",
            "President Theodore Roosevelt"
        ],
        "model_ans": "Theodore Roosevelt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Theodore Roosevelt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the remake of dirty dancing filmed",
        "answers": [
            "High Hampton Inn in Cashiers",
            "Hendersonville, North Carolina",
            "western North Carolina"
        ],
        "model_ans": "Lake Lure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Lure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the little boy in polar express",
        "answers": [
            "Daryl Sabara",
            "Dante Pastula"
        ],
        "model_ans": "Tom Hanks",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Hanks </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what channel does thursday night football come on regular tv",
        "answers": [
            "NBC"
        ],
        "model_ans": "fox",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fox </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did how you remind me come out",
        "answers": [
            "August\u00a021,\u00a02001",
            "August 21, 2001"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is new prime minister of italy 2018",
        "answers": [
            "TBD"
        ],
        "model_ans": "Giuseppe Conte",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Giuseppe Conte </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the subway open in new york",
        "answers": [
            "October 27, 1904",
            "1904"
        ],
        "model_ans": "1904",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1904 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the speed of the nascar pace car",
        "answers": [
            "pit road speed"
        ],
        "model_ans": "100-150 mph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100-150 mph </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the silver medal in womens figure skating",
        "answers": [
            "Evgenia Medvedeva"
        ],
        "model_ans": "Yuna Kim",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yuna Kim </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what year is the deer hunter set in",
        "answers": [
            "late 1967",
            "1967"
        ],
        "model_ans": "1968\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1968\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of writing did ancient egypt use",
        "answers": [
            "hieroglyphs",
            "Egyptian hieroglyphs"
        ],
        "model_ans": "Hieroglyphics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hieroglyphics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the united states win its independence from",
        "answers": [
            "the British Empire",
            "Great Britain"
        ],
        "model_ans": "Great Britain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Great Britain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the first element on the periodic table is",
        "answers": [
            "Hydro\u00adgen",
            "hydrogen"
        ],
        "model_ans": "Hydrogen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hydrogen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the song oh lord won't you buy me a mercedes benz",
        "answers": [
            "Janis Joplin",
            "Bob Neuwirth",
            "Michael McClure"
        ],
        "model_ans": "Jagger",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jagger</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first imperial power that was fighting in vietnam",
        "answers": [
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the captain of richmond football club",
        "answers": [
            "Trent Cotchin"
        ],
        "model_ans": "Trent Cotchin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Trent Cotchin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the first indian climber of mount everest",
        "answers": [
            "Bachendri Pal"
        ],
        "model_ans": "Sonam Gyatso",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sonam Gyatso </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the writer of 50 shades of grey",
        "answers": [
            "Erika Mitchell Leonard",
            "E. L. James"
        ],
        "model_ans": "E.L. James",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> E.L. James </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who votes to elect a rajya sabha memmber",
        "answers": [
            "state legislatures"
        ],
        "model_ans": "Lok Sabha",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lok Sabha </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what land mass was north america a part of about 300 million years ago",
        "answers": [
            "Pangaea",
            "Pangaea or Pangea"
        ],
        "model_ans": "Pangaea",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pangaea </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was defeated in the french and indian war",
        "answers": [
            "the French",
            "Wabanaki Confederacy",
            "British",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many episodes curse of oak island season 5",
        "answers": [
            "18"
        ],
        "model_ans": "22\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "22\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first nhl hockey game played",
        "answers": [
            "Ottawa",
            "Montreal"
        ],
        "model_ans": "Montreal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montreal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played mr thatcher in when calls the heart",
        "answers": [
            "Garwin Sanford"
        ],
        "model_ans": "Martin Cummins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Martin Cummins </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays cesar in the show on my block",
        "answers": [
            "Diego Tinoco"
        ],
        "model_ans": "Isaiah Mustafa",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Isaiah Mustafa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where would the group bacteroids likely be found",
        "answers": [
            "the human colon",
            "human colon"
        ],
        "model_ans": "soil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> soil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the pinkerton detective agency's first female detective",
        "answers": [
            "Kate Warne"
        ],
        "model_ans": "Kate Warne",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kate Warne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played harley in harley davidson and the marlboro man",
        "answers": [
            "Mickey Rourke"
        ],
        "model_ans": "Don Johnson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Don Johnson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the original voices of the flintstones",
        "answers": [
            "Verna Felton",
            "Bea Benaderet",
            "Don Messick",
            "Harvey Korman",
            "Alan Reed",
            "Mel Blanc",
            "Jean Vander Pyl",
            "John Stephenson"
        ],
        "model_ans": "Alan Reed (Fred Flintstone) and Jean Vander Pyl (Wilma Flintstone)",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Alan Reed (Fred Flintstone) and Jean Vander Pyl (Wilma Flintstone) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did they get the vibranium to make captain americas shield",
        "answers": [
            "Wakanda"
        ],
        "model_ans": "Wakanda",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wakanda </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays the short cop on will and grace",
        "answers": [
            "Ryan Pinkston"
        ],
        "model_ans": "Sean Hayes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sean Hayes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is loihi and where does it originate from",
        "answers": [
            "from the Hawaii hotspot"
        ],
        "model_ans": "Loihi is an underwater volcano located off the coast of Hawaii",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Loihi is an underwater volcano located off the coast of Hawaii </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "anastomosis between the epididymis and the vas deferens",
        "answers": [
            "Vasoepididymostomy"
        ],
        "model_ans": "epididymo-vas deferens anastomosis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> epididymo-vas deferens anastomosis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time astros was in the world series",
        "answers": [
            "2017",
            "2005"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won so you think you can dance season 13",
        "answers": [
            "Kida",
            "Leon \"Kida\" Burns"
        ],
        "model_ans": "Jasmine Harper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jasmine Harper </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played lionel in as time goes by",
        "answers": [
            "Geoffrey Dyson Palmer, OBE",
            "Geoffrey Dyson Palmer"
        ],
        "model_ans": "John Rhys-Davies",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Rhys-Davies </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who helped the british in the french and indian war",
        "answers": [
            "Cherokee",
            "Iroquois Confederacy",
            "the colonies of British America",
            "Catawba",
            "Iroquois"
        ],
        "model_ans": "Prussia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Prussia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the german leader who signed the treaty of versailles",
        "answers": [
            "Gustav Bauer",
            "President Friedrich Ebert"
        ],
        "model_ans": "wilhelm ii",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wilhelm ii </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played ricky in secret life of the american teenager",
        "answers": [
            "Daren Maxwell Kagasoff"
        ],
        "model_ans": "Daren Kagasoff",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Daren Kagasoff </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a good that can be used in place of another good",
        "answers": [
            "A substitute good",
            "substitute good"
        ],
        "model_ans": "substitute",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> substitute </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of the name sinead",
        "answers": [
            "God forgave/God gratified"
        ],
        "model_ans": "fiery hearth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> fiery hearth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who gets first pick of fa cup games",
        "answers": [
            "BBC",
            "the BBC"
        ],
        "model_ans": "Manchester City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Manchester City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the written dialogue portion of a musical called",
        "answers": [
            "script",
            "libretto"
        ],
        "model_ans": "lyrics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lyrics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in florida it is illegal to sell alcohol before 1 pm on any sunday. this is an example of",
        "answers": [
            "Blue laws"
        ],
        "model_ans": "blue law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> blue law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played the original wonder woman on tv",
        "answers": [
            "Lynda Carter"
        ],
        "model_ans": "Lynda Carter",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lynda Carter </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the man in the high castle episode 1 season 1",
        "answers": [
            "The New World"
        ],
        "model_ans": "Amazon Studios",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amazon Studios </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the voice of the other mother in coraline",
        "answers": [
            "Teri Hatcher"
        ],
        "model_ans": "Teri Hatcher",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Teri Hatcher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the dodgers played yankees in the world series",
        "answers": [
            "1981"
        ],
        "model_ans": "1981\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1981\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the highest paid contract in the nba",
        "answers": [
            "Stephen Curry"
        ],
        "model_ans": "Stephen Curry",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Stephen Curry </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does jo come in grey's anatomy",
        "answers": [
            "season 9",
            "2012",
            "July 2012"
        ],
        "model_ans": "Season 2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which financial statement involves all aspects of the accounting\u200b equation",
        "answers": [
            "balance sheet",
            "The balance sheet"
        ],
        "model_ans": "Balance Sheet",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Balance Sheet </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who got the most passing yards in the nfl",
        "answers": [
            "Peyton Manning"
        ],
        "model_ans": "Drew Brees",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Drew Brees </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was it was not death for i stood up published",
        "answers": [
            "1890",
            "1891"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bacterial cell walls are made rigid by the presence of",
        "answers": [
            "Peptidoglycan"
        ],
        "model_ans": "peptidoglycan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> peptidoglycan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did 10 shilling note go out of circulation",
        "answers": [
            "22 November 1970",
            "1970"
        ],
        "model_ans": "1988\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1988\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many medals did austria win in the 2011 alpine skiing world championships",
        "answers": [
            "8"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the song rapper's delight come out",
        "answers": [
            "1979",
            "September 16, 1979"
        ],
        "model_ans": "1974\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1974\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the flash first appear on arrow",
        "answers": [
            "second season"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang how can you mend a broken heart first",
        "answers": [
            "Bee Gees",
            "the Bee Gees"
        ],
        "model_ans": "Al Green",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Al Green </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played in the stanley cup finals last year",
        "answers": [
            "Nashville Predators",
            "Pittsburgh Penguins"
        ],
        "model_ans": "Tampa Bay Lightning",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tampa Bay Lightning </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the continental congress vote to adopt the declaration of independence",
        "answers": [
            "July 2, 1776"
        ],
        "model_ans": "1776\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1776\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the us launch space shuttles from",
        "answers": [
            "Florida"
        ],
        "model_ans": "Kennedy Space Center",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kennedy Space Center </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a country having an island location and a country having continental location",
        "answers": [
            "Australia"
        ],
        "model_ans": "Japan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Japan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which horse and jockey won the melbourne cup in 2002",
        "answers": [
            "Media Puzzle",
            "Damien Oliver"
        ],
        "model_ans": "Makybe Diva",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Makybe Diva </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was last time bayern munich won champions league",
        "answers": [
            "2012\u201313",
            "2013",
            "2000\u201301"
        ],
        "model_ans": "2020\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2020\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang what i like about you originally",
        "answers": [
            "The Romantics.",
            "The Romantics",
            "American rock band The Romantics"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the complete collection of dna and genes is called",
        "answers": [
            "genome",
            "chromosome"
        ],
        "model_ans": "genome",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> genome </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays big momma in big mommas house",
        "answers": [
            "Ella Mitchell",
            "Martin Lawrence"
        ],
        "model_ans": "Martin Lawrence",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Martin Lawrence </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when were 7 books removed from the bible",
        "answers": [
            "1546"
        ],
        "model_ans": "325 AD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 325 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what percentage of global man-made co2 emissions comes from worldwide aviation",
        "answers": [
            "4 percent cumulative effect"
        ],
        "model_ans": "2-3%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2-3% </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did i'm coming out come out",
        "answers": [
            "August\u00a022,\u00a01980",
            "August 22, 1980"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long has tom brady been playing professional football",
        "answers": [
            "18-season career"
        ],
        "model_ans": "22 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 22 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is one element a topographic map shows",
        "answers": [
            "relief"
        ],
        "model_ans": "elevation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> elevation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "spyder from once upon a time in venice",
        "answers": [
            "Jason Momoa"
        ],
        "model_ans": "Marcello Mastroianni",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Marcello Mastroianni </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who dies in season 6 of once upon a time",
        "answers": [
            "Hyde",
            "Jekyll"
        ],
        "model_ans": "Robin Hood",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robin Hood </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won mark and goal of the year 2017",
        "answers": [
            "Joe Daniher"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who said i'll gladly pay you tuesday",
        "answers": [
            "Wimpy"
        ],
        "model_ans": "WC Fields",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> WC Fields </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the 7th game of the world series played",
        "answers": [
            "Dodger Stadium, Los Angeles"
        ],
        "model_ans": "At the home stadium of the team that wins the 6th game",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> At the home stadium of the team that wins the 6th game </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the next season of wynonna earp start",
        "answers": [
            "2018",
            "January 15, 2018"
        ],
        "model_ans": "June 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the emblematic rhythm of dominican republic",
        "answers": [
            "merengue",
            "bachata"
        ],
        "model_ans": "Merengue",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Merengue </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what side does us army go on acu",
        "answers": [
            "the right"
        ],
        "model_ans": "Army Combat Uniform",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Army Combat Uniform </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang it's a mean old world",
        "answers": [
            "T-Bone Walker"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the astros play last time they were in the world series",
        "answers": [
            "White Sox",
            "Los Angeles Dodgers"
        ],
        "model_ans": "Washington Nationals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Washington Nationals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the inventor who developed a way to record sound",
        "answers": [
            "Thomas Edison"
        ],
        "model_ans": "Thomas Edison",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Edison </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who became a leader of the indian national congress",
        "answers": [
            "Mahatma Gandhi"
        ],
        "model_ans": "Jawaharlal Nehru",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jawaharlal Nehru </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most sacks in college football",
        "answers": [
            "Mike Czerwien"
        ],
        "model_ans": "Terrell Suggs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Terrell Suggs </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does zonia receive from reuben in the play",
        "answers": [
            "kiss"
        ],
        "model_ans": "a letter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a letter </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "during the great depression in the 1930s the u.s. economy experienced a",
        "answers": [
            "economic recession",
            "recession",
            "an economic recession"
        ],
        "model_ans": "recession",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> recession </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the guy who walked across the twin towers",
        "answers": [
            "Philippe Petit"
        ],
        "model_ans": "Philippe Petit",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philippe Petit </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "turkish finnish and hungarian belong to which family of languages",
        "answers": [
            "Uralic languages"
        ],
        "model_ans": "Uralic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uralic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sponsored the phoenix open before waste management",
        "answers": [
            "Friedman Billings Ramsey"
        ],
        "model_ans": "IBM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was i can only imagine the song released",
        "answers": [
            "1999",
            "2001"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much money did the film titanic make",
        "answers": [
            "$2.18 billion",
            "$2.187 billion"
        ],
        "model_ans": "$2.1 billion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $2.1 billion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who came up with the theory of relativity",
        "answers": [
            "Albert Einstein"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does prime rib come from on a cow",
        "answers": [
            "the primal rib"
        ],
        "model_ans": "Rib",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rib </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the meridian that is opposite the prime meridian located",
        "answers": [
            "the 180th meridian",
            "antimeridian"
        ],
        "model_ans": "180\u00b0 E",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 180\u00b0 E </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does it mean to fuse the spine",
        "answers": [
            "joins two or more vertebrae"
        ],
        "model_ans": "Spinal fusion is a surgical procedure where two or more vertebrae are joined together to stabilize the spine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spinal fusion is a surgical procedure where two or more vertebrae are joined together to stabilize the spine </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who took control of jamestown and made new rules that made everyone work",
        "answers": [
            "John Smith"
        ],
        "model_ans": "Powhatan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Powhatan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who presides over the highest criminal court in a district",
        "answers": [
            "District Judge"
        ],
        "model_ans": "Judge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Judge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played stonewall jackson in gods and generals",
        "answers": [
            "Stephen Lang"
        ],
        "model_ans": "Robert Duvall",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robert Duvall </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how did early humans make use of stones during the prehistoric period",
        "answers": [
            "hunt",
            "start fires",
            "bury their dead"
        ],
        "model_ans": "Early humans used stones for various purposes such as tools, weapons, and shelter construction",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Early humans used stones for various purposes such as tools, weapons, and shelter construction </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won britain's next top model 2016",
        "answers": [
            "Chloe Keenan"
        ],
        "model_ans": "Abigail Clancy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abigail Clancy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which state was returned to spain after the revolutionary war",
        "answers": [
            "Florida",
            "Menorca"
        ],
        "model_ans": "Florida\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Florida\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where do they film take me out fernando's",
        "answers": [
            "Club Bijou on Chapel Street"
        ],
        "model_ans": "Miami",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Miami </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played booster in jingle all the way",
        "answers": [
            "Curtis Armstrong"
        ],
        "model_ans": "Jake Lloyd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jake Lloyd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "dendrites and cell bodies are components of what type of matter found in the brain",
        "answers": [
            "gray",
            "Grey matter"
        ],
        "model_ans": "biological",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> biological </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the united states foreign policy after ww1 started",
        "answers": [
            "neutrality"
        ],
        "model_ans": "The United States initially maintained a policy of neutrality, but eventually entered the war on the side of the Allies in 1917.",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The United States initially maintained a policy of neutrality, but eventually entered the war on the side of the Allies in 1917. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which nfl coach has the most superbowl rings",
        "answers": [
            "Bill Belichick"
        ],
        "model_ans": "Bill Belichick",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bill Belichick </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did radio shack change to the source",
        "answers": [
            "April 26, 2005",
            "2005"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the theme song for the winter olympics",
        "answers": [
            "Leo Arnaud"
        ],
        "model_ans": "John Williams",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Williams </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did little polveir win the grand national",
        "answers": [
            "1989"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "most assists in an nba all star game",
        "answers": [
            "60",
            "22"
        ],
        "model_ans": "Magic Johnson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Magic Johnson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the next episode of flash airing",
        "answers": [
            "May\u00a08,\u00a02018"
        ],
        "model_ans": "The next episode of Flash is airing on November 12, 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The next episode of Flash is airing on November 12, 2022 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the democratic party change its name",
        "answers": [
            "the 1830s"
        ],
        "model_ans": "1848",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1848 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did michael showers play on vampire diaries",
        "answers": [
            "The Man"
        ],
        "model_ans": "Finn Mikaelson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Finn Mikaelson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the largest amount of federal tax revenue come from",
        "answers": [
            "California"
        ],
        "model_ans": "income taxes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> income taxes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does wild caught sockeye salmon come from",
        "answers": [
            "the Northern Pacific Ocean"
        ],
        "model_ans": "Alaska",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alaska </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the mvp for the national league",
        "answers": [
            "Stanton, Giancarlo",
            "Giancarlo Stanton"
        ],
        "model_ans": "Bryce Harper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bryce Harper </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the latest edition of the intelligent investor",
        "answers": [
            "Fourth Revised Edition",
            "2003"
        ],
        "model_ans": "The Intelligent Investor (2005)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Intelligent Investor (2005) </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl that played darlene in roseanne",
        "answers": [
            "Sara Gilbert"
        ],
        "model_ans": "Sara Gilbert",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sara Gilbert </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does tyler end up with in you get me",
        "answers": [
            "Ali"
        ],
        "model_ans": "Ally",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ally </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "big bang theory season 11 how many episodes",
        "answers": [
            "14",
            "12"
        ],
        "model_ans": "24\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "24\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was i look at the world poem written",
        "answers": [
            "30\u201331 October 2000"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the year round weather in dubai",
        "answers": [
            "tropical desert climate"
        ],
        "model_ans": "hot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played g baby in the movie hardball",
        "answers": [
            "DeWayne Warren"
        ],
        "model_ans": "Keanu Reeves",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Keanu Reeves </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was where have all the flowers gone written",
        "answers": [
            "1955"
        ],
        "model_ans": "1955\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1955\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the wheel introduced to north america",
        "answers": [
            "about 1500 BC"
        ],
        "model_ans": "around 2000 BCE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 2000 BCE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was named african footballer of the year 2014",
        "answers": [
            "Yaya Tour\u00e9"
        ],
        "model_ans": "Yaya Tour\u00e9",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yaya Tour\u00e9 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the last name cintron come from",
        "answers": [
            "Portuguese",
            "Spanish-French"
        ],
        "model_ans": "Spain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who formed and first came to the colony of maryland",
        "answers": [
            "the English"
        ],
        "model_ans": "Lord Baltimore",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lord Baltimore </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the biggest town in west virginia",
        "answers": [
            "Charleston"
        ],
        "model_ans": "Charleston",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charleston </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are the 5 prohibitions of yom kippur",
        "answers": [
            "No marital relations",
            "No wearing of leather shoes",
            "No eating and drinking",
            "No bathing or washing"
        ],
        "model_ans": "1. Eating and drinking, 2. Wearing leather shoes, 3. Washing, 4. Anointing, 5. Using perfumes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1. Eating and drinking, 2. Wearing leather shoes, 3. Washing, 4. Anointing, 5. Using perfumes </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who died in the first episode of stranger things",
        "answers": [
            "Benny"
        ],
        "model_ans": "Will Byers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Will Byers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays zoey in i love you man",
        "answers": [
            "Rashida Jones"
        ],
        "model_ans": "Rashida Jones",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rashida Jones </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which is the default file extension for an audio file in windows media player",
        "answers": [
            "Windows Playlist (WPL)"
        ],
        "model_ans": ".wma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> .wma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who owns the dower house in the archers",
        "answers": [
            "Lilian Bellamy",
            "Caroline Sterling"
        ],
        "model_ans": "Caroline Archer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Caroline Archer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "to aru kagaku no railgun s episode 3",
        "answers": [
            "Project Radio Noise"
        ],
        "model_ans": "Mikoto Misaka",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mikoto Misaka </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "1 the bureau of land management manages over acres of land in the united states",
        "answers": [
            "247.3\u00a0million"
        ],
        "model_ans": "245 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 245 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what cities are in san joaquin county california",
        "answers": [
            "Lodi",
            "Stockton",
            "Lathrop",
            "Manteca",
            "Ripon",
            "Tracy",
            "Escalon"
        ],
        "model_ans": "Stockton, Lodi, Tracy, Manteca, Modesto",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Stockton, Lodi, Tracy, Manteca, Modesto </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the mlb season start and finish",
        "answers": [
            "March 29",
            "October 31, 2018"
        ],
        "model_ans": "The MLB season typically starts in late March or early April and ends in late September or early October.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The MLB season typically starts in late March or early April and ends in late September or early October. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the 2018 formula one australia grand prix tournament",
        "answers": [
            "Ferrari driver Sebastian Vettel",
            "Sebastian Vettel"
        ],
        "model_ans": "Lewis Hamilton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lewis Hamilton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who said everyone will be famous for 15 minutes",
        "answers": [
            "Andy Warhol"
        ],
        "model_ans": "Andy Warhol",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andy Warhol </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the new adventure time come out",
        "answers": [
            "April 21, 2017"
        ],
        "model_ans": "There is no official release date announced yet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official release date announced yet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "dynamin is associated with which type of vesicle",
        "answers": [
            "newly formed vesicles"
        ],
        "model_ans": "synaptic vesicle",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> synaptic vesicle </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the revolution begin in the united states",
        "answers": [
            "1775",
            "1765"
        ],
        "model_ans": "1775\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1775\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played tom on as the world turns",
        "answers": [
            "Jason Kincaid (1984)",
            "Jason Kincaid",
            "C. David Colson",
            "Peter Galman",
            "Scott Holmes",
            "Gregg Marx",
            "Justin Deas",
            "others",
            "Tom Tammi"
        ],
        "model_ans": "Van Hansis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Van Hansis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the ncaa women's championship last year 2017",
        "answers": [
            "South Carolina Gamecocks",
            "South Carolina"
        ],
        "model_ans": "South Carolina",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> South Carolina </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made the nuclear model of an atom",
        "answers": [
            "Ernest Rutherford"
        ],
        "model_ans": "Ernest Rutherford",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ernest Rutherford </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the little couples new season start",
        "answers": [
            "September 19, 2017"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the common name for gravitational force",
        "answers": [
            "Gravity",
            "Gravity, or gravitation"
        ],
        "model_ans": "Gravity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gravity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played mrs warboys in one foot in the grave",
        "answers": [
            "Doreen Mantle"
        ],
        "model_ans": "Annette Crosbie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Annette Crosbie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does tony end up with on skins",
        "answers": [
            "Michelle"
        ],
        "model_ans": "Minnie Ashworth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Minnie Ashworth </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the population of fayetteville north carolina",
        "answers": [
            "204,408 in 2013"
        ],
        "model_ans": "213,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 213,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was harry potter and the philosopher's stone made",
        "answers": [
            "14 November 2001",
            "1997"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the nationalist in the spanish civil war",
        "answers": [
            "the CEDA",
            "the Falange"
        ],
        "model_ans": "Nationalist forces",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nationalist forces </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who owns the biggest house in beverly hills",
        "answers": [
            "Anthony Pritzker"
        ],
        "model_ans": "The Playboy Mansion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Playboy Mansion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the flash coming back after christmas",
        "answers": [
            "January\u00a016,\u00a02018"
        ],
        "model_ans": "January 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 2023 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the signals for apoptosis come from",
        "answers": [
            "from other cells"
        ],
        "model_ans": "Mitochondria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitochondria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the battles of lexington and concord happen",
        "answers": [
            "April 19, 1775"
        ],
        "model_ans": "April 19, 1775",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> April 19, 1775 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most number one single hits",
        "answers": [
            "The Beatles"
        ],
        "model_ans": "Madonna",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Madonna </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what do you call a person who officiates a wedding",
        "answers": [
            "vow master",
            "solemniser",
            "marriage officiant",
            "\"vow master\""
        ],
        "model_ans": "Officiant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Officiant</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the river thames start and end",
        "answers": [
            "Thames Estuary, North Sea"
        ],
        "model_ans": "The River Thames starts at its source in Gloucestershire, England, and flows approximately 346 km (215 miles) to its mouth in the North Sea, near London.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The River Thames starts at its source in Gloucestershire, England, and flows approximately 346 km (215 miles) to its mouth in the North Sea, near London. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is a simple gear train used in real life",
        "answers": [
            "Automobile drivetrains"
        ],
        "model_ans": "bicycles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> bicycles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was how deep is your love released",
        "answers": [
            "1977",
            "September 1977"
        ],
        "model_ans": "1986",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1986 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which apostle spoke at the council of jerusalem",
        "answers": [
            "Paul",
            "James",
            "Barnabas",
            "Simon Peter"
        ],
        "model_ans": "James",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time the seattle seahawks won the superbowl",
        "answers": [
            "2013"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who said one man's vulgarity is another's lyric",
        "answers": [
            "Justice Harlan"
        ],
        "model_ans": "Oscar Wilde",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oscar Wilde </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did men's curling start in the olympics",
        "answers": [
            "1924",
            "1998",
            "1998 Nagano Games"
        ],
        "model_ans": "1924\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1924\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does claire from mcleods daughters end up with",
        "answers": [
            "Alex Ryan"
        ],
        "model_ans": "Darcy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Darcy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the dwarf's name in game of thrones",
        "answers": [
            "Tyrion Lannister"
        ],
        "model_ans": "Bran Stark",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bran Stark</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the queen in victoria and abdul",
        "answers": [
            "Judi Dench"
        ],
        "model_ans": "Judi Dench",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Judi Dench</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the grapes of wrath take place",
        "answers": [
            "Oklahoma",
            "California"
        ],
        "model_ans": "Oklahoma",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oklahoma </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is last time the astros won the world series",
        "answers": [
            "2017"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did drop it like it's hot release",
        "answers": [
            "September 12, 2004"
        ],
        "model_ans": "2004\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2004\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was south african youth day first celebrated",
        "answers": [
            "1976",
            "June 16"
        ],
        "model_ans": "16 June 1976",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 16 June 1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "china in chinese is called zhongguo which means",
        "answers": [
            "Central States"
        ],
        "model_ans": "middle country",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> middle country </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many counties does the state of georgia have",
        "answers": [
            "159",
            "159 counties"
        ],
        "model_ans": "159\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "159\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is mercy mercy me by marvin gaye about",
        "answers": [
            "sorrow regarding the environment",
            "the environment"
        ],
        "model_ans": "The song \"Mercy Mercy Me\" by Marvin Gaye is about the dangers of pollution and the destruction of the environment.",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The song \"Mercy Mercy Me\" by Marvin Gaye is about the dangers of pollution and the destruction of the environment. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the compound p4010",
        "answers": [
            "Phosphorus pentoxide"
        ],
        "model_ans": "4,4'-Methylenebis(2-chloroaniline)",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,4'-Methylenebis(2-chloroaniline) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the msc in msc cruises stand for",
        "answers": [
            "Mediterranean Shipping Company S.A.",
            "Mediterranean Shipping Company"
        ],
        "model_ans": "Mediterranean Shipping Company",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Mediterranean Shipping Company </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played joey's agent estelle on friends",
        "answers": [
            "June Gable"
        ],
        "model_ans": "June Gable",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> June Gable </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the sixth president of the united states",
        "answers": [
            "John Quincy Adams"
        ],
        "model_ans": "John Quincy Adams",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John Quincy Adams </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the food network star in 2016",
        "answers": [
            "Tregaye Fraser"
        ],
        "model_ans": "Eddie Huang",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Eddie Huang </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of bird is in the lion king",
        "answers": [
            "red-billed hornbill",
            "a red-billed hornbill"
        ],
        "model_ans": "Hornbill",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hornbill </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the judges on dancing on ice 2014",
        "answers": [
            "Jason Gardiner",
            "Ashley Roberts",
            "Robin Cousins",
            "Karen Barber"
        ],
        "model_ans": "Jayne Torvill, Christopher Dean, Robin Cousins",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jayne Torvill, Christopher Dean, Robin Cousins </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did this case of product tampering occur",
        "answers": [
            "the Chicago metropolitan area"
        ],
        "model_ans": "Chicago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what happens to water that infiltrates the soil if it is not absorbed by the roots of plants",
        "answers": [
            "runoff"
        ],
        "model_ans": "It becomes groundwater",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> It becomes groundwater </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who starred in the pirates of the caribbean",
        "answers": [
            "Johnny Depp",
            "Orlando Bloom",
            "Geoffrey Rush",
            "Kevin McNally",
            "Jonathan Pryce",
            "Jack Davenport",
            "Keira Knightley"
        ],
        "model_ans": "Johnny Depp",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Depp </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays bianca in that's so raven",
        "answers": [
            "Erica Rivera"
        ],
        "model_ans": "Raven-Symon\u00e9",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Raven-Symon\u00e9 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did we find out the smoking man was mulder's father",
        "answers": [
            "Later in the sixth season",
            "in the sixth season"
        ],
        "model_ans": "never",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> never </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what causes cracked skin at the corners of your mouth",
        "answers": [
            "allergies",
            "infection",
            "irritation"
        ],
        "model_ans": "dry air",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dry air </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the south west wind blows across nigeria between",
        "answers": [
            "till September"
        ],
        "model_ans": "May and September",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May and September </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the lead singer of collective soul",
        "answers": [
            "Ed Roland"
        ],
        "model_ans": "Ed Roland",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ed Roland </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are the top five wine producing states",
        "answers": [
            "Washington",
            "Pennsylvania",
            "Oregon",
            "New York",
            "California"
        ],
        "model_ans": "California, Italy, France, Spain, and Argentina",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> California, Italy, France, Spain, and Argentina </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is known as the father of indian constitution",
        "answers": [
            "Bhimrao Ramji Ambedkar"
        ],
        "model_ans": "B.R. Ambedkar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>B.R. Ambedkar</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what episode does lori die on the walking dead",
        "answers": [
            "\"Killer Within\"",
            "Killer Within"
        ],
        "model_ans": "316",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 316 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who penned the famous indian epic the ramayana",
        "answers": [
            "Valmiki",
            "the Hindu sage Valmiki"
        ],
        "model_ans": "Valmiki",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Valmiki </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the united kingdom entered world war 2",
        "answers": [
            "1939"
        ],
        "model_ans": "September 3, 1939",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> September 3, 1939 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does jack ryan live in patriot games",
        "answers": [
            "Baltimore, Maryland"
        ],
        "model_ans": "Washington D.C.",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Washington D.C. </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does season 8 for blue bloods start",
        "answers": [
            "September 29, 2017"
        ],
        "model_ans": "September 25, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 25, 2020 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "nobel laureate who began career as accountant in calcutta",
        "answers": [
            "Amartya Sen"
        ],
        "model_ans": "Amartya Sen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amartya Sen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what order do the captain america movies go in",
        "answers": [
            "Captain America: Civil War"
        ],
        "model_ans": "Captain America: The First Avenger (2011), Captain America: The Winter Soldier (2014), Captain America: Civil War (2016), Avengers: Infinity War (2018), Avengers: Endgame (2019) </</confidence>",
        "model_confidence": "",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Captain America: The First Avenger (2011), Captain America: The Winter Soldier (2014), Captain America: Civil War (2016), Avengers: Infinity War (2018), Avengers: Endgame (2019) </</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did virginia cavaliers lose to in basketball this year",
        "answers": [
            "Virginia Tech",
            "West Virginia",
            "UMBC"
        ],
        "model_ans": "Virginia Tech",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Virginia Tech </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times have the golden state warriors been to the playoffs",
        "answers": [
            "nine"
        ],
        "model_ans": "34",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 34 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays emma in air bud world pup",
        "answers": [
            "Brittany Paige Bouck"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the qb for the saints before drew brees",
        "answers": [
            "Aaron Brooks"
        ],
        "model_ans": "Aaron Brooks",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Aaron Brooks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of government is in north america",
        "answers": [
            "Federal presidential constitutional republic",
            "federal republic"
        ],
        "model_ans": "Federal Republic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Federal Republic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the first episode of that 70s show air",
        "answers": [
            "August 23, 1998",
            "August\u00a023,\u00a01998"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is an example of an americanized mexican food created by tex-mex cuisine",
        "answers": [
            "fajitas",
            "nachos",
            "hard tacos",
            "chili con carne"
        ],
        "model_ans": "nachos",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nachos </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the film manchester by the sea filmed",
        "answers": [
            "Lynn",
            "Swampscott",
            "Beverly",
            "Gloucester",
            "Manchester",
            "Essex",
            "Middleton",
            "Salem",
            "Tewksbury"
        ],
        "model_ans": "Boston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the nba add the three point line",
        "answers": [
            "1979\u201380",
            "1979\u201380 season",
            "the 1979\u201380 season"
        ],
        "model_ans": "1979",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1979 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time someone won the super bowl back to back",
        "answers": [
            "2004"
        ],
        "model_ans": "2003-2004",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2003-2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the best nba record this season",
        "answers": [
            "Houston Rockets"
        ],
        "model_ans": "Los Angeles Lakers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles Lakers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the main character in their eyes were watching god",
        "answers": [
            "Janie Crawford"
        ],
        "model_ans": "Jane",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jane</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who bowled the last over of the 2007 world twenty20 that india won",
        "answers": [
            "Pakistan"
        ],
        "model_ans": "Joginder Sharma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joginder Sharma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the youngest president to be elected",
        "answers": [
            "Theodore Roosevelt",
            "John F. Kennedy"
        ],
        "model_ans": "John F. Kennedy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John F. Kennedy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is the last time wisconsin missed the ncaa tournament",
        "answers": [
            "1997\u201398"
        ],
        "model_ans": "1998",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1998 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin",
        "answers": [
            "post translational modification"
        ],
        "model_ans": "proteolytic cleavage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> proteolytic cleavage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how much venom can a king cobra produce",
        "answers": [
            "420\u00a0mg",
            "up to 7\u00a0ml",
            "200 to 500\u00a0mg"
        ],
        "model_ans": "250-400 mg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 250-400 mg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl in the hinder video lips of an angel",
        "answers": [
            "Emmanuelle Chriqui"
        ],
        "model_ans": "Tamara Daybell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tamara Daybell </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the name of bombay change to mumbai",
        "answers": [
            "1995"
        ],
        "model_ans": "1995\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1995\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does season 7 game of thrones dvd release",
        "answers": [
            "December 12, 2017"
        ],
        "model_ans": "December 3, 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 3, 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the twenty one pilots hiatus start",
        "answers": [
            "November 2016",
            "July 2017"
        ],
        "model_ans": "2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2021 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who becomes chief resident on grey's anatomy season 7",
        "answers": [
            "April Kepner M.D.",
            "Kepner"
        ],
        "model_ans": "Jackson Avery",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jackson Avery </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the heart develop and begin pumping blood",
        "answers": [
            "by week 4 of development",
            "week 4 of development"
        ],
        "model_ans": "around 5 weeks after conception",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 5 weeks after conception </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the fifth season of america's got talent",
        "answers": [
            "Michael Grimm",
            "Soul singer Michael Grimm"
        ],
        "model_ans": "Bianca Ryan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bianca Ryan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the origin of the word celsius",
        "answers": [
            "the Swedish astronomer Anders Celsius"
        ],
        "model_ans": "Sweden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sweden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the official slogan for the 2018 winter olympics",
        "answers": [
            "Passion. Connected."
        ],
        "model_ans": "Passionaero",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Passionaero </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who starred in the film walk the line",
        "answers": [
            "Ginnifer Goodwin",
            "Reese Witherspoon",
            "Dallas Roberts",
            "Joaquin Phoenix",
            "Robert Patrick"
        ],
        "model_ans": "Joaquin Phoenix",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Joaquin Phoenix</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang the song brother let me be your shelter",
        "answers": [
            "Needtobreathe",
            "American Christian rock band Needtobreathe"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays justin on the haves and the have nots",
        "answers": [
            "Nicholas James"
        ],
        "model_ans": "Tyler Lepley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tyler Lepley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who gave a speech to the democratic national convention in 1984",
        "answers": [
            "Mario Cuomo",
            "Jesse Jackson",
            "Rev. Jesse Jackson",
            "New York Governor Mario Cuomo",
            "Senator Gary Hart",
            "Gary Hart"
        ],
        "model_ans": "Walter Mondale",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Walter Mondale </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings what the world needs now in boss baby",
        "answers": [
            "Missi Hale",
            "Steve Mazzaro",
            "Hans Zimmer"
        ],
        "model_ans": "Sia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings only love can break your heart",
        "answers": [
            "Neil Young"
        ],
        "model_ans": "Neil Young",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neil Young </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings ive loved you for a thousand years",
        "answers": [
            "Christina Perri"
        ],
        "model_ans": "Madeleine Peyroux",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Madeleine Peyroux </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first case of alzheimer's diagnosed",
        "answers": [
            "1901"
        ],
        "model_ans": "1906\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1906\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the founder of google and when was it founded",
        "answers": [
            "1998",
            "Sergey Brin",
            "Larry Page",
            "Larry Page and Sergey Brin"
        ],
        "model_ans": "Larry Page and Sergey Brin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Larry Page and Sergey Brin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the longest serving chief minister in india as on jan 2015",
        "answers": [
            "Jyotirindra Basu"
        ],
        "model_ans": "Jyoti Basu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jyoti Basu </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "joined mexico and the united states to form nafta",
        "answers": [
            "Canada"
        ],
        "model_ans": "Canada",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Canada </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the chief guest of 2014 republic day",
        "answers": [
            "Prime Minister Shinzo Abe"
        ],
        "model_ans": "Francois Hollande",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Francois Hollande </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes of ray donovan series 3 are there",
        "answers": [
            "60",
            "12"
        ],
        "model_ans": "12\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "12\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do they put the rockefeller tree up",
        "answers": [
            "mid November",
            "late November or early December"
        ],
        "model_ans": "Late November",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Late November </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does synapsis of homologous chromosomes occur in mitosis",
        "answers": [
            "prophase I of meiosis",
            "during prophase I of meiosis"
        ],
        "model_ans": "Meiosis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Meiosis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the civil rights act of 1964 protect",
        "answers": [
            "all Americans"
        ],
        "model_ans": "African Americans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> African Americans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time america hosted the summer olympics",
        "answers": [
            "Salt Lake City",
            "1996"
        ],
        "model_ans": "1996\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1996\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does season 8 of shameless come back",
        "answers": [
            "November 5, 2017"
        ],
        "model_ans": "June 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 2023 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the heart muscle is stimulated to contract by electrical impulses which are generated where",
        "answers": [
            "the sinoatrial node"
        ],
        "model_ans": "the sinoatrial node",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the sinoatrial node </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who scored the most points in their nba career",
        "answers": [
            "Kareem Abdul-Jabbar"
        ],
        "model_ans": "Kareem Abdul-Jabbar",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kareem Abdul-Jabbar </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the meaning of the name gomez",
        "answers": [
            "man"
        ],
        "model_ans": "means \"goat\" in Spanish",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> means \"goat\" in Spanish </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first t20 cricket match played",
        "answers": [
            "Lord's"
        ],
        "model_ans": "Johannesburg",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Johannesburg </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the most masters green jackets",
        "answers": [
            "Jack Nicklaus"
        ],
        "model_ans": "Jack Nicklaus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack Nicklaus</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was appointed to manage the national recovery administration",
        "answers": [
            "Hugh S. Johnson"
        ],
        "model_ans": "Harry Hopkins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harry Hopkins </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who want to be a millionaire calls his dad",
        "answers": [
            "Carpenter"
        ],
        "model_ans": "Regis Philbin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Regis Philbin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the suite life of zack and cody made",
        "answers": [
            "March\u00a018,\u00a02005",
            "September\u00a01,\u00a02008",
            "2005"
        ],
        "model_ans": "2005\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2005\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played shaggy in the new scooby doo movie",
        "answers": [
            "Matthew Lyn Lillard"
        ],
        "model_ans": "Matthew Lillard",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matthew Lillard </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the song diamonds and rust about",
        "answers": [
            "Bob Dylan"
        ],
        "model_ans": "Joni Mitchell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Joni Mitchell</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the resting stage of the cell cycle is",
        "answers": [
            "Gap 0",
            "Interphase"
        ],
        "model_ans": "G0",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> G0 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what do you call initials that stand for something",
        "answers": [
            "acronym",
            "An acronym"
        ],
        "model_ans": "Acronym",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Acronym </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang oh annie i not your daddy",
        "answers": [
            "Kid Creole and the Coconuts",
            "Kid Creole & The Coconuts"
        ],
        "model_ans": "Tony Bennett",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tony Bennett </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played king theoden in lord of the rings",
        "answers": [
            "Bernard Hill"
        ],
        "model_ans": "Bernard Hill",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bernard Hill </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what country shares borders with both belarus and romania",
        "answers": [
            "Ukraine"
        ],
        "model_ans": "Ukraine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ukraine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was harry potter and the deathly hallows part 1 filmed",
        "answers": [
            "on location"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many farmers are there in the usa",
        "answers": [
            "3.2 million"
        ],
        "model_ans": "2,044,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,044,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the 3 layers of the meninges",
        "answers": [
            "the arachnoid mater",
            "arachnoid mater",
            "pia mater",
            "the pia mater",
            "dura mater"
        ],
        "model_ans": "Dura mater, Arachnoid mater, Pia mater",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dura mater, Arachnoid mater, Pia mater </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which of the following helmiths feeds on blood",
        "answers": [
            "Necator americanus",
            "Ancylostoma duodenale"
        ],
        "model_ans": "Hookworm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hookworm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what culture region is germany a part of",
        "answers": [
            "Central Germany"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was guantanamo bay before it was a prison",
        "answers": [
            "Guantanamo Bay Naval Base"
        ],
        "model_ans": "US Naval Base",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> US Naval Base </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote most of the declaration of independance",
        "answers": [
            "Thomas Jefferson"
        ],
        "model_ans": "Thomas Jefferson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Jefferson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "in what part of the digestive tube do you expect the initial digestion of starch",
        "answers": [
            "the mouth",
            "the minor salivary glands"
        ],
        "model_ans": "Mouth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mouth </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do kidneys for kidney transplant come from",
        "answers": [
            "living-donor"
        ],
        "model_ans": "Deceased donors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Deceased donors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what song did the titanic band play when it sank",
        "answers": [
            "\"Autumn\""
        ],
        "model_ans": "Nearer, My God, to Thee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nearer, My God, to Thee </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how tall is the tallest building in las vegas",
        "answers": [
            "The Drew Las Vegas",
            "1,149 feet"
        ],
        "model_ans": "550 feet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 550 feet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the new series of keeping faith starting",
        "answers": [
            "13 February 2018"
        ],
        "model_ans": "BBC One has announced that the new series of Keeping Faith will start on Monday, August 9, 2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> BBC One has announced that the new series of Keeping Faith will start on Monday, August 9, 2021 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote trust and believe by keyshia cole",
        "answers": [
            "Jessyca Wilson",
            "Darhyl Camper, Jr.",
            "Guordan Banks",
            "Keyshia Cole"
        ],
        "model_ans": "Keyshia Cole",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Keyshia Cole </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the oldest team in the nba",
        "answers": [
            "Sacramento Kings",
            "New York Knickerbockers"
        ],
        "model_ans": "Boston Celtics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Boston Celtics</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the electronic funds transfer act signed into law",
        "answers": [
            "in 1978",
            "November 10, 1978",
            "1978"
        ],
        "model_ans": "1978",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1978 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the election for mayor in boston",
        "answers": [
            "Marty J. Walsh",
            "Marty Walsh"
        ],
        "model_ans": "Boston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Boston</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the first medal in olympics for india",
        "answers": [
            "Norman Pritchard"
        ],
        "model_ans": "Norman Pritchard",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Norman Pritchard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the music for christmas story live",
        "answers": [
            "Pasek and Paul",
            "Pasek & Paul",
            "Justin Paul",
            "Benj Pasek"
        ],
        "model_ans": "Brett James",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brett James</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "first jnanpith award was an autor of which language",
        "answers": [
            "Malayalam"
        ],
        "model_ans": "Hindi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hindi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which is the ring finger for male in india",
        "answers": [
            "the left ring finger",
            "left ring finger"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which condition would most likely require nutrition delivered through tpn",
        "answers": [
            "bowel obstruction",
            "ulcerative colitis",
            "high-output fistula",
            "short bowel syndrome",
            "very severe Crohn's disease",
            "prolonged diarrhea",
            "gastroschisis"
        ],
        "model_ans": "Malabsorption",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Malabsorption </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the voice of stewie family guy",
        "answers": [
            "Seth MacFarlane"
        ],
        "model_ans": "Seth MacFarlane",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Seth MacFarlane </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the name of the restaurant in seinfeld",
        "answers": [
            "Monk\u2019s",
            "Monk's Caf\u00e9"
        ],
        "model_ans": "Monk's Cafe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Monk's Cafe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played david on the assassination of gianni versace",
        "answers": [
            "Cody Fern"
        ],
        "model_ans": "Edgar Ramirez",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edgar Ramirez </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the democracy of the united states",
        "answers": [
            "federal republic"
        ],
        "model_ans": "Representative democracy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Representative democracy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays grace in the secret life of the american teenager",
        "answers": [
            "Megan Park"
        ],
        "model_ans": "Francia Raisa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Francia Raisa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the rulers of the qing dynasty originate",
        "answers": [
            "Manchuria"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in what state was the united states center of population gravity located during the period 1790",
        "answers": [
            "Maryland",
            "Kent County, Maryland"
        ],
        "model_ans": "Pennsylvania",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pennsylvania </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the royalties for winnie the pooh go",
        "answers": [
            "the Slesinger family",
            "Slesinger, Inc."
        ],
        "model_ans": "Disney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Disney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the new season of chicago pd",
        "answers": [
            "September 27, 2017"
        ],
        "model_ans": "September 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 2023 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who owns the majority of the us debt",
        "answers": [
            "China",
            "Japan and China",
            "Japan",
            "the public"
        ],
        "model_ans": "The Federal Reserve",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Federal Reserve </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the most on who wants to be a millionaire",
        "answers": [
            "Kevin Olmstead",
            "David Goodman"
        ],
        "model_ans": "Brad Pitt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brad Pitt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of ash in sing",
        "answers": [
            "Scarlett Johansson"
        ],
        "model_ans": "Ash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was tammy from basketball wives married to",
        "answers": [
            "basketball player Kenny Anderson",
            "Kenny Anderson"
        ],
        "model_ans": "Tami Roman was married to Kenny Anderson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tami Roman was married to Kenny Anderson </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang original i want a hippopotamus for christmas",
        "answers": [
            "Gayla Peevey"
        ],
        "model_ans": "Gayla Peevey",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gayla Peevey </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "roman god of the underworld also called orcus or pluto",
        "answers": [
            "Dis Pater"
        ],
        "model_ans": "Pluto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pluto </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the donkey talk in the bible",
        "answers": [
            "Numbers 22:28"
        ],
        "model_ans": "Balaam's donkey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Balaam's donkey </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is chinese new year and what year is it",
        "answers": [
            "the year of the Dog",
            "Friday, 16 February",
            "year of the Dog"
        ],
        "model_ans": "Chinese New Year typically falls between January 21 and February 20.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chinese New Year typically falls between January 21 and February 20. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did korea separate into north and south",
        "answers": [
            "1945",
            "17 August 1945"
        ],
        "model_ans": "1948",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1948 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote if i were a boy reba or beyonce",
        "answers": [
            "Toby Gad",
            "BC Jean"
        ],
        "model_ans": "Beyonc\u00e9",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Beyonc\u00e9</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what color is the golden gate bridge in san francisco",
        "answers": [
            "orange vermilion called international orange",
            "red",
            "International Orange"
        ],
        "model_ans": "orange",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> orange </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played jennifer in back to the future",
        "answers": [
            "Claudia Grace Wells"
        ],
        "model_ans": "Claudia Wells",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Claudia Wells </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the italian episode of everybody loves raymond filmed",
        "answers": [
            "Anguillara Sabazia outside of Rome"
        ],
        "model_ans": "Rome",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rome </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last bear killed in the uk",
        "answers": [
            "c. 1000 AD"
        ],
        "model_ans": "1848",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1848 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song stop the world and let me off",
        "answers": [
            "W. S. Stevenson",
            "Carl Belew"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the book wealth of nations about",
        "answers": [
            "what builds nations' wealth"
        ],
        "model_ans": "economics",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> economics </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "most consecutive games with 20+ points - nba history",
        "answers": [
            "126"
        ],
        "model_ans": "Stephen Curry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stephen Curry </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who in germany signed the treaty of versailles",
        "answers": [
            "Gustav Bauer",
            "colonial minister Johannes Bell",
            "Foreign minister Hermann M\u00fcller"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first president of the constituent assembly",
        "answers": [
            "Dr. Rajendra Prasad"
        ],
        "model_ans": "Sachchidanand Sinha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sachchidanand Sinha </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the purse for the senior open",
        "answers": [
            "$2 million in 2011"
        ],
        "model_ans": "The Senior Open Championship",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Senior Open Championship </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did american idol end the first time",
        "answers": [
            "April 7, 2016"
        ],
        "model_ans": "2009",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2009 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played anna in once upon a time",
        "answers": [
            "Elizabeth Dean Lail"
        ],
        "model_ans": "Jennifer Morrison",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jennifer Morrison</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the original song send in the clowns",
        "answers": [
            "Glynis Johns",
            "the actress Glynis Johns"
        ],
        "model_ans": "Frank Sinatra",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Frank Sinatra </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the drinking age set to 21",
        "answers": [
            "By mid-1988"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who produced the movie i can only imagine",
        "answers": [
            "Pete Shilaimon",
            "Raymond Harris",
            "Daryl Lefever",
            "Kevin Downes",
            "Cindy Bond",
            "Joe Knopp",
            "Mickey Liddell"
        ],
        "model_ans": "Cloudburst Productions",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cloudburst Productions </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of auv in cars",
        "answers": [
            "action utility vehicles"
        ],
        "model_ans": "Anti-lock braking system",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anti-lock braking system </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who monitor the recovery of the location during a disaster",
        "answers": [
            "management team"
        ],
        "model_ans": "Emergency Management Agency",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Emergency Management Agency </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the treasure of the sierra madre",
        "answers": [
            "B. Traven",
            "bilingual German author B. Traven"
        ],
        "model_ans": "B. Traven",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>B. Traven</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the first line of http request message is called ____",
        "answers": [
            "A request line",
            "A status line",
            "the status line",
            "status line"
        ],
        "model_ans": "Request Line",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Request Line </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who hit 6 sixes in an over in test cricket",
        "answers": [
            "Ravi Shastri",
            "Garfield Sobers"
        ],
        "model_ans": "Ravi Shastri",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ravi Shastri </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the internet introduced to the public",
        "answers": [
            "September 1993",
            "1995",
            "in the very late 1980s"
        ],
        "model_ans": "1991\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1991\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in texas how is the commissioner of insurance placed in office",
        "answers": [
            "Appointed"
        ],
        "model_ans": "elected",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> elected </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the first fleet arive in australia",
        "answers": [
            "18 January 1788",
            "1788"
        ],
        "model_ans": "1788\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1788\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings so come and dance with me jai ho",
        "answers": [
            "Mahalaxmi Iyer",
            "Vijay Prakash",
            "Tanvi Shah",
            "Sukhvinder Singh"
        ],
        "model_ans": "A.R. Rahman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A.R. Rahman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "this inventor co-created the film fred ott\u2019s sneeze",
        "answers": [
            "Fred Ott",
            "Edison"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which city is called the manchester of north india",
        "answers": [
            "Ahmedabad"
        ],
        "model_ans": "Ludhiana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ludhiana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the first video game for nintendo",
        "answers": [
            "Magnavox Odyssey",
            "EVR Race"
        ],
        "model_ans": "Donkey Kong",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Donkey Kong </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the american anthem at the super bowl",
        "answers": [
            "Pink"
        ],
        "model_ans": "Gladys Knight",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gladys Knight </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "seven union territories of india and their capital",
        "answers": [
            "Chandigarh \u2014 Chandigarh",
            "Daman and Diu \u2014 Daman",
            "Lakshwadweep \u2014 Kavaratti",
            "Puducherry \u2014 Pondicherry"
        ],
        "model_ans": "Delhi, Chandigarh, Shimla, Kolkata, Thiruvananthapuram, Hyderabad, and Ranchi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Delhi, Chandigarh, Shimla, Kolkata, Thiruvananthapuram, Hyderabad, and Ranchi </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "mount everest is part of what mountain range",
        "answers": [
            "Himalayas"
        ],
        "model_ans": "Himalayas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Himalayas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many us states are commonwealths and which states are they",
        "answers": [
            "Kentucky",
            "Pennsylvania",
            "Massachusetts",
            "Virginia"
        ],
        "model_ans": "3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the river irk start and finish",
        "answers": [
            "east of Royton",
            "the east of Royton"
        ],
        "model_ans": "The River Irk starts in the Pennines and flows through Manchester before emptying into the River Irwell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The River Irk starts in the Pennines and flows through Manchester before emptying into the River Irwell </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the most important new religious figure of the new kingdom of ancient egypt",
        "answers": [
            "Aten"
        ],
        "model_ans": "Akhenaten",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Akhenaten </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the average salary for a us congressman",
        "answers": [
            "$174,000"
        ],
        "model_ans": "$174,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> $174,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the full name of the titanic",
        "answers": [
            "RMS Titanic"
        ],
        "model_ans": "RMS Titanic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RMS Titanic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the book my country my life",
        "answers": [
            "L. K. Advani"
        ],
        "model_ans": "Nelson Mandela",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nelson Mandela </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "winner of first series of great british bake off",
        "answers": [
            "Edd Kimber"
        ],
        "model_ans": "Celia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Celia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many rooms is there in buckingham palace",
        "answers": [
            "775",
            "775 rooms"
        ],
        "model_ans": "775\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "775\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in the new beauty and the beast",
        "answers": [
            "Kevin Kline"
        ],
        "model_ans": "Kevin Kline",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kevin Kline </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does season 3 of the riveras start",
        "answers": [
            "March\u00a011,\u00a02018"
        ],
        "model_ans": "August 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won more national championships michigan or ohio state",
        "answers": [
            "Michigan"
        ],
        "model_ans": "Michigan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Michigan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what happened to the actor who played frost on rizzoli and isles",
        "answers": [
            "committed suicide",
            "Lee Thompson Young"
        ],
        "model_ans": "Sasha Alexander",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sasha Alexander </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did lynyrd skynyrd's plane crash happen",
        "answers": [
            "October 20, 1977"
        ],
        "model_ans": "January 10, 1977",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 10, 1977 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many countries in the world have scouts",
        "answers": [
            "216",
            "169",
            "216 countries and territories"
        ],
        "model_ans": "216",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 216 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of season 6 of american horror story",
        "answers": [
            "Roanoke",
            "American Horror Story: Roanoke"
        ],
        "model_ans": "Cult",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cult </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did dragon ball super tournament of power start",
        "answers": [
            "February 19, 2017"
        ],
        "model_ans": "July 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays bongos on sympathy for the devil",
        "answers": [
            "Rocky Dzidzornu",
            "Rocky Dzidzornu\u00a0\u2013 congas"
        ],
        "model_ans": "Charlie Watts",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charlie Watts </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who said if a tree falls in the woods and nobody hears it",
        "answers": [
            "Philosopher George Berkeley",
            "Charles Riborg Mann",
            "George Ransom Twiss"
        ],
        "model_ans": "George Carlin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> George Carlin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who formed the indian society of oriental art",
        "answers": [
            "Abanindranath Tagore CIE",
            "Abanindranath Tagore"
        ],
        "model_ans": "The Asiatic Society",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Asiatic Society </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of lord shiva lingam",
        "answers": [
            "reminds of the Omnipotent Lord"
        ],
        "model_ans": "Lord Shiva Lingam is a symbol of the divine union of Lord Shiva and Goddess Parvati",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lord Shiva Lingam is a symbol of the divine union of Lord Shiva and Goddess Parvati </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the queen of hearts in alice in wonderland",
        "answers": [
            "the primary antagonist"
        ],
        "model_ans": "The Queen of Hearts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Queen of Hearts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the octet rule states that in chemical compounds atoms tend to have the electron configuration of a",
        "answers": [
            "noble gas"
        ],
        "model_ans": "noble gas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> noble gas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the majority of phosphorous stored in the environment",
        "answers": [
            "minerals",
            "rocks",
            "in rocks and minerals"
        ],
        "model_ans": "soil",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> soil </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the hotel used in the movie the shining",
        "answers": [
            "The Stanley Hotel"
        ],
        "model_ans": "The Stanley Hotel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stanley Hotel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the father of the princes in the tower",
        "answers": [
            "Edward IV of England",
            "Edward IV"
        ],
        "model_ans": "Edward IV",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Edward IV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the titanic started to be built",
        "answers": [
            "31 March 1909"
        ],
        "model_ans": "1909\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1909\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the first nba basketball game start",
        "answers": [
            "October 17, 2017"
        ],
        "model_ans": "6:00 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6:00 PM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the german princes who chose the holy roman empire were called",
        "answers": [
            "prince-electors",
            "the Prince-Electors"
        ],
        "model_ans": "Electors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Electors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did refrigerator perry play for the bears",
        "answers": [
            "1985\u20131993"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who came up with the idea of the transcontinental railroad",
        "answers": [
            "Dr. Hartwell Carver"
        ],
        "model_ans": "Abraham Lincoln",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abraham Lincoln </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the elements in each period have the same number of",
        "answers": [
            "electron shells"
        ],
        "model_ans": "electrons",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> electrons </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the new season of wentworth coming out",
        "answers": [
            "19 June 2018"
        ],
        "model_ans": "August 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2023 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "leader of carthage in the first punic war",
        "answers": [
            "Hanno the Great",
            "Xanthippus",
            "Hasdrubal the Fair",
            "Hamilcar Barca"
        ],
        "model_ans": "Hannibal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hannibal </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won latest america's next top model",
        "answers": [
            "Kyla Coleman"
        ],
        "model_ans": "Kyla Coleman",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kyla Coleman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the main use of the eiffel tower in modern times",
        "answers": [
            "visited paid monument",
            "paid monument"
        ],
        "model_ans": "Tourist attraction",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tourist attraction </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang smoke gets in your eyes first",
        "answers": [
            "Gertrude Niesen",
            "Tamara Drasin"
        ],
        "model_ans": "Jessie J",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jessie J</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the soviet union first gain control of parts of poland and the baltic republics",
        "answers": [
            "14 June 1940"
        ],
        "model_ans": "1939\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1939\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played nathan scott on one tree hill",
        "answers": [
            "James Martin Lafferty"
        ],
        "model_ans": "James Lafferty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Lafferty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the movie the wizard of oz made",
        "answers": [
            "1939",
            "August\u00a025,\u00a01939"
        ],
        "model_ans": "1939\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1939\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who died doing the luge in the olympics",
        "answers": [
            "Nodar Kumaritashvili"
        ],
        "model_ans": "Nodar Kumaritashvili",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nodar Kumaritashvili </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays dr. sloan on kevin saves the world",
        "answers": [
            "Richard Masur"
        ],
        "model_ans": "Jason Ritter",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jason Ritter </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was clash royale released in the us",
        "answers": [
            "March 2, 2016"
        ],
        "model_ans": "2016\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2016\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ranjit sagar dam has builded over which river",
        "answers": [
            "Ravi River",
            "the Ravi River"
        ],
        "model_ans": "river sagar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> river sagar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the sword art online movie take place",
        "answers": [
            "2026",
            "the year 2026"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was vietnam called in the years before world war 2",
        "answers": [
            "French Indochina"
        ],
        "model_ans": "French Indochina",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French Indochina </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "third president of the united states of america",
        "answers": [
            "Thomas Jefferson"
        ],
        "model_ans": "Thomas Jefferson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Jefferson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played stumpy in the movie rio bravo",
        "answers": [
            "Walter Brennan"
        ],
        "model_ans": "Dean Martin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dean Martin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the dogs name in wizard of oz",
        "answers": [
            "Toto"
        ],
        "model_ans": "Toto",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Toto </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the next warrior book come out",
        "answers": [
            "April 10, 2018"
        ],
        "model_ans": "There is no official release date announced yet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official release date announced yet </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many senators are there in the us senate",
        "answers": [
            "100",
            "100 members"
        ],
        "model_ans": "100",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 100 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is hosting e live from the red carpet",
        "answers": [
            "Ryan Seacrest",
            "Giuliana Rancic"
        ],
        "model_ans": "E!",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> E! </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do the greasers live in the outsiders",
        "answers": [
            "Tulsa, Oklahoma"
        ],
        "model_ans": "Greasers live in the wrong side of the tracks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greasers live in the wrong side of the tracks </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many pitchers does a major league team have",
        "answers": [
            "five starting pitchers",
            "seven relief pitchers"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the team find out prentiss is alive",
        "answers": [
            "In the season seven premiere",
            "the season seven premiere"
        ],
        "model_ans": "Season 6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many steps does the cn tower have",
        "answers": [
            "2,579 steps",
            "2,579"
        ],
        "model_ans": "147",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 147 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "trick taking card game name derived from spanish for man",
        "answers": [
            "Skat"
        ],
        "model_ans": "Piquet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Piquet</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which two regions grow most of china\u2019s rice",
        "answers": [
            "provinces along the Yangtze River",
            "provinces in the south"
        ],
        "model_ans": "Yangtze River Delta and Pearl River Delta",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Yangtze River Delta and Pearl River Delta </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "from whose perspective is the story of all quiet on the western front told",
        "answers": [
            "Paul Baumer"
        ],
        "model_ans": "Baum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Baum </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the meaning of the song puff the magic dragon",
        "answers": [
            "the hardships of growing older"
        ],
        "model_ans": "The song is about a dragon that is brought to life by a puff of magic smoke, and it is often interpreted as a metaphor for the fleeting nature of childhood and the loss of innocence.",
        "model_confidence": "unsure</",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The song is about a dragon that is brought to life by a puff of magic smoke, and it is often interpreted as a metaphor for the fleeting nature of childhood and the loss of innocence. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a player that can shoot pass or dribble is considered to be",
        "answers": [
            "Triple threat"
        ],
        "model_ans": "a combo guard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> a combo guard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the temple of vesta built for",
        "answers": [
            "Vesta"
        ],
        "model_ans": "Vesta",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vesta </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who invented the printing press and what year",
        "answers": [
            "circa 1439",
            "Johannes Gutenberg"
        ],
        "model_ans": "Johannes Gutenberg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Johannes Gutenberg</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the worlds first laptop computer introduced in the market and by whom",
        "answers": [
            "September 1980",
            "R2E Micral CCMC"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many states have a cracker barrel restaurant",
        "answers": [
            "43"
        ],
        "model_ans": "45\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "45\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did new york stop using the electric chair",
        "answers": [
            "1963",
            "1972"
        ],
        "model_ans": "2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2004 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of gorakh dhanda in urdu",
        "answers": [
            "You are a Puzzle"
        ],
        "model_ans": "Gorakh Dhanda is a phrase used in Urdu which means \" Gorakh's business\" or \" Gorakh's trick\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gorakh Dhanda is a phrase used in Urdu which means \" Gorakh's business\" or \" Gorakh's trick\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first english child born in north america",
        "answers": [
            "Virginia Dare"
        ],
        "model_ans": "Virginia Dare",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virginia Dare </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who killed barry allen's mom tv show",
        "answers": [
            "the Reverse-Flash",
            "Professor Eobard Thawne"
        ],
        "model_ans": "Reverse-Flash",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Reverse-Flash </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when were the words under god added to the pledge",
        "answers": [
            "on Flag Day in 1954",
            "1954",
            "Flag Day in 1954"
        ],
        "model_ans": "1954\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1954\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how do you say zest for life in french",
        "answers": [
            "Joie de vivre"
        ],
        "model_ans": "go\u00fbt de vivre",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> go\u00fbt de vivre </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the song you'll never find another love like mine",
        "answers": [
            "Lou Rawls"
        ],
        "model_ans": "Sade",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sade </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is dylan's father in bates motel",
        "answers": [
            "Norma's brother, Caleb"
        ],
        "model_ans": "Norman Bates",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Norman Bates </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in which country bikram sambhat the official calender",
        "answers": [
            "Nepal"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was suite judy blue eyes written about",
        "answers": [
            "singer/songwriter Judy Collins",
            "Judy Collins"
        ],
        "model_ans": "Judy Garland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Judy Garland</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does middle-earth shadow of mordor come out",
        "answers": [
            "September 2014"
        ],
        "model_ans": "September 30, 2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 30, 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the bread plate located in a formal setting",
        "answers": [
            "at each place"
        ],
        "model_ans": "upper right",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> upper right </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was in dont worry be happy video",
        "answers": [
            "Bill Irwin",
            "Robin Williams",
            "McFerrin"
        ],
        "model_ans": "Ariana Grande",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ariana Grande </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the secretory cells of endocrine glands secrete their products",
        "answers": [
            "epithelial surface",
            "bloodstream",
            "directly into the bloodstream"
        ],
        "model_ans": "bloodstream",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> bloodstream </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time vancouver had an earthquake",
        "answers": [
            "1946"
        ],
        "model_ans": "2018\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2018\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does canada switch to daylight savings time",
        "answers": [
            "the second Sunday of March"
        ],
        "model_ans": "Second Sunday in March and First Sunday in November",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Second Sunday in March and First Sunday in November </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much of the world's diamonds does de beers own",
        "answers": [
            "33% in 2013"
        ],
        "model_ans": "80%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the ashes from ash wednesday originate",
        "answers": [
            "Pope Gregory I the Great"
        ],
        "model_ans": "Jerusalem",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jerusalem </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the diaphragm located on the human body",
        "answers": [
            "the inferior thoracic border",
            "the thorax or chest region"
        ],
        "model_ans": "between the chest and abdominal cavity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> between the chest and abdominal cavity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who drafted the document of the un declaration of human rights",
        "answers": [
            "John Peters Humphrey, Canada",
            "Charles Habib Malik, Lebanon",
            "John Peters Humphrey",
            "William Roy Hodgson",
            "Charles Habib Malik",
            "Ren\u00e9 Cassin, France",
            "Hern\u00e1n Santa Cruz",
            "William Roy Hodgson, Australia",
            "Hern\u00e1n Santa Cruz, Chile",
            "Ren\u00e9 Cassin",
            "Peng Chun Chang",
            "Alexander E. Bogomolov",
            "Eleanor Roosevelt",
            "Charles Dukes",
            "Charles Dukes, United Kingdom"
        ],
        "model_ans": "Eleanor Roosevelt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eleanor Roosevelt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did all night long come out lionel richie",
        "answers": [
            "1983",
            "August 31, 1983"
        ],
        "model_ans": "1985\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1985\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much square feet is a basketball court",
        "answers": [
            "94 by 50 feet"
        ],
        "model_ans": "4,500 square feet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4,500 square feet </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the cold dry winds that blow over northern india in winter are called",
        "answers": [
            "Northeast Monsoon",
            "Retreating Monsoon",
            "Northeast Monsoon or Retreating Monsoon"
        ],
        "model_ans": "Chillai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Chillai</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i don't want to be lonely",
        "answers": [
            "Ronnie Dyson"
        ],
        "model_ans": "Avril Lavigne",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Avril Lavigne </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has been chosen as the brand ambassador of the campaign 'beti bachao-beti padhao",
        "answers": [
            "Sakshi Malik"
        ],
        "model_ans": "Bollywood actress Deepika Padukone",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bollywood actress Deepika Padukone</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the second half of vikings season 5 coming out",
        "answers": [
            "2018"
        ],
        "model_ans": "December 30, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 30, 2020 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "original cast of natasha pierre and the great comet of 1812",
        "answers": [
            "Amber Gray",
            "Blake DeLong",
            "Paul Pinto",
            "Shaina Taub",
            "Dave Malloy",
            "Nick Choksi",
            "Brittain Ashford",
            "Phillipa Soo",
            "Lucas Steele",
            "Amelia Workman"
        ],
        "model_ans": "Josh Groban, Den\u00e9e Benton, Lucas Steele, and Anne Hathaway",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Josh Groban, Den\u00e9e Benton, Lucas Steele, and Anne Hathaway </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the biggest country in western europe",
        "answers": [
            "Russia*",
            "Russia",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when do wood thrushes fly when they are migrating",
        "answers": [
            "in the winter",
            "at night"
        ],
        "model_ans": "April to October",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> April to October </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the title of the person who runs the house of representatives",
        "answers": [
            "the Speaker of the House",
            "Speaker of the House"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is a whistle blower suit under the false claims act",
        "answers": [
            "qui tam"
        ],
        "model_ans": "qui tam",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>qui tam</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the oldest house in america located",
        "answers": [
            "Taos Pueblo"
        ],
        "model_ans": "St. Augustine, Florida",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> St. Augustine, Florida </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the land rover defender first built",
        "answers": [
            "1991",
            "1983",
            "in the 1980s"
        ],
        "model_ans": "1948\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1948\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the main source of nutrients in an estuary",
        "answers": [
            "sea water",
            "fresh water",
            "detritus"
        ],
        "model_ans": "phytoplankton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> phytoplankton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the biggest nfl stadium in the united states",
        "answers": [
            "Michigan Stadium",
            "MetLife Stadium"
        ],
        "model_ans": "AT&T Stadium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> AT&T Stadium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the walker rick killed in the first episode",
        "answers": [
            "Addy Miller"
        ],
        "model_ans": "Shane Walsh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shane Walsh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did aeneas go when he left carthage",
        "answers": [
            "Sicily"
        ],
        "model_ans": "Italy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Italy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "vapor pressure of water at 100c in torr",
        "answers": [
            "759.9625"
        ],
        "model_ans": "760\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "760\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time stock market crashed",
        "answers": [
            "27 Oct 1997",
            "18 August 2015"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "during which season does cape town receive rainfall",
        "answers": [
            "winter",
            "summer"
        ],
        "model_ans": "winter",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> winter </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who owns the rights to rocky and bullwinkle",
        "answers": [
            "Universal Pictures"
        ],
        "model_ans": "Paramount Pictures",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Paramount Pictures</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what state did they film daddy's home 2",
        "answers": [
            "Great Barrington, Massachusetts",
            "Framingham, Massachusetts",
            "Massachusetts",
            "Concord, Massachusetts"
        ],
        "model_ans": "Indiana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Indiana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "first day collection of mission china assamese film",
        "answers": [
            "\u20b9 39.97 lakh"
        ],
        "model_ans": "\u20b9 1.25 crore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \u20b9 1.25 crore </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the florida marlins have spring training",
        "answers": [
            "Roger Dean Stadium"
        ],
        "model_ans": "Jupiter",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jupiter</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won french open 2017 tennis tournament in men's double category",
        "answers": [
            "Ryan Harrison",
            "Michael Venus"
        ],
        "model_ans": "Ryan Harrison and Michael Venus",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ryan Harrison and Michael Venus </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the united states became a nation",
        "answers": [
            "1776",
            "July 4, 1776",
            "In 1776"
        ],
        "model_ans": "September 17, 1787",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 17, 1787 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played santa in the santa clause movies",
        "answers": [
            "Tim Allen"
        ],
        "model_ans": "Tim Allen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tim Allen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "type of disappearing lake found in limestone areas in the west of ireland",
        "answers": [
            "turlough",
            "turlough, or turlach",
            "A turlough, or turlach"
        ],
        "model_ans": "karst lake",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> karst lake </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the spanish civil war fought between",
        "answers": [
            "Nationalists",
            "Republicans"
        ],
        "model_ans": "Nationalist forces led by General Francisco Franco and the Republican government",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nationalist forces led by General Francisco Franco and the Republican government </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "georgia out of angus thongs and perfect snogging",
        "answers": [
            "Georgia Groome as Georgia Nicolson",
            "Georgia Groome"
        ],
        "model_ans": "Georgia Groome",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Georgia Groome </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who issued gold coins for the first time in india",
        "answers": [
            "Gupta Empire"
        ],
        "model_ans": "British East India Company",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> British East India Company </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which greek god flew too close to the sun",
        "answers": [
            "Icarus"
        ],
        "model_ans": "Icarus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Icarus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where can carbon be found in the biosphere",
        "answers": [
            "other living organisms",
            "The terrestrial biosphere",
            "plants",
            "soil"
        ],
        "model_ans": "everywhere",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> everywhere </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does star trek discovery air on tv",
        "answers": [
            "September 19, 2017"
        ],
        "model_ans": "CBS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CBS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did earth's atmosphere change due to living organisms",
        "answers": [
            "around 2.45\u00a0billion years ago"
        ],
        "model_ans": "around 2.7 billion years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 2.7 billion years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the area code for phoenix arizona",
        "answers": [
            "602",
            "623",
            "480"
        ],
        "model_ans": "602\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "602\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where in the bible are the 12 disciples",
        "answers": [
            "Acts 1:13"
        ],
        "model_ans": "Matthew 10:1-4",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matthew 10:1-4 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who came up with popcorn at the movies",
        "answers": [
            "Glen W. Dickson"
        ],
        "model_ans": "Charles Cretors",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Cretors </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is responsible for establishing local licensing forum",
        "answers": [
            "unitary authorities",
            "local authorities",
            "district councils"
        ],
        "model_ans": "Local authorities",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Local authorities </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did clifford the big red dog first air on tv",
        "answers": [
            "September 4, 2000"
        ],
        "model_ans": "2000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is episode 12 of miraculous ladybug season 2 coming out",
        "answers": [
            "30\u00a0March\u00a02018"
        ],
        "model_ans": "December 2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is natural gas found in the us",
        "answers": [
            "Louisiana",
            "Pennsylvania",
            "Wyoming",
            "Arkansas",
            "New Mexico",
            "West Virginia",
            "Colorado",
            "Texas"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the most number of songs in the world",
        "answers": [
            "Asha Bhosle"
        ],
        "model_ans": "Elvis Presley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elvis Presley </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i will go down with this ship",
        "answers": [
            "Dido"
        ],
        "model_ans": "All-American Rejects",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> All-American Rejects </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the right to buy scheme start",
        "answers": [
            "1980"
        ],
        "model_ans": "1981\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1981\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the wave hill walk off end",
        "answers": [
            "16 August 1975"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the new episode of scorpion come on",
        "answers": [
            "January\u00a015,\u00a02018"
        ],
        "model_ans": "Scorpion airs on CBS on Mondays at 10/9c",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Scorpion airs on CBS on Mondays at 10/9c </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the songs in crazy ex girlfriend",
        "answers": [
            "Rachel Bloom"
        ],
        "model_ans": "Rebecca Bunch",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rebecca Bunch </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many winnie the pooh books are there",
        "answers": [
            "four"
        ],
        "model_ans": "8",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "wolf of wall street number of f words",
        "answers": [
            "569"
        ],
        "model_ans": "569\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "569\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "india south africa test series 2018 highest runs",
        "answers": [
            "286",
            "AB de Villiers"
        ],
        "model_ans": "153",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 153 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last person executed in florida",
        "answers": [
            "Eric Scott Branch",
            "February 22, 2018"
        ],
        "model_ans": "2006",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who represented the state of tennessee in the scopes trial",
        "answers": [
            "William Jennings Bryan"
        ],
        "model_ans": "Clarence Darrow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Clarence Darrow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the marathon in new york city",
        "answers": [
            "Geoffrey Kamworor"
        ],
        "model_ans": "Geoffrey Kamworor",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Geoffrey Kamworor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the setting of the story sorry wrong number",
        "answers": [
            "Manhattan"
        ],
        "model_ans": "Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "does archie end up with betty or veronica in riverdale",
        "answers": [
            "Betty"
        ],
        "model_ans": "Betty",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Betty</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how and why were serial novels a phenomenon in the nineteenth century",
        "answers": [
            "improved economics of distribution",
            "technological advances in printing",
            "the rise of literacy"
        ],
        "model_ans": "Serial novels were a phenomenon in the 19th century because they were a way for authors to make a living by publishing installments of their work, often in magazines or newspapers. This format allowed readers to follow the story over time,</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Serial novels were a phenomenon in the 19th century because they were a way for authors to make a living by publishing installments of their work, often in magazines or newspapers. This format allowed readers to follow the story over time,</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did this season of american idol start",
        "answers": [
            "March 11, 2018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the newest macbook pro come out",
        "answers": [
            "June 5, 2017",
            "October 27, 2016",
            "June\u00a05,\u00a02017"
        ],
        "model_ans": "November 2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> November 2021 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the outcome of the battle of san juan hill",
        "answers": [
            "Cuban-American victory"
        ],
        "model_ans": "The battle of San Juan Hill was a decisive Union victory during the Battle of Santiago de Cuba in the Spanish-American War.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The battle of San Juan Hill was a decisive Union victory during the Battle of Santiago de Cuba in the Spanish-American War. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the christmas song all i want for christmas is you",
        "answers": [
            "Mariah Carey"
        ],
        "model_ans": "Mariah Carey",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mariah Carey </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was christmas first celebrated as a holiday",
        "answers": [
            "336"
        ],
        "model_ans": "336 AD",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 336 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the dodgers went to the world seris",
        "answers": [
            "2012"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did teenage mutant ninja turtles come out",
        "answers": [
            "1984"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when were 2 dollar bills stopped being made",
        "answers": [
            "current denomination of U.S. currency"
        ],
        "model_ans": "1966\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1966\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the leading african producer of wool",
        "answers": [
            "Sudan",
            "South Africa"
        ],
        "model_ans": "South Africa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> South Africa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the president get authority to issue executive orders",
        "answers": [
            "Constitution"
        ],
        "model_ans": "The Constitution",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Constitution </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how long do you have to serve in the israeli military",
        "answers": [
            "two years for women"
        ],
        "model_ans": "3 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "dark parables return of the salt princess release date",
        "answers": [
            "September 2017"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the womens ice skating for the olympics",
        "answers": [
            "21 February",
            "21\u201323 February",
            "23 February"
        ],
        "model_ans": "February",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> February </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the most current adobe flash player version",
        "answers": [
            "28.0.0.137"
        ],
        "model_ans": "Adobe Flash Player 32.0.0.465",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Adobe Flash Player 32.0.0.465 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many players have scored 10000 runs in odi",
        "answers": [
            "11",
            "eleven"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays lindsay denton in line of duty",
        "answers": [
            "Keeley Clare Julia Hawes"
        ],
        "model_ans": "Jessie Ennis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jessie Ennis</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the first wireless beats come out",
        "answers": [
            "October 2012"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who discovered the atom and in what year",
        "answers": [
            "early 1800s",
            "John Dalton"
        ],
        "model_ans": "Democritus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Democritus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the philadelphia eagles play in the super bowl last",
        "answers": [
            "Super Bowl LII"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the word for clarified butter in the balkans and middle east",
        "answers": [
            "smen"
        ],
        "model_ans": "Zeyt",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zeyt </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the electron transport chain get its electrons from",
        "answers": [
            "electron donors",
            "donor molecule"
        ],
        "model_ans": "NADH and FADH2",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NADH and FADH2 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is fight or flight in the brain",
        "answers": [
            "the adrenal medulla"
        ],
        "model_ans": "Amygdala",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amygdala </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the road that connects the tombs is called",
        "answers": [
            "\"Spirit Way\""
        ],
        "model_ans": "Avenue of the Immortals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Avenue of the Immortals </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the idea of a unicorn come from",
        "answers": [
            "Greek writers of natural history"
        ],
        "model_ans": "ancient Mesopotamia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> ancient Mesopotamia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which approach to psychology focuses on the body especially the brain and nervous system",
        "answers": [
            "neuropsychology",
            "Neuropsychology"
        ],
        "model_ans": "Biological",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Biological </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who's the model on let's make a deal",
        "answers": [
            "Tiffany Adams Coyne"
        ],
        "model_ans": "Wayne Brady",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Wayne Brady</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "uruguay is located along what body of water",
        "answers": [
            "Bay of Montevideo"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what drug does the mom use in requiem for a dream",
        "answers": [
            "weight-loss amphetamines",
            "amphetamines"
        ],
        "model_ans": "heroin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> heroin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the second part of vikings season 4 start",
        "answers": [
            "November 30, 2016"
        ],
        "model_ans": "December 2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 2016 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who donates a christmas tree to trafalgar square",
        "answers": [
            "Oslo, Norway"
        ],
        "model_ans": "Norway",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Norway </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the original stephen king it movie made",
        "answers": [
            "1990"
        ],
        "model_ans": "1959",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1959 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays ser davos in game of thrones",
        "answers": [
            "Liam Cunningham"
        ],
        "model_ans": "Liam Cunningham",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Liam Cunningham</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the botswana currency first come into circulation",
        "answers": [
            "1976"
        ],
        "model_ans": "1966",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1966 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the largest salt mine in the us",
        "answers": [
            "Western New York",
            "Central New York"
        ],
        "model_ans": "Hutchinson Salt Company's mine in Hutchinson, Kansas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hutchinson Salt Company's mine in Hutchinson, Kansas </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays dylan in daddy's home 2",
        "answers": [
            "Owen Vaccaro"
        ],
        "model_ans": "Luis Guzm\u00e1n",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Luis Guzm\u00e1n </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the rock and roll hall of fame built in cleveland",
        "answers": [
            "1995",
            "September 1995"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is nebula on guardians of the galaxy",
        "answers": [
            "Karen Gillan"
        ],
        "model_ans": "Gamora",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gamora </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the significance of the sahara desert",
        "answers": [
            "the largest hot desert"
        ],
        "model_ans": "The Sahara Desert is the largest hot desert in the world, covering most of North Africa. It is known for its extreme heat, vast expanses of sand dunes, and unique ecosystem.",
        "model_confidence": "unsure</",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Sahara Desert is the largest hot desert in the world, covering most of North Africa. It is known for its extreme heat, vast expanses of sand dunes, and unique ecosystem. </answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first coronated king of manipur at kangla",
        "answers": [
            "Pakhangba",
            "Pamheiba"
        ],
        "model_ans": "Nongda Lairen Pakhangba",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Nongda Lairen Pakhangba </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the pastor of new birth missionary baptist church now",
        "answers": [
            "Stephen A. Davis"
        ],
        "model_ans": "Dr. Samuel Rodriquez",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dr. Samuel Rodriquez </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did saudi crown prince go to college",
        "answers": [
            "King Saud University"
        ],
        "model_ans": "King Saud University",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> King Saud University </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the revolution period of venus in earth years",
        "answers": [
            "224.7 Earth days",
            "0.615198\u00a0yr"
        ],
        "model_ans": "225 Earth years\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "225 Earth years\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the definition of ph in water",
        "answers": [
            "potential of hydrogen"
        ],
        "model_ans": "pH is a measure of the concentration of hydrogen ions in a solution, with a pH of 7 being neutral, below 7 being acidic, and above 7 being basic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> pH is a measure of the concentration of hydrogen ions in a solution, with a pH of 7 being neutral, below 7 being acidic, and above 7 being basic </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the national flag of india adopted",
        "answers": [
            "15 August 1947",
            "22 July 1947"
        ],
        "model_ans": "July 22, 1947",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July 22, 1947 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ajay devgan preity zinta and madhuri dixit movie",
        "answers": [
            "Yeh Raaste Hain Pyaar Ke"
        ],
        "model_ans": "Dil Se",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dil Se </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did virgin australia (formerly virgin blue) commence flying in australia",
        "answers": [
            "November 1999"
        ],
        "model_ans": "2000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who created separation of powers and checks and balances",
        "answers": [
            "Montesquieu in the Enlightenment"
        ],
        "model_ans": "Montesquieu",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montesquieu </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes of sabrina the teenage witch are there",
        "answers": [
            "163"
        ],
        "model_ans": "91",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 91 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "1. what was the precursor to the present day internet",
        "answers": [
            "the ARPANET project"
        ],
        "model_ans": "ARPANET\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " ARPANET\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first british team to win the european cup",
        "answers": [
            "Celtic"
        ],
        "model_ans": "Liverpool",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Liverpool </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who inaugurated 'world teachers' day'",
        "answers": [
            "UNESCO",
            "ILO"
        ],
        "model_ans": "UNESCO",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UNESCO </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many house of representative do we have in nigeria",
        "answers": [
            "360",
            "360 members"
        ],
        "model_ans": "360",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 360 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which type of fire detector uses the effect of smoke on a light source and photo-electric cell",
        "answers": [
            "optical smoke detector"
        ],
        "model_ans": "Optical",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Optical </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many votes to approve supreme court justice",
        "answers": [
            "A simple majority vote",
            "A simple majority"
        ],
        "model_ans": "51",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 51 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who do you meet at the gates of heaven",
        "answers": [
            "Saint Peter"
        ],
        "model_ans": "Saint Peter",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saint Peter </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "iupac name of element with atomic number 107",
        "answers": [
            "Bohrium",
            "bohrium"
        ],
        "model_ans": "Berkelium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Berkelium</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the setting for beauty and the beast",
        "answers": [
            "Rococo-era France",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time nebraska voted democrat",
        "answers": [
            "1964"
        ],
        "model_ans": "2008",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2008 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "winner of worst cooks in america season 5",
        "answers": [
            "Amber Brauner"
        ],
        "model_ans": "Doreen",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Doreen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the movie jeepers creepers come out",
        "answers": [
            "September 26, 2017"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who got the first nobel prize in physics",
        "answers": [
            "Wilhelm Conrad R\u00f6ntgen"
        ],
        "model_ans": "Wilhelm Conrad R\u00f6ntgen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wilhelm Conrad R\u00f6ntgen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who's the guy in call me maybe",
        "answers": [
            "Holden Nowell"
        ],
        "model_ans": "Carly Rae Jepsen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carly Rae Jepsen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the longest river in the united states",
        "answers": [
            "Missouri River"
        ],
        "model_ans": "Missouri River",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Missouri River </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the japanese videogame company nintendo founded",
        "answers": [
            "23 September 1889"
        ],
        "model_ans": "1889\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1889\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the evil doctor in wonder woman",
        "answers": [
            "Elena Anaya",
            "Spanish actress Elena Anaya"
        ],
        "model_ans": "David Thewlis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Thewlis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how old do you have to be to get a gun licence in nz",
        "answers": [
            "16 or older"
        ],
        "model_ans": "18",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 18 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is ishani in lies of the heart",
        "answers": [
            "Siddharth Arora/Vibhav Roy",
            "Nalini Negi"
        ],
        "model_ans": "Ishani Sharma",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ishani Sharma </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did indoor toilets become common in america",
        "answers": [
            "After World War I"
        ],
        "model_ans": "Late 19th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Late 19th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the king of dance season 2",
        "answers": [
            "LAAB Crew From Team Sherif"
        ],
        "model_ans": "Raghav Juyal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Raghav Juyal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "only player to play for manchester united manchester city liverpool and everton",
        "answers": [
            "Peter Andrew Beardsley",
            "Peter Andrew Beardsley MBE"
        ],
        "model_ans": "Owen Hargreaves",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Owen Hargreaves </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did france and belgium invade the ruhr",
        "answers": [
            "11 January 1923",
            "January 1923",
            "1923"
        ],
        "model_ans": "1914",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1914 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the first nfl game of the season",
        "answers": [
            "the New England Patriots",
            "the Kansas City Chiefs"
        ],
        "model_ans": "Green Bay Packers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Green Bay Packers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings in walk hard the dewey cox story",
        "answers": [
            "John C. Reilly"
        ],
        "model_ans": "John C. Reilly",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>John C. Reilly</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the american league pennant in 2017",
        "answers": [
            "Houston Astros",
            "the Houston Astros"
        ],
        "model_ans": "Houston Astros",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Houston Astros </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where are the san juan mountains in new mexico",
        "answers": [
            "northwestern New Mexico"
        ],
        "model_ans": "New Mexico",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Mexico </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won last year's grand national 2017",
        "answers": [
            "One For Arthur"
        ],
        "model_ans": "Ribchester",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ribchester </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played daisy duke in the new dukes of hazzard",
        "answers": [
            "Jessica Simpson"
        ],
        "model_ans": "Jessica Simpson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jessica Simpson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in drake and josh",
        "answers": [
            "Jonathan Goldstein"
        ],
        "model_ans": "Joe",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joe </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what do mobile numbers start with in the uk",
        "answers": [
            "0"
        ],
        "model_ans": "07\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "07\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the lost dutchman's mine supposed to be located",
        "answers": [
            "in the southwestern United States"
        ],
        "model_ans": "Superstition Mountains",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Superstition Mountains </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did hollywood become the centre of the film industry",
        "answers": [
            "1912",
            "By 1912"
        ],
        "model_ans": "1910s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1910s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is known as father of green revolution in india",
        "answers": [
            "Mankombu Sambasivan Swaminathan"
        ],
        "model_ans": "M.S. Swaminathan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> M.S. Swaminathan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who brought the idea of castles to england",
        "answers": [
            "Norman invaders"
        ],
        "model_ans": "Normans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Normans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do willow and tara get back together",
        "answers": [
            "Entropy",
            "Seeing Red"
        ],
        "model_ans": "Willow and Tara never got back together",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Willow and Tara never got back together </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of artwork was created in the safavid empire",
        "answers": [
            "architecture",
            "metal",
            "ceramics",
            "gardens",
            "book",
            "glass"
        ],
        "model_ans": "Persian miniature",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Persian miniature </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the current mac os operating system",
        "answers": [
            "10.13.4",
            "macOS High Sierra"
        ],
        "model_ans": "macOS Big Sur",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> macOS Big Sur </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the fountain of youth stakes at gulfstream park",
        "answers": [
            "Gunnevera"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the nfl first draft pick 2017",
        "answers": [
            "Myles Garrett"
        ],
        "model_ans": "Myles Garrett",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Myles Garrett </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why wasnt agent matthews in miss congeniality 2",
        "answers": [
            "relocated to Miami",
            "gets relocated to Miami"
        ],
        "model_ans": "Sandra Bullock's character, Gracie Hart, was the main character in the movie Miss Congeniality, but there was no Agent Matthews in the movie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sandra Bullock's character, Gracie Hart, was the main character in the movie Miss Congeniality, but there was no Agent Matthews in the movie </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of dog was laika the spacedog",
        "answers": [
            "mongrel female"
        ],
        "model_ans": "Soviet space dog",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Soviet space dog </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who signed the declaration of independence for maryland",
        "answers": [
            "William Paca",
            "Samuel Chase",
            "Charles Carroll of Carrollton",
            "Thomas Stone"
        ],
        "model_ans": "Charles Carroll",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Carroll </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who expanded the territory of china during the qing dynasty",
        "answers": [
            "Qianlong",
            "the Qianlong Emperor",
            "Prince Bao"
        ],
        "model_ans": "Qing Dynasty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Qing Dynasty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has scored more goals in the premier league",
        "answers": [
            "Alan Shearer"
        ],
        "model_ans": "Alan Shearer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alan Shearer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays kevins shrink on kevin probably saves the world",
        "answers": [
            "Richard Masur"
        ],
        "model_ans": "Jordan Peele",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jordan Peele </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the 2015 rugby union world cup held",
        "answers": [
            "England",
            "Wales"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won an oscar for schindler's list",
        "answers": [
            "Steven Zaillian",
            "Michael Kahn",
            "Steven Spielberg",
            "Janusz Kami\u0144ski",
            "John Williams",
            "Ewa Braun",
            "Gerald R. Molen",
            "Branko Lustig",
            "Allan Starski"
        ],
        "model_ans": "Liam Neeson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Liam Neeson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did britain set up east indian trading company",
        "answers": [
            "31 December 1600"
        ],
        "model_ans": "1600",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>1600</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the movie jeremiah johnson filmed at",
        "answers": [
            "Utah"
        ],
        "model_ans": "Utah",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Utah </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does a wrinkle in time take place",
        "answers": [
            "Connecticut"
        ],
        "model_ans": "Cambridge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cambridge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the potter's wheel first develop",
        "answers": [
            "in the Near East",
            "the Near East"
        ],
        "model_ans": "Mesopotamia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mesopotamia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did where are you now come out",
        "answers": [
            "February 27, 2015",
            "February\u00a027,\u00a02015"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the two teams in super bowl 2018",
        "answers": [
            "New England Patriots",
            "Philadelphia Eagles"
        ],
        "model_ans": "Philadelphia Eagles and New England Patriots",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Philadelphia Eagles and New England Patriots </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is dj's boyfriends name on full house",
        "answers": [
            "Steve Hale",
            "Steven \"Steve\" Hale",
            "rich kid Nelson",
            "Viper"
        ],
        "model_ans": "Danny Tanner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Danny Tanner </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did end of the road come out",
        "answers": [
            "1992",
            "June\u00a030,\u00a01992"
        ],
        "model_ans": "1993\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1993\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what year did the golden state warriors win their first nba championship",
        "answers": [
            "1947"
        ],
        "model_ans": "1947",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1947 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i want to be a rockstar",
        "answers": [
            "Nickelback",
            "Canadian rock band Nickelback",
            "Billy Gibbons of ZZ Top"
        ],
        "model_ans": "Bow Wow Wow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bow Wow Wow </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time new england had a hurricane",
        "answers": [
            "Hurricane Hanna"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won every men's biathlon event in the 2002 winter olympics",
        "answers": [
            "Norway",
            "Ole Einar Bj\u00f8rndalen"
        ],
        "model_ans": "Ole Einar Bj\u00f8rndalen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ole Einar Bj\u00f8rndalen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does dwyane wade play for right now",
        "answers": [
            "the Miami Heat",
            "Miami Heat"
        ],
        "model_ans": "Miami Heat",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miami Heat </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the nurse on andy griffith show",
        "answers": [
            "Julie Adams",
            "Langdon"
        ],
        "model_ans": "Betty Lynn",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Betty Lynn </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the form of mozart symphony no 40",
        "answers": [
            "G minor",
            "minor key symphonies"
        ],
        "model_ans": "Sonata form",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sonata form </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the head of parliament in uk",
        "answers": [
            "The Lord Fowler",
            "John Bercow",
            "Elizabeth II"
        ],
        "model_ans": "Speaker of the House of Commons",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker of the House of Commons </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the sciatic nerve run in the foot",
        "answers": [
            "on the posterior aspect"
        ],
        "model_ans": "The sciatic nerve runs down the back of the leg, from the lower back to the foot, and then splits into two branches that run down the back of the calf and into the foot.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The sciatic nerve runs down the back of the leg, from the lower back to the foot, and then splits into two branches that run down the back of the calf and into the foot. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the workd series of poker 2017",
        "answers": [
            "Scott Blumstein"
        ],
        "model_ans": "Scott Blumstein",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Scott Blumstein </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the creation of human beings in the kumulipo happens during which w\u0101 or period of creation",
        "answers": [
            "In the ninth w\u0101",
            "the ninth w\u0101,",
            "the ninth w\u0101",
            "the ninth"
        ],
        "model_ans": "W\u0101\u02bbahiluhia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> W\u0101\u02bbahiluhia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote hit me baby one more time",
        "answers": [
            "Max Martin"
        ],
        "model_ans": "Britney Spears",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Britney Spears</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is cost of first class mail stamp",
        "answers": [
            "49 cents",
            "47 cents",
            ".49"
        ],
        "model_ans": "$0.55",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> $0.55 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the book the origin of species",
        "answers": [
            "Charles Darwin"
        ],
        "model_ans": "Charles Darwin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Darwin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what's in a beam me up scotty",
        "answers": [
            "phencyclidine",
            "cocaine"
        ],
        "model_ans": "Scotty",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotty </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the red river start and end in louisiana",
        "answers": [
            "the Texas Panhandle"
        ],
        "model_ans": "The Red River starts in Texas and ends in Louisiana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Red River starts in Texas and ends in Louisiana </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the official symbol of the carnival of quebec",
        "answers": [
            "Bonhomme Carnaval"
        ],
        "model_ans": "Beaver",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Beaver </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the main mineral in lithium batteries",
        "answers": [
            "Lithium",
            "lithium"
        ],
        "model_ans": "Lithium",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lithium </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the middle sister on full house",
        "answers": [
            "Jodie Sweetin"
        ],
        "model_ans": "Andrea Barber",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrea Barber </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays caesar planet of the apes 2014",
        "answers": [
            "Andy Serkis"
        ],
        "model_ans": "Jamie Bell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jamie Bell</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of car is a jeep considered",
        "answers": [
            "off-road vehicles",
            "light utility vehicles",
            "sport utility vehicles"
        ],
        "model_ans": "SUV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SUV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many us states currently use capital punishment",
        "answers": [
            "31 states",
            "31"
        ],
        "model_ans": "27",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 27 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time dallas cowboys won the super bowl",
        "answers": [
            "1995"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is salt mined in the united states",
        "answers": [
            "Avery Island, Louisiana",
            "Houston, Texas",
            "Avery Island",
            "Saltville, Virginia",
            "Central New York",
            "Hutchinson, Kansas",
            "Syracuse",
            "Grand Saline in East Texas",
            "Detroit, Michigan",
            "Western New York"
        ],
        "model_ans": "Various locations in the United States, including Louisiana, Texas, Kansas, Oklahoma, and Utah",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Various locations in the United States, including Louisiana, Texas, Kansas, Oklahoma, and Utah </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the new episodes of supernatural start",
        "answers": [
            "October\u00a012,\u00a02017",
            "May\u00a03,\u00a02018",
            "October 12, 2017"
        ],
        "model_ans": "October",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played pink in pink floyd the wall",
        "answers": [
            "Kevin McKeon as Young Pink",
            "Bob Geldof as Pink",
            "David Bingham as Little Pink",
            "Bob Geldof",
            "David Bingham",
            "Kevin McKeon"
        ],
        "model_ans": "Bob Geldof",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bob Geldof </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did goku first go super saiyan 4",
        "answers": [
            "Dragon Ball GT"
        ],
        "model_ans": "Goku first went Super Saiyan 4 in Dragon Ball GT",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Goku first went Super Saiyan 4 in Dragon Ball GT </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the giant redwoods located in california",
        "answers": [
            "Humboldt County",
            "Del Norte County",
            "the coast of northern California"
        ],
        "model_ans": "Northern California",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Northern California </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first woman to win who wants to be a millionaire",
        "answers": [
            "Judith Cynthia Aline Keppel"
        ],
        "model_ans": "Judith Keppel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Judith Keppel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings for the beast in the new movie",
        "answers": [
            "Dan Stevens"
        ],
        "model_ans": "BTS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> BTS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "industrial city in germany on the rhine herne canal",
        "answers": [
            "Henrichenburg",
            "Duisburg"
        ],
        "model_ans": "Duisburg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Duisburg </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who declared war on the united states four days after pearl harbor",
        "answers": [
            "Fascist Italy",
            "Nazi Germany"
        ],
        "model_ans": "Germany",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "premier league players to score 5 goals in one game",
        "answers": [
            "Alan Shearer",
            "Andy Cole",
            "Jermain Defoe",
            "Sergio Ag\u00fcero",
            "Dimitar Berbatov"
        ],
        "model_ans": "Robbie Fowler, Sadio Man\u00e9, Sergio Ag\u00fcero,",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Robbie Fowler, Sadio Man\u00e9, Sergio Ag\u00fcero, </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "an edge that is between a vertex and itself is a",
        "answers": [
            "loop"
        ],
        "model_ans": "loop",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> loop </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who took part in the american civil war",
        "answers": [
            "nationalists of the Union"
        ],
        "model_ans": "Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was penicillin first introduced to the public",
        "answers": [
            "After World War II",
            "1942"
        ],
        "model_ans": "1941",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1941 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what ethnic group celebrates its contribution to america in october",
        "answers": [
            "Filipino Americans",
            "Filipino American",
            "Filipino"
        ],
        "model_ans": "Italian-American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Italian-American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time a hurricane hit massachusetts",
        "answers": [
            "November 3, 2007"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who heads the executive department of west virginia government",
        "answers": [
            "the Governor of West Virginia",
            "the governor of West Virginia",
            "Jim Justice"
        ],
        "model_ans": "Jim Justice",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jim Justice </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who owned the colts when they left baltimore",
        "answers": [
            "Robert Irsay",
            "Irsay"
        ],
        "model_ans": "Baltimore",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Baltimore </answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays elsa's aunt in once upon a time",
        "answers": [
            "Elizabeth Mitchell"
        ],
        "model_ans": "Samantha",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Samantha </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which president supported the creation of the environmental protection agency (epa)",
        "answers": [
            "Richard Nixon",
            "President Richard Nixon"
        ],
        "model_ans": "Richard Nixon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Nixon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played taylor on the bold and beautiful",
        "answers": [
            "Hunter Tylo",
            "Sherilyn Wolter",
            "Sherilyn Wolter (1990)"
        ],
        "model_ans": "Hunter Tylo",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Hunter Tylo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are trigger points located in the body",
        "answers": [
            "muscles"
        ],
        "model_ans": "muscles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> muscles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings that aint no way to go",
        "answers": [
            "Brooks & Dunn"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did they get the tree for rockefeller center",
        "answers": [
            "State College, PA"
        ],
        "model_ans": "Norway",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Norway </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does bill nye saves the world season 2 come out",
        "answers": [
            "December\u00a029,\u00a02017"
        ],
        "model_ans": "April 10, 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> April 10, 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the song holiday road come out",
        "answers": [
            "1983",
            "June 24, 1983"
        ],
        "model_ans": "1987\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1987\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the purpose of the bantu education act",
        "answers": [
            "enforcing racially separated educational facilities"
        ],
        "model_ans": "segregation",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> segregation </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the longest railway station in india",
        "answers": [
            "Gorakhpur Junction",
            "Gorakhpur railway station"
        ],
        "model_ans": "Gorakhpur Junction",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Gorakhpur Junction </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has played raoul in phantom of the opera",
        "answers": [
            "Tim Martin Gleason",
            "Hadley Fraser",
            "Steve Barton"
        ],
        "model_ans": "Ramin Karimloo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ramin Karimloo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "fast & furious 8 release date in india",
        "answers": [
            "April 12, 2017"
        ],
        "model_ans": "3 June 2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "3 June 2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song be thankful for what you got",
        "answers": [
            "William DeVaughn"
        ],
        "model_ans": "Buju Banting",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Buju Banting</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did iowa state football coach come from",
        "answers": [
            "Massillon, Ohio",
            "Toledo"
        ],
        "model_ans": "Iowa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iowa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did scotland last qualify for world cup",
        "answers": [
            "1998"
        ],
        "model_ans": "1998",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1998 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang in the movie i walk the line",
        "answers": [
            "Reese Witherspoon",
            "Tyler Hilton",
            "Waylon Payne",
            "Johnathan Rice",
            "Shooter Jennings",
            "Joaquin Phoenix"
        ],
        "model_ans": "Johnny Cash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Cash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what kind of food did the woolly mammoth eat",
        "answers": [
            "grass and sedges"
        ],
        "model_ans": "grasses and fruits",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> grasses and fruits </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what's the average lifespan of a basset hound",
        "answers": [
            "Median 10\u201312 years",
            "10\u201312 years"
        ],
        "model_ans": "10-12 years\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "10-12 years\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the great plague of london start and end",
        "answers": [
            "1665 to 1666",
            "1666",
            "1665",
            "from 1665 to 1666"
        ],
        "model_ans": "1665-1666",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1665-1666 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the movie the king and i made",
        "answers": [
            "1956"
        ],
        "model_ans": "1956\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1956\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the first persian gulf war take place",
        "answers": [
            "Israel",
            "Persian Gulf",
            "Saudi Arabia",
            "Iraq",
            "Kuwait"
        ],
        "model_ans": "Iraq",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iraq </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is considered the father of modern behaviorism",
        "answers": [
            "John B. Watson"
        ],
        "model_ans": "John B. Watson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John B. Watson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did to kill a mockingbird become popular",
        "answers": [
            "1960"
        ],
        "model_ans": "1960",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1960 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the first nfl thursday night football game",
        "answers": [
            "Denver Broncos",
            "the visiting Denver Broncos",
            "the Kansas City Chiefs",
            "Kansas City Chiefs"
        ],
        "model_ans": "Jim Nantz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jim Nantz </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what language is the olympic anthem sang in",
        "answers": [
            "Greek"
        ],
        "model_ans": "French",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> French </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "is jaffa cakes a biscuit or a cake",
        "answers": [
            "Cake",
            "biscuit-sized cakes",
            "cakes"
        ],
        "model_ans": "cake",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cake </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what's the difference between salisbury steak and hamburger steak",
        "answers": [
            "ingredients"
        ],
        "model_ans": "Salisbury steak is typically made with a mixture of ground beef and breadcrumbs, while hamburger steak is made with pure ground beef.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Salisbury steak is typically made with a mixture of ground beef and breadcrumbs, while hamburger steak is made with pure ground beef. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did chocolate originate the americas spain asia",
        "answers": [
            "Mesoamerica",
            "the Americas",
            "Americas"
        ],
        "model_ans": "Mesoamerica",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mesoamerica </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who received the most (but not a majority of) electoral votes in 1824",
        "answers": [
            "Andrew Jackson"
        ],
        "model_ans": "John Quincy Adams",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Quincy Adams </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the papillary layer of the skin lie",
        "answers": [
            "adjacent to the epidermis"
        ],
        "model_ans": "between the epidermis and dermis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> between the epidermis and dermis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the original singer of you re going to love me",
        "answers": [
            "Jennifer Holliday"
        ],
        "model_ans": "Charles Aznavour",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charles Aznavour </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of song is what a wonderful world",
        "answers": [
            "a pop ballad",
            "jazz",
            "pop ballad",
            "Traditional pop"
        ],
        "model_ans": "Jazz",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jazz</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "suffix applied to the end of the name of enzymes",
        "answers": [
            "-ase"
        ],
        "model_ans": "ase",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>ase </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of business is chamber of commerce",
        "answers": [
            "a form of business network"
        ],
        "model_ans": "Non-profit",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Non-profit </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who directed the best years of our lives",
        "answers": [
            "William Wyler"
        ],
        "model_ans": "William Wyler",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William Wyler </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the assassination of gianni versace american crime story season 2 episode 2",
        "answers": [
            "Manhunt"
        ],
        "model_ans": "Gianni Versace",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gianni Versace </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when's the last time the philadelphia eagles played the new england patriots",
        "answers": [
            "in Super Bowl LII"
        ],
        "model_ans": "2022-01-24\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2022-01-24\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first indian to be appointed as a judge in the international court of justice",
        "answers": [
            "Sir Benegal Narsing Rau"
        ],
        "model_ans": "Dalveer Bhandari",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dalveer Bhandari </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of tale is the pardoner's tale",
        "answers": [
            "a moral tale",
            "an extended exemplum"
        ],
        "model_ans": "morality tale",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> morality tale </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the all time leading scorer in ncaa tournament history",
        "answers": [
            "Pete Maravich"
        ],
        "model_ans": "Pete Maravich",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Pete Maravich </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times has lake placid hosted the winter olympics",
        "answers": [
            "twice"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do some of the natural air pollutants come from",
        "answers": [
            "wildfires",
            "Volcanic activity",
            "Dust",
            "Carbon dioxide",
            "Vegetation"
        ],
        "model_ans": "industrial activities, vehicle emissions, and biomass burning",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> industrial activities, vehicle emissions, and biomass burning </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the shape with 100 sides",
        "answers": [
            "hectogon",
            "hecatogon",
            "hecatontagon"
        ],
        "model_ans": "Dodecagon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dodecagon </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is i can only imagine coming out",
        "answers": [
            "March 16, 2018"
        ],
        "model_ans": "May 2015",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the robot in lost in space 2018",
        "answers": [
            "Brian Steele"
        ],
        "model_ans": "Robot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is recognized as the founder of islam",
        "answers": [
            "the Islamic prophet Muhammad",
            "Muhammad"
        ],
        "model_ans": "Muhammad",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the new mlp movie come out",
        "answers": [
            "September 24, 2017",
            "October\u00a06,\u00a02017",
            "October 6, 2017"
        ],
        "model_ans": "September 24, 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> September 24, 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was robin hood prince of thieves made",
        "answers": [
            "the United Kingdom"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most goals in soccer 2018",
        "answers": [
            "Ali Daei"
        ],
        "model_ans": "Harry Kane",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harry Kane </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does it's a wonderful life comes on",
        "answers": [
            "Christmas season"
        ],
        "model_ans": "December 24th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 24th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the original little red riding hood story",
        "answers": [
            "Charles Perrault"
        ],
        "model_ans": "Charles Perrault",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Perrault </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the inscription on the statue of liberty",
        "answers": [
            "The New Colossus"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the captain of the mayflower when it took the pilgrims to the new world",
        "answers": [
            "Captain Jones",
            "Master Christopher Jones",
            "Christopher Jones"
        ],
        "model_ans": "Christopher Jones",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christopher Jones </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the top speed of thrust ssc",
        "answers": [
            "1,228\u00a0km/h"
        ],
        "model_ans": "511 mph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 511 mph </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the oldest civilization known to man",
        "answers": [
            "Mesopotamia"
        ],
        "model_ans": "Mesopotamia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mesopotamia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does scully come back in season 2",
        "answers": [
            "One Breath",
            "8"
        ],
        "model_ans": "Episode 10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Episode 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many lines of symmetry are there in a equilateral triangle",
        "answers": [
            "3"
        ],
        "model_ans": "3\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "3\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "has been honoured with the wisden leading cricketer in the world award for 2016",
        "answers": [
            "Virat Kohli"
        ],
        "model_ans": "Virat Kohli",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Virat Kohli </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the witch of blackbird pond published",
        "answers": [
            "United States",
            "1958",
            "Houghton Mifflin"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the number of total presidential electoral votes",
        "answers": [
            "538"
        ],
        "model_ans": "538\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "538\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the breakdown product formed when one phosphate group is removed from atp",
        "answers": [
            "adenosine diphosphate (ADP)"
        ],
        "model_ans": "ADP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ADP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations",
        "answers": [
            "Windows Easy Transfer"
        ],
        "model_ans": "Robocopy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robocopy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the season finale of designated survivor",
        "answers": [
            "May\u00a016,\u00a02018"
        ],
        "model_ans": "May 16, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May 16, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time an american won the new york marathon",
        "answers": [
            "2009",
            "2017"
        ],
        "model_ans": "2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2017 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the girl that died in eyes wide shut",
        "answers": [
            "Mandy"
        ],
        "model_ans": "Milly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Milly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the prime minister of india full name",
        "answers": [
            "Narendra Modi"
        ],
        "model_ans": "Narendra Damodardas Modi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Narendra Damodardas Modi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the grandfather on the cosby show",
        "answers": [
            "Earle Hyman"
        ],
        "model_ans": "Judge Clarence",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judge Clarence </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "list of books written by abul kalam azad",
        "answers": [
            "Ghubar-e-Khatir",
            "Tarjumanul Quran",
            "Tazkirah",
            "India Wins Freedom"
        ],
        "model_ans": "India Wins Freedom, Inquilab Zindabad, and Leaves of Faith",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> India Wins Freedom, Inquilab Zindabad, and Leaves of Faith </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the 5 boroughs of new york city",
        "answers": [
            "Manhattan",
            "Queens",
            "Staten Island",
            "Brooklyn",
            "the Bronx"
        ],
        "model_ans": "Manhattan, Brooklyn, Queens, The Bronx, Staten Island",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manhattan, Brooklyn, Queens, The Bronx, Staten Island </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did ohio state join the big 10",
        "answers": [
            "1912"
        ],
        "model_ans": "1912\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1912\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the ouija board first come out",
        "answers": [
            "July 1, 1890"
        ],
        "model_ans": "1890\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1890\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "distinctive characteristics of animals classified as vertebrates include",
        "answers": [
            "backbones",
            "have a vertebral column"
        ],
        "model_ans": "having a backbone, being warm-blooded, having a brain, having sensory organs",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> having a backbone, being warm-blooded, having a brain, having sensory organs </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the last world cup held and who won",
        "answers": [
            "Germany",
            "hosted by Brazil",
            "won by Germany",
            "Est\u00e1dio do Maracan\u00e3"
        ],
        "model_ans": "Russia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Russia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long is a prime minister term in uk",
        "answers": [
            "At Her Majesty's pleasure"
        ],
        "model_ans": "5 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the optic nerve cross the midline \u200b",
        "answers": [
            "optic chiasm"
        ],
        "model_ans": "optic chiasm",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> optic chiasm </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was it that described the structure of dna",
        "answers": [
            "James Watson and Francis Crick",
            "James Watson",
            "Francis Crick"
        ],
        "model_ans": "James Watson and Francis Crick",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watson and Francis Crick </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang the theme song from russia with love",
        "answers": [
            "Matt Monro"
        ],
        "model_ans": "Matt Monro",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matt Monro </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the song 10 green bottles come from",
        "answers": [
            "United Kingdom"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what kind of national legislature did the constitution created",
        "answers": [
            "bicameral Congress"
        ],
        "model_ans": "Congress",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Congress </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "vikram samvat calender is official in which country",
        "answers": [
            "Nepal"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did one child policy end in china",
        "answers": [
            "January 1, 2016"
        ],
        "model_ans": "2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the definition of the name thomas",
        "answers": [
            "\"twin\"",
            "twin"
        ],
        "model_ans": "Thomas is a masculine given name that originated from the Aramaic name \"Taoma\" meaning \"twin\"",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Thomas is a masculine given name that originated from the Aramaic name \"Taoma\" meaning \"twin\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was generally the preferred way for european powers to control colonial regions",
        "answers": [
            "Indirect rule"
        ],
        "model_ans": "indirect rule",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> indirect rule </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which is the only test playing nation that india has never beat in t20",
        "answers": [
            "Scotland"
        ],
        "model_ans": "England",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "input that tells the computer which task to execute is",
        "answers": [
            "source code",
            "A computer program"
        ],
        "model_ans": "command",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> command </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won season 2 of real chance of love",
        "answers": [
            "Jackie DaFonseca",
            "Kamille Leai",
            "Hot Wings",
            "Doll"
        ],
        "model_ans": "",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>  </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of nelson on simpsons",
        "answers": [
            "Nancy Jean Cartwright"
        ],
        "model_ans": "Harry Shearer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Harry Shearer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the coach of university of kentucky basketball",
        "answers": [
            "John Calipari",
            "John Vincent Calipari"
        ],
        "model_ans": "John Calipari",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Calipari </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the gold for the men's figure skating",
        "answers": [
            "Yuzuru Hanyu"
        ],
        "model_ans": "Yuzuru Hanyu",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Yuzuru Hanyu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song tell me something good",
        "answers": [
            "Rufus and Chaka Khan"
        ],
        "model_ans": "Jay-Z",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jay-Z</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the initial unification of upper and lower egypt took place during which period",
        "answers": [
            "3000 BC",
            "c. 3000 BC"
        ],
        "model_ans": "Predynastic Period",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Predynastic Period </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays voldemort in harry potter and the philosopher's stone",
        "answers": [
            "Richard Bremmer",
            "Ian Hart"
        ],
        "model_ans": "Richard Harris",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Harris </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the next star trek episode come out",
        "answers": [
            "2018",
            "February\u00a04,\u00a02018"
        ],
        "model_ans": "The release date of the next Star Trek episode is not publicly available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The release date of the next Star Trek episode is not publicly available </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the present rajya sabha speaker of india",
        "answers": [
            "Venkaiah Naidu"
        ],
        "model_ans": "M. Venkaiah Naidu",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> M. Venkaiah Naidu </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the book of galatians written to",
        "answers": [
            "the churches of Galatia"
        ],
        "model_ans": "The Galatian churches",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Galatian churches </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "panda is a national animal of which country",
        "answers": [
            "China"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when will the flash season 4 episode 17 come out",
        "answers": [
            "April\u00a010,\u00a02018",
            "April\u00a017,\u00a02018"
        ],
        "model_ans": "March 21, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 21, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what do the 3 dots mean in math",
        "answers": [
            "therefore sign",
            "the therefore sign"
        ],
        "model_ans": "Ellipsis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ellipsis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does star wars battlefront 2 com out",
        "answers": [
            "November 17, 2017"
        ],
        "model_ans": "November 17, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> November 17, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the british army launch a successful invasion in 1776",
        "answers": [
            "New York",
            "Long Island"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "doric ionic and corinthian orders all refer to types of",
        "answers": [
            "architecture"
        ],
        "model_ans": "architecture",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> architecture </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "consist of the sum of the fixed and variable costs for any given level of production",
        "answers": [
            "total cost (TC)"
        ],
        "model_ans": "Total Cost",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Total Cost </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how old was sasuke when his clan died",
        "answers": [
            "seven"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the religion in the virginia colony",
        "answers": [
            "Anglican church",
            "The Church of England",
            "Anglican"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote how do you do it by gerry and the pacemakers",
        "answers": [
            "Mitch Murray"
        ],
        "model_ans": "Jerry Lee Lewis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jerry Lee Lewis</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who devised the fingerprint classification still used today in europe and the us",
        "answers": [
            "Hem Chandra Bose",
            "Azizul Haque",
            "Sir Edward Henry"
        ],
        "model_ans": "Sir Francis Galton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sir Francis Galton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the first vice president of india who become the president letter was",
        "answers": [
            "Sarvepalli Radhakrishnan"
        ],
        "model_ans": "Zakir Hussain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zakir Hussain </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who led the soldiers in ending the raid on the harper's ferry arsenal",
        "answers": [
            "Colonel Robert E. Lee",
            "First Lieutenant Israel Greene",
            "Brevet Colonel Robert E. Lee"
        ],
        "model_ans": "Robert E. Lee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robert E. Lee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the cell spend most of its time in the cell cycle",
        "answers": [
            "Interphase"
        ],
        "model_ans": "G1 phase",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>G1 phase</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang a whiter shade of pale first",
        "answers": [
            "Procol Harum",
            "British rock band Procol Harum"
        ],
        "model_ans": "Joy Division",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Joy Division</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was first governor general of british india",
        "answers": [
            "Louis Mountbatten",
            "Warren Hastings"
        ],
        "model_ans": "Warren Hastings",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Warren Hastings </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "surface area in many kinds of organs is important because the amount of surface determines",
        "answers": [
            "effective gas exchange"
        ],
        "model_ans": "the amount of oxygen that can be absorbed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the amount of oxygen that can be absorbed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has majority in the house and senate",
        "answers": [
            "Republican"
        ],
        "model_ans": "Democrats",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Democrats </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the most losing team in nfl history",
        "answers": [
            "Arizona Cardinals",
            "Tampa Bay Buccaneers"
        ],
        "model_ans": "Cleveland Browns",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cleveland Browns </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the highest scoring letter in scrabble",
        "answers": [
            "Q"
        ],
        "model_ans": "J",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> J </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the book small steps take place",
        "answers": [
            "Austin, Texas"
        ],
        "model_ans": "Mumbai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mumbai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did bihar bifurcate from bengal and some parts of chota nagpur merged into bengal",
        "answers": [
            "1912"
        ],
        "model_ans": "1912",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1912 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many series of diary of a wimpy kid are there",
        "answers": [
            "12"
        ],
        "model_ans": "16\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "16\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who created the very first adhesive postage stamp and what year",
        "answers": [
            "Sir Rowland Hill",
            "1837"
        ],
        "model_ans": "Sir Rowland Hill",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sir Rowland Hill </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the writer of a walk to remember",
        "answers": [
            "American writer Nicholas Sparks",
            "Nicholas Sparks"
        ],
        "model_ans": "Nicholas Sparks",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nicholas Sparks </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did red dead redemption 1 come out",
        "answers": [
            "May 18, 2010",
            "May 2010"
        ],
        "model_ans": "2010",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2010 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings theme tune to orange is the new black",
        "answers": [
            "Spektor"
        ],
        "model_ans": "Regina Spektor",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Regina Spektor </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what channel is abc on in phoenix arizona",
        "answers": [
            "15"
        ],
        "model_ans": "ABC is on channel 15 in Phoenix, Arizona.\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " ABC is on channel 15 in Phoenix, Arizona.\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the brazos river start and stop",
        "answers": [
            "Gulf of Mexico",
            "Llano Estacado"
        ],
        "model_ans": "Brazos River starts at the confluence of the Double Mountain Fork and the Salt Fork of the Brazos River in the rolling hills of north-central Texas, and ends at the Gulf of Mexico.",
        "model_confidence": "unsure</",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Brazos River starts at the confluence of the Double Mountain Fork and the Salt Fork of the Brazos River in the rolling hills of north-central Texas, and ends at the Gulf of Mexico.</answer>\n<confidence>unsure</</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the purpose of the bromophenol blue dye in the samples",
        "answers": [
            "as a pH indicator",
            "a dye",
            "a color marker",
            "a pH indicator"
        ],
        "model_ans": "pH indicator",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pH indicator </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does jim propose to pam on the office",
        "answers": [
            "In the Season 5 premiere"
        ],
        "model_ans": "Season 6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who dies in akame ga kill night raid",
        "answers": [
            "Tatsumi"
        ],
        "model_ans": "Esdeath",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Esdeath </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played mary in christmas with the kranks",
        "answers": [
            "Felicity Huffman"
        ],
        "model_ans": "Jaime Pressly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jaime Pressly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does dragon ball super episode 113 start",
        "answers": [
            "October 29, 2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of marceline on adventure time",
        "answers": [
            "Cloris Leachman",
            "Olivia Olson",
            "Olivia Olson in most appearances",
            "Ava Acres as a child",
            "Ava Acres"
        ],
        "model_ans": "Olivia Olson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Olivia Olson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most green jackets from the masters",
        "answers": [
            "Nicklaus",
            "Jack Nicklaus (6)"
        ],
        "model_ans": "Jack Nicklaus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack Nicklaus</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the eagle creek fire located in oregon",
        "answers": [
            "Cascade Locks",
            "Columbia River Gorge"
        ],
        "model_ans": "Eagle Creek",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eagle Creek </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "sending money home to the native country is an example of",
        "answers": [
            "international capital flows",
            "remittance"
        ],
        "model_ans": "remittance",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> remittance </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many episodes is ash vs evil dead season 3",
        "answers": [
            "10"
        ],
        "model_ans": "10\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "10\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the song in red dead redemption",
        "answers": [
            "Far Away"
        ],
        "model_ans": "Far Away",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Far Away </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the head of the department of homeland security 2017",
        "answers": [
            "Kirstjen Nielsen"
        ],
        "model_ans": "John Kelly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Kelly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the ceo of what's up",
        "answers": [
            "Jan Koum"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what part of dc is howard university in",
        "answers": [
            "in northwest Washington",
            "northwest",
            "northwest Washington"
        ],
        "model_ans": "Northwest",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Northwest </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most olympic medals in figure skating",
        "answers": [
            "Scott Moir",
            "Tessa Virtue"
        ],
        "model_ans": "Irina Rodnina",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Irina Rodnina </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who scored the most points in a single game in the nba",
        "answers": [
            "Wilt Chamberlain"
        ],
        "model_ans": "Wilt Chamberlain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wilt Chamberlain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the design period known as art deco",
        "answers": [
            "1910\u20131939"
        ],
        "model_ans": "1925",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1925 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "disagreements involving slavery and states' rights were two of the main causes of",
        "answers": [
            "the American Civil War"
        ],
        "model_ans": "the American Civil War",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> the American Civil War </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the biggest tank in world war 2",
        "answers": [
            "Panzerkampfwagen VIII Maus"
        ],
        "model_ans": "Maus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does the c stand for chrysler 300c",
        "answers": [
            "coupe"
        ],
        "model_ans": "Chrysler",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chrysler </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the walking boss in cool hand luke",
        "answers": [
            "Morgan Woodward"
        ],
        "model_ans": "Strother Martin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Strother Martin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first lady nominated member of the rajya sabha",
        "answers": [
            "Mary Kom"
        ],
        "model_ans": "Sarojini Naidu",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sarojini Naidu </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the canada open women's doubles",
        "answers": [
            "Wakana Nagahara",
            "Mayu Matsumoto"
        ],
        "model_ans": "Martina Navratilova",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Martina Navratilova </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played charles on when calls the heart",
        "answers": [
            "Steve Bacic"
        ],
        "model_ans": "Jack Wagner",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jack Wagner </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many wins does tiger woods have on the pga tour",
        "answers": [
            "79"
        ],
        "model_ans": "82",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 82 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most subscribers in faze clan",
        "answers": [
            "FaZe Rug"
        ],
        "model_ans": "Tfue",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tfue </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the movie a walk among the tombstones filmed",
        "answers": [
            "New York City"
        ],
        "model_ans": "Toronto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toronto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the paraguay river start and end",
        "answers": [
            "Paran\u00e1 River"
        ],
        "model_ans": "The Paraguay River starts in the Brazilian state of Mato Grosso do Sul and ends in the Argentine province of Corrientes.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Paraguay River starts in the Brazilian state of Mato Grosso do Sul and ends in the Argentine province of Corrientes. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the nurses' health study is an example of what type of study",
        "answers": [
            "long-term",
            "prospective",
            "prospective studies"
        ],
        "model_ans": "cohort study",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cohort study </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the region that stretches between the black and caspian seas",
        "answers": [
            "The Caucasus Mountains",
            "Caucasus Mountains"
        ],
        "model_ans": "Caucasus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Caucasus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays red on orange is new black",
        "answers": [
            "\"Kate\" Mulgrew"
        ],
        "model_ans": "Jason Mantzoukas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jason Mantzoukas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the name of the plant on little shop of horrors",
        "answers": [
            "Audrey II"
        ],
        "model_ans": "Audrey II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Audrey II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what nba player has scored the most 3 pointers",
        "answers": [
            "Ray Allen"
        ],
        "model_ans": "Stephen Curry",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stephen Curry </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "wal-mart is a prime example of which type organization",
        "answers": [
            "multinational retail corporation"
        ],
        "model_ans": "Retail",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Retail </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won season 8 of america's next top model",
        "answers": [
            "Jaslene Gonzalez"
        ],
        "model_ans": "Danielle Evans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Danielle Evans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did macbook pro 13 inch come out",
        "answers": [
            "October 2008",
            "June 8, 2009"
        ],
        "model_ans": "2012\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2012\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the mission san antonio de valero built",
        "answers": [
            "the 18th century",
            "1718"
        ],
        "model_ans": "1718\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1718\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the current rate of interest on ppf",
        "answers": [
            "7.6% Per Annum",
            "7.6%"
        ],
        "model_ans": "7.5% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7.5% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the lion king start on broadway",
        "answers": [
            "Broadway",
            "October 15, 1997",
            "July 8, 1997",
            "November 13, 1997"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is john snow on game of thrones",
        "answers": [
            "Kit Harington"
        ],
        "model_ans": "Jon Snow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jon Snow </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "list of strict nature reserve in the philippines",
        "answers": [
            "Palawan",
            "Lake Malimanga",
            "Olango Island",
            "Calauit Safari Park",
            "Lake Buluan",
            "Calavite and FB Harrison"
        ],
        "model_ans": "There are 13 strict nature reserves in the Philippines, including the following:",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There are 13 strict nature reserves in the Philippines, including the following: </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last easter that fell on april 1st",
        "answers": [
            "2018"
        ],
        "model_ans": "2008\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2008\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the city of beijing previously known as",
        "answers": [
            "Peking"
        ],
        "model_ans": "Peking",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Peking </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the book of acts written to",
        "answers": [
            "Jewish audiences",
            "to Jewish audiences"
        ],
        "model_ans": "The early Christian churches",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The early Christian churches </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the secret of crickley hall how many episodes",
        "answers": [
            "3"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of the gorilla in the movie sing",
        "answers": [
            "Taron Egerton"
        ],
        "model_ans": "Jason Schwartzman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jason Schwartzman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did billy don't be a hero come out",
        "answers": [
            "1974"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the regular season start in mlb",
        "answers": [
            "March 29, 2018"
        ],
        "model_ans": "Late March",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Late March </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the song push it come out",
        "answers": [
            "March 8, 1987",
            "1987"
        ],
        "model_ans": "1993\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1993\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the name loyola university come from",
        "answers": [
            "St. Ignatius of Loyola"
        ],
        "model_ans": "Loyola",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Loyola </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the last name edwards come from",
        "answers": [
            "England",
            "Scotland",
            "Wales"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did the term spirits for alcohol come from",
        "answers": [
            "Middle Eastern alchemy"
        ],
        "model_ans": "Latin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Latin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does south by southwest start in austin texas",
        "answers": [
            "mid-March"
        ],
        "model_ans": "March",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> March </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the joint between a coxal bone of the pelvis and the sacrum",
        "answers": [
            "sacroiliac joint"
        ],
        "model_ans": "Sacroiliac joint",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sacroiliac joint </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the phantom of the opera music",
        "answers": [
            "Andrew Lloyd Webber"
        ],
        "model_ans": "Andrew Lloyd Webber",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Lloyd Webber </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did starbucks become a publicly traded company",
        "answers": [
            "June 1992",
            "1992"
        ],
        "model_ans": "1992\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1992\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was nepal declared a secular state in bs",
        "answers": [
            "January 15, 2007"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of novel is goodbye mr chips",
        "answers": [
            "Psychological fiction",
            "novella"
        ],
        "model_ans": "Novel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Novel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is next in line to inherit the british throne",
        "answers": [
            "Charles, Prince of Wales"
        ],
        "model_ans": "Prince William",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prince William </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has climbed mount everest the number of times",
        "answers": [
            "Phurba Tashi Sherpa",
            "Apa Sherpa",
            "Kami Rita Sherpa"
        ],
        "model_ans": "Kami Rita Sherpa",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Kami Rita Sherpa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did toyota first come to the united states",
        "answers": [
            "1957"
        ],
        "model_ans": "1957",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1957 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the main character in hacksaw ridge",
        "answers": [
            "Andrew Garfield"
        ],
        "model_ans": "Andrew Garfield",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Garfield </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did gimme gimme gimme start",
        "answers": [
            "8 January 1999",
            "1999"
        ],
        "model_ans": "1979\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1979\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did you go to drink during prohibition",
        "answers": [
            "Speakeasies"
        ],
        "model_ans": "speakeasy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> speakeasy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the actual year that the movie regarding the titans took place",
        "answers": [
            "1971"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays frankie\u2019s sister teddy on grace and frankie",
        "answers": [
            "Talia Shire"
        ],
        "model_ans": "Brooklyn Decker",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brooklyn Decker </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did dwight howard play for last year",
        "answers": [
            "Atlanta Hawks",
            "Charlotte Hornets"
        ],
        "model_ans": "Houston Rockets",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Houston Rockets </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who made the first spanish landing on the mainland of north america",
        "answers": [
            "1535",
            "Christopher Columbus"
        ],
        "model_ans": "Juan Ponce de Le\u00f3n",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Juan Ponce de Le\u00f3n </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who lives in the blue house in balamory",
        "answers": [
            "Edie McCredie"
        ],
        "model_ans": "Spencer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spencer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first season of when calls the heart",
        "answers": [
            "January 11, 2014",
            "2014"
        ],
        "model_ans": "2014\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2014\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played lead guitar on 25 or 6 to 4",
        "answers": [
            "Terry Kath"
        ],
        "model_ans": "Terry Kath",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Terry Kath </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is credited with the discovery of the neutron",
        "answers": [
            "James Chadwick"
        ],
        "model_ans": "James Chadwick",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Chadwick </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does zay come to girl meets world",
        "answers": [
            "May\u00a013,\u00a02015"
        ],
        "model_ans": "Zayn Malik appears in the episode \"Girl Meets Zay Zay\" in Season 3 of Girl Meets World",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Zayn Malik appears in the episode \"Girl Meets Zay Zay\" in Season 3 of Girl Meets World </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the original steve mcgarrett on hawaii five-o",
        "answers": [
            "John Joseph Patrick Ryan",
            "Jack Lord"
        ],
        "model_ans": "Jack Lord",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jack Lord</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what mlb teams did deion sanders play for",
        "answers": [
            "San Francisco Giants",
            "New York Yankees",
            "Atlanta Braves",
            "Cincinnati Reds"
        ],
        "model_ans": "Atlanta Braves, New York Yankees, San Francisco Giants, Cincinnati Reds",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Atlanta Braves, New York Yankees, San Francisco Giants, Cincinnati Reds </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the phantom of the opera open",
        "answers": [
            "October 1986:",
            "1986",
            "9 October 1986"
        ],
        "model_ans": "1986",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1986 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "branch of science that deals with the structure of human body parts",
        "answers": [
            "Anatomy",
            "Human anatomy",
            "human anatomy"
        ],
        "model_ans": "Anatomy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Anatomy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what's the medal count for canada in the olympics",
        "answers": [
            "501",
            "302"
        ],
        "model_ans": "227",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 227 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is cain and abel software used for",
        "answers": [
            "password recovery"
        ],
        "model_ans": "accounting",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> accounting </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has given the theory of unbalanced economic growth",
        "answers": [
            "Hirschman"
        ],
        "model_ans": "Joan Robinson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joan Robinson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when were the first general elections held in independent india",
        "answers": [
            "1951\u201352"
        ],
        "model_ans": "1952",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1952 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays steve's wife on my three sons",
        "answers": [
            "Beverly Garland"
        ],
        "model_ans": "Juanita Jennings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Juanita Jennings</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who conducted the opening concert at carnegie hall",
        "answers": [
            "Pyotr Ilyich Tchaikovsky",
            "maestro Walter Damrosch",
            "Walter Damrosch"
        ],
        "model_ans": "Vladimir Horowitz",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vladimir Horowitz </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the most played artist on spotify",
        "answers": [
            "Justin Bieber",
            "Ed Sheeran"
        ],
        "model_ans": "Drake",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Drake </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "vine with heart shaped leaves and white flowers",
        "answers": [
            "Antigonon leptopus"
        ],
        "model_ans": "Philodendron",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Philodendron </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the first phantom of the opera",
        "answers": [
            "Michael Crawford"
        ],
        "model_ans": "Herbert Lom",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Herbert Lom </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the new jurassic world game coming out",
        "answers": [
            "June 12, 2018"
        ],
        "model_ans": "There is no official release date announced yet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official release date announced yet </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what part of brain is responsible for complex thinking",
        "answers": [
            "the frontal lobe"
        ],
        "model_ans": "Prefrontal cortex",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prefrontal cortex </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the owner of the mandalay bay in vegas",
        "answers": [
            "MGM Resorts International"
        ],
        "model_ans": "MGM Resorts International",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MGM Resorts International </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who owns spirit of the suwannee music park",
        "answers": [
            "The Cornett family"
        ],
        "model_ans": "Suwannee River Jam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Suwannee River Jam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name baca come from",
        "answers": [
            "New Mexico"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who voiced simba in the lion king 2",
        "answers": [
            "Matthew Broderick"
        ],
        "model_ans": "Matthew Broderick",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matthew Broderick </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who founded amazon where is the headquarters of amazon",
        "answers": [
            "Seattle, Washington",
            "based in Seattle, Washington",
            "Jeff Bezos",
            "founded by Jeff Bezos",
            "Seattle, Washington, U.S."
        ],
        "model_ans": "Jeff Bezos",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jeff Bezos </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the population of the tri-cities washington",
        "answers": [
            "283,846",
            "over 300,000"
        ],
        "model_ans": "152,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 152,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does rick and morty play on tv",
        "answers": [
            "late-night"
        ],
        "model_ans": "Sunday nights",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sunday nights </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "i like the way you move video cast",
        "answers": [
            "Big Boi",
            "Sleepy Brown",
            "Fonzworth Bentley",
            "actress Ki Toy Johnson",
            "Ki Toy Johnson"
        ],
        "model_ans": "Jodeci",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jodeci </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many nfl teams has st louis had",
        "answers": [
            "four"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did season 4 of glee come out",
        "answers": [
            "September 13, 2012"
        ],
        "model_ans": "2011\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2011\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i want to dance with you",
        "answers": [
            "George Strait"
        ],
        "model_ans": "Rick Astley",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rick Astley </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang my bucket got a hole in it",
        "answers": [
            "Hank Williams"
        ],
        "model_ans": "Primus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Primus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the major countries involved in the cold war",
        "answers": [
            "the Soviet Union",
            "the United States"
        ],
        "model_ans": "United States and Soviet Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States and Soviet Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does star trek discovery season 1 end",
        "answers": [
            "February\u00a011,\u00a02018"
        ],
        "model_ans": "April 7, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> April 7, 2018 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote catch 22 (both names)",
        "answers": [
            "Joseph Heller.",
            "American author Joseph Heller",
            "Joseph Heller"
        ],
        "model_ans": "Joseph Heller",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joseph Heller </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why did kevin can't wait wife leave the show",
        "answers": [
            "creative reasons"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many students attend university of texas at austin",
        "answers": [
            "51,331 (Fall 2016)",
            "over 50,000",
            "51,331"
        ],
        "model_ans": "around 50,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 50,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays janie in the search for santa paws",
        "answers": [
            "G. Hannelius"
        ],
        "model_ans": "Briana Evigan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Briana Evigan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the first non native settlers in the us",
        "answers": [
            "European colonization",
            "West Norse sailors"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played the king in the ten commandments",
        "answers": [
            "Yul Brynner",
            "Woodrow Strode"
        ],
        "model_ans": "Charlton Heston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charlton Heston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who produced a change is gonna come",
        "answers": [
            "Hugo & Luigi"
        ],
        "model_ans": "Aretha Franklin",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aretha Franklin </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang theme song for license to kill",
        "answers": [
            "Gladys Knight"
        ],
        "model_ans": "Gladys Knight",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gladys Knight </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "legends of tomorrow season 3 finale air date",
        "answers": [
            "April 9, 2018",
            "April\u00a09, 2018"
        ],
        "model_ans": "May 7, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> May 7, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings my anaconda don't want none",
        "answers": [
            "Sir Mix-a-Lot"
        ],
        "model_ans": "Nicki Minaj",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nicki Minaj </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the result of the revolt of 1857",
        "answers": [
            "British victory",
            "Suppression of the revolt"
        ],
        "model_ans": "The British East India Company regained control",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The British East India Company regained control </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name three large lakes other than the great lakes in the united states",
        "answers": [
            "Iliamna Lake",
            "Great Salt Lake",
            "Lake of the Woods"
        ],
        "model_ans": "Lake Superior, Lake Michigan, Lake Huron",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lake Superior, Lake Michigan, Lake Huron </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote i can feel at home in this world anymore",
        "answers": [
            "Macon Blair"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of the word autumn",
        "answers": [
            "fall"
        ],
        "model_ans": "autumn",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> autumn </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the speaker in shooting an elephant",
        "answers": [
            "Orwell"
        ],
        "model_ans": "George Orwell",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Orwell </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the part of the cytoskeleton made from the protein actin is called",
        "answers": [
            "Microfilaments",
            "microfilament"
        ],
        "model_ans": "microfilaments",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> microfilaments </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is dancing on ice on the tv",
        "answers": [
            "2019"
        ],
        "model_ans": "Sunday",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sunday </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first executive president of guyana",
        "answers": [
            "Arthur Chung",
            "Forbes Burnham"
        ],
        "model_ans": "Cheddi Jagan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cheddi Jagan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the us take over wake island",
        "answers": [
            "July 4, 1898",
            "January 17, 1899"
        ],
        "model_ans": "1899",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1899 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the term the west come from",
        "answers": [
            "the Roman Empire"
        ],
        "model_ans": "The term \"the West\" is believed to have originated from the ancient Greeks, who referred to the region west of Greece as \"the Occident\".",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The term \"the West\" is believed to have originated from the ancient Greeks, who referred to the region west of Greece as \"the Occident\". </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played john coffey in the movie the green mile",
        "answers": [
            "Michael Clarke Duncan"
        ],
        "model_ans": "Michael Clarke Duncan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Clarke Duncan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "two main types of research methods used in psychology",
        "answers": [
            "quantitative data",
            "quantitative",
            "Quantitative psychological research",
            "qualitative",
            "Experimental research",
            "Qualitative psychological research",
            "qualitative data",
            "Correlational research",
            "Descriptive research"
        ],
        "model_ans": "Experimental and Correlational",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Experimental and Correlational </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do dwight and angela start dating again",
        "answers": [
            "In \"A.A.R.M.\"",
            "Goodbye Toby",
            "\"Goodbye Toby\""
        ],
        "model_ans": "Season 7",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 7 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where's the tv show the crossing filmed",
        "answers": [
            "British Columbia, Canada"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does god of war ghost of sparta take place",
        "answers": [
            "ancient Greece"
        ],
        "model_ans": "Ancient Greece",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ancient Greece </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings the song i want to go outside in the rain",
        "answers": [
            "Milira"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang one bad apple spoils the bunch",
        "answers": [
            "The Osmonds"
        ],
        "model_ans": "Jay and the Americans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jay and the Americans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the new season on the 100 come out",
        "answers": [
            "April 24, 2018"
        ],
        "model_ans": "August 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the woodsman in over the garden wall",
        "answers": [
            "Christopher Lloyd"
        ],
        "model_ans": "Elijah Wood",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elijah Wood </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the job of justice of the peace",
        "answers": [
            "dispense summary justice"
        ],
        "model_ans": "Judge",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Judge </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did hollywood video go out of business",
        "answers": [
            "2005.",
            "May 2010"
        ],
        "model_ans": "2010\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2010\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the largest magnitude earthquake that has occurred in the pacific northwest",
        "answers": [
            "The 1700 Cascadia earthquake"
        ],
        "model_ans": "9.0\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "9.0\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did michigan state play in the rose bowl",
        "answers": [
            "Stanford Cardinal"
        ],
        "model_ans": "USC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> USC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the ncaa tournament became more important than the nit",
        "answers": [
            "By the mid-1980s"
        ],
        "model_ans": "1985",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1985 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does junior want to go to find hope",
        "answers": [
            "off the rez"
        ],
        "model_ans": "nowhere",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> nowhere </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time mount ruapehu erupted",
        "answers": [
            "25 September 2007"
        ],
        "model_ans": "1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "character in macbeth who is murdered and appears as a ghost",
        "answers": [
            "Lord Banquo",
            "Banquo"
        ],
        "model_ans": "Banquo",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Banquo</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does season 8 of vampire diaries come out",
        "answers": [
            "October 21, 2016",
            "on October 21, 2016"
        ],
        "model_ans": "October 3, 2013",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 3, 2013 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "whose new political ideas of natural rights influenced the declaration of independence",
        "answers": [
            "Francis Hutcheson",
            "John Locke"
        ],
        "model_ans": "John Locke",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Locke </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who built the first temple for god in jerusalem",
        "answers": [
            "Solomon"
        ],
        "model_ans": "Jews",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jews</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who negotiated an agreement with japan concerning the future of korea",
        "answers": [
            "the Korean Empire",
            "Empire of Japan",
            "Taft",
            "Korean Empire"
        ],
        "model_ans": "The United States",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The United States </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the voice of salem the cat",
        "answers": [
            "Nicholas \"Nick\" Bakay"
        ],
        "model_ans": "Unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the central powers defeat on the eastern front before concentrating back on france",
        "answers": [
            "the Russian army"
        ],
        "model_ans": "Russia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Russia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes are there in ordeal by innocence",
        "answers": [
            "three part",
            "three"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the enrollment at university of miami",
        "answers": [
            "16,801",
            "16,801 students"
        ],
        "model_ans": "17,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 17,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the lupus foundation of america founded",
        "answers": [
            "1977"
        ],
        "model_ans": "1949",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1949 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the legend of the easter bunny come from",
        "answers": [
            "German Lutherans"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the tv show the waltons first air",
        "answers": [
            "September 1972"
        ],
        "model_ans": "1972\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1972\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the boy in the striped pajamas take place",
        "answers": [
            "World War II",
            "during World War II"
        ],
        "model_ans": "during World War II",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> during World War II </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings gimme some lovin in days of thunder",
        "answers": [
            "The Spencer Davis Group",
            "Spencer Davis Group"
        ],
        "model_ans": "The Spencer Davis Group",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Spencer Davis Group </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the statue of liberty in france built",
        "answers": [
            "Paris"
        ],
        "model_ans": "1886",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1886 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the largest man made lake in the us",
        "answers": [
            "Lake Oahe"
        ],
        "model_ans": "Lake Mead",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lake Mead </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many points are scored for a touchdown in american football",
        "answers": [
            "six",
            "six points"
        ],
        "model_ans": "6\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "6\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the jurassic park movies come out",
        "answers": [
            "Jurassic Park (1993)",
            "2001",
            "2015",
            "2018",
            "1993",
            "Jurassic World (2015)",
            "1997"
        ],
        "model_ans": "1993, 1997, 2001, 2015\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1993, 1997, 2001, 2015\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was child benefit paid for the first child",
        "answers": [
            "1975"
        ],
        "model_ans": "1946",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1946 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what class of ship is the carnival glory",
        "answers": [
            "Conquest",
            "Conquest-class cruise ship"
        ],
        "model_ans": "cruise ship",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cruise ship </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did scotland beat england in six nations",
        "answers": [
            "2 April 2000",
            "25 February 2006",
            "24 February 2018",
            "8 March 2008"
        ],
        "model_ans": "1999",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1999 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the theme song to that 70s show",
        "answers": [
            "Big Star",
            "Todd Griffin",
            "Cheap Trick"
        ],
        "model_ans": "My Morning Jacket",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> My Morning Jacket </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "season 2 this is us number of episodes",
        "answers": [
            "15",
            "18",
            "13"
        ],
        "model_ans": "16\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "16\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who led an attack that allowed for american victory at yorktown",
        "answers": [
            "George Washington",
            "Comte de Rochambeau"
        ],
        "model_ans": "George Washington",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Washington </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the oldest wrestler that is still wrestling",
        "answers": [
            "Dory Funk Jr."
        ],
        "model_ans": "Ric Flair",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ric Flair </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who developed a set of postulates to prove that specific microorganisms cause disease",
        "answers": [
            "Robert Koch",
            "Friedrich Loeffler"
        ],
        "model_ans": "Louis Pasteur",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis Pasteur </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what's the name of the last mission impossible movie",
        "answers": [
            "Mission: Impossible \u2013 Fallout"
        ],
        "model_ans": "Mission: Impossible - Fallout",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mission: Impossible - Fallout </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "gabbar is back is a remake of which telugu movie",
        "answers": [
            "Tagore"
        ],
        "model_ans": "Simhasanam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Simhasanam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang it going to take a miracle",
        "answers": [
            "The Royalettes"
        ],
        "model_ans": "Take That",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Take That </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "winner of the women's royal rumble match",
        "answers": [
            "Asuka"
        ],
        "model_ans": "Charlotte Flair",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charlotte Flair </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played in the first fifty shades of grey",
        "answers": [
            "Marcia Gay Harden",
            "Jamie Dornan",
            "Dakota Johnson",
            "Jennifer Ehle"
        ],
        "model_ans": "Dakota Johnson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dakota Johnson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the most popular religion in sweden",
        "answers": [
            "Lutheran",
            "Lutheran Church of Sweden",
            "Christianity"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the last scene of the danish girl filmed",
        "answers": [
            "the Mount Mannen in Norway"
        ],
        "model_ans": "Berlin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Berlin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the movie 500 days of summer filmed",
        "answers": [
            "Los Angeles"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "i want to be with you everywhere song",
        "answers": [
            "Everywhere"
        ],
        "model_ans": "I Want to Be with You Everywhere",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> I Want to Be with You Everywhere </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang the songs on walk the line",
        "answers": [
            "Reese Witherspoon",
            "Tyler Hilton",
            "Waylon Payne",
            "Johnathan Rice",
            "Shooter Jennings",
            "Joaquin Phoenix"
        ],
        "model_ans": "Johnny Cash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Cash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is playing the halftime show for the superbowl",
        "answers": [
            "Justin Timberlake"
        ],
        "model_ans": "Dr. Dre",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dr. Dre </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "german word for pleasure from someone else's pain",
        "answers": [
            "Schadenfreude"
        ],
        "model_ans": "Schadenfreude",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Schadenfreude </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "actress who plays penelope garcia on criminal minds",
        "answers": [
            "Kirsten Simone Vangsness"
        ],
        "model_ans": "Kirsten Vangsness",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kirsten Vangsness </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did cricket go to 6 ball overs",
        "answers": [
            "1979/80",
            "Since 1979/80"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the soviet union start and end",
        "answers": [
            "in Eurasia"
        ],
        "model_ans": "1922-1991",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1922-1991 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the bridge over the hoover dam built",
        "answers": [
            "2010"
        ],
        "model_ans": "1936",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1936 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the theme song for the proud family",
        "answers": [
            "Destiny's Child",
            "Solange Knowles"
        ],
        "model_ans": "The Proud Family Theme Song",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Proud Family Theme Song </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most votes for the all star game",
        "answers": [
            "fan voting"
        ],
        "model_ans": "Mike Trout",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mike Trout </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did john hart play the lone ranger",
        "answers": [
            "from 1952 until 1953"
        ],
        "model_ans": "1949",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1949 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was assassinated during a visit to sarajevo in bosnia",
        "answers": [
            "Archduke Franz Ferdinand of Austria"
        ],
        "model_ans": "Archduke Franz Ferdinand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Archduke Franz Ferdinand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won big brother head of household canada",
        "answers": [
            "Kaela"
        ],
        "model_ans": "Arisa Cox",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arisa Cox </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the theme song for degrassi the next generation",
        "answers": [
            "Jakalope",
            "The Degrassi Junior Strings"
        ],
        "model_ans": "Drake",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Drake </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the authority or governing body of mca",
        "answers": [
            "Indian government"
        ],
        "model_ans": "MCA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MCA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played junior on in the heat of the night",
        "answers": [
            "Christian LeBlanc"
        ],
        "model_ans": "Sidney Poitier",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sidney Poitier </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the tenure of the office of the lokayukt of up",
        "answers": [
            "eight years",
            "8 years"
        ],
        "model_ans": "5 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "all the gases in the earth's atmosphere",
        "answers": [
            "Water vapor",
            "small amounts of other gases",
            "nitrogen",
            "oxygen",
            "Methane",
            "Helium",
            "Oxygen",
            "Carbon\u00a0dioxide",
            "Nitrogen",
            "Neon",
            "Argon",
            "argon",
            "carbon dioxide"
        ],
        "model_ans": "nitrogen, oxygen, argon, carbon dioxide, neon, helium, methane, krypton, hydrogen",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> nitrogen, oxygen, argon, carbon dioxide, neon, helium, methane, krypton, hydrogen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who's playing in the world series and when is it",
        "answers": [
            "Houston Astros",
            "Los Angeles Dodgers",
            "October 24 \u2013 November 1"
        ],
        "model_ans": "The World Series is played between the American League (AL) champion team and the National League (NL) champion team. The exact teams and dates vary from year to year.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The World Series is played between the American League (AL) champion team and the National League (NL) champion team. The exact teams and dates vary from year to year. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which domain of life are humans members of",
        "answers": [
            "Eukarya"
        ],
        "model_ans": "Eukarya",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eukarya </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does the voice of the elephant in sing",
        "answers": [
            "Tori Kelly"
        ],
        "model_ans": "Jason Bateman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jason Bateman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who propounded the idea of basic education in india",
        "answers": [
            "Mahatma Gandhi"
        ],
        "model_ans": "Mahatma Gandhi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mahatma Gandhi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the most followed user on instagram 2017",
        "answers": [
            "Instagram's own account"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many champions league trophies does arsenal have",
        "answers": [
            "13"
        ],
        "model_ans": "0\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "0\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the next deadpool movie being released",
        "answers": [
            "May 18, 2018"
        ],
        "model_ans": "June 3, 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 3, 2023 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the academy award for the deer hunter",
        "answers": [
            "John Peverall",
            "Michael Deeley",
            "Peter Zinner",
            "William L. McCaughey",
            "Michael Cimino",
            "Barry Spikings",
            "Richard Portman",
            "Aaron Rochin",
            "C. Darin Knight",
            "Christopher Walken"
        ],
        "model_ans": "Robert De Niro",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robert De Niro </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was part of the classic surfing movie endless summer filmed",
        "answers": [
            "Ghana",
            "Hawaii",
            "Nigeria",
            "Tahiti",
            "Australia",
            "New Zealand",
            "Senegal",
            "South Africa"
        ],
        "model_ans": "Hawaii",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hawaii </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what percentage of the earth's surface is water",
        "answers": [
            "78%",
            "roughly 78%"
        ],
        "model_ans": "71%\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "71%\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who killed missy in a bend in the road",
        "answers": [
            "Brian",
            "Sarah's brother, Brian"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who became king of erebor after thorin dies",
        "answers": [
            "D\u00e1in",
            "his cousin D\u00e1in"
        ],
        "model_ans": "Baldor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Baldor</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the ghost of christmas present sprinkle from his torch",
        "answers": [
            "warmth",
            "a little warmth"
        ],
        "model_ans": "Gold",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gold </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song fly me to the moon",
        "answers": [
            "Bart Howard"
        ],
        "model_ans": "Bart Howard",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Bart Howard</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote song what a friend we have in jesus",
        "answers": [
            "Charles Crozat Converse",
            "Joseph M. Scriven",
            "William Bolcom"
        ],
        "model_ans": "Charles Crozat Converse",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Charles Crozat Converse </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang never gonna let you go",
        "answers": [
            "Joe Pizzulo and Leeza Miller",
            "Joe Pizzulo",
            "Leeza Miller"
        ],
        "model_ans": "Sergio Mendes & Brasil '66",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sergio Mendes & Brasil '66 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when will miraculous season 2 episode 11 be released",
        "answers": [
            "30\u00a0March\u00a02018",
            "27\u00a0October\u00a02017"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who destroyed the first temple and exiled the two tribes of judah to babylon",
        "answers": [
            "Nebuchadnezzar"
        ],
        "model_ans": "Babylon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Babylon</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played forrest gumps mother in the 1994 film",
        "answers": [
            "Sally Field"
        ],
        "model_ans": "Sally Field",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sally Field </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is iodine found in the periodic table",
        "answers": [
            "heaviest of the stable halogens"
        ],
        "model_ans": "Group 17",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Group 17 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of india pakistan border",
        "answers": [
            "International Border",
            "IB",
            "International Border (IB)",
            "India and Pakistan Border",
            "The India and Pakistan Border"
        ],
        "model_ans": "Wagah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wagah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who made the song we are the world",
        "answers": [
            "produced by Quincy Jones"
        ],
        "model_ans": "USA for Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> USA for Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "whats the difference between tomato paste and tomato puree",
        "answers": [
            "consistency"
        ],
        "model_ans": "Tomato paste is a concentrated form of tomatoes that has been cooked down to remove excess water and has a thicker consistency, whereas tomato puree is a smooth, blended form of tomatoes that has not been cooked down as much.",
        "model_confidence": "",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tomato paste is a concentrated form of tomatoes that has been cooked down to remove excess water and has a thicker consistency, whereas tomato puree is a smooth, blended form of tomatoes that has not been cooked down as much.</answer>\n<</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did chicano studies become major studies programs on college campuses",
        "answers": [
            "By 1975",
            "1972"
        ],
        "model_ans": "1960s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1960s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the actress who plays baker on blue bloods",
        "answers": [
            "Abigail Hawk"
        ],
        "model_ans": "Marisa Ramirez",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Marisa Ramirez </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the killer in the movie i know what you did last summer",
        "answers": [
            "Ben Willis"
        ],
        "model_ans": "Ben Willis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ben Willis </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many countries touches the land boundary of india",
        "answers": [
            "seven"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the wicked witch in wicked on broadway",
        "answers": [
            "Rachel Kelly Tucker"
        ],
        "model_ans": "Idina Menzel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Idina Menzel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last easter fell on april 1",
        "answers": [
            "2018"
        ],
        "model_ans": "2008  April 20",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2008 <answer> April 20 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many world series wins does the dodgers have",
        "answers": [
            "6",
            "six"
        ],
        "model_ans": "6\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "6\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the second it movie come out",
        "answers": [
            "September 6, 2019",
            "September\u00a08,\u00a02017"
        ],
        "model_ans": "2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the guitar solo in beat it",
        "answers": [
            "Eddie Van Halen"
        ],
        "model_ans": "Eddie Van Halen",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Eddie Van Halen </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the anti smacking law come in nz",
        "answers": [
            "anti-smacking bill",
            "21 June 2007"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first sonic drive in located",
        "answers": [
            "Woodward, Oklahoma"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what episode does caroline come into the originals",
        "answers": [
            "Brave New World"
        ],
        "model_ans": "Episode 1",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Episode 1 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of amy on futurama",
        "answers": [
            "Lauren Tom"
        ],
        "model_ans": "Lauren Tom",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lauren Tom </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the original singer of just when i needed you most",
        "answers": [
            "Randy VanWarmer"
        ],
        "model_ans": "Boyz II Men",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Boyz II Men </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the names of the beaches on d day",
        "answers": [
            "Juno Beach",
            "Omaha Beach",
            "Utah Beach",
            "Gold Beach",
            "Sword Beach"
        ],
        "model_ans": "Omaha Beach, Utah Beach, Gold Beach, Juno Beach, Sword Beach",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Omaha Beach, Utah Beach, Gold Beach, Juno Beach, Sword Beach </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was a hologram for the king filmed",
        "answers": [
            "Morocco",
            "Berlin and D\u00fcsseldorf in Germany",
            "Berlin",
            "Hurghada in Egypt",
            "D\u00fcsseldorf in Germany",
            "Egypt",
            "Germany"
        ],
        "model_ans": "Morocco",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Morocco </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the guy who died in glee",
        "answers": [
            "Cory Allan Michael Monteith"
        ],
        "model_ans": "Cory Monteith",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cory Monteith </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the first epistle of john written",
        "answers": [
            "AD 95\u2013110",
            "probably written in Ephesus"
        ],
        "model_ans": "90-110 AD",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 90-110 AD </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made the movie fifty shades of grey",
        "answers": [
            "Universal Pictures and Focus Features",
            "Sam Taylor-Johnson"
        ],
        "model_ans": "Universal Pictures",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Universal Pictures </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which is the tallest building in the world 2018",
        "answers": [
            "Burj Khalifa in Dubai",
            "Burj Khalifa"
        ],
        "model_ans": "Burj Khalifa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Burj Khalifa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has won the most superbowls as a player",
        "answers": [
            "Charles Haley",
            "Neal Dahlen",
            "Bill Belichick",
            "Tom Brady"
        ],
        "model_ans": "Tom Brady",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Brady </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "time of the state of the nation address",
        "answers": [
            "after 9pm\u00a0ET"
        ],
        "model_ans": "2:30 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2:30 PM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the rap in baby by justin bieber",
        "answers": [
            "Ludacris"
        ],
        "model_ans": "Ludacris",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ludacris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is season 4 of flash coming out",
        "answers": [
            "October 10, 2017",
            "on October 10, 2017"
        ],
        "model_ans": "October 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays christian in 50 shades of grey",
        "answers": [
            "James \"Jamie\" Dornan"
        ],
        "model_ans": "Jamie Dornan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jamie Dornan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did stephen curry won the mvp award",
        "answers": [
            "2015,",
            "2015",
            "2014\u201315",
            "2016"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the cosbys live in new york",
        "answers": [
            "in Brooklyn",
            "Brooklyn, New York"
        ],
        "model_ans": "Brooklyn",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brooklyn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the world cup in cricket 2017",
        "answers": [
            "Pakistan"
        ],
        "model_ans": "Pakistan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Pakistan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the cornell method of note taking",
        "answers": [
            "Walter Pauk"
        ],
        "model_ans": "Walter Pauk",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Walter Pauk </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the water from the california aqueduct come from",
        "answers": [
            "Sierra Nevada Mountains",
            "the Sierra Nevada Mountains"
        ],
        "model_ans": "Sierra Nevada mountains",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sierra Nevada mountains </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the name of the first continent",
        "answers": [
            "Pangaea"
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "phase change from gas to solid is called",
        "answers": [
            "Deposition",
            "desublimation"
        ],
        "model_ans": "Deposition",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Deposition </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song should have been a cowboy",
        "answers": [
            "Toby Keith"
        ],
        "model_ans": "Toby Keith",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Toby Keith </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first mad max movie release",
        "answers": [
            "12\u00a0April\u00a01979",
            "April 1979",
            "1979"
        ],
        "model_ans": "1979\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1979\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a political leader during the roman empire was called",
        "answers": [
            "emperors"
        ],
        "model_ans": "Emperor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Emperor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was uncle tom's cabin first published",
        "answers": [
            "The National Era"
        ],
        "model_ans": "Harper's Weekly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Harper's Weekly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name roberts come from",
        "answers": [
            "Norman",
            "Norman origin"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the world consumer right day celebrated",
        "answers": [
            "15 March every year",
            "15 March"
        ],
        "model_ans": "March 15",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 15 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "royal society for the protection of birds number of members",
        "answers": [
            "more than a million"
        ],
        "model_ans": "100,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many wing stops are there in the united states",
        "answers": [
            "1,000",
            "more than 1,000"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do pineapples come from in the world",
        "answers": [
            "Costa Rica",
            "Philippines",
            "Brazil",
            "the Philippines",
            "Thailand",
            "Indonesia",
            "India"
        ],
        "model_ans": "Hawaii",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hawaii </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does blonde hair green eyes come from",
        "answers": [
            "a low concentration in pigmentation"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the second book in the alchemyst series",
        "answers": [
            "The Magician"
        ],
        "model_ans": "The sorceress",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The sorceress </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "skin that covers the palms fingertips and soles of the feet",
        "answers": [
            "stratum lucidum"
        ],
        "model_ans": "epidermis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> epidermis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the latest version of chrome for linux",
        "answers": [
            "67.0.3396",
            "67.0"
        ],
        "model_ans": "Chrome 89",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chrome 89 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the largest bill in american money",
        "answers": [
            "$100"
        ],
        "model_ans": "$100",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> $100 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how long is the bridge between new brunswick and prince edward island",
        "answers": [
            "12.9-kilometre"
        ],
        "model_ans": "13 km",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13 km </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many nfl games were played in london",
        "answers": [
            "21"
        ],
        "model_ans": "28",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 28 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many characters are present in icd-10 codes",
        "answers": [
            "7"
        ],
        "model_ans": "12",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many seasons of ray donovan has there been",
        "answers": [
            "5"
        ],
        "model_ans": "7\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "7\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do peaches come from in the us",
        "answers": [
            "other states",
            "South Carolina",
            "California",
            "Georgia"
        ],
        "model_ans": "Georgia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Georgia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the name of atom bomb dropped by usa on hiroshima",
        "answers": [
            "Little Boy"
        ],
        "model_ans": "Little Boy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Little Boy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "songs on 4 your eyez only j cole",
        "answers": [
            "Immortal",
            "4 Your Eyez Only",
            "Ville Mentality",
            "Deja Vu",
            "She's Mine Pt. 2",
            "She's Mine Pt. 1",
            "Change",
            "For Whom the Bell Tolls",
            "Neighbors",
            "Foldin Clothes"
        ],
        "model_ans": "J. Cole",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>J. Cole</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what happened to western rome after it fell",
        "answers": [
            "divided into several successor polities"
        ],
        "model_ans": "The Western Roman Empire was eventually absorbed into the barbarian kingdoms, and the Eastern Roman Empire, also known as the Byzantine Empire, continued to exist until its capital, Constantinople, was conquered by the Ottoman Empire in 1453</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Western Roman Empire was eventually absorbed into the barbarian kingdoms, and the Eastern Roman Empire, also known as the Byzantine Empire, continued to exist until its capital, Constantinople, was conquered by the Ottoman Empire in 1453</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who helped them recapture mycenae once they were old enough to fight",
        "answers": [
            "Aegisthus"
        ],
        "model_ans": "Spartans",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spartans </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the cast of the new tomb raider movie",
        "answers": [
            "Alicia Vikander as Lara Croft"
        ],
        "model_ans": "Alicia Vikander",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alicia Vikander </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who came up with the term baby boomer",
        "answers": [
            "The Washington Post"
        ],
        "model_ans": "Gerontologist",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gerontologist </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the cardiac and vasomotor centers found",
        "answers": [
            "medulla oblongata",
            "the medulla oblongata"
        ],
        "model_ans": "Medulla oblongata",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medulla oblongata </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played anne in anne with an e",
        "answers": [
            "Amybeth McNulty"
        ],
        "model_ans": "Amybeth McNulty",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amybeth McNulty </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "number of employees in the department of health and human services",
        "answers": [
            "79,540 (2015)",
            "79,540"
        ],
        "model_ans": "80,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 80,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played big enos in smokey and the bandit",
        "answers": [
            "Pat McCormick"
        ],
        "model_ans": "Paul Newman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Newman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays chris grandy in 13 going on 30",
        "answers": [
            "Jim Gaffigan",
            "Alex Black"
        ],
        "model_ans": "Jennifer Garner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jennifer Garner</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has hit a double century in the ranji trophy for jharkhand in 2016",
        "answers": [
            "Jaydev Shah"
        ],
        "model_ans": "Saurabh Tiwary",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Saurabh Tiwary </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the hero golf challenge being played",
        "answers": [
            "The Bahamas",
            "Albany development in the Bahamas"
        ],
        "model_ans": "Dubai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dubai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the wave length of x rays",
        "answers": [
            "from 0.01 to 10 nanometers"
        ],
        "model_ans": "0.01-10 nanometers\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "0.01-10 nanometers\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the oscar for best picture in 1976",
        "answers": [
            "Rocky"
        ],
        "model_ans": "Rocky",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rocky </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who were the two mathematicians that invented calculus",
        "answers": [
            "Gottfried Leibniz",
            "Isaac Newton"
        ],
        "model_ans": "Isaac Newton and Gottfried Wilhelm Leibniz",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isaac Newton and Gottfried Wilhelm Leibniz </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does porter fly out of in toronto",
        "answers": [
            "Billy Bishop Toronto City Airport"
        ],
        "model_ans": "Toronto Pearson International Airport",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Toronto Pearson International Airport </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the end of the world as we know it",
        "answers": [
            "R.E.M."
        ],
        "model_ans": "R.E.M.",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> R.E.M. </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who challenged the aristotelian model of a geocentric universe",
        "answers": [
            "Copernicus"
        ],
        "model_ans": "Copernicus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Copernicus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "delhi is on the banks of which river",
        "answers": [
            "Yamuna"
        ],
        "model_ans": "Yamuna",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yamuna </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what happened at the 1939 worlds fair in regards to television",
        "answers": [
            "Television demonstrations are held"
        ],
        "model_ans": "The first public demonstration of television was held at the 1939 World's Fair in New York City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The first public demonstration of television was held at the 1939 World's Fair in New York City </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "krypton-85 decays by emission of a beta particle. the product of this decay is",
        "answers": [
            "rubidium-85"
        ],
        "model_ans": "85Rb",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 85Rb </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who starred in the tv show even stevens",
        "answers": [
            "Nick Spano",
            "Donna Pescow",
            "Christy Carlson Romano",
            "Shia LaBeouf",
            "Tom Virtue"
        ],
        "model_ans": "Shia LaBeouf",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shia LaBeouf </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what percent of the us population controls the wealth",
        "answers": [
            "1%"
        ],
        "model_ans": "10% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "10% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the oasis in ready player one",
        "answers": [
            "a virtual reality simulator"
        ],
        "model_ans": "The Oasis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Oasis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the song one of these nights",
        "answers": [
            "American rock band Eagles",
            "the American rock band Eagles",
            "Eagles"
        ],
        "model_ans": "Elton John",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elton John </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of energy do satellites generally use to communicate with earth",
        "answers": [
            "radio and microwave frequencies",
            "electromagnetic waves"
        ],
        "model_ans": "Radio Frequency",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Radio Frequency </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has most followers on instagram in world",
        "answers": [
            "Instagram's own account",
            "Instagram",
            "Selena Gomez"
        ],
        "model_ans": "Cristiano Ronaldo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cristiano Ronaldo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the international space station go into space",
        "answers": [
            "1998"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the first capital city of australia",
        "answers": [
            "New South Wales",
            "Melbourne",
            "Sydney"
        ],
        "model_ans": "Sydney",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sydney </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are the toll roads called in mexico",
        "answers": [
            "autopistas"
        ],
        "model_ans": "Pemex",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pemex </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the good doctor episode 8 air",
        "answers": [
            "November\u00a020,\u00a02017"
        ],
        "model_ans": "2019-02-25",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019-02-25 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the name of the horse in steptoe and son",
        "answers": [
            "Hercules"
        ],
        "model_ans": "Maggie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Maggie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what state does rick and morty take place in",
        "answers": [
            "Washington",
            "the U.S. state of Washington"
        ],
        "model_ans": "Colorado",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Colorado </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is an open university grade 3 pass",
        "answers": [
            "55\u201369%"
        ],
        "model_ans": "40-49%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40-49% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who dies in season 2 of the originals",
        "answers": [
            "Kol"
        ],
        "model_ans": "Davina",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Davina </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the approximate volume of blood in your body",
        "answers": [
            "approximately 5 liters"
        ],
        "model_ans": "5 liters\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5 liters\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who's winning the election in virginia for governor",
        "answers": [
            "Ralph Northam",
            "Democratic nominee Ralph Northam"
        ],
        "model_ans": "Glenn Youngkin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Glenn Youngkin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are three different types of hotel properties",
        "answers": [
            "Bed and breakfast",
            "Hotel barge",
            "Botel"
        ],
        "model_ans": "Hotel, Resort, and Inn",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hotel, Resort, and Inn </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the phrase dressed to the nines",
        "answers": [
            "Scots in origin"
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did harvard become an ivy league school",
        "answers": [
            "1945"
        ],
        "model_ans": "1650",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1650 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who claimed land in south america for portugal",
        "answers": [
            "John II of Portugal"
        ],
        "model_ans": "Pedro \u00c1lvares Cabral",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pedro \u00c1lvares Cabral </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who proposed that electrons behave like waves and particles",
        "answers": [
            "Einstein"
        ],
        "model_ans": "Louis de Broglie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis de Broglie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the celebrities enter the big brother house",
        "answers": [
            "February\u00a07,\u00a02018",
            "2017"
        ],
        "model_ans": "2000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what state courts can order a new trial",
        "answers": [
            "appellate court"
        ],
        "model_ans": "all state courts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> all state courts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the peak to peak gondola built",
        "answers": [
            "in 2007 and 2008"
        ],
        "model_ans": "1986",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1986 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what allows chyme to enter the small intestine",
        "answers": [
            "pyloric valve",
            "the pyloric valve"
        ],
        "model_ans": "pyloric sphincter",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pyloric sphincter </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did they film the royal tv series",
        "answers": [
            "City of Bradford",
            "the North Riding of Yorkshire",
            "Scarborough",
            "Whitby"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do they get the hair for a hair transplant",
        "answers": [
            "chest",
            "legs",
            "shoulders",
            "back of the head",
            "torso",
            "back"
        ],
        "model_ans": "Donor hair",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Donor hair </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many co2 molecules are produced in aerobic respiration",
        "answers": [
            "6"
        ],
        "model_ans": "36\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "36\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the red guards start and end",
        "answers": [
            "1966 and 1967",
            "in 1966 and 1967"
        ],
        "model_ans": "1966-1976",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1966-1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the father of genetics and what did he study",
        "answers": [
            "the common edible pea",
            "Mendel",
            "pea plants",
            "variation in plants",
            "Gregor Mendel"
        ],
        "model_ans": "Gregor Mendel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gregor Mendel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the meaning of the name mandy",
        "answers": [
            "Lovable"
        ],
        "model_ans": "Mandy is a diminutive form of Amanda, which means \"worthy of love\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mandy is a diminutive form of Amanda, which means \"worthy of love\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do new episodes of mindy project air",
        "answers": [
            "November\u00a07,\u00a02017",
            "September\u00a012,\u00a02017",
            "December\u00a012,\u00a02017",
            "November\u00a028,\u00a02017",
            "December\u00a019,\u00a02017",
            "November\u00a014,\u00a02017",
            "November\u00a021,\u00a02017",
            "December\u00a05,\u00a02017"
        ],
        "model_ans": "Tuesday nights",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tuesday nights </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what material was used to build the roofs of houses in burzahom",
        "answers": [
            "birch"
        ],
        "model_ans": "wood",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wood </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the inner sanctuary of the parthenon where the statue of athena is located in known as the",
        "answers": [
            "cella",
            "naos"
        ],
        "model_ans": "naos",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> naos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "one piece episode 534 english dubbed release date",
        "answers": [
            "February 5, 2012"
        ],
        "model_ans": "2022-07-24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022-07-24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the original singer of i write sins not tragedies",
        "answers": [
            "Panic! at the Disco"
        ],
        "model_ans": "Panic! At The Disco",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Panic! At The Disco </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why did jean valjean take care of cosette",
        "answers": [
            "he had promised"
        ],
        "model_ans": "Jean Valjean took care of Cosette because he had a deep sense of responsibility and compassion for the young girl, who was the daughter of his former love, Fantine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jean Valjean took care of Cosette because he had a deep sense of responsibility and compassion for the young girl, who was the daughter of his former love, Fantine </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the lincoln highway begin and end",
        "answers": [
            "Lincoln Park in San Francisco"
        ],
        "model_ans": "Lincoln Highway begins in Times Square, New York City, and ends in Lincoln Park, San Francisco",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lincoln Highway begins in Times Square, New York City, and ends in Lincoln Park, San Francisco </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the ultimate objective of financial management",
        "answers": [
            "Profit maximization"
        ],
        "model_ans": "Maximizing Shareholder Value",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maximizing Shareholder Value </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what year did the price is right first air",
        "answers": [
            "November 26, 1956",
            "1956"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did under the cork tree come out",
        "answers": [
            "May 3, 2005"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did colour tv come out in uk",
        "answers": [
            "July 1, 1967",
            "1967/1969/1976",
            "1967"
        ],
        "model_ans": "1967\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1967\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are the characters in yo gabba gabba",
        "answers": [
            "DJ Lance Rock",
            "Gooble",
            "Brobee",
            "Foofa",
            "Muno",
            "Plex",
            "Toodee"
        ],
        "model_ans": "DJ Lance Rock, Muno, Brobee, Toodee, Foofa, and Plex",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> DJ Lance Rock, Muno, Brobee, Toodee, Foofa, and Plex </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "list of local government area in benue state",
        "answers": [
            "Guma",
            "Ogbadibo",
            "Gwer East",
            "Gboko",
            "Gwer West",
            "Apa",
            "Ukum",
            "Okpokwu",
            "Ohimini",
            "Agatu",
            "Kwande",
            "Makurdi",
            "Vandeikya",
            "Otukpo",
            "Obi",
            "Oju",
            "Ado",
            "Konshisha",
            "Logo",
            "Tarka",
            "Ushongo",
            "Katsina-Ala",
            "Buruku"
        ],
        "model_ans": "23",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 23 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "panic at the disco la devotee video cast",
        "answers": [
            "Noah Schnapp"
        ],
        "model_ans": "Brendon Urie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brendon Urie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played the villain in tiger zinda hai",
        "answers": [
            "Sajjad Delafrooz"
        ],
        "model_ans": "Sajjad Delafrooz",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sajjad Delafrooz </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what types of cells go through binary fission",
        "answers": [
            "domains of Archaea and Bacteria",
            "prokaryotic"
        ],
        "model_ans": "Bacteria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bacteria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote it's gonna take a lot of love",
        "answers": [
            "Neil Young"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who become ceo of wipro company in 2016",
        "answers": [
            "Abid Ali Neemuchwala"
        ],
        "model_ans": "Abidali Neemuchwala",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abidali Neemuchwala </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the 2018 women's royal rumble match",
        "answers": [
            "Asuka"
        ],
        "model_ans": "Asuka",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Asuka </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what channel is big 10 network on fios",
        "answers": [
            "585 (HD)",
            "85 (SD)"
        ],
        "model_ans": "670",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 670 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played hyde in league of extraordinary gentlemen",
        "answers": [
            "Jason Flemyng"
        ],
        "model_ans": "Johnny Depp",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Depp </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the 2017 college football season end",
        "answers": [
            "December 9, 2017"
        ],
        "model_ans": "January 9, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 9, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the under butler in downton abbey",
        "answers": [
            "Charles Carson",
            "Mr Carson"
        ],
        "model_ans": "Mr. Molesley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mr. Molesley </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has hosted the most fifa world cups",
        "answers": [
            "Italy",
            "Germany",
            "France",
            "Brazil",
            "Mexico"
        ],
        "model_ans": "Brazil",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brazil </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the top scorer in 2014 world cup",
        "answers": [
            "James Rodr\u00edguez"
        ],
        "model_ans": "James Rodriguez",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Rodriguez </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time the carolina hurricanes made the playoffs",
        "answers": [
            "2008\u201309"
        ],
        "model_ans": "2022\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2022\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the first permanent european settlement on future united states soil was located where",
        "answers": [
            "Jamestown",
            "St. Augustine",
            "Puerto Rico"
        ],
        "model_ans": "Jamestown",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jamestown </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the snow on mars made of",
        "answers": [
            "water ice",
            "Frozen carbon dioxide"
        ],
        "model_ans": "Water ice",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Water ice </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the movie mothers day take place",
        "answers": [
            "Atlanta",
            "Atlanta, Georgia"
        ],
        "model_ans": "Atlanta",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlanta </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the first immigrants come to hawaii",
        "answers": [
            "Around 1200"
        ],
        "model_ans": "1789",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1789 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the main industry in the canadian shield",
        "answers": [
            "mining"
        ],
        "model_ans": "mining",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mining </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does monday night raw come on hulu",
        "answers": [
            "the following day"
        ],
        "model_ans": "Monday nights",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Monday nights </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the first light beer in the us",
        "answers": [
            "Miller Lite"
        ],
        "model_ans": "Miller Lite",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miller Lite </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the ancient chinese umbrella used for",
        "answers": [
            "a defense against rain"
        ],
        "model_ans": "protection from the sun",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> protection from the sun </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played guitar on my guitar gently weeps",
        "answers": [
            "Eric Clapton",
            "George Harrison"
        ],
        "model_ans": "George Harrison",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George Harrison </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings the song i feel it still",
        "answers": [
            "Portugal. The Man.",
            "Portugal. The Man"
        ],
        "model_ans": "Portugal. The Man",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Portugal. The Man </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the protease which is released in the stomach",
        "answers": [
            "Pepsin"
        ],
        "model_ans": "Pepsin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pepsin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does fungi go on a food web",
        "answers": [
            "the end",
            "decomposers",
            "At the end"
        ],
        "model_ans": "decomposers",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> decomposers </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is wind power used most in the united states",
        "answers": [
            "Texas",
            "the central plains",
            "Iowa"
        ],
        "model_ans": "Texas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Texas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are some elements that are similar to silver",
        "answers": [
            "Roentgenium (Rg)",
            "copper (Cu)",
            "gold (Au)"
        ],
        "model_ans": "Copper, Gold, Platinum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Copper, Gold, Platinum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did michigan last win a national championship",
        "answers": [
            "1989"
        ],
        "model_ans": "1997",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1997 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which indian actor has won most national awards",
        "answers": [
            "Amitabh Bachchan"
        ],
        "model_ans": "Soumitra Chatterjee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Soumitra Chatterjee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what",
        "answers": [
            "volume of blood",
            "ethanol"
        ],
        "model_ans": "100 milliliters",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 100 milliliters </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what year did seven nation army come out",
        "answers": [
            "2003",
            "March 2003"
        ],
        "model_ans": "2003\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2003\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "role of malonyl coa in fatty acid synthesis",
        "answers": [
            "chain elongation"
        ],
        "model_ans": "Malonyl-CoA is an intermediate in the fatty acid synthesis pathway, it is the first committed step in the synthesis of fatty acids from acetyl-CoA",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Malonyl-CoA is an intermediate in the fatty acid synthesis pathway, it is the first committed step in the synthesis of fatty acids from acetyl-CoA </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the glasses that give sight to the blind",
        "answers": [
            "2006",
            "Conrad Lewis"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the average time in hospice care",
        "answers": [
            "57 days"
        ],
        "model_ans": "3-4 weeks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3-4 weeks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the little girl in jurassic park",
        "answers": [
            "Ariana Clarice Richards"
        ],
        "model_ans": "Ariana Richards",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ariana Richards </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has participated in the most super bowls",
        "answers": [
            "New England Patriots"
        ],
        "model_ans": "Tom Brady",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Brady </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time michigan basketball won the championship",
        "answers": [
            "1989"
        ],
        "model_ans": "1989",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1989 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays spock in the new star trek movies",
        "answers": [
            "Zachary John Quinto"
        ],
        "model_ans": "Zachary Quinto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Zachary Quinto</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did las vegas become a gambling town",
        "answers": [
            "1931",
            "In 1931"
        ],
        "model_ans": "1905",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1905 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wins america's next top model cycle 20",
        "answers": [
            "Jourdan Miller"
        ],
        "model_ans": "Jourdan Miller",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jourdan Miller </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the day that the pubs ran dry in the poem 9-3",
        "answers": [
            "31 October 1972"
        ],
        "model_ans": "1969",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1969 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote were going on a bear hunt",
        "answers": [
            "Michael Rosen"
        ],
        "model_ans": "Michael Rosen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Rosen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was son of a preacher man released",
        "answers": [
            "late 1968",
            "November 8, 1968"
        ],
        "model_ans": "1969\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1969\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most restaurants in the world",
        "answers": [
            "SUBWAY"
        ],
        "model_ans": "Subway",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Subway </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the eagles win the super bowl",
        "answers": [
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the eclipse end in the us",
        "answers": [
            "2:44\u00a0p.m. EDT"
        ],
        "model_ans": "August 21, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 21, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "hart of dixie season 4 how many episodes",
        "answers": [
            "10"
        ],
        "model_ans": "10\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "10\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "green algae is an example of which type of reproduction",
        "answers": [
            "alternation of generations",
            "alternation of generations."
        ],
        "model_ans": "asexual",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> asexual </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did avatar the last airbender first air",
        "answers": [
            "February 2005",
            "February 21, 2005",
            "February\u00a021,\u00a02005"
        ],
        "model_ans": "2005\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2005\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where will the first round of march madness be played",
        "answers": [
            "Wichita State University",
            "Boise State University",
            "Duquesne University",
            "Big 12 Conference"
        ],
        "model_ans": "Various locations",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Various locations </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the abacus invented in ancient china",
        "answers": [
            "2nd century BC"
        ],
        "model_ans": "around 2500 BC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> around 2500 BC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who's playing in the sec championship 2017",
        "answers": [
            "Auburn Tigers",
            "Georgia Bulldogs"
        ],
        "model_ans": "Alabama and Clemson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alabama and Clemson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song if loving you is wrong i don't want to be right",
        "answers": [
            "The Emotions",
            "Luther Ingram"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the declaration of man and citizen",
        "answers": [
            "General Lafayette",
            "Honor\u00e9 Mirabeau",
            "Thomas Jefferson"
        ],
        "model_ans": "Jean-Jacques Rousseau",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jean-Jacques Rousseau </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what written material is included in the talmud",
        "answers": [
            "the Mishnah",
            "the Gemara"
        ],
        "model_ans": "Mishnah",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mishnah </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the boards name on ed edd and eddy",
        "answers": [
            "Plank"
        ],
        "model_ans": "Jawbreakers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jawbreakers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the blood vessels that supply the retinal cells lie",
        "answers": [
            "optic nerve",
            "The optic nerve"
        ],
        "model_ans": "optic disc",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> optic disc </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is responsible for introducing the principle of uniformitarianism",
        "answers": [
            "James Hutton",
            "geologist James Hutton",
            "William Whewell"
        ],
        "model_ans": "James Hutton",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Hutton </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the actor who played grizzly adams",
        "answers": [
            "\"Dan\" Haggerty"
        ],
        "model_ans": "Paul Gleason",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paul Gleason </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who owns the delano hotel in las vegas",
        "answers": [
            "MGM Resorts International"
        ],
        "model_ans": "MGM Resorts International",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MGM Resorts International </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the owner of the crowne plaza",
        "answers": [
            "InterContinental Hotels Group"
        ],
        "model_ans": "InterContinental Hotels Group",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> InterContinental Hotels Group </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the location at the end of minority report",
        "answers": [
            "an undisclosed location"
        ],
        "model_ans": "Washington D.C.",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Washington D.C. </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the 2017 women's wimbledon final",
        "answers": [
            "Garbi\u00f1e Muguruza"
        ],
        "model_ans": "Garbi\u00f1e Muguruza",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Garbi\u00f1e Muguruza </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what part of maryland is close to washington dc",
        "answers": [
            "Charles County",
            "Calvert County",
            "Montgomery County",
            "Washington metropolitan area",
            "Prince George's County",
            "Frederick County"
        ],
        "model_ans": "Baltimore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Baltimore</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the chip in. debit cards",
        "answers": [
            "Helmut Gr\u00f6ttrup",
            "J\u00fcrgen Dethloff"
        ],
        "model_ans": "Visa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Visa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who proposed evolution in 1859 as the basis of biological development",
        "answers": [
            "Alfred Russel Wallace",
            "Charles Darwin"
        ],
        "model_ans": "Charles Darwin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Darwin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang raindrops keep fallin on my head",
        "answers": [
            "B. J. Thomas"
        ],
        "model_ans": "B.J. Thomas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>B.J. Thomas</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many countries participated for the first time in the 2014 olympic winter games in sochi",
        "answers": [
            "Brazil",
            "Uzbekistan",
            "Turkey"
        ],
        "model_ans": "15\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "15\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of a camel with 2 humps",
        "answers": [
            "Bactrian",
            "the Bactrian"
        ],
        "model_ans": "Dromedary",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dromedary </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a 58-story skyscraper in san francisco is tilting and sinking",
        "answers": [
            "Millennium Tower"
        ],
        "model_ans": "Millennium Tower",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Millennium Tower </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the men's worlds curling start",
        "answers": [
            "March 31"
        ],
        "model_ans": "March 31, 2023",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> March 31, 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who were the three elves who got rings",
        "answers": [
            "C\u00edrdan",
            "Gil-galad",
            "Galadriel"
        ],
        "model_ans": "Jean, Tom, and Harry",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean, Tom, and Harry</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the movie breakfast club come out",
        "answers": [
            "February 15, 1985",
            "February\u00a015,\u00a01985",
            "1985"
        ],
        "model_ans": "1985\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1985\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang the song how far is heaven",
        "answers": [
            "Los Lonely Boys"
        ],
        "model_ans": "",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>  </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did zendaya place in dancing with the stars",
        "answers": [
            "Runner-up"
        ],
        "model_ans": "16th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does sloan come into grey's anatomy",
        "answers": [
            "season two"
        ],
        "model_ans": "Sloan is a character in Grey's Anatomy, played by actor Eric Dane, who first appears in the show's 5th season.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sloan is a character in Grey's Anatomy, played by actor Eric Dane, who first appears in the show's 5th season. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many countries are a part of opec",
        "answers": [
            "14"
        ],
        "model_ans": "14",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does buffy tell her friends she was in heaven",
        "answers": [
            "Something to Sing About"
        ],
        "model_ans": "In the episode \"Hush\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> In the episode \"Hush\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the nba start playing zone defense",
        "answers": [
            "2002",
            "the 2001\u20132002 season"
        ],
        "model_ans": "1990s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1990s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many plane surfaces does a cylinder have",
        "answers": [
            "two parallel planes",
            "two"
        ],
        "model_ans": "2\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays max voice in a goofy movie",
        "answers": [
            "Jason Marsden"
        ],
        "model_ans": "Jason Marsden",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jason Marsden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did ford change the f150 body style",
        "answers": [
            "the 2009 model year",
            "1957"
        ],
        "model_ans": "2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2021 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played scotty baldwins father on general hospital",
        "answers": [
            "Ross Elliott",
            "Peter Hansen"
        ],
        "model_ans": "John Beradino",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Beradino </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the miraculous journey of edward tulane published",
        "answers": [
            "2006",
            "March 30, 2006"
        ],
        "model_ans": "2006\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2006\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the current defence against the dark arts teacher",
        "answers": [
            "Amycus Carrow"
        ],
        "model_ans": "Professor McGonagall",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Professor McGonagall </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of snake is kaa in jungle book",
        "answers": [
            "Indian rock python"
        ],
        "model_ans": "Cobra",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cobra </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does ellen's new game show start",
        "answers": [
            "December 18, 2017"
        ],
        "model_ans": "Ellen's Game of Games premiered on December 12, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ellen's Game of Games premiered on December 12, 2017 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the original host of jokers wild",
        "answers": [
            "Jack Barry"
        ],
        "model_ans": "Allen Ludden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Allen Ludden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has more super bowl wins nfc or afc",
        "answers": [
            "NFC",
            "NFC/NFL"
        ],
        "model_ans": "AFC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> AFC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name the tissue type of the inner most layer of cells",
        "answers": [
            "Epithelium"
        ],
        "model_ans": "epithelial",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> epithelial </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what city was zeus the patron god of",
        "answers": [
            "Olympia",
            "Elis"
        ],
        "model_ans": "olympia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> olympia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the implantation of the embryo occur",
        "answers": [
            "around 9 days after ovulation"
        ],
        "model_ans": "6-10 days after fertilization",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6-10 days after fertilization </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the richest club in the championship",
        "answers": [
            "Manchester City",
            "Aston Villa"
        ],
        "model_ans": "Aston Villa",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Aston Villa </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the opening ceremonies of the olympics 2018",
        "answers": [
            "9 February 2018"
        ],
        "model_ans": "February 9, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> February 9, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has said that caste is a closed class",
        "answers": [
            "Frederik Barth"
        ],
        "model_ans": "Ambedkar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ambedkar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "all time highest goal scorer in spain national team",
        "answers": [
            "David Villa"
        ],
        "model_ans": "David Villa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Villa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the snooker world open currently held",
        "answers": [
            "Hainan International Exhibition Center",
            "Haikou"
        ],
        "model_ans": "Shanghai",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shanghai </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does iron ore come from in australia",
        "answers": [
            "Western Australia"
        ],
        "model_ans": "Western Australia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Western Australia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the first pokemon game come out",
        "answers": [
            "October 2000",
            "1996"
        ],
        "model_ans": "1996\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1996\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays jill bigelow in line of duty",
        "answers": [
            "Polly Walker"
        ],
        "model_ans": "Vicky McClure",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vicky McClure </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what do you say when you win bingo",
        "answers": [
            "Yes",
            "Bingo",
            "Line",
            "House"
        ],
        "model_ans": "Bingo!",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bingo!</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who rebuilt the temple after the babylonian captivity",
        "answers": [
            "Herod"
        ],
        "model_ans": "Zerubbabel",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Zerubbabel </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia",
        "answers": [
            "Shahzar Rizvi"
        ],
        "model_ans": "Om Prakash Mitharwal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Om Prakash Mitharwal </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "philadelphia is known as the city of what",
        "answers": [
            "City of Brotherly Love",
            "Brotherly Love"
        ],
        "model_ans": "brotherly love",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> brotherly love </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the supreme court judge was a former chief justice of kerala high court",
        "answers": [
            "Konakuppakatil Gopinathan Balakrishnan"
        ],
        "model_ans": "Justice P Sathasivam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Justice P Sathasivam </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the young man in hawthorne's my kinsman major molineux",
        "answers": [
            "Robin",
            "Robin, a youth"
        ],
        "model_ans": "Major Molineux",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Major Molineux </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings stop listen what's that sound",
        "answers": [
            "Buffalo Springfield"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the red badge of courage take place",
        "answers": [
            "the field of battle"
        ],
        "model_ans": "during the American Civil War",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> during the American Civil War </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the first step in the evolution of the eye",
        "answers": [
            "photoreceptor proteins that sense light",
            "eyespots"
        ],
        "model_ans": "light detection",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> light detection </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who came up with the first working periodic table",
        "answers": [
            "Dmitri Mendeleev"
        ],
        "model_ans": "Dmitri Mendeleev",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dmitri Mendeleev </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who used morse code in world war 2",
        "answers": [
            "naval bases",
            "warships"
        ],
        "model_ans": "The Allies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Allies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the first season of slasher filmed",
        "answers": [
            "Orangeville, Ontario, Canada",
            "Sudbury, Parry Sound"
        ],
        "model_ans": "Toronto",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Toronto </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the broncos win the super bowl",
        "answers": [
            "1998",
            "2015",
            "1997"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who are you in assassin's creed 4",
        "answers": [
            "third-person perspective",
            "an Abstergo agent"
        ],
        "model_ans": "Edward Kenway",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edward Kenway </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do the events in the story take place geographically",
        "answers": [
            "Persia"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is a dropped pin on google maps for",
        "answers": [
            "marks locations in Google Maps",
            "marks locations"
        ],
        "model_ans": "a location marker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> a location marker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the movie citizen kane based on",
        "answers": [
            "William Randolph Hearst"
        ],
        "model_ans": "Orson Welles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Orson Welles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the ottoman governor who led egypt in the years following the napoleonic wars",
        "answers": [
            "Husrev Pasha",
            "Isma'il Pasha and Tewfik Pasha"
        ],
        "model_ans": "Muhammad Ali",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad Ali </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which is the first private medical college in kerala",
        "answers": [
            "Government Medical College, Thiruvananthapuram",
            "1998"
        ],
        "model_ans": "Amrita Institute of Medical Sciences",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Amrita Institute of Medical Sciences </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the chiefs play in the playoffs",
        "answers": [
            "the Tennessee Titans"
        ],
        "model_ans": "Tennessee Titans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tennessee Titans </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the time setting of game of thrones",
        "answers": [
            "medieval"
        ],
        "model_ans": "8th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 8th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has access to the presidential daily briefing",
        "answers": [
            "National Security Advisor",
            "Secretaries of State",
            "Defense",
            "the President"
        ],
        "model_ans": "The President of the United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The President of the United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played buffy the vampire slayer in the movie",
        "answers": [
            "Kristy Swanson"
        ],
        "model_ans": "Sarah Michelle Gellar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sarah Michelle Gellar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is ranked 1 in women's tennis",
        "answers": [
            "Simona Halep"
        ],
        "model_ans": "Serena Williams",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Serena Williams </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the mens curling in the olympics 2018",
        "answers": [
            "United States"
        ],
        "model_ans": "Sweden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sweden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does what in the sam hill come from",
        "answers": [
            "simple bowdlerization"
        ],
        "model_ans": "Nashville",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nashville </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who defeated the last remaining roman army in europe",
        "answers": [
            "Goths"
        ],
        "model_ans": "Franks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Franks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the temperature of gas is proportional to the",
        "answers": [
            "volume"
        ],
        "model_ans": "square root of the pressure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> square root of the pressure </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who's flag is red white and green",
        "answers": [
            "Hungary"
        ],
        "model_ans": "Italy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Italy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "country with most olympic gold medals all time",
        "answers": [
            "United States"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who proposed the virginia plan at the constitutional convention",
        "answers": [
            "Madison",
            "James Madison"
        ],
        "model_ans": "Edmund Randolph",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edmund Randolph </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays yoda in revenge of the sith",
        "answers": [
            "Frank Oz"
        ],
        "model_ans": "Jake Lloyd",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jake Lloyd</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the bad guy in silence of the lambs",
        "answers": [
            "Buffalo Bill"
        ],
        "model_ans": "Hannibal Lecter",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hannibal Lecter </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who become the ceo of it wipro company in 2016",
        "answers": [
            "Abid Ali Neemuchwala"
        ],
        "model_ans": "Abidali Neemuchwala",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Abidali Neemuchwala </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "actress who plays brad pitts wife in war machine",
        "answers": [
            "Meg Tilly"
        ],
        "model_ans": "Toni Collette",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toni Collette </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who comes after the president if he dies",
        "answers": [
            "vice president"
        ],
        "model_ans": "Vice President",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Vice President </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays the protagonist peter rabbit in the 2018 motion picture release",
        "answers": [
            "James Corden"
        ],
        "model_ans": "James Corden",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> James Corden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the movie i am number 4 filmed",
        "answers": [
            "the Pittsburgh metropolitan area"
        ],
        "model_ans": "New Orleans",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New Orleans </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the granite mountain hotshots get certified",
        "answers": [
            "2008"
        ],
        "model_ans": "1994",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1994 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did brent barry won the dunk contest",
        "answers": [
            "1996"
        ],
        "model_ans": "2002",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2002 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the purpose of a jake brake",
        "answers": [
            "slowing the vehicle"
        ],
        "model_ans": "To slow down a truck",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> To slow down a truck </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings in everybody dies in their nightmares",
        "answers": [
            "XXXTentacion"
        ],
        "model_ans": "Underoath",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Underoath </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who established the idea that microorganisms play a role in disease",
        "answers": [
            "Robert Koch",
            "Agostino Bassi"
        ],
        "model_ans": "Louis Pasteur",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Louis Pasteur </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the rise of the planet of the apes filmed",
        "answers": [
            "Oahu, Hawaii",
            "Vancouver, British Columbia",
            "San Francisco, California"
        ],
        "model_ans": "Vancouver",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Vancouver </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first underwater cable laid beneath the english channel",
        "answers": [
            "1850"
        ],
        "model_ans": "1858\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1858\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song balls to the wall",
        "answers": [
            "Deaffy",
            "Udo Dirkschneider",
            "Herman Frank",
            "Wolf Hoffmann",
            "Stefan Kaufmann",
            "Peter Baltes"
        ],
        "model_ans": "Accept",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Accept </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the girl in wreck it ralph",
        "answers": [
            "Stefanie Scott",
            "Sarah Silverman"
        ],
        "model_ans": "Sarah Silverman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sarah Silverman </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the purpose of a revival meeting during the second great awakening",
        "answers": [
            "evangelizing"
        ],
        "model_ans": "Revival meetings during the Second Great Awakening were a way for people to experience spiritual renewal and conversion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Revival meetings during the Second Great Awakening were a way for people to experience spiritual renewal and conversion </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did krakow become the capital of poland",
        "answers": [
            "1038"
        ],
        "model_ans": "1038\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1038\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the neutrons come from in nuclear fission",
        "answers": [
            "Startup neutron source"
        ],
        "model_ans": "Uranium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uranium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "glycogen and amylopectin are long chains of which simple sugar(s)",
        "answers": [
            "glucose"
        ],
        "model_ans": "glucose",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> glucose </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the actress that plays penny on the big bang theory",
        "answers": [
            "Kaley Christine Cuoco"
        ],
        "model_ans": "Kaley Cuoco",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kaley Cuoco </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was one reason south carolina gave for its decision to secede from the union",
        "answers": [
            "to preserve slavery"
        ],
        "model_ans": "States' rights",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> States' rights </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the main religion in british columbia",
        "answers": [
            "Protestant",
            "Catholic"
        ],
        "model_ans": "Christianity",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christianity </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is wake forest located in north carolina",
        "answers": [
            "78.51889\u00b0W",
            "in Franklin and Wake counties",
            "35.97333\u00b0N"
        ],
        "model_ans": "Winston-Salem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Winston-Salem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is a real world application of an atwood machine",
        "answers": [
            "An elevator with a counterbalance"
        ],
        "model_ans": "crane",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> crane </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who started the tradition of coloring easter eggs",
        "answers": [
            "early Christians of Mesopotamia"
        ],
        "model_ans": "The ancient Mesopotamians",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The ancient Mesopotamians </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the most selling music artist of all time",
        "answers": [
            "The Beatles"
        ],
        "model_ans": "The Beatles",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Beatles </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays stacey's mum in gavin and stacey",
        "answers": [
            "Melanie Walters"
        ],
        "model_ans": "Alison Steadman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alison Steadman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings love me tender in princess diaries 2",
        "answers": [
            "Norah Jones",
            "Adam Levy"
        ],
        "model_ans": "Joss Stone",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joss Stone </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the term for circular movement around a central point",
        "answers": [
            "angular rotation",
            "Coriolis effect"
        ],
        "model_ans": "rotation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> rotation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first to say i'm going to disney world",
        "answers": [
            "Jeana Yeager",
            "Phil Simms",
            "Dick Rutan"
        ],
        "model_ans": "Walt Disney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Walt Disney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is considered as architect of india constitution",
        "answers": [
            "B. R. Ambedkar"
        ],
        "model_ans": "B.R. Ambedkar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>B.R. Ambedkar</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the girl that played cindy lou who",
        "answers": [
            "Taylor Michel Momsen"
        ],
        "model_ans": "Kiera Chaplin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kiera Chaplin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the winner of bigg boss kannada season",
        "answers": [
            "Chandan Shetty",
            "rapper Chandan Shetty"
        ],
        "model_ans": "Shashi Kumar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shashi Kumar </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the new stadium being built in las vegas",
        "answers": [
            "Paradise, Nevada",
            "in Paradise, Nevada"
        ],
        "model_ans": "Allegiant Stadium",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Allegiant Stadium </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where in the bible can i find the lord's prayer",
        "answers": [
            "the Gospel of Matthew",
            "the Gospel of Luke"
        ],
        "model_ans": "Matthew 6:9-13",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matthew 6:9-13 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did they live in sex and the city",
        "answers": [
            "New York City"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who are the artists in the traveling wilburys",
        "answers": [
            "Roy Orbison",
            "Jeff Lynne",
            "George Harrison",
            "Bob Dylan",
            "Tom Petty"
        ],
        "model_ans": "Tom Petty, Jeff Lynne, Roy Orbison, George Harrison, Bob Dylan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tom Petty, Jeff Lynne, Roy Orbison, George Harrison, Bob Dylan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played violet in a series of unfortunate events netflix",
        "answers": [
            "Malina Weissman"
        ],
        "model_ans": "Daisy Edgar-Jones",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Daisy Edgar-Jones </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the theme song to step by step",
        "answers": [
            "Jesse Frederick James Conaway",
            "Jesse Frederick"
        ],
        "model_ans": "Hanson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hanson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the tower of london originally used for",
        "answers": [
            "a royal residence",
            "as a royal residence"
        ],
        "model_ans": "Palace",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Palace </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who dies in the beginning of deathly hallows part 1",
        "answers": [
            "Mad-Eye Moody",
            "Hedwig"
        ],
        "model_ans": "Dobby",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dobby </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many tornado planes does the uk have",
        "answers": [
            "138"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who designed the traffic circle in long beach ca",
        "answers": [
            "German engineer Werner Ruchti",
            "Werner Ruchti"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays carrie's boss on king of queens",
        "answers": [
            "Doug Pruzan",
            "Alex Skuby"
        ],
        "model_ans": "Jerry Stiller",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jerry Stiller </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did computer become widespread in homes and schools",
        "answers": [
            "1980s"
        ],
        "model_ans": "1980s",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1980s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the age of new media began",
        "answers": [
            "the 1980s"
        ],
        "model_ans": "1990s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1990s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does agents of shield season five start",
        "answers": [
            "December 1, 2017"
        ],
        "model_ans": "December 1, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> December 1, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the thames river begin and end",
        "answers": [
            "Lighthouse Cove",
            "Near Tavistock"
        ],
        "model_ans": "The Thames River begins at its source in Gloucestershire, England, and ends at its mouth in the North Sea, near Southend-on-Sea, Essex, England.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Thames River begins at its source in Gloucestershire, England, and ends at its mouth in the North Sea, near Southend-on-Sea, Essex, England. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the term 'robot' come from",
        "answers": [
            "Czech"
        ],
        "model_ans": "Czech Republic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Czech Republic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was on the first season of dwts",
        "answers": [
            "Joey McIntyre",
            "Evander Holyfield",
            "John O'Hurley",
            "Rachel Hunter",
            "Trista Sutter",
            "Kelly Monaco"
        ],
        "model_ans": "Kelly Monaco",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kelly Monaco </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings i feel love with the blue man group",
        "answers": [
            "Annette Strean",
            "Annette",
            "Venus Hum"
        ],
        "model_ans": "Bj\u00f6rk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bj\u00f6rk</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the ucla usc game being played",
        "answers": [
            "UCLA",
            "USC",
            "Coliseum",
            "Rose Bowl"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings i just want to use your love tonight",
        "answers": [
            "English rock band the Outfield"
        ],
        "model_ans": "Rod Stewart",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rod Stewart </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does planet of the apes come out 2017",
        "answers": [
            "July 14, 2017",
            "July\u00a014,\u00a02017"
        ],
        "model_ans": "July 14, 2017",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> July 14, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are they playing the superbowl at this year",
        "answers": [
            "Minneapolis, Minnesota"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who starred in the movie summer of 42",
        "answers": [
            "Oliver Conant",
            "Christopher Norris",
            "Gary Grimes",
            "Katherine Allentuck",
            "Jennifer O'Neill",
            "Jerry Houser",
            "Robert Mulligan",
            "Maureen Stapleton"
        ],
        "model_ans": "Jean-Pierre Jeunet",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Pierre Jeunet</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the voice of johnny in sing",
        "answers": [
            "Taron Egerton"
        ],
        "model_ans": "Matthew Morrison",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Matthew Morrison </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the owner of phoenix mall in chennai",
        "answers": [
            "Sharyans Resources",
            "Phoenix Mills Limited"
        ],
        "model_ans": "Phoenix Mall",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Phoenix Mall </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the greatest pool player of all time",
        "answers": [
            "Efren Manalang Reyes"
        ],
        "model_ans": "Willie Mosconi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Willie Mosconi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what states were most affected by the dust bowl",
        "answers": [
            "Iowa",
            "Oklahoma",
            "Nebraska",
            "Arkansas",
            "New Mexico",
            "Kansas",
            "Colorado",
            "Texas",
            "Missouri"
        ],
        "model_ans": "Texas, Oklahoma, Kansas, Nebraska, and Colorado",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Texas, Oklahoma, Kansas, Nebraska, and Colorado </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes are in season 7 of pretty little liars",
        "answers": [
            "20"
        ],
        "model_ans": "14\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "14\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a type of basic rock popular in the 1980s",
        "answers": [
            "alternative rock"
        ],
        "model_ans": "Punk Rock",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Punk Rock </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how are leaders of the two parties in congress chosen",
        "answers": [
            "Senate Republican Conference",
            "Senate Democratic Caucus"
        ],
        "model_ans": "The leaders of the two parties in Congress are chosen by their respective party caucuses",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The leaders of the two parties in Congress are chosen by their respective party caucuses </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "itai-itai disease was a form of poisoning associated with ingestion of",
        "answers": [
            "cadmium",
            "Cadmium"
        ],
        "model_ans": "cadmium",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cadmium </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the code name of the us program to develop an atomic bomb",
        "answers": [
            "Manhattan",
            "Development of Substitute Materials",
            "The Manhattan Project"
        ],
        "model_ans": "Manhattan Project",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Manhattan Project </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the real name of our sun",
        "answers": [
            "The Sun"
        ],
        "model_ans": "Sol",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sol </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the song oh what a lonely boy",
        "answers": [
            "Andrew Gold"
        ],
        "model_ans": "Alphaville",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alphaville </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in the dynastic cycle what is the right to rule called",
        "answers": [
            "the Mandate of Heaven",
            "Mandate of Heaven"
        ],
        "model_ans": "Mandate of Heaven",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mandate of Heaven </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the problem of cfc's discovered",
        "answers": [
            "late 1970s",
            "1974",
            "1973",
            "1970s"
        ],
        "model_ans": "1974",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1974 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which president of the united states was a boy scout",
        "answers": [
            "Gerald Ford",
            "President Gerald Ford"
        ],
        "model_ans": "Gerald Ford",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Gerald Ford </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the 2017 sports personality of the year",
        "answers": [
            "Mo Farah"
        ],
        "model_ans": "BBC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the first significant restriction on free immigration in u.s. history was the",
        "answers": [
            "Naturalization Act of 1790",
            "Chinese Exclusion Act in 1882"
        ],
        "model_ans": "Chinese Exclusion Act",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chinese Exclusion Act </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays young voldemort in the half blood prince",
        "answers": [
            "Hero Beauregard Fiennes-Tiffin"
        ],
        "model_ans": "Hero Fiennes-Tiffin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hero Fiennes-Tiffin </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time mount etna exploded",
        "answers": [
            "July\u2013October 2012",
            "16 March 2017"
        ],
        "model_ans": "2021\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2021\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does some like it hot take place",
        "answers": [
            "Chicago",
            "Miami"
        ],
        "model_ans": "Miami",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Miami </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did dragon ball z air in australia",
        "answers": [
            "Fall 1998"
        ],
        "model_ans": "1996",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1996 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "describe the various uses of forests to human beings",
        "answers": [
            "a source of lumber",
            "acting as a carbon sink",
            "aiding in regulating climate,",
            "recreational areas",
            "purifying water",
            "serving as a genetic reserve"
        ],
        "model_ans": "Forests provide numerous benefits to humans, including timber, fuelwood, charcoal, paper, and other wood products. They also serve as habitats for a vast array of plant and animal species, and play a crucial role in regulating the climate</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Forests provide numerous benefits to humans, including timber, fuelwood, charcoal, paper, and other wood products. They also serve as habitats for a vast array of plant and animal species, and play a crucial role in regulating the climate</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in my name is earl season 4",
        "answers": [
            "27"
        ],
        "model_ans": "13\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "13\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did maria work in west side story",
        "answers": [
            "the dress shop",
            "dress shop"
        ],
        "model_ans": "Doc's Candy Store",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Doc's Candy Store </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "an influential religion to enter china along the silk route during the han dynasty was",
        "answers": [
            "Buddhism"
        ],
        "model_ans": "Buddhism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Buddhism</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the last name andersen originate from",
        "answers": [
            "Danish",
            "Norwegian"
        ],
        "model_ans": "Denmark",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Denmark </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where will the next summer and winter olympics be held",
        "answers": [
            "Beijing",
            "Tokyo"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played mr. kincaid on the partridge family",
        "answers": [
            "David Joseph Madden"
        ],
        "model_ans": "David Cassidy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Cassidy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did they stop making pull tabs on beer cans",
        "answers": [
            "1990",
            "1970s"
        ],
        "model_ans": "1970s",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1970s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i wanna rock'n'roll all night",
        "answers": [
            "Kiss"
        ],
        "model_ans": "Poison",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Poison </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who scored fastest 10000 runs in test cricket",
        "answers": [
            "Alastair Cook",
            "Kumar Sangakkara",
            "Brian Lara",
            "Sachin Tendulkar"
        ],
        "model_ans": "Brian Lara",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Brian Lara</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who presides over the joint sessions of parliament",
        "answers": [
            "President"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "cast of the have and have nots play",
        "answers": [
            "Tony Hightower as Frank",
            "Palmer Williams Jr. as Floyd",
            "Maurice Lauchner as Lewis",
            "Jeffery Lewis as Wallie",
            "Alexis Jones as Diane",
            "Kislyck Halsey as Rose",
            "Patrice Lovely as Hattie"
        ],
        "model_ans": "The Young and the Restless",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Young and the Restless </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who starred in the movie on golden pond",
        "answers": [
            "William Lanteau",
            "Christopher Rydell",
            "Dabney Coleman",
            "Henry Fonda",
            "Jane Fonda",
            "Katharine Hepburn",
            "Doug McKeon"
        ],
        "model_ans": "Henry Fonda",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry Fonda </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the salary of us secretary of state",
        "answers": [
            "$205,700",
            "$205,700 annually"
        ],
        "model_ans": "$210,700",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $210,700 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "latest series of keeping up with the kardashians",
        "answers": [
            "14"
        ],
        "model_ans": "24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "avatar the last airbender season 3 episode 12",
        "answers": [
            "The Western Air Temple"
        ],
        "model_ans": "The Crossroads of Destiny",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Crossroads of Destiny </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the mughal garden of rashtrapati bhavan is modelled on which garden",
        "answers": [
            "the Persian gardens",
            "charbagh"
        ],
        "model_ans": "Char Bagh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Char Bagh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was to god be the glory written",
        "answers": [
            "around 1872"
        ],
        "model_ans": "1933",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1933 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the cat and mouse act introduced",
        "answers": [
            "1913"
        ],
        "model_ans": "1971",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1971 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang i dig rock and roll music",
        "answers": [
            "Peter, Paul and Mary"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played skeletor in the movie masters of the universe",
        "answers": [
            "Frank Langella"
        ],
        "model_ans": "Frank Langella",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Frank Langella </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has been ranked no. 1 in the latest football rankings announced by fifa",
        "answers": [
            "Germany"
        ],
        "model_ans": "Belgium",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Belgium </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "explorer who led an early voyage to the coast of newfoundland",
        "answers": [
            "Jacques Cartier"
        ],
        "model_ans": "John Cabot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Cabot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many walker texas ranger seasons are there",
        "answers": [
            "Eight",
            "8"
        ],
        "model_ans": "9\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "9\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the light between two oceans filmed",
        "answers": [
            "Australia",
            "New Zealand"
        ],
        "model_ans": "Bora Bora",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bora Bora </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played bubba in the heat of the night",
        "answers": [
            "Carlos Alan Autry Jr."
        ],
        "model_ans": "Sidney Poitier",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sidney Poitier </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played sarah hedley in when the boat comes in",
        "answers": [
            "Rosalind Bailey"
        ],
        "model_ans": "Jean Alexander",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean Alexander</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the beast in the movie beauty and the beast",
        "answers": [
            "Dan Stevens",
            "Adam Mitchell"
        ],
        "model_ans": "Robby Benson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robby Benson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the us cut off trade with cuba",
        "answers": [
            "1961",
            "1962"
        ],
        "model_ans": "1960\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1960\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who developed the first printing press in 1430s",
        "answers": [
            "Johannes Gutenberg"
        ],
        "model_ans": "Johannes Gutenberg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Johannes Gutenberg</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does stevia in the raw come from",
        "answers": [
            "South America",
            "the plant species Stevia rebaudiana"
        ],
        "model_ans": "stevia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> stevia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many jimmy johns are there in the us",
        "answers": [
            "more than 2,500",
            "almost 3,000 stores",
            "2,630",
            "2,630 (December 2016)",
            "more than 2,500 locations"
        ],
        "model_ans": "over 2,800",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> over 2,800 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the music producer in pitch perfect 2",
        "answers": [
            "Keegan-Michael Key"
        ],
        "model_ans": "Hailee Steinfeld",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hailee Steinfeld </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which layer of the meninges is connected to the brain",
        "answers": [
            "pia mater",
            "The pia mater"
        ],
        "model_ans": "Dura mater",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dura mater </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most ncaa basketball tournament appearances",
        "answers": [
            "Kentucky"
        ],
        "model_ans": "Kentucky",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kentucky </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when will the flash season 4 episode 14 coming out",
        "answers": [
            "February\u00a027,\u00a02018"
        ],
        "model_ans": "March 21, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 21, 2018 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "mainland greece is a body of land with water on three sides called",
        "answers": [
            "peninsula",
            "peninsular"
        ],
        "model_ans": "Mediterranean",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mediterranean </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of legal system is used in the uk",
        "answers": [
            "Scots law",
            "Northern Ireland law",
            "English law"
        ],
        "model_ans": "Common Law",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Common Law </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who painted the world famous painting the last supper",
        "answers": [
            "Leonardo da Vinci"
        ],
        "model_ans": "Leonardo da Vinci",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leonardo da Vinci </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the original purpose of the kremlin",
        "answers": [
            "the tsar's Moscow residence"
        ],
        "model_ans": "The original purpose of the Kremlin was as a fortified city, with the first walls being built in the 12th century.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The original purpose of the Kremlin was as a fortified city, with the first walls being built in the 12th century. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the third season of total drama",
        "answers": [
            "World Tour",
            "Total Drama World Tour"
        ],
        "model_ans": "Total Drama World Tour",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Total Drama World Tour </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the probability of making a type i error when retaining ho at the .05 level of significance is",
        "answers": [
            "5%"
        ],
        "model_ans": "0.05\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "0.05\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what nfl coach has the most wins ever",
        "answers": [
            "Shula, Don",
            "Don Shula"
        ],
        "model_ans": "Don Shula",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Don Shula </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the rule of the three rightly guided caliphs was called",
        "answers": [
            "Rashidun",
            "the Rashidun",
            "The Rashidun Caliphs"
        ],
        "model_ans": "Rashidun",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rashidun </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "ray charles hit the road jack album name",
        "answers": [
            "Ray Charles Greatest Hits"
        ],
        "model_ans": "yes indeed",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> yes indeed </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the wizards of waverly place theme song",
        "answers": [
            "Selena Gomez"
        ],
        "model_ans": "Selena Gomez",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Selena Gomez </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many times has the saints won the super bowl",
        "answers": [
            "1"
        ],
        "model_ans": "6",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the statue of liberty originally built",
        "answers": [
            "Paris",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the first political society started under british rule in india was",
        "answers": [
            "The British Indian Association"
        ],
        "model_ans": "The Asiatic Society",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Asiatic Society </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the bob and tom show broadcast from",
        "answers": [
            "WFBQ in Indianapolis, Indiana",
            "Indianapolis, Indiana"
        ],
        "model_ans": "Chicago",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what age do you have to be to buy cigarettes in california",
        "answers": [
            "21"
        ],
        "model_ans": "21\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "21\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did the whistling in the muppet movie",
        "answers": [
            "Andrew Bird",
            "musician Andrew Bird"
        ],
        "model_ans": "Jim Henson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jim Henson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where would a subcutaneous injection be made in the skin",
        "answers": [
            "the subcutis"
        ],
        "model_ans": "thigh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> thigh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song with reba does he love you",
        "answers": [
            "Linda Davis"
        ],
        "model_ans": "Linda Davis",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Linda Davis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote you must have been a beautiful baby",
        "answers": [
            "Johnny Mercer",
            "lyrics by Johnny Mercer",
            "music by Harry Warren",
            "Harry Warren"
        ],
        "model_ans": "Johnny Mercer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Johnny Mercer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the immediate catalyst to the civil war",
        "answers": [
            "slavery"
        ],
        "model_ans": "The election of Abraham Lincoln as President",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The election of Abraham Lincoln as President </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which player won the pga championship by the most shots",
        "answers": [
            "Rory McIlroy"
        ],
        "model_ans": "Y.E. Yang",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Y.E. Yang </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when are you considered under the poverty line",
        "answers": [
            "US$11,770"
        ],
        "model_ans": "50% of the median income",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50% of the median income </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the author of the art of war",
        "answers": [
            "Sun Tzu"
        ],
        "model_ans": "Sun Tzu",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sun Tzu </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what has been the origin of most classical dances of india",
        "answers": [
            "the Sanskrit text Natya Shastra",
            "Natya Shastra",
            "The Natya Shastra"
        ],
        "model_ans": "Bharatanatyam",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bharatanatyam</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time kentucky won ncaa",
        "answers": [
            "2012"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2012 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what olympic athlete has won the most medals",
        "answers": [
            "American swimmer Michael Phelps",
            "Marit Bj\u00f8rgen",
            "Michael Phelps"
        ],
        "model_ans": "Michael Phelps",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Phelps </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the movie peter pan come out",
        "answers": [
            "2003",
            "25\u00a0December\u00a02003"
        ],
        "model_ans": "1953\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1953\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the transfer speed for sata 1",
        "answers": [
            "1.5\u00a0Gbit/s"
        ],
        "model_ans": "150 MB/s\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "150 MB/s\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does new crust come from in sea floor spreading",
        "answers": [
            "basaltic magma",
            "volcanic activity"
        ],
        "model_ans": "Mid-ocean ridges",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mid-ocean ridges </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who cracked the enigma code in world war 2",
        "answers": [
            "Turing"
        ],
        "model_ans": "Alan Turing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alan Turing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what were the two causes of the dust bowl",
        "answers": [
            "severe drought"
        ],
        "model_ans": "Drought and poor farming practices",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Drought and poor farming practices </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of reaction occurs to form a dipeptide",
        "answers": [
            "peptide bond"
        ],
        "model_ans": "condensation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> condensation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the un security council get troops for military actions",
        "answers": [
            "member states of the UN",
            "member states"
        ],
        "model_ans": "Member states",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Member states </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who voices hiccup in how to train your dragon 2",
        "answers": [
            "Jay Baruchel"
        ],
        "model_ans": "Jay Baruchel",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jay Baruchel </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does luke skywalker fall in love with",
        "answers": [
            "Mara Jade"
        ],
        "model_ans": "Leia Organa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leia Organa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "if there is a line that lies parallel to the horizon it is said to be",
        "answers": [
            "A vanishing point"
        ],
        "model_ans": "horizontal",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> horizontal </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last year the raiders won the superbowl",
        "answers": [
            "1983"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much energy does coal produce in the us",
        "answers": [
            "16.5 quadrillion BTUs",
            "30.4%"
        ],
        "model_ans": "2,000,000 GWh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2,000,000 GWh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the definition of the word hosanna",
        "answers": [
            "save, rescue, savior",
            "rescue",
            "savior",
            "save"
        ],
        "model_ans": "a Hebrew word meaning \"save now\" or \"deliver now\"",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> a Hebrew word meaning \"save now\" or \"deliver now\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the sun hit the us first",
        "answers": [
            "the summit of Cadillac Mountain"
        ],
        "model_ans": "Hawaii",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hawaii </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the only 2 families that have had 3 generations of oscar winners",
        "answers": [
            "The Hustons",
            "the Coppolas",
            "Hustons",
            "Farrow/Previn/Allens",
            "Coppolas"
        ],
        "model_ans": "The Barrymores and The Hustons",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Barrymores and The Hustons </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the chief justice of ghana",
        "answers": [
            "Sophia Akuffo"
        ],
        "model_ans": "Sophia Akuffo",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sophia Akuffo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is considered the father of modern cosmology",
        "answers": [
            "Edwin Hubble"
        ],
        "model_ans": "Edwin Hubble",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edwin Hubble </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who discovered one of the first taxonomic classification schemes",
        "answers": [
            "Swedish botanist Carl Linnaeus"
        ],
        "model_ans": "Carl Linnaeus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carl Linnaeus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays on the tv show the resident",
        "answers": [
            "Merrin Dungey",
            "Emily VanCamp",
            "Bruce Greenwood",
            "Melina Kanakaredes",
            "Manish Dayal",
            "Matt Czuchry",
            "Moran Atias",
            "Shaunette Ren\u00e9e Wilson"
        ],
        "model_ans": "Matt Czuchry",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matt Czuchry </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did are you smarter than a 5th grader first air",
        "answers": [
            "February 27, 2007"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the detective in little boy blue",
        "answers": [
            "Stephen Graham"
        ],
        "model_ans": "Hugh Bonneville",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hugh Bonneville </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what parts make up the peripheral nervous system",
        "answers": [
            "autonomic nervous system",
            "somatic nervous system"
        ],
        "model_ans": "sensory neurons, motor neurons, and autonomic neurons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> sensory neurons, motor neurons, and autonomic neurons </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is star vs the forces of evil coming back 2018",
        "answers": [
            "March\u00a03,\u00a02018"
        ],
        "model_ans": "July 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July 2019 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who gets to race in the daytona clash",
        "answers": [
            "Daytona Pole Award winners",
            "former Clash race winners"
        ],
        "model_ans": "NASCAR",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NASCAR </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in which sea pearl is found in india",
        "answers": [
            "the Indian Ocean"
        ],
        "model_ans": "Arabian Sea",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Arabian Sea </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they stop making the nissan xterra",
        "answers": [
            "2015",
            "after the 2015 model year"
        ],
        "model_ans": "2006",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2006 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does ctrl+shift+t do",
        "answers": [
            "New tab",
            "Open a previously closed tab"
        ],
        "model_ans": "Opens the last closed tab",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Opens the last closed tab </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang heard it thru the grapevine first",
        "answers": [
            "Gladys Knight & the Pips",
            "the Miracles",
            "The Miracles"
        ],
        "model_ans": "Marvin Gaye",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marvin Gaye </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang theme song for dukes of hazard",
        "answers": [
            "Waylon Jennings"
        ],
        "model_ans": "Waylon Jennings",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Waylon Jennings </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the coral sea meet the pacific ocean",
        "answers": [
            "in the east",
            "South Pacific"
        ],
        "model_ans": "Queensland",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Queensland </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the new season of are you the one come on",
        "answers": [
            "2018"
        ],
        "model_ans": "August 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> August 2022 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the beer hall putsch take place",
        "answers": [
            "Munich, Bavaria"
        ],
        "model_ans": "Munich",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Munich </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the northernmost land action of the american civil war occur",
        "answers": [
            "St. Albans, Vermont"
        ],
        "model_ans": "Minnesota",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Minnesota </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of molech in the bible",
        "answers": [
            "king"
        ],
        "model_ans": "Molech is a deity in the Hebrew Bible, often associated with child sacrifice",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Molech is a deity in the Hebrew Bible, often associated with child sacrifice </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what areas of africa were involved in colonization",
        "answers": [
            "90 percent of the continent"
        ],
        "model_ans": "Most of Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Most of Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who took the first steps on the moon in 1969",
        "answers": [
            "Neil Armstrong"
        ],
        "model_ans": "Neil Armstrong",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Neil Armstrong </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played john connor in the original terminator",
        "answers": [
            "Michael Edwards",
            "Edward Furlong"
        ],
        "model_ans": "Arnold Schwarzenegger",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arnold Schwarzenegger </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of planet is neptune known as",
        "answers": [
            "giant",
            "ice giants"
        ],
        "model_ans": "Ice giant",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ice giant </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the original host of what's my line",
        "answers": [
            "John Daly"
        ],
        "model_ans": "John Daly",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John Daly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the drummer with the travelling wilburys",
        "answers": [
            "Jim Keltner"
        ],
        "model_ans": "Jeff Lynne",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jeff Lynne </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the name of darth vader star destroyer",
        "answers": [
            "Devastator",
            "the Devastator"
        ],
        "model_ans": "Executor",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Executor </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "by 1914 which of the following african countries were still independent",
        "answers": [
            "Liberia",
            "Ethiopia"
        ],
        "model_ans": "Ethiopia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ethiopia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is best thing i never had song about",
        "answers": [
            "revenge and karma",
            "karma",
            "revenge"
        ],
        "model_ans": "heartbreak",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> heartbreak </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did university of miami play last week",
        "answers": [
            "FIU"
        ],
        "model_ans": "I don't have information about the University of Miami's last game",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I don't have information about the University of Miami's last game </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who appoints the members of the board of governors of the federal reserve",
        "answers": [
            "the President"
        ],
        "model_ans": "The President",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The President </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was hitchhiker's guide to the galaxy made",
        "answers": [
            "2005",
            "1978"
        ],
        "model_ans": "1981\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1981\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes are there in modern family",
        "answers": [
            "201",
            "232"
        ],
        "model_ans": "250\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "250\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the eurostar train arrives in london",
        "answers": [
            "St Pancras International"
        ],
        "model_ans": "London St Pancras International",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London St Pancras International </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the karate kid 2010 take place",
        "answers": [
            "China",
            "Beijing",
            "Beijing, China"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played adaline in the age of adaline",
        "answers": [
            "Adaline Bowman",
            "Blake Lively"
        ],
        "model_ans": "Blake Lively",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Blake Lively </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the general structure of an url",
        "answers": [
            "a protocol",
            "a hostname",
            "a file name"
        ],
        "model_ans": "http://www.example.com/path/to/page",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> http://www.example.com/path/to/page </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who said the poison is in the dose",
        "answers": [
            "credited to Paracelsus",
            "Paracelsus"
        ],
        "model_ans": "Aristophanes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Aristophanes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played young clark kent in 1978 superman",
        "answers": [
            "Jeff East"
        ],
        "model_ans": "Jeff East",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jeff East </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did equus first appear in fossil record",
        "answers": [
            "1820s",
            "~3.5 million years old",
            "about 3.5 mya"
        ],
        "model_ans": "50 million years ago",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 million years ago </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays poppy in the beat goes on",
        "answers": [
            "Amanda Leighton"
        ],
        "model_ans": "Cindy Robinson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cindy Robinson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when are the opening ceremonies for the 2018 olympic games",
        "answers": [
            "9\u00a0February\u00a02018",
            "9 February 2018"
        ],
        "model_ans": "February 9, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> February 9, 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long do nhl players stay on waivers",
        "answers": [
            "24 hours"
        ],
        "model_ans": "3 days",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 days </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the removal of temperature in fire fighting method is known as",
        "answers": [
            "cooling",
            "penciling"
        ],
        "model_ans": "Cooling",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cooling </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "lilo and stitch the series season 1 episode 1",
        "answers": [
            "Richter"
        ],
        "model_ans": "Ohana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ohana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the main functions of the stem",
        "answers": [
            "Production of new living tissue",
            "Storage of nutrients"
        ],
        "model_ans": "transport, support, storage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> transport, support, storage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the baby in ghost busters 2",
        "answers": [
            "Hank J. Deutschendorf II",
            "William T. Deutschendorf"
        ],
        "model_ans": "Oscar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Oscar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang from russia with love james bond",
        "answers": [
            "Matt Monro"
        ],
        "model_ans": "Matt Monro",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Matt Monro </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what football player is called the honey badger",
        "answers": [
            "Tyrann Devine Mathieu"
        ],
        "model_ans": "Thomas Ducret",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Ducret </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which material is the heaviest in term of density",
        "answers": [
            "Osmium"
        ],
        "model_ans": "Osmium",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Osmium </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang for lee bowman in my dream is yours",
        "answers": [
            "Hal Derwin"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most conference championships in college basketball",
        "answers": [
            "Kansas"
        ],
        "model_ans": "UCLA",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> UCLA </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played sandy's jock boyfriend in grease",
        "answers": [
            "John Travolta",
            "Lorenzo Lamas"
        ],
        "model_ans": "Barry Pearl",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Barry Pearl </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the doc in back to the future",
        "answers": [
            "Christopher Allen Lloyd"
        ],
        "model_ans": "Christopher Lloyd",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christopher Lloyd </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did come fly with me come out",
        "answers": [
            "25 December 2010"
        ],
        "model_ans": "2002\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2002\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of bridge is the charles bridge",
        "answers": [
            "a bow bridge",
            "bow bridge",
            "Stone"
        ],
        "model_ans": "Stone arch bridge",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Stone arch bridge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is pictured on the 5000 dollar bill",
        "answers": [
            "James Madison"
        ],
        "model_ans": "Abraham Lincoln",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Abraham Lincoln </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the word leviathan mentioned in the bible",
        "answers": [
            "Book of Job",
            "Psalms",
            "Isaiah"
        ],
        "model_ans": "Job 41:1-34",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Job 41:1-34 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the american league east in 2017",
        "answers": [
            "The Yankees",
            "Houston Astros"
        ],
        "model_ans": "Boston Red Sox",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Boston Red Sox</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a system of fortifications along france's border",
        "answers": [
            "Maginot Line",
            "The Maginot Line"
        ],
        "model_ans": "Maginot Line",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maginot Line </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was hope brady's mother on days of our lives",
        "answers": [
            "Ciara Brady",
            "Addie Horton"
        ],
        "model_ans": "Alice Horton",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alice Horton </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how much does a new gulfstream g650 cost",
        "answers": [
            "US$66.61 million",
            "$66.5 million"
        ],
        "model_ans": "$65 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $65 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which us ship was captured off the coast of massachusetts by the british",
        "answers": [
            "USS Chesapeake"
        ],
        "model_ans": "USS Chesapeake",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> USS Chesapeake </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did congress passes legislation to fund the national cancer institute",
        "answers": [
            "August 5, 1937"
        ],
        "model_ans": "1937",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1937 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the film coming home for christmas filmed",
        "answers": [
            "British Columbia"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the 7 man elimination chamber match",
        "answers": [
            "Roman Reigns"
        ],
        "model_ans": "Edge",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edge </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wins the final fight in real steel",
        "answers": [
            "Zeus"
        ],
        "model_ans": "Charlie Kenton",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Charlie Kenton </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "published a treatise on perspective della pitture (or on painting) in 1435",
        "answers": [
            "Leon Battista Alberti"
        ],
        "model_ans": "Leon Battista Alberti",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leon Battista Alberti </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the first indian who got oscar for lifetime achievement",
        "answers": [
            "Mehboob Khan"
        ],
        "model_ans": "Satyajit Ray",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Satyajit Ray </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what network is showing the monday night football game",
        "answers": [
            "ESPN"
        ],
        "model_ans": "ESPN",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ESPN </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how did leo dalton die in silent witness",
        "answers": [
            "in an explosion"
        ],
        "model_ans": "Leo Dalton died in Silent Witness in 2004",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Leo Dalton died in Silent Witness in 2004 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who holds the record for most platinum albums",
        "answers": [
            "The Beatles",
            "Elvis Presley",
            "AC/DC"
        ],
        "model_ans": "Garth Brooks",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Garth Brooks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which battle ended britain's support for the south",
        "answers": [
            "Battle of Antietam",
            "the Battle of Antietam"
        ],
        "model_ans": "Battle of Antietam",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Battle of Antietam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does panic at the disco album come out",
        "answers": [
            "December 15, 2017"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the flash season 4 episode 3 air",
        "answers": [
            "October\u00a024,\u00a02017"
        ],
        "model_ans": "October 10, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 10, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who directed the iconic animated short educational film ek anek aur ekta",
        "answers": [
            "Vijaya Mulay"
        ],
        "model_ans": "Bhanu Athaiya",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bhanu Athaiya </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "tad the lost explorer and the secret of king midas english cast",
        "answers": [
            "Ariel Winter as Sara Lavrof",
            "Cheech Marin as Freddy",
            "Bruce Mackinnon as the mummy",
            "Lewis MacLeod",
            "Liza Ross as Grandma",
            "Fiona Glascott",
            "Adam Jones as Max Morden"
        ],
        "model_ans": "Not found",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not found </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the actor that plays saul on grace and frankie",
        "answers": [
            "Sam Waterston"
        ],
        "model_ans": "Martin Sheen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Martin Sheen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who holds the most home runs in mlb history",
        "answers": [
            "Barry Bonds"
        ],
        "model_ans": "Babe Ruth",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Babe Ruth</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who cooks for the president of the united states",
        "answers": [
            "Cristeta Comerford",
            "White House Executive Chef",
            "The White House Executive Chef"
        ],
        "model_ans": "The White House Executive Chef",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The White House Executive Chef </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who hosted and won the inagural world cup",
        "answers": [
            "Uruguay"
        ],
        "model_ans": "Uruguay",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Uruguay </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many cracker barrels in the united states",
        "answers": [
            "639",
            "more than 600"
        ],
        "model_ans": "600",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 600 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "striking the funny bone is actually compression of the",
        "answers": [
            "The ulnar nerve",
            "ulnar nerve"
        ],
        "model_ans": "ulnar nerve",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> ulnar nerve </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the wwe championship elimination chamber 2018",
        "answers": [
            "Roman Reigns"
        ],
        "model_ans": "Braun Strowman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Braun Strowman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the most stanley cups in history",
        "answers": [
            "Montreal Canadiens"
        ],
        "model_ans": "Montreal Canadiens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Montreal Canadiens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who starred in the movie the day the earth stood still",
        "answers": [
            "Jennifer Connelly",
            "Jaden Smith",
            "Kyle Chandler",
            "Keanu Reeves",
            "Jon Hamm",
            "Kathy Bates",
            "John Cleese"
        ],
        "model_ans": "Keanu Reeves",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Keanu Reeves </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the battle of britain in ww2",
        "answers": [
            "Britain",
            "the United Kingdom",
            "British"
        ],
        "model_ans": "Allies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Allies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does shadowhunters season 2 episode 17 come out",
        "answers": [
            "February\u00a013,\u00a02017",
            "January\u00a023,\u00a02017",
            "July\u00a024,\u00a02017"
        ],
        "model_ans": "March 27, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> March 27, 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played kelly taylor's mom on 90210",
        "answers": [
            "Ann Gillespie"
        ],
        "model_ans": "Jeanette Collins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jeanette Collins</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the concept of micro financing was developed by who in 1976",
        "answers": [
            "Muhammad Yunus"
        ],
        "model_ans": "Muhammad Yunus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad Yunus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the actor that plays ducky on ncis",
        "answers": [
            "David McCallum"
        ],
        "model_ans": "David McCallum",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> David McCallum </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first cell phone call made",
        "answers": [
            "April 3, 1973"
        ],
        "model_ans": "Martin Cooper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Martin Cooper </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what breed of cat has spots and stripes",
        "answers": [
            "tabby"
        ],
        "model_ans": "Bengal",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bengal</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the monomer building blocks of dna and rna",
        "answers": [
            "Nucleotides"
        ],
        "model_ans": "nucleotides",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nucleotides </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the 3rd largest state in usa",
        "answers": [
            "Alaska",
            "California"
        ],
        "model_ans": "montana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> montana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which mode is used for short wave broadcast service",
        "answers": [
            "Olivia",
            "MFSK"
        ],
        "model_ans": "AM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> AM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does cerebrospinal fluid flow to when it exits the cerebral aqueduct",
        "answers": [
            "the fourth ventricle",
            "fourth ventricle"
        ],
        "model_ans": "cisterna magna",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> cisterna magna </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how old is baby in dirty dancing movie",
        "answers": [
            "17-year-old",
            "17"
        ],
        "model_ans": "11",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 11 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did lord howe island became a world heritage site",
        "answers": [
            "in 1982",
            "1982"
        ],
        "model_ans": "1982",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1982 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which foreign currency option is the\u200b right but not the\u200b obligation to buy foreign\u200b currency",
        "answers": [
            "foreign exchange option"
        ],
        "model_ans": "Call Option",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Call Option </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in great british bake off 2017",
        "answers": [
            "10"
        ],
        "model_ans": "32\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "32\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first baseball player to be featured on a postage stamp",
        "answers": [
            "Jackie Robinson"
        ],
        "model_ans": "Babe Ruth",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Babe Ruth</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of car is a g wagon",
        "answers": [
            "Mercedes-Benz"
        ],
        "model_ans": "SUV",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> SUV </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the last time congress passed a complete budget",
        "answers": [
            "FY2010",
            "March 23, 2013"
        ],
        "model_ans": "1997\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1997\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when's the last time scotland won the calcutta cup",
        "answers": [
            "2018"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is dragon ball super episode 131 releasing",
        "answers": [
            "TBA",
            "March 25, 2018"
        ],
        "model_ans": "Not specified",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not specified </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang i knew the bride when she used to rock and roll",
        "answers": [
            "Dave Edmunds"
        ],
        "model_ans": "Billy Idol",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Billy Idol </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the term liberal arts come from",
        "answers": [
            "the Roman Empire"
        ],
        "model_ans": "Ancient Greece",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ancient Greece </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote when a man loves a woman",
        "answers": [
            "Calvin Lewis and Andrew Wright",
            "Calvin Lewis",
            "Percy Sledge",
            "Andrew Wright"
        ],
        "model_ans": "Sam Cooke",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sam Cooke </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the site of secretion of h+ and cl-",
        "answers": [
            "Parietal cells"
        ],
        "model_ans": "Stomach",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stomach </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the talismans in sailor moon s",
        "answers": [
            "Haruka and Michiru",
            "Haruka",
            "Michiru",
            "Sailor Pluto"
        ],
        "model_ans": "Luna",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Luna </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "tv show theme song would you like to swing on a star",
        "answers": [
            "Out of This World"
        ],
        "model_ans": "Bing Crosby",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bing Crosby </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are haploid cells found in the human body",
        "answers": [
            "sperm",
            "sperm or egg cells",
            "ova"
        ],
        "model_ans": "sperm cells",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sperm cells </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the three little pigs come out",
        "answers": [
            "first published in 1890",
            "1933",
            "c.1886",
            "1886"
        ],
        "model_ans": "1842",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1842 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the california gold rush take place",
        "answers": [
            "Northern California",
            "Sierra Nevada"
        ],
        "model_ans": "California",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many strong verbs are there in german",
        "answers": [
            "more than 200",
            "more than 200 strong"
        ],
        "model_ans": "1,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who invented the submarine during the civil war",
        "answers": [
            "Horace Lawson Hunley"
        ],
        "model_ans": "The Union",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Union </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won more grand slam titles in tennis",
        "answers": [
            "Roger Federer"
        ],
        "model_ans": "Roger Federer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Roger Federer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "chandra and bhaga river meets at the place",
        "answers": [
            "Tandi, in Lahaul",
            "at Tandi, in Lahaul"
        ],
        "model_ans": "Allahabad",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Allahabad </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the recipient of first jnanpith award was an author which language",
        "answers": [
            "Malayalam"
        ],
        "model_ans": "Hindi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hindi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the cast of despicable me 3",
        "answers": [
            "Steve Carell",
            "Nev Scharrel",
            "Miranda Cosgrove",
            "Pierre Coffin",
            "Kristen Wiig",
            "Trey Parker",
            "Andy Nyman",
            "Julie Andrews",
            "Steve Coogan",
            "Jenny Slate",
            "John Cygan",
            "Dana Gaier",
            "Adrian Ciscato"
        ],
        "model_ans": "Steve Carell, Kristen Wiig, Trey Parker, Miranda Cosgrove, Dana Gaier, Steve Coogan, Jenny Slate, and Pierre Coffin",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Steve Carell, Kristen Wiig, Trey Parker, Miranda Cosgrove, Dana Gaier, Steve Coogan, Jenny Slate, and Pierre Coffin </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the tigers name in life of pi",
        "answers": [
            "Richard Parker"
        ],
        "model_ans": "Richard Parker",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Parker </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the presiding officer of legislative council in india",
        "answers": [
            "Chairman"
        ],
        "model_ans": "Speaker",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speaker </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who will get ticket to finale in rising star 2",
        "answers": [
            "Hemant Brijwasi"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "referring to the organs of reproduction is called",
        "answers": [
            "Reproductive system"
        ],
        "model_ans": "genitalia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> genitalia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in which country were the two battles of el alamein fought",
        "answers": [
            "Egypt"
        ],
        "model_ans": "Egypt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Egypt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who invented the printing press and in what year",
        "answers": [
            "the German Johannes Gutenberg",
            "Johannes Gutenberg around 1440",
            "1440",
            "Johannes Gutenberg",
            "around 1440"
        ],
        "model_ans": "Johannes Gutenberg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Johannes Gutenberg</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the song always be humble and kind",
        "answers": [
            "Lori McKenna"
        ],
        "model_ans": "Taylor Swift",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Taylor Swift </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a drug that might be used in surgery for its amnesic properties is",
        "answers": [
            "benzodiazepines",
            "Benzodiazepines"
        ],
        "model_ans": "Ketamine",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ketamine </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time the womens hockey team won gold",
        "answers": [
            "2018"
        ],
        "model_ans": "2010",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2010 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "region of antarctica where march of the penguins filmed",
        "answers": [
            "Dumont d'Urville in Ad\u00e9lie Land",
            "Dumont d'Urville Station",
            "Ad\u00e9lie Land"
        ],
        "model_ans": "Terre Adelie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Terre Adelie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which film won the oscar for best animated feature in 2007",
        "answers": [
            "Ratatouille"
        ],
        "model_ans": "Happy Feet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Happy Feet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which episode does gideon die in criminal minds",
        "answers": [
            "\"Nelson's Sparrow\"",
            "Nelson's Sparrow"
        ],
        "model_ans": "Season 5, Episode 21",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 5, Episode 21 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the first line of an http request to the server",
        "answers": [
            "A request line",
            "the status line"
        ],
        "model_ans": "GET",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> GET </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when are the next commonwealth games going to be held",
        "answers": [
            "2022"
        ],
        "model_ans": "2026",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2026 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the multiplication sign on the computer",
        "answers": [
            "a rotationally symmetric saltire",
            "the symbol \u00d7",
            "*"
        ],
        "model_ans": "*",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> * </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which site of an enzyme is called allosteric site",
        "answers": [
            "regulatory site"
        ],
        "model_ans": "non-essential site",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> non-essential site </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the most world series in baseball",
        "answers": [
            "the New York Yankees",
            "New York Yankees"
        ],
        "model_ans": "New York Yankees",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York Yankees </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "towns on the border of texas and oklahoma",
        "answers": [
            "Texhoma"
        ],
        "model_ans": "Sherman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sherman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most rushing yards in a super bowl",
        "answers": [
            "Timmy Smith"
        ],
        "model_ans": "Franco Harris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Franco Harris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule",
        "answers": [
            "3-phosphoglycerate"
        ],
        "model_ans": "RuBP",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> RuBP </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who said that religion is the opiate of the masses",
        "answers": [
            "Karl Marx.",
            "Karl Marx"
        ],
        "model_ans": "Karl Marx",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Karl Marx </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which was the first village of karnataka which declared independence",
        "answers": [
            "Hyderabad"
        ],
        "model_ans": "Mysore",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mysore </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang once upon a dream at the end of maleficent",
        "answers": [
            "Lana Del Rey"
        ],
        "model_ans": "Lana Del Rey",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Lana Del Rey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was last person to be executed in us",
        "answers": [
            "Ruben Cardenas Ramirez"
        ],
        "model_ans": "Clayton Lockett",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Clayton Lockett </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the story the great gatsby take place",
        "answers": [
            "Long Island of 1922"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many scholarships do division 2 football teams get",
        "answers": [
            "36.0"
        ],
        "model_ans": "85",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 85 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who scored the most goals in premier league season",
        "answers": [
            "Alan Shearer",
            "Andy Cole",
            "Chelsea"
        ],
        "model_ans": "Alan Shearer",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alan Shearer </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings in cry baby for johnny depp",
        "answers": [
            "James Intveld"
        ],
        "model_ans": "Courtney Love",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Courtney Love </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who lived in jamestown before the arrival of the english",
        "answers": [
            "uninhabited"
        ],
        "model_ans": "Powhatan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Powhatan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the corporate tax rate in great britain",
        "answers": [
            "20%"
        ],
        "model_ans": "19%",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 19% </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i want to rock and roll",
        "answers": [
            "Kiss"
        ],
        "model_ans": "Led Zeppelin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Led Zeppelin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many seasons of the smurfs are there",
        "answers": [
            "9"
        ],
        "model_ans": "9",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 9 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song city of new orleans",
        "answers": [
            "Steve Goodman"
        ],
        "model_ans": "Arlo Guthrie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Arlo Guthrie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did i'm like a bird come out",
        "answers": [
            "October\u00a024,\u00a02000"
        ],
        "model_ans": "2004\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2004\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings god is great beer is good",
        "answers": [
            "Currington"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was night at the museum 3 filmed",
        "answers": [
            "British Columbia, Canada",
            "January to May 2014",
            "2014",
            "London, England",
            "from January to May 2014"
        ],
        "model_ans": "2013\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2013\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who added a press room to the white house",
        "answers": [
            "Richard Nixon",
            "President Richard Nixon"
        ],
        "model_ans": "Thomas Jefferson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Jefferson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first documented case of tool mark identification",
        "answers": [
            "1835"
        ],
        "model_ans": "1950s",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who did the 49ers beat in the super bowls",
        "answers": [
            "San Diego Chargers",
            "Denver Broncos",
            "Cincinnati Bengals",
            "Miami Dolphins"
        ],
        "model_ans": "20 times",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 times </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of dog is charkie from curious george",
        "answers": [
            "black cocker spaniel",
            "cocker spaniel"
        ],
        "model_ans": "Jack Russell Terrier",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jack Russell Terrier </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are mucosal associated lymphoid tissues present in the human body and why",
        "answers": [
            "oral passage",
            "salivary glands",
            "gastrointestinal tract",
            "breast",
            "skin",
            "thyroid",
            "lung",
            "nasopharyngeal tract",
            "eye"
        ],
        "model_ans": "Mucosal associated lymphoid tissues are present in the human body in the respiratory, gastrointestinal, and genitourinary tracts.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mucosal associated lymphoid tissues are present in the human body in the respiratory, gastrointestinal, and genitourinary tracts. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the roles of international monetary fund",
        "answers": [
            "foster global monetary cooperation",
            "secure financial stability",
            "to foster global monetary cooperation",
            "reduce poverty around the world",
            "facilitate international trade"
        ],
        "model_ans": "The International Monetary Fund (IMF) plays a crucial role in promoting international monetary cooperation, exchange rate stability, and economic growth.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The International Monetary Fund (IMF) plays a crucial role in promoting international monetary cooperation, exchange rate stability, and economic growth. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was 1 john 5 7 added to the bible",
        "answers": [
            "the 9th century"
        ],
        "model_ans": "2011",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2011 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the saskatchewan river start and end",
        "answers": [
            "central Saskatchewan",
            "the Hudson Bay",
            "Saskatchewan River Forks, Saskatchewan",
            "Saskatchewan Glacier, Alberta"
        ],
        "model_ans": "The Saskatchewan River starts at Lake Athabasca and ends at the Manitoba border, where it flows into Lake Winnipeg.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Saskatchewan River starts at Lake Athabasca and ends at the Manitoba border, where it flows into Lake Winnipeg. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "calpurnia son name in to kill a mockingbird",
        "answers": [
            "Zeebo",
            "James Zeebo"
        ],
        "model_ans": "Calpurnia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Calpurnia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what are the first and second major religions in france",
        "answers": [
            "Islam",
            "Catholicism",
            "Not religious",
            "Protestantism",
            "Christianity"
        ],
        "model_ans": "Catholicism and Islam",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Catholicism and Islam </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the plane of earth's orbit is called the",
        "answers": [
            "ecliptic"
        ],
        "model_ans": "ecliptic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ecliptic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is a another name for the water cycle",
        "answers": [
            "the hydrological cycle",
            "the hydrologic cycle",
            "hydrologic cycle",
            "hydrological cycle"
        ],
        "model_ans": "Hydrologic cycle",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hydrologic cycle </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the champions league round of 16 start",
        "answers": [
            "13 February"
        ],
        "model_ans": "February",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> February </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states",
        "answers": [
            "25"
        ],
        "model_ans": "23rd\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "23rd\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did a wrinkle in time start filming",
        "answers": [
            "November 2, 2016"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played mr. willoughby in sense and sensibility",
        "answers": [
            "Matthew Gregory Wise"
        ],
        "model_ans": "Greg Wise",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Greg Wise </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the men's single title of australia open on 1 february 2015",
        "answers": [
            "Djokovic",
            "Novak Djokovic"
        ],
        "model_ans": "Novak Djokovic",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Novak Djokovic </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does nathan get in a car accident",
        "answers": [
            "The Show Must Go On"
        ],
        "model_ans": "Season 2 Episode 5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 2 Episode 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the white stork a symbol for in western culture",
        "answers": [
            "bringing babies to new parents"
        ],
        "model_ans": "Purity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Purity </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who got the first arjun award in athletics",
        "answers": [
            "Gurbachan Singh Randhawa"
        ],
        "model_ans": "Milkha Singh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Milkha Singh </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings good night on the beatles white album",
        "answers": [
            "Ringo Starr"
        ],
        "model_ans": "The Beatles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Beatles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does season 5 of ruby come out",
        "answers": [
            "October 14, 2017",
            "October\u00a014,\u00a02017"
        ],
        "model_ans": "There is no information available about the release date of season 5 of Ruby",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no information available about the release date of season 5 of Ruby </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the winter olympic games being held this year",
        "answers": [
            "Pyeongchang County, South Korea"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "nitty gritty dirt band fishin in the dark album",
        "answers": [
            "Hold On"
        ],
        "model_ans": "Fishin' in the Dark",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fishin' in the Dark </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "nickname given to railroad executives due to shady practices of their businesses",
        "answers": [
            "Robber baron",
            "Robber Barons"
        ],
        "model_ans": "Robber Barons",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Robber Barons </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what was the first star trek enterprise ship",
        "answers": [
            "NCC-1701"
        ],
        "model_ans": "Enterprise",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Enterprise </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the full scientific name for the e. coli bacteria",
        "answers": [
            "Escherichia coli"
        ],
        "model_ans": "Escherichia coli",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Escherichia coli </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "rain sleet or snow that contains a high concentration of acids is called",
        "answers": [
            "Acid rain",
            "\"Acid rain\""
        ],
        "model_ans": "acid rain",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> acid rain </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who had won the first grammy award for the best new artist",
        "answers": [
            "Chance the Rapper",
            "Bobby Darin"
        ],
        "model_ans": "Ella Fitzgerald",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ella Fitzgerald </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the christmas tree at rockefeller center come from",
        "answers": [
            "State College, PA"
        ],
        "model_ans": "Germany",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Germany </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the new season of lost in space come out",
        "answers": [
            "April 13, 2018"
        ],
        "model_ans": "December 18, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 18, 2020 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the organ mountains in new mexico",
        "answers": [
            "southern New Mexico"
        ],
        "model_ans": "Organ Mountains",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Organ Mountains </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "creating appropriation bills falls under which power of congress",
        "answers": [
            "raising revenue"
        ],
        "model_ans": "legislative",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> legislative </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played the hobbits in the lord of the rings",
        "answers": [
            "Dominic Monaghan",
            "Ian Holm",
            "Sean Astin",
            "Elijah Wood as Frodo Baggins",
            "Billy Boyd",
            "Elijah Wood"
        ],
        "model_ans": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan, and Viggo Mortensen",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan, and Viggo Mortensen </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the usa join world war one",
        "answers": [
            "April 1917",
            "April 6, 1917",
            "in April 1917"
        ],
        "model_ans": "April 6, 1917",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> April 6, 1917 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they start 3 pointers in basketball",
        "answers": [
            "1961",
            "1945"
        ],
        "model_ans": "1946",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1946 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "through what process has the colorado river created the grand canyon in the usa",
        "answers": [
            "erosion"
        ],
        "model_ans": "erosion",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> erosion </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the rate limiting enzyme of kreb's cycle",
        "answers": [
            "Isocitrate dehydrogenase"
        ],
        "model_ans": "Citrate synthase",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Citrate synthase </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "term limits for house of representatives and senate",
        "answers": [
            "Unlimited six-year terms",
            "Unlimited two-year terms"
        ],
        "model_ans": "6 years for Senate, 2 years for House",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 6 years for Senate, 2 years for House </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what information is displayed in clear text from the ftp header",
        "answers": [
            "all transmissions"
        ],
        "model_ans": "FTP commands",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> FTP commands </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most big ten championships in football",
        "answers": [
            "Michigan"
        ],
        "model_ans": "Ohio State",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ohio State </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does ss stand for on naval ships",
        "answers": [
            "Single-screw Steamship"
        ],
        "model_ans": "Submarine",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Submarine </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which hormone is released from the ruptured follicle or corpus luteum",
        "answers": [
            "estrogen",
            "estradiol",
            "inhibin A",
            "progesterone"
        ],
        "model_ans": "Progesterone",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Progesterone </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where do the elves go on the boat in lord of the rings",
        "answers": [
            "Valinor"
        ],
        "model_ans": "Rivendell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rivendell </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times has psg won champions league",
        "answers": [
            "46"
        ],
        "model_ans": "2\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did ga state get a football team",
        "answers": [
            "2010"
        ],
        "model_ans": "1993",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1993 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the mens singles title in the australian open tennis tournament",
        "answers": [
            "Roger Federer"
        ],
        "model_ans": "Novak Djokovic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Novak Djokovic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the longest english word in the dictionary",
        "answers": [
            "Methionylglutaminylarginyltyrosylglutamyl...serine",
            "pneumonoultramicroscopicsilicovolcanoconiosis",
            "Pneumonoultramicroscopicsilicovolcanoconiosis"
        ],
        "model_ans": "pneumonoultramicroscopicsilicovolcanoconiosis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> pneumonoultramicroscopicsilicovolcanoconiosis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "in which city are the wimbledon game held",
        "answers": [
            "London",
            "Wimbledon, London"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the oscar for best actor when titanic was nominated",
        "answers": [
            "Jack Nicholson"
        ],
        "model_ans": "Jack Nicholson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Jack Nicholson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did australia 2 win the america's cup",
        "answers": [
            "1983"
        ],
        "model_ans": "1983",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1983 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many points did lebron james scored in his career",
        "answers": [
            "31,038"
        ],
        "model_ans": "35,237",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 35,237 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does sound travel fastest solid liquid or gas",
        "answers": [
            "solids"
        ],
        "model_ans": "gas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> gas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "cat in the hat knows a lot about space movie",
        "answers": [
            "Space is the Place"
        ],
        "model_ans": "The Cat in the Hat Knows a Lot About Space!",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Cat in the Hat Knows a Lot About Space! </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang on the back in black album",
        "answers": [
            "Brian Johnson",
            "Malcolm Young",
            "Cliff Williams"
        ],
        "model_ans": "AC/DC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> AC/DC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the race in grease take place",
        "answers": [
            "Thunder Road"
        ],
        "model_ans": "Rydell High School",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rydell High School </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what year did bennie and the jets come out",
        "answers": [
            "in 1973",
            "4 February 1974",
            "1974",
            "1973"
        ],
        "model_ans": "1975\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1975\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the witch and the hundred knight 2 us release",
        "answers": [
            "March 27, 2018",
            "March 2018"
        ],
        "model_ans": "N/A",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> N/A </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays jack skellington in nightmare before christmas",
        "answers": [
            "Danny Elfman",
            "Chris Sarandon"
        ],
        "model_ans": "Chris Sarandon",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Chris Sarandon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the denver nuggets made the playoffs",
        "answers": [
            "2012\u201313",
            "2009\u201310",
            "1994\u201395"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the winner of the first indianapolis 500",
        "answers": [
            "Ray Harroun"
        ],
        "model_ans": "Ray Harroun\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " Ray Harroun\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when will the next episode of my next guest needs no introduction",
        "answers": [
            "May 31, 2018"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name hidalgo come from",
        "answers": [
            "Spanish"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where in the bible is the book of revelation",
        "answers": [
            "last book",
            "in the New Testament"
        ],
        "model_ans": "Revelation",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Revelation </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has played in the most premier league derbies",
        "answers": [
            "Neville Southall"
        ],
        "model_ans": "Jamie Carragher",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jamie Carragher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has become the new chairman of sebi",
        "answers": [
            "Ajay Tyagi"
        ],
        "model_ans": "Ajay Tyagi",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Ajay Tyagi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who present the central budget in lok sabha",
        "answers": [
            "the Finance Minister of India"
        ],
        "model_ans": "Finance Minister",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Finance Minister </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is an example of a government monopoly in the united states",
        "answers": [
            "West Virginia American Water",
            "State Bar of Arizona"
        ],
        "model_ans": "United States Postal Service",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States Postal Service </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did world war one begin and end",
        "answers": [
            "28 July 1914",
            "11 November 1918"
        ],
        "model_ans": "World War I began on July 28, 1914, and ended on November 11, 1918",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> World War I began on July 28, 1914, and ended on November 11, 1918 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played ethel on the doris day show",
        "answers": [
            "Carol Worthington"
        ],
        "model_ans": "Anne Whitney",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anne Whitney </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote somewhere there's a place for us",
        "answers": [
            "Stephen Sondheim",
            "lyrics by Stephen Sondheim",
            "Leonard Bernstein"
        ],
        "model_ans": "Sade",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sade </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the peanut butter jelly time song come from",
        "answers": [
            "Buckwheat Boyz",
            "The Buckwheat Boyz"
        ],
        "model_ans": "The song \"Peanut Butter Jelly Time\" was written by the American rock band Buckwheat Boyz",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The song \"Peanut Butter Jelly Time\" was written by the American rock band Buckwheat Boyz </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the jewish man in coming to america",
        "answers": [
            "Eddie Murphy"
        ],
        "model_ans": "Eddie Murphy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eddie Murphy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who talks for belle in beauty and the beast",
        "answers": [
            "Julie Nathanson",
            "Jodi Benson",
            "Paige O'Hara"
        ],
        "model_ans": "Belle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Belle</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has a ring of power in lotr",
        "answers": [
            "Sauron"
        ],
        "model_ans": "Jean-Luc Picard",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jean-Luc Picard</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who introduced the first chrismas tree to the uk",
        "answers": [
            "Charlotte of Mecklenburg-Strelitz"
        ],
        "model_ans": "Prince Albert",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prince Albert </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many writes does a flash drive have",
        "answers": [
            "up to 100,000"
        ],
        "model_ans": "1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the inner core of the earth made from",
        "answers": [
            "some other elements",
            "iron\u2013nickel alloy",
            "an iron\u2013nickel alloy"
        ],
        "model_ans": "Iron",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Iron </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes is season 4 of the flash",
        "answers": [
            "23 episodes",
            "19",
            "23"
        ],
        "model_ans": "22\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "22\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays in the new mary poppins movie",
        "answers": [
            "Meryl Streep",
            "Nathanael Saleh",
            "Emily Blunt",
            "Colin Firth",
            "Joel Dawson",
            "Emily Mortimer",
            "Lin-Manuel Miranda",
            "Ben Whishaw",
            "Pixie Davies",
            "Julie Walters"
        ],
        "model_ans": "Emily Blunt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Emily Blunt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the old man and the sea page count",
        "answers": [
            "127"
        ],
        "model_ans": "127 pages\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "127 pages\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "mount and blade with fire and sword time period",
        "answers": [
            "1648-51"
        ],
        "model_ans": "medieval",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> medieval </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "nearest metro station to gandhi nagar in delhi",
        "answers": [
            "Shastri Park metro station"
        ],
        "model_ans": "Rajouri Garden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rajouri Garden </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was looking for a sunset bird in winter written",
        "answers": [
            "1923"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are the winter olympic games being played",
        "answers": [
            "Beijing"
        ],
        "model_ans": "Beijing",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beijing </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why was the plague that struck athens so devastating",
        "answers": [
            "close quarters and poor hygiene"
        ],
        "model_ans": "The plague was devastating because it was caused by the bacterium Yersinia pestis, which was spread through the bites of infected fleas that lived on rats and other rodents.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The plague was devastating because it was caused by the bacterium Yersinia pestis, which was spread through the bites of infected fleas that lived on rats and other rodents. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "baseball teams who have not won a world series",
        "answers": [
            "Washington Nationals",
            "Tampa Bay Rays",
            "San Diego Padres",
            "Milwaukee Brewers",
            "Seattle Mariners",
            "Texas Rangers",
            "Colorado Rockies"
        ],
        "model_ans": "12 teams",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 teams </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote ain't living long like this",
        "answers": [
            "Rodney Crowell"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what group of animals do octopus belong to",
        "answers": [
            "class Cephalopoda"
        ],
        "model_ans": "Mollusca",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mollusca </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the new football stadium in atlanta",
        "answers": [
            "Mercedes-Benz Stadium"
        ],
        "model_ans": "Mercedes-Benz Stadium",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mercedes-Benz Stadium </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last god of war made",
        "answers": [
            "2018",
            "March 12, 2013"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the zords in the power rangers movie",
        "answers": [
            "animal-themed Ninja Zords"
        ],
        "model_ans": "Megazord",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Megazord </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "why the hole in the ozone layer over antarctica",
        "answers": [
            "bromine",
            "chlorine",
            "methyl bromide",
            "CFCs",
            "halons"
        ],
        "model_ans": "Chlorofluorocarbons (CFCs)",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Chlorofluorocarbons (CFCs) </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name waller come from",
        "answers": [
            "Anglo-Saxon origin"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the music phantom of the opera",
        "answers": [
            "Andrew Lloyd Webber"
        ],
        "model_ans": "Andrew Lloyd Webber",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Lloyd Webber </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when's the last time michigan won a national championship in basketball",
        "answers": [
            "1989"
        ],
        "model_ans": "1989",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1989 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the icc under 19 world cup 2018",
        "answers": [
            "West Indies",
            "India"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "in the honour of which god is anant chaturdashi celebrated",
        "answers": [
            "Ganesh"
        ],
        "model_ans": "Lord Vishnu",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lord Vishnu </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the us stop trading with japan",
        "answers": [
            "1939",
            "1940"
        ],
        "model_ans": "1941\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1941\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what territory is spain and the united kingdom in a dispute over",
        "answers": [
            "Gibraltar"
        ],
        "model_ans": "Gibraltar",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gibraltar </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was you'll never walk alone first released",
        "answers": [
            "1945"
        ],
        "model_ans": "1965",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1965 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "atlantic ocean's shape is similar to which english alphabet",
        "answers": [
            "S"
        ],
        "model_ans": "S",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> S </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the titanic sink at what ocean",
        "answers": [
            "North Atlantic Ocean"
        ],
        "model_ans": "North Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "dogs name in the grinch who stole christmas",
        "answers": [
            "Max"
        ],
        "model_ans": "Max",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Max </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many gold medals won by india in 2018 commonwealth games",
        "answers": [
            "26",
            "66"
        ],
        "model_ans": "66\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "66\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "civil war what did the north fight for",
        "answers": [
            "maintaining the republic",
            "loyalty to the U.S. Constitution"
        ],
        "model_ans": "Union",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Union </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the next episode of rebels come out",
        "answers": [
            "February 19, 2018"
        ],
        "model_ans": "The next episode of Rebels is scheduled to air on March 17, 2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The next episode of Rebels is scheduled to air on March 17, 2018 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who dies in transformers revenge of the fallen",
        "answers": [
            "Ravage and the Decepticon Rampage",
            "Jetfire"
        ],
        "model_ans": "Jazz",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jazz </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "perth is the capital of which australian state",
        "answers": [
            "Western Australia"
        ],
        "model_ans": "Western Australia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Western Australia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who gets the golden boot if its a tie",
        "answers": [
            "shared"
        ],
        "model_ans": "The players who have scored the same number of goals",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The players who have scored the same number of goals </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "three movies made from agatha christie's novels",
        "answers": [
            "Alibi",
            "Die Abenteurer G.m.b.H.",
            "The Passing of Mr. Quinn"
        ],
        "model_ans": "Murder on the Orient Express, Death on the Nile, and Evil Under the Sun",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Murder on the Orient Express, Death on the Nile, and Evil Under the Sun </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does a cell have condensed visible chromosomes also known as sister chromatids",
        "answers": [
            "metaphase"
        ],
        "model_ans": "during mitosis",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> during mitosis </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "is greenland part of europe or north america",
        "answers": [
            "North America"
        ],
        "model_ans": "Europe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Europe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the boiling point of water is 100 degrees celsius express this in si units",
        "answers": [
            "100\u00a0\u00b0C"
        ],
        "model_ans": "100 degrees Celsius is equal to 100 degrees Celsius in SI units.\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "100 degrees Celsius is equal to 100 degrees Celsius in SI units.\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what's the nba record for most points in a half",
        "answers": [
            "59"
        ],
        "model_ans": "89",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 89 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name tavarez come from",
        "answers": [
            "Spanish"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who owns and operates the panama canal today",
        "answers": [
            "Panama Canal Authority",
            "Panamanian government",
            "Panama"
        ],
        "model_ans": "Panama",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Panama </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the vast interior rural area of australia is known as the",
        "answers": [
            "The Outback",
            "Outback"
        ],
        "model_ans": "Outback",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Outback </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings god gave rock and roll to you",
        "answers": [
            "the British band Argent",
            "Petra",
            "Kiss"
        ],
        "model_ans": "The Mamas & The Papas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Mamas & The Papas </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who shot first in the shot heard around the world",
        "answers": [
            "Americans acting under orders"
        ],
        "model_ans": "British",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> British </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the 2017 mens singles mutua madrid open tennis",
        "answers": [
            "Rafael Nadal"
        ],
        "model_ans": "Rafael Nadal",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rafael Nadal </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "method used by a writer to develop a character",
        "answers": [
            "Anthropomorphism",
            "Personification",
            "Hamartia",
            "Pathetic fallacy"
        ],
        "model_ans": "Characterization",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Characterization </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did linkin park release one more light",
        "answers": [
            "May 19, 2017"
        ],
        "model_ans": "2017\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2017\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "created propaganda to support the war effort & encourage the sale of war bonds",
        "answers": [
            "the government"
        ],
        "model_ans": "J. Howard Miller",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> J. Howard Miller </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what us state forms the western boundary of montana",
        "answers": [
            "Idaho"
        ],
        "model_ans": "Idaho",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Idaho </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the edinburgh fringe festival take place",
        "answers": [
            "in Edinburgh, Scotland"
        ],
        "model_ans": "Edinburgh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Edinburgh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "first dynasty to issue gold coins in india",
        "answers": [
            "The Gupta Empire"
        ],
        "model_ans": "Mauryan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mauryan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many games does a football team have to win to be bowl eligible",
        "answers": [
            "5"
        ],
        "model_ans": "6\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "6\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the journey start in the canterbury tales",
        "answers": [
            "London"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the first time lebron went to the finals",
        "answers": [
            "2007"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has made the most premier league appearances",
        "answers": [
            "Gareth Barry"
        ],
        "model_ans": "Gareth Barry",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gareth Barry </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time it snowed in england on christmas day",
        "answers": [
            "2009"
        ],
        "model_ans": "2010\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2010\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first star wars film released",
        "answers": [
            "1977",
            "May\u00a025,\u00a01977"
        ],
        "model_ans": "1977\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1977\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does the movie the star come out",
        "answers": [
            "November 17, 2017"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who carried florida by 537 votes in 2000",
        "answers": [
            "George W. Bush",
            "Bush"
        ],
        "model_ans": "Bush",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bush</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "first who wants to be a millionaire winner uk",
        "answers": [
            "Judith Cynthia Aline Keppel"
        ],
        "model_ans": "Paddy McGuinness",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paddy McGuinness </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "actor who played caesar in dawn of the planet of the apes",
        "answers": [
            "Andy Serkis"
        ],
        "model_ans": "Andy Serkis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andy Serkis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does wentworth season 6 start in australia",
        "answers": [
            "2019",
            "19 June 2018"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the north pole on the world map",
        "answers": [
            "latitude 90\u00b0 North"
        ],
        "model_ans": "Arctic",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arctic </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played sam in clarissa explains it all",
        "answers": [
            "Sean O'Neal"
        ],
        "model_ans": "Jason Zimbler",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jason Zimbler </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did puss in boots grew up with",
        "answers": [
            "Humpty Dumpty",
            "Kitty Softpaws",
            "Humpty Alexander Dumpty"
        ],
        "model_ans": "Humpty Dumpty",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Humpty Dumpty </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who commissioned the first christmas card in 1943",
        "answers": [
            "Sir Henry Cole"
        ],
        "model_ans": "Henry Cole",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry Cole </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who can be called a man of god",
        "answers": [
            "beloved religious leaders",
            "prophets"
        ],
        "model_ans": "Jesus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jesus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what nfl player has the most nfl rings",
        "answers": [
            "Charles Haley",
            "Neal Dahlen",
            "Bill Belichick",
            "Tom Brady",
            "\"Mean Joe\" Greene"
        ],
        "model_ans": "Tom Brady",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Brady </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "most passing yards by nfl qb in a game",
        "answers": [
            "Norm Van Brocklin",
            "554"
        ],
        "model_ans": "Norm Van Brocklin",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Norm Van Brocklin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings jungle book i wanna be like you",
        "answers": [
            "Louis Prima.",
            "Louis Prima"
        ],
        "model_ans": "Jungle Book",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jungle Book</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the new pete's dragon filmed",
        "answers": [
            "New Zealand"
        ],
        "model_ans": "Sydney",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sydney </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "total goals scored by ronaldo in la liga",
        "answers": [
            "309"
        ],
        "model_ans": "311\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "311\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who's opening for foo fighters at fenway",
        "answers": [
            "N/A"
        ],
        "model_ans": "The Pretenders",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Pretenders </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the eagles last play in a superbowl",
        "answers": [
            "2017 season"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did south sudan join east african community",
        "answers": [
            "April 2016",
            "2016"
        ],
        "model_ans": "2016",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the nfl start playing in london",
        "answers": [
            "since 2007",
            "October 28, 2007",
            "2007"
        ],
        "model_ans": "2007\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2007\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the world's tallest jain statue is located in which state of india",
        "answers": [
            "Maharashtra"
        ],
        "model_ans": "Gujarat",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gujarat </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who said beware of the ides of march",
        "answers": [
            "the soothsayer",
            "a seer",
            "a haruspex named Spurinna"
        ],
        "model_ans": "Julius Caesar",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Julius Caesar </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do the maple leafs play hockey in toronto",
        "answers": [
            "Air Canada Centre",
            "the Air Canada Centre"
        ],
        "model_ans": "Scotiabank Arena",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scotiabank Arena </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what kind of dog is nana in snow dogs",
        "answers": [
            "a Border Collie",
            "Border Collie"
        ],
        "model_ans": "Siberian Husky",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Siberian Husky </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did hyderabad became a part of india",
        "answers": [
            "24 November 1949"
        ],
        "model_ans": "1947",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1947 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made possible the first reproduction of the human voice on the phonograph",
        "answers": [
            "Thomas Alva Edison",
            "Thomas Edison"
        ],
        "model_ans": "Thomas Edison",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Edison </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does wonder woman come out on blue ray",
        "answers": [
            "September 19, 2017"
        ],
        "model_ans": "Wonder Woman (2017) was released on Blu-ray on December 19, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Wonder Woman (2017) was released on Blu-ray on December 19, 2017 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang i dreamed a dream in les miserables",
        "answers": [
            "Rose Laurens",
            "Fantine",
            "the character Fantine"
        ],
        "model_ans": "Colm Wilkinson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Colm Wilkinson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what time is it in alaska time zone",
        "answers": [
            "UTC\u221209:00"
        ],
        "model_ans": "12 hours behind UTC",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12 hours behind UTC </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is winter big brother going to start",
        "answers": [
            "February 7, 2018"
        ],
        "model_ans": "January 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the nfl game in london played",
        "answers": [
            "Twickenham Stadium",
            "Wembley Stadium"
        ],
        "model_ans": "Wembley Stadium",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Wembley Stadium </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the quarterback for the green bay packers",
        "answers": [
            "Aaron Rodgers"
        ],
        "model_ans": "Aaron Rodgers",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aaron Rodgers </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played the face in the a team",
        "answers": [
            "Dirk Benedict"
        ],
        "model_ans": "Bradley Cooper",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bradley Cooper </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the battle of bonhomme richard take place",
        "answers": [
            "near Flamborough Head"
        ],
        "model_ans": "New York",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time that the eagles were at the super bowl",
        "answers": [
            "2017",
            "2017 season"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the original singer of fool if you think it's over",
        "answers": [
            "Chris Rea"
        ],
        "model_ans": "Joss Stone",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joss Stone </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who stars in kevin probably save the world",
        "answers": [
            "J. August Richards",
            "Kimberly Hebert Gregory",
            "India de Beaufort",
            "Jason Ritter",
            "Chloe East",
            "JoAnna Garcia Swisher",
            "Dustin Ybarra"
        ],
        "model_ans": "Jim Parsons",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jim Parsons </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is in a pat o brien hurricane",
        "answers": [
            "fruit juice",
            "syrup or grenadine",
            "rum"
        ],
        "model_ans": "Rum",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rum </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did the us share the oregon country with",
        "answers": [
            "French Canadian",
            "British"
        ],
        "model_ans": "Britain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Britain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is eliminated in big boss kannada 5",
        "answers": [
            "Shruti",
            "Niveditha",
            "Diwakar"
        ],
        "model_ans": "Niveditha Gowda",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Niveditha Gowda </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won la liga in the last 10 years",
        "answers": [
            "Real Madrid",
            "Barcelona",
            "Atl\u00e9tico Madrid"
        ],
        "model_ans": "Barcelona",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Barcelona </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has played in the most masters tournaments",
        "answers": [
            "Gary Player"
        ],
        "model_ans": "Juan Carlos Formella",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Juan Carlos Formella</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did beryl markham fly across the atlantic",
        "answers": [
            "September 1936",
            "4 September 1936"
        ],
        "model_ans": "1936\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1936\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are some special products made in mississippi",
        "answers": [
            "farm-raised catfish"
        ],
        "model_ans": "catfish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> catfish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many numbers are in the euromillions draw",
        "answers": [
            "7"
        ],
        "model_ans": "50\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "50\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the heart of palm on a palm tree",
        "answers": [
            "inner core and growing bud",
            "the inner core",
            "growing bud",
            "the center core"
        ],
        "model_ans": "center",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> center </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who enforces the charter of rights and freedoms",
        "answers": [
            "Supreme Court of Canada",
            "the courts",
            "courts",
            "The courts"
        ],
        "model_ans": "Supreme Court of Canada",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Supreme Court of Canada </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the buccaneers qb when they won the superbowl",
        "answers": [
            "Brad Johnson"
        ],
        "model_ans": "Brad Johnson",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Brad Johnson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes in season 3 of good witch",
        "answers": [
            "10"
        ],
        "model_ans": "13\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "13\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was theme from a summer place released",
        "answers": [
            "1960",
            "1959",
            "September 1959"
        ],
        "model_ans": "1959",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1959 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the two extracellular fluid compartments in the body",
        "answers": [
            "transcellular",
            "intravascular",
            "interstitial"
        ],
        "model_ans": "Intravascular and interstitial",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Intravascular and interstitial </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "in 1945 which party came into power in england",
        "answers": [
            "Labour Party",
            "Conservative",
            "Labour"
        ],
        "model_ans": "Labour",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Labour </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the best director in bollywood 2017",
        "answers": [
            "Nitesh Tiwari"
        ],
        "model_ans": "Neeraj Ghaywan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Neeraj Ghaywan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the population of keystone heights florida",
        "answers": [
            "1,350",
            "1,461"
        ],
        "model_ans": "16,111",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16,111 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the term sustainability start to be used",
        "answers": [
            "1987"
        ],
        "model_ans": "1987",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1987 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the cowboys start playing on thanksgiving day",
        "answers": [
            "In 1966",
            "1966",
            "1978"
        ],
        "model_ans": "1920",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1920 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played emma in h2o just add water",
        "answers": [
            "Claire Rhiannon Holt"
        ],
        "model_ans": "Claire Holt",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Claire Holt </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what does fancy dress mean in the uk",
        "answers": [
            "A costume",
            "guests dress up in costumes",
            "costumes"
        ],
        "model_ans": "costume",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> costume </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the new tappan zee bridge going to be finished",
        "answers": [
            "by June 15, 2018",
            "June 15, 2018"
        ],
        "model_ans": "2025",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2025 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the 5 pillars of faith of islam",
        "answers": [
            "concern for the needy",
            "the pilgrimage",
            "life",
            "self-purification",
            "prayer"
        ],
        "model_ans": "Shahada, Salat, Zakat, Sawm, Hajj",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shahada, Salat, Zakat, Sawm, Hajj </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does i'm a celebrity get me out of here start in the uk",
        "answers": [
            "2018"
        ],
        "model_ans": "June",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays meredith quill in guardians of the galaxy 2",
        "answers": [
            "Laura Jane Haddock"
        ],
        "model_ans": "Karen Gillan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Karen Gillan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many terms can a mayor serve in texas",
        "answers": [
            "two four-year terms"
        ],
        "model_ans": "2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first time the internet was used",
        "answers": [
            "1969",
            "November 22, 1977"
        ],
        "model_ans": "1983\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1983\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote hallelujah i just love her so",
        "answers": [
            "Ray Charles"
        ],
        "model_ans": "Leonard Cohen",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Leonard Cohen </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the oldest man elected president of usa",
        "answers": [
            "Ronald Reagan",
            "Donald Trump"
        ],
        "model_ans": "Joe Biden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joe Biden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where will the cricket world cup 2019 be held",
        "answers": [
            "England and Wales"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who painted the ceiling of the florence cathedral",
        "answers": [
            "Giorgio Vasari",
            "Federico Zuccari",
            "Giorgio Vasari and Federico Zuccari"
        ],
        "model_ans": "Brunelleschi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brunelleschi</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "author of the hymn great is thy faithfulness",
        "answers": [
            "William M. Runyan",
            "written by Thomas Chisholm",
            "Thomas Chisholm"
        ],
        "model_ans": "Thomas Oden",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Thomas Oden </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does sleeping freshmen never lie take place",
        "answers": [
            "J.P. Zenger High"
        ],
        "model_ans": "Tokyo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tokyo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "word that means separation of church and state",
        "answers": [
            "separationism"
        ],
        "model_ans": "secularism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> secularism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "actor who plays dr avery on grey's anatomy",
        "answers": [
            "Jesse Wesley Williams"
        ],
        "model_ans": "Jesse Williams",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jesse Williams</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does season 13 of america's got talent premiere",
        "answers": [
            "May 29, 2018"
        ],
        "model_ans": "June 1, 2021",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 1, 2021 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which animal on earth has the longest life span",
        "answers": [
            "tortoise"
        ],
        "model_ans": "Turritopsis dohrnii",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Turritopsis dohrnii </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was held the first session of muslim league",
        "answers": [
            "Dhaka, Bangladesh",
            "Lucknow"
        ],
        "model_ans": "Dhaka",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dhaka </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who does the democratic republic of congo trade with",
        "answers": [
            "Group of 77",
            "WTO",
            "Zimbabwe",
            "Belgium",
            "SADC",
            "Kenya",
            "South Africa",
            "China",
            "AU",
            "Zambia",
            "IMF",
            "World Bank",
            "African Development Bank",
            "France"
        ],
        "model_ans": "China",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> China </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of india 29 state",
        "answers": [
            "Rajasthan"
        ],
        "model_ans": "29 states of India are: Andhra Pradesh, Arunachal Pradesh, Assam, Bihar, Chhattisgarh, Goa, Gujarat, Haryana, Himachal Pradesh, Jammu and Kashmir, Jharkhand, Karnataka</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "29 states of India are: Andhra Pradesh, Arunachal Pradesh, Assam, Bihar, Chhattisgarh, Goa, Gujarat, Haryana, Himachal Pradesh, Jammu and Kashmir, Jharkhand, Karnataka</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time miss texas won miss america",
        "answers": [
            "1975"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what new deal program limited production in industry",
        "answers": [
            "National Industrial Recovery Act",
            "NIRA"
        ],
        "model_ans": "NIRA",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> NIRA </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who beat university of virginia in basketball this year",
        "answers": [
            "Virginia Tech",
            "UMBC",
            "West Virginia"
        ],
        "model_ans": "Virginia Tech",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Virginia Tech </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "two atoms of the same element that are covalently bonded",
        "answers": [
            "shared pairs or bonding pairs"
        ],
        "model_ans": "molecule",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> molecule </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is don quixote's horse's name",
        "answers": [
            "Rocinante"
        ],
        "model_ans": "Rocinante",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rocinante </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played morticia in the addams family tv show",
        "answers": [
            "Carolyn Sue Jones"
        ],
        "model_ans": "Carolyn Jones",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carolyn Jones </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was pac man released in the us",
        "answers": [
            "October 26, 1980",
            "October 1980",
            "in October 1980"
        ],
        "model_ans": "1982\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1982\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how much is the united states in debt to china",
        "answers": [
            "$1.06 trillion",
            "1,200.5"
        ],
        "model_ans": "1.1 trillion",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1.1 trillion </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which type of hematoma is a result of torn bridging meningeal veins",
        "answers": [
            "A subdural hematoma",
            "subdural hematoma (SDH)",
            "subdural hematoma"
        ],
        "model_ans": "epidural hematoma",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> epidural hematoma </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang i'm gonna run away from you",
        "answers": [
            "Tami Lynn"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what kind of sentence contains an independent clause and a dependent clause",
        "answers": [
            "A complex sentence",
            "complex sentence"
        ],
        "model_ans": "Complex sentence",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Complex sentence </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did remember the titans camp take place",
        "answers": [
            "Gettysburg College"
        ],
        "model_ans": "Rock Hill",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rock Hill </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "criminal minds episode where jj becomes a profiler",
        "answers": [
            "season seven premiere",
            "The season seven premiere"
        ],
        "model_ans": "\"The Fisher King\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \"The Fisher King\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the most fundamental unit of life according to the cell theory",
        "answers": [
            "cells"
        ],
        "model_ans": "cell",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cell </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many national parks are present in india",
        "answers": [
            "103"
        ],
        "model_ans": "104",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 104 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the remake of wake in fright filmed",
        "answers": [
            "Broken",
            "Broken Hill",
            "Broken Hill and Sydney"
        ],
        "model_ans": "Adelaide",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Adelaide </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the atomic number of indium which belongs to 5th period is",
        "answers": [
            "49"
        ],
        "model_ans": "49\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "49\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "bowler to take hattrick in both inning in test match",
        "answers": [
            "leg spinner Jimmy Matthews",
            "Jimmy Matthews"
        ],
        "model_ans": "Richard Hadlee",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Richard Hadlee </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the synthesis of new dna from existing dna occurs",
        "answers": [
            "origins of replication"
        ],
        "model_ans": "nucleus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nucleus </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the prosecutor on law and order svu",
        "answers": [
            "Ra\u00fal Eduardo Esparza"
        ],
        "model_ans": "Sam Waterston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sam Waterston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the ship hector arrived in pictou",
        "answers": [
            "1773"
        ],
        "model_ans": "1819",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1819 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the mom on the tv show mom",
        "answers": [
            "Allison Janney",
            "Anna Faris"
        ],
        "model_ans": "Allison Janney",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Allison Janney </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the song the joker come out",
        "answers": [
            "1973",
            "October 1973"
        ],
        "model_ans": "1962\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1962\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is bigg boss tamil house is located",
        "answers": [
            "Chennai"
        ],
        "model_ans": "Chennai",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chennai </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote yakkity yak don't talk back",
        "answers": [
            "Jerry Leiber and Mike Stoller",
            "Jerry Leiber",
            "Mike Stoller"
        ],
        "model_ans": "Jimmy Soul",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jimmy Soul </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played doctor smith in lost in space",
        "answers": [
            "Jonathan Harris"
        ],
        "model_ans": "Jonathan Harris",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jonathan Harris </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won the ncaa basketball championship in 1994",
        "answers": [
            "Arkansas",
            "Arkansas Razorbacks"
        ],
        "model_ans": "Arkansas Razorbacks",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Arkansas Razorbacks </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the original flight of the phoenix filmed",
        "answers": [
            "20th Century-Fox Studios",
            "Buttercup Valley, Arizona",
            "Pilot Knob Mesa, California"
        ],
        "model_ans": "Berlin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Berlin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what nba team did derrick rose play for",
        "answers": [
            "Minnesota Timberwolves",
            "Cleveland Cavaliers",
            "New York Knicks",
            "Chicago Bulls"
        ],
        "model_ans": "Chicago Bulls",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago Bulls </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "points outside the production possibilities curve represent combinations of products that are",
        "answers": [
            "unattainable"
        ],
        "model_ans": "impossible",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> impossible </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is dancing on ice filmed this year",
        "answers": [
            "RAF Bovingdon"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "another name for a hairpin bend crossword clue",
        "answers": [
            "hairpin bend",
            "switchback",
            "hairpin corner",
            "switchbacks"
        ],
        "model_ans": "HOG",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> HOG </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the theme song for laverne and shirley",
        "answers": [
            "Cyndi Grecco"
        ],
        "model_ans": "Penny Marshall",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Penny Marshall </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the dallas cowboys playing on thanksgiving",
        "answers": [
            "Los Angeles Chargers",
            "the Detroit Lions"
        ],
        "model_ans": "The Washington Redskins",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Washington Redskins </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "a request to the supreme court that it review a case that was already decided is made via a(n)",
        "answers": [
            "a writ of certiorari",
            "writ of certiorari"
        ],
        "model_ans": "petition for certiorari",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> petition for certiorari </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the last volcano erupt in iceland",
        "answers": [
            "2010"
        ],
        "model_ans": "2021\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2021\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what nfl team is robert griffin the third playing for",
        "answers": [
            "currently a free agent"
        ],
        "model_ans": "Washington Redskins",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Washington Redskins </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the united states fight in the war of 1812",
        "answers": [
            "United Kingdom"
        ],
        "model_ans": "Great Britain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Great Britain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "india's first arctic research station set up in 2008 what is the name",
        "answers": [
            "Himadri Station"
        ],
        "model_ans": "Himadri",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Himadri </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "name of black man in to kill a mockingbird",
        "answers": [
            "Thomas \"Tom\" Robinson",
            "Tom Robinson"
        ],
        "model_ans": "Tom Robinson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tom Robinson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "why does cooling water run through the condenser",
        "answers": [
            "condense the steam"
        ],
        "model_ans": "to remove heat from the steam",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> to remove heat from the steam </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of son of lord krishna",
        "answers": [
            "Pradyumna"
        ],
        "model_ans": "Pradyumna",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Pradyumna </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what nfl team has the most expensive super bowl ring",
        "answers": [
            "the New England Patriots",
            "New England Patriots"
        ],
        "model_ans": "Dallas Cowboys",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Dallas Cowboys </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings i'm going to soak up the sun",
        "answers": [
            "Kidz Bop Kids",
            "American artist Sheryl Crow",
            "backing vocals by Liz Phair",
            "Sheryl Crow"
        ],
        "model_ans": "Sheryl Crow",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sheryl Crow </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does rt mean on a dodge car",
        "answers": [
            "Road/Track"
        ],
        "model_ans": "Rallye Touring",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rallye Touring </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does water come from in new york city",
        "answers": [
            "The Catskill Aqueduct",
            "The Delaware Aqueduct",
            "The New Croton Aqueduct"
        ],
        "model_ans": "Catskill Mountains",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Catskill Mountains </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played mike stivic on all in the family",
        "answers": [
            "Rob Reiner"
        ],
        "model_ans": "Rob Reiner",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rob Reiner </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays the grandmother in game of thrones",
        "answers": [
            "Rigg"
        ],
        "model_ans": "Olivia Broadbent",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Olivia Broadbent </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the main characteristic of post-world war ii american society",
        "answers": [
            "strong economic growth"
        ],
        "model_ans": "consumerism",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> consumerism </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the name of the skin between your nostrils",
        "answers": [
            "the nasal septum",
            "septum"
        ],
        "model_ans": "Columella",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Columella </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the leader of the zulu in south africa who led the fight against the british",
        "answers": [
            "Cetshwayo",
            "Cetshwayo kaMpande"
        ],
        "model_ans": "Cetewayo",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cetewayo </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is playing halftime at the pro bowl",
        "answers": [
            "Jordan Fisher"
        ],
        "model_ans": "Bruno Mars",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bruno Mars </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the importance of rigor mortis in meat processing",
        "answers": [
            "tenderness of meat"
        ],
        "model_ans": "Rigor mortis is important in meat processing as it helps to determine the freshness and quality of the meat.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rigor mortis is important in meat processing as it helps to determine the freshness and quality of the meat. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "right to property according to the constitution of india is a",
        "answers": [
            "constitutional right"
        ],
        "model_ans": "fundamental right",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fundamental right </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "today gestalt psychology ideas are part of which branch of psychology",
        "answers": [
            "Berlin School of experimental psychology",
            "experimental psychology"
        ],
        "model_ans": "Clinical Psychology",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Clinical Psychology </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "cls bank deals with transactions arising out of",
        "answers": [
            "foreign exchange market",
            "the foreign exchange market"
        ],
        "model_ans": "cheques",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> cheques </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "is aluminium a ferrous or non ferrous metal",
        "answers": [
            "non-ferrous"
        ],
        "model_ans": "non ferrous",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> non ferrous </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many grams of alcohol in one beer",
        "answers": [
            "14",
            "about 14 grams of alcohol",
            "14 grams"
        ],
        "model_ans": "12-15 grams",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 12-15 grams </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does a yellow 35 mph sign mean",
        "answers": [
            "advisory speed limits"
        ],
        "model_ans": "Speed limit",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Speed limit </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who came in last place on amazing race",
        "answers": [
            "Kevin & Jenn"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the extensor pollicis longus tendon located",
        "answers": [
            "dorsally on the forearm",
            "located dorsally on the forearm"
        ],
        "model_ans": "forearm",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> forearm </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do you pray the chaplet of divine mercy",
        "answers": [
            "Good Friday"
        ],
        "model_ans": "3:00 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3:00 PM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the world chess tournament 2017 held",
        "answers": [
            "Tbilisi, Georgia",
            "in Tbilisi, Georgia"
        ],
        "model_ans": "London",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the dj on in living color",
        "answers": [
            "DJ Twist"
        ],
        "model_ans": "Ed Lover",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ed Lover </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who made the first to record with the electric guitar",
        "answers": [
            "George Warren Barnes"
        ],
        "model_ans": "Les Paul",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Les Paul </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the grand tour season 2 episode 2 celebrity guests",
        "answers": [
            "Brian Wilson",
            "Kevin Pietersen, Brian Wilson",
            "Abbie Eaton",
            "Kevin Pietersen"
        ],
        "model_ans": "Jeremy Clarkson, Richard Hammond, James May",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jeremy Clarkson, Richard Hammond, James May </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the new season of law and order svu come on",
        "answers": [
            "September 27, 2017"
        ],
        "model_ans": "NBC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> NBC </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sing say you won't let go",
        "answers": [
            "James Arthur"
        ],
        "model_ans": "Jessie J",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jessie J</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is credited with developing the geocentric view",
        "answers": [
            "Ptolemy"
        ],
        "model_ans": "Aristarchus of Samos",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Aristarchus of Samos </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the first high level language operating system created",
        "answers": [
            "at IBM"
        ],
        "model_ans": "IBM",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> IBM </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "a legislative act passed by congress is an example of",
        "answers": [
            "statutory law"
        ],
        "model_ans": "Statute",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Statute </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the last episode of the flash",
        "answers": [
            "The Elongated Knight Rises",
            "\"Finish Line\""
        ],
        "model_ans": "\"Heart of the Matter\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \"Heart of the Matter\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wants a heart in the wizard of oz",
        "answers": [
            "Tin Woodman",
            "the Tin Woodman"
        ],
        "model_ans": "Dorothy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dorothy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the voice of chucky in seed of chucky",
        "answers": [
            "Brad Dourif"
        ],
        "model_ans": "Brad Dourif",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Brad Dourif </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the latest version of microsoft office 2010",
        "answers": [
            "14.0.7182.5000"
        ],
        "model_ans": "2010\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2010\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the battle of saratoga in 1777",
        "answers": [
            "Americans",
            "the Americans"
        ],
        "model_ans": "American",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> American </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does creatine come from in the body",
        "answers": [
            "kidneys",
            "liver",
            "the liver and kidneys",
            "arginine",
            "glycine"
        ],
        "model_ans": "liver",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> liver </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the battle of britain flight based",
        "answers": [
            "RAF Coningsby in Lincolnshire"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the president of usa right now",
        "answers": [
            "Donald Trump"
        ],
        "model_ans": "Joe Biden",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Joe Biden </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the song suddenly with olivia newton john",
        "answers": [
            "Cliff Richard"
        ],
        "model_ans": "Cliff Richard",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Cliff Richard </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the movie proof of life take place",
        "answers": [
            "The Republic of Tecala"
        ],
        "model_ans": "Bolivia",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bolivia</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was involved in the mapp vs ohio case",
        "answers": [
            "Dollree Mapp"
        ],
        "model_ans": "Earl Warren",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Earl Warren </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the sixteenth century physician who published",
        "answers": [
            "Andreas Vesalius"
        ],
        "model_ans": "Andreas Vesalius",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andreas Vesalius </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the cross on a letter t called",
        "answers": [
            "arm",
            "crossbar"
        ],
        "model_ans": "Tilde",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Tilde </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes of the killing on netflix",
        "answers": [
            "6",
            "six"
        ],
        "model_ans": "4",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 4 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes are there in season six of nashville",
        "answers": [
            "16",
            "16 episodes"
        ],
        "model_ans": "22\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "22\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what breed of dog is the teddy bear dog",
        "answers": [
            "Zuchon"
        ],
        "model_ans": "Ural Mountain Dog",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ural Mountain Dog </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many levels are there on the eiffel tower",
        "answers": [
            "three"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many episodes in 1st season of the crown",
        "answers": [
            "10"
        ],
        "model_ans": "10\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "10\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first chief minister of west bengal",
        "answers": [
            "Prafulla Chandra Ghosh"
        ],
        "model_ans": "Huseyn Shaheed Suhrawardy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Huseyn Shaheed Suhrawardy </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do the walking dead comics come out",
        "answers": [
            "October\u00a02003\u00a0\u2013 present",
            "2003"
        ],
        "model_ans": "Monthly",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Monthly </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the originator of the plan-do-check-act model of performance improvement",
        "answers": [
            "W. Edwards Deming"
        ],
        "model_ans": "Walter Shewhart",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Walter Shewhart </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which supreme court judge has surved in international court of justice",
        "answers": [
            "Dalveer Bhandari"
        ],
        "model_ans": "Judge Abdulqawi Yusuf",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judge Abdulqawi Yusuf </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the main crops grown in the united states",
        "answers": [
            "Corn",
            "Hay, (non-Alfalfa)",
            "Cotton",
            "Alfalfa",
            "Sorghum",
            "Wheat",
            "Rice",
            "Barley",
            "Soybeans",
            "Hay",
            "Tobacco"
        ],
        "model_ans": "corn, soybeans, wheat, cotton, hay",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> corn, soybeans, wheat, cotton, hay </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many players in football hall of fame",
        "answers": [
            "318",
            "318 individuals"
        ],
        "model_ans": "350",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 350 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who gave the famous objective co relative theory",
        "answers": [
            "T.S. Eliot"
        ],
        "model_ans": "Albert Einstein",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Albert Einstein </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the song photograph by ringo starr",
        "answers": [
            "George Harrison",
            "Ringo Starr",
            "Richard Starkey"
        ],
        "model_ans": "Ringo Starr",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ringo Starr </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the first prime minister of france",
        "answers": [
            "Michel Debr\u00e9"
        ],
        "model_ans": "Louis XIV",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Louis XIV </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played truman capote in in cold blood",
        "answers": [
            "Philip Seymour Hoffman"
        ],
        "model_ans": "Philip Seymour Hoffman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philip Seymour Hoffman </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was the film the remains of the day filmed",
        "answers": [
            "Powderham Castle",
            "Weston-super-Mare",
            "Dyrham Park",
            "Badminton House",
            "Corsham Court",
            "Limpley Stoke"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who eliminated costa rica in world cup 2014",
        "answers": [
            "Netherlands"
        ],
        "model_ans": "Greece",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Greece </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the name of the weapon the grim reaper carries",
        "answers": [
            "scythe"
        ],
        "model_ans": "Scythe",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Scythe </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the battle of bull run start",
        "answers": [
            "July\u00a021,\u00a01861",
            "July 21, 1861",
            "5:15\u00a0a.m."
        ],
        "model_ans": "1861\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1861\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the first kind of vertebrate to exist on earth",
        "answers": [
            "believed to be the Myllokunmingia",
            "the Myllokunmingia",
            "Myllokunmingia"
        ],
        "model_ans": "Fish",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fish </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote shes always a woman to me",
        "answers": [
            "Billy Joel",
            "Joel"
        ],
        "model_ans": "Jay-Z",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jay-Z</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the first season of america's got talent",
        "answers": [
            "Bianca Ryan"
        ],
        "model_ans": "Brian Justin Crum",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brian Justin Crum</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "in the early 1800s california society was dominated by which group",
        "answers": [
            "Spanish"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "gestational sac and yolk sac but no baby at 7 weeks",
        "answers": [
            "an anembryonic gestation"
        ],
        "model_ans": "Ectopic pregnancy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ectopic pregnancy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the last time the us lost the olympics",
        "answers": [
            "2018 Pyeongchang"
        ],
        "model_ans": "1904\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1904\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does this season's survivor take place",
        "answers": [
            "Mamanuca Islands, Fiji",
            "Ghost Island"
        ],
        "model_ans": "Fiji",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fiji </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is singing in something just like this",
        "answers": [
            "Will Champion",
            "Coldplay",
            "The Chainsmokers",
            "Chris Martin"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "why dry ether is used in woods reaction",
        "answers": [
            "to form a higher alkane"
        ],
        "model_ans": "to remove impurities",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> to remove impurities </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays lady talisa in game of thrones",
        "answers": [
            "Oona Castilla Chaplin",
            "Oona Chaplin"
        ],
        "model_ans": "Oona Chaplin",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Oona Chaplin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the population of the roman empire at its height",
        "answers": [
            "50 to 90\u00a0million inhabitants",
            "70\u00a0million",
            "55\u201360 million",
            "an estimated 70\u00a0million people"
        ],
        "model_ans": "50-60 million\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "50-60 million\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the phrase train of thought come from",
        "answers": [
            "Thomas Hobbes in his Leviathan"
        ],
        "model_ans": "The phrase \"train of thought\" is believed to have originated in the 17th century, when the concept of a train of thought was seen as a metaphor for the way the mind moves from one idea to another, much like a</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The phrase \"train of thought\" is believed to have originated in the 17th century, when the concept of a train of thought was seen as a metaphor for the way the mind moves from one idea to another, much like a</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which body system differentiates a male from a female",
        "answers": [
            "the external genitalia",
            "the sex hormones",
            "reproductive",
            "the type of gonads"
        ],
        "model_ans": "Reproductive",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reproductive </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "name the process of fusion of an egg with a sperm",
        "answers": [
            "fertilization",
            "Human fertilization"
        ],
        "model_ans": "fertilization",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fertilization </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who were the first kings to issue coins bearing their names",
        "answers": [
            "the Indo-Greek kings"
        ],
        "model_ans": "Lydia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lydia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played michael jackson in jackson 5 movie",
        "answers": [
            "Alex Burrall",
            "Abolade David Olatunde",
            "Wylie Draper",
            "Jason Weaver"
        ],
        "model_ans": "Michael Jackson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Jackson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who are the stars in dancing with the stars",
        "answers": [
            "Jennie Finch Daigle",
            "Jamie Anderson",
            "Arike Ogunbowale",
            "Mirai Nagasu",
            "Adam Rippon",
            "Josh Norman",
            "Tonya Harding",
            "Kareem Abdul-Jabbar",
            "Chris Mazdzer",
            "Johnny Damon"
        ],
        "model_ans": "Various",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Various </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who hosted they think it's all over",
        "answers": [
            "Nick Hancock",
            "Des Lynam",
            "comedian Nick Hancock",
            "Lee Mack"
        ],
        "model_ans": "BBC",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>BBC</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did red bull come to the united states",
        "answers": [
            "1997"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how long has tom brady been the patriots quarterback",
        "answers": [
            "2001",
            "16 seasons"
        ],
        "model_ans": "20 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 20 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many casinos are in atlantic city new jersey",
        "answers": [
            "eleven",
            "seven"
        ],
        "model_ans": "9\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "9\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the great fire of london end",
        "answers": [
            "5 September 1666",
            "Wednesday, 5 September 1666"
        ],
        "model_ans": "5th of September 1666",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th of September 1666 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the singer of kal ho na ho",
        "answers": [
            "Sonu Nigam",
            "Richa Sharma",
            "Alka Yagnik"
        ],
        "model_ans": "A.R. Rahman",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> A.R. Rahman </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the passion of the christ come out",
        "answers": [
            "February 25, 2004",
            "February\u00a025,\u00a02004",
            "2004"
        ],
        "model_ans": "2004\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2004\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "star wars the clone wars season 3 episode 1",
        "answers": [
            "Clone Cadets"
        ],
        "model_ans": "\"Supply and Demand\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> \"Supply and Demand\" </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "is the united states a country or nation",
        "answers": [
            "country"
        ],
        "model_ans": "country",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> country </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most podium finishes in australia",
        "answers": [
            "Michael Schumacher"
        ],
        "model_ans": "Michael Schumacher",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Michael Schumacher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did john steinbeck write of mice and me",
        "answers": [
            "1937"
        ],
        "model_ans": "John Steinbeck wrote Of Mice and Men in 1937",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> John Steinbeck wrote Of Mice and Men in 1937 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays faith on when calls the heart",
        "answers": [
            "Andrea Brooks"
        ],
        "model_ans": "Erin Krakow\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Erin Krakow\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the movie the glass castle filmed",
        "answers": [
            "in Welch, West Virginia",
            "Welch, West Virginia"
        ],
        "model_ans": "Pittsburgh",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pittsburgh </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many seasons of prison break are on netflix",
        "answers": [
            "five"
        ],
        "model_ans": "5\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the turn of the screw take place",
        "answers": [
            "1898"
        ],
        "model_ans": "1898\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1898\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the longest serving member of the house in history",
        "answers": [
            "John Dingell"
        ],
        "model_ans": "John Denham",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John Denham </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did first fast and furious come out",
        "answers": [
            "2001"
        ],
        "model_ans": "2001\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2001\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the second half of vikings season 5 air",
        "answers": [
            "2018",
            "in 2018"
        ],
        "model_ans": "November 28, 2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> November 28, 2019 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of fish live in the salton sea",
        "answers": [
            "tilapia"
        ],
        "model_ans": "tilapia",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> tilapia </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the song you got a friend in me",
        "answers": [
            "Lyle Lovett",
            "Randy Newman"
        ],
        "model_ans": "Randy Newman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Randy Newman </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the strongest earthquake in the united states",
        "answers": [
            "1964 Alaska earthquake and tsunami",
            "1700 Cascadia earthquake"
        ],
        "model_ans": "The Great Alaska Earthquake of 1964",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Great Alaska Earthquake of 1964 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote put your hand in the hand of the man who stilled the water",
        "answers": [
            "Gene MacLellan"
        ],
        "model_ans": "Gene MacLellan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Gene MacLellan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the white castle that harold and kumar go to",
        "answers": [
            "in Cherry Hill"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who headed the 7th central pay commission of india",
        "answers": [
            "Justice A.K Mathur"
        ],
        "model_ans": "Justice Ashok Kumar Mathur",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Justice Ashok Kumar Mathur </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is season 3 of the detour filmed",
        "answers": [
            "Alaska"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the voice of sulley in monsters inc",
        "answers": [
            "John Goodman"
        ],
        "model_ans": "John Goodman",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Goodman </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "largest state in the us by land mass",
        "answers": [
            "Alaska"
        ],
        "model_ans": "Alaska\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Alaska\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when do you get your dress blues in the army",
        "answers": [
            "during initial entry training",
            "when commissioned"
        ],
        "model_ans": "Typically, soldiers receive their dress blues during basic training, usually around the 10th week.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Typically, soldiers receive their dress blues during basic training, usually around the 10th week. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who used to present i'm a celebrity now",
        "answers": [
            "Ant & Dec"
        ],
        "model_ans": "Brian Conley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brian Conley</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does congress declare war for the first time",
        "answers": [
            "June 18, 1812",
            "War of 1812"
        ],
        "model_ans": "1812",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1812 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the longest panic at the disco song title",
        "answers": [
            "Bohemian Rhapsody"
        ],
        "model_ans": "Nine in the Afternoon",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nine in the Afternoon </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played mark on the show the rifleman",
        "answers": [
            "John Ernest Crawford"
        ],
        "model_ans": "Chuck Connors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chuck Connors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the last name orozco originate from",
        "answers": [
            "Spanish/Basque origin"
        ],
        "model_ans": "Mexico",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mexico </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did marley die in a christmas carol",
        "answers": [
            "December 24, 1836"
        ],
        "model_ans": "December 24, 1843",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> December 24, 1843 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does a girl wear an engagement ring",
        "answers": [
            "left hand ring finger"
        ],
        "model_ans": "on the left hand",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> on the left hand </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the art and science of making objects from clay is called",
        "answers": [
            "Ceramic art",
            "Ceramic"
        ],
        "model_ans": "ceramics",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ceramics </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did i ain't mad at cha come out",
        "answers": [
            "September 15, 1996"
        ],
        "model_ans": "2000\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2000\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "communities of similar organisms found in a particular environment are called",
        "answers": [
            "species",
            "habitat"
        ],
        "model_ans": "biomes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> biomes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what happened to the west wing of the white house during a christmas party in 1929",
        "answers": [
            "electrical fire"
        ],
        "model_ans": "The West Wing of the White House caught fire during a Christmas party in 1929, but the exact details of the incident are unclear.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The West Wing of the White House caught fire during a Christmas party in 1929, but the exact details of the incident are unclear. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played tom hagon in the godfather series",
        "answers": [
            "Robert Duvall"
        ],
        "model_ans": "James Caan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Caan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the song i hate you i love you",
        "answers": [
            "Garrett Nash",
            "Olivia O'Brien",
            "Angel Benitez"
        ],
        "model_ans": "Gnash",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gnash </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings the theme tune to mum on bbc2",
        "answers": [
            "Lulu and the Lampshades"
        ],
        "model_ans": "Anna Calvi",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Anna Calvi </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the general term for software that is designed to damage disable or steal data is",
        "answers": [
            "Malware"
        ],
        "model_ans": "Malware",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Malware </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what kind of plate boundary is nepal on",
        "answers": [
            "orogenic belt"
        ],
        "model_ans": "convergent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> convergent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "chemicals produced in one part of a plant that affect the growth and response of other parts",
        "answers": [
            "Plant hormones",
            "hormones"
        ],
        "model_ans": "hormones",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> hormones </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the basic steps of rational decision making include defining goals and",
        "answers": [
            "Implementation of plans/policies"
        ],
        "model_ans": "identifying alternatives",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> identifying alternatives </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote if she knew what she wants",
        "answers": [
            "Jules Shear"
        ],
        "model_ans": "5 Seconds of Summer\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "5 Seconds of Summer\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the medals in men's figure skating 2018",
        "answers": [
            "Yuzuru Hanyu",
            "Javier Fern\u00e1ndez",
            "Shoma Uno"
        ],
        "model_ans": "Yuzuru Hanyu",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuzuru Hanyu </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who ruled the ottoman empire in the 1500s",
        "answers": [
            "Selim I"
        ],
        "model_ans": "Suleiman the Magnificent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Suleiman the Magnificent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who appoints the chief election commissioner of india",
        "answers": [
            "President of India",
            "the president"
        ],
        "model_ans": "President of India",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> President of India </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "song have i told you lately i love you",
        "answers": [
            "Have I Told You Lately"
        ],
        "model_ans": "Rod Stewart",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rod Stewart </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the legal drinking age changed to 21",
        "answers": [
            "By mid-1988",
            "October 1986"
        ],
        "model_ans": "1984",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1984 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "eukaryotes have how many origins of dna replication",
        "answers": [
            "up to 100,000"
        ],
        "model_ans": "1",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> 1 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who performed the halftime show at super bowl 51",
        "answers": [
            "Lady Gaga"
        ],
        "model_ans": "Lady Gaga",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Lady Gaga </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did world war 2 officially start and end",
        "answers": [
            "1939",
            "1945",
            "2\u00a0September\u00a01945",
            "1\u00a0September\u00a01939"
        ],
        "model_ans": "September 1, 1939 - September 2, 1945",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> September 1, 1939 - September 2, 1945 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the new death of superman come out",
        "answers": [
            "2019",
            "2018",
            "in 2018 and 2019",
            "late 2018"
        ],
        "model_ans": "July 5, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> July 5, 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who win road march in trinidad and tobago",
        "answers": [
            "Superblue",
            "Machel Montano"
        ],
        "model_ans": "Machel Montano",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Machel Montano </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was elected president of the united states in 1928",
        "answers": [
            "Herbert Hoover"
        ],
        "model_ans": "Herbert Hoover",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Herbert Hoover </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the theme song to law and order",
        "answers": [
            "Mike Post"
        ],
        "model_ans": "Mike Post",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mike Post </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did the angel of the north get built",
        "answers": [
            "1998",
            "1994"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays lois's dad on family guy",
        "answers": [
            "MacFarlane"
        ],
        "model_ans": "Adam West",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Adam West </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays david in alvin and the chipmunks",
        "answers": [
            "Jason Lee"
        ],
        "model_ans": "Jay Hernandez",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jay Hernandez</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is the tennessee titans football stadium located",
        "answers": [
            "Nashville, Tennessee"
        ],
        "model_ans": "Nashville",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nashville </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the salary of the ceo of microsoft",
        "answers": [
            "$84.3 million",
            "$84.3 million (2018)"
        ],
        "model_ans": "$242 million",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> $242 million </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is directly elected according to the constitution",
        "answers": [
            "senators"
        ],
        "model_ans": "President",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> President </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the suez canal located on a map",
        "answers": [
            "Egypt"
        ],
        "model_ans": "Egypt",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Egypt </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "baga beach is in north or south goa",
        "answers": [
            "North Goa",
            "North"
        ],
        "model_ans": "south",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> south </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what disney cartoon character's middle name is fauntleroy",
        "answers": [
            "Donald Duck",
            "Donald Fauntleroy Duck"
        ],
        "model_ans": "Mortimer",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mortimer </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the romanticism period start and end",
        "answers": [
            "1780\u20131830"
        ],
        "model_ans": "Romanticism started around 1780 and ended around 1850",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Romanticism started around 1780 and ended around 1850 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "three act puccini opera first performed in 1900",
        "answers": [
            "Tosca"
        ],
        "model_ans": "La Boh\u00e8me",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> La Boh\u00e8me </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which is the largest great lake in north america",
        "answers": [
            "Lake Superior"
        ],
        "model_ans": "Lake Superior",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lake Superior </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote the song what child is this",
        "answers": [
            "William Chatterton Dix"
        ],
        "model_ans": "William Chatterton Dix",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> William Chatterton Dix </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is credited with creating the gothic art movement",
        "answers": [
            "Abbot Suger"
        ],
        "model_ans": "Michelangelo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michelangelo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they stop using aluminum wiring in ontario",
        "answers": [
            "mid-1970s"
        ],
        "model_ans": "1975",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1975 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is nuclear energy used most in the world",
        "answers": [
            "United States",
            "France"
        ],
        "model_ans": "France",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> France </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who carried the us flag in the 2014 olympics",
        "answers": [
            "Todd Lodwick",
            "Julie Chu"
        ],
        "model_ans": "Nastia Liukin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Nastia Liukin </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the next apollo book come out",
        "answers": [
            "May 1, 2018"
        ],
        "model_ans": "I am unsure",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I am unsure </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time lebron scored 50 points",
        "answers": [
            "March 5, 2008",
            "November 3, 2017"
        ],
        "model_ans": "2023-02-26\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2023-02-26\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who created the borders of africa's countries",
        "answers": [
            "European imperial powers"
        ],
        "model_ans": "European powers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> European powers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did the british empire control an entire continent",
        "answers": [
            "Australia"
        ],
        "model_ans": "Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won best boy band i heart radio music awards",
        "answers": [
            "BTS"
        ],
        "model_ans": "BTS",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> BTS </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did it become law to stand for the national anthem",
        "answers": [
            "June 22, 1942"
        ],
        "model_ans": "1942",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1942 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the character of santa claus based on",
        "answers": [
            "Saint Nicholas",
            "Father Christmas",
            "Sinterklaas",
            "Wodan"
        ],
        "model_ans": "Saint Nicholas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saint Nicholas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who created the convention on the rights of the child",
        "answers": [
            "The UN General Assembly",
            "The United Nations"
        ],
        "model_ans": "United Nations",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United Nations </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote the song the glory of love",
        "answers": [
            "Billy Hill"
        ],
        "model_ans": "Peter Yarrow",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Peter Yarrow </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who spoke the words ich bin ein berliner",
        "answers": [
            "U.S. President John F. Kennedy"
        ],
        "model_ans": "John F. Kennedy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John F. Kennedy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang the american national anthem at the super bowl",
        "answers": [
            "Pink"
        ],
        "model_ans": "Whitney Houston",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Whitney Houston </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "capital of georgia the former soviet republic 7 letters",
        "answers": [
            "Tbilisi"
        ],
        "model_ans": "Tbilisi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Tbilisi</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who owns the four seasons hotel in las vegas",
        "answers": [
            "MGM Resorts International"
        ],
        "model_ans": "Four Seasons Hotels and Resorts",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Four Seasons Hotels and Resorts </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was allowed to vote in the roman republic",
        "answers": [
            "unknown",
            "citizens"
        ],
        "model_ans": "Citizens",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Citizens </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "form from material that has accumulated on the earths surface",
        "answers": [
            "Sedimentary rock"
        ],
        "model_ans": "sediment",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sediment </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the sport psychology sub-field of performance enhancement deals primarily with",
        "answers": [
            "Arousal regulation"
        ],
        "model_ans": "optimizing performance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> optimizing performance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the prr first begin its passenger service between pittsburgh and philadelphia",
        "answers": [
            "by 1854",
            "1854"
        ],
        "model_ans": "1846",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1846 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do luke and lorelai get back together",
        "answers": [
            "Say Goodbye to Daisy Miller"
        ],
        "model_ans": "They don't get back together",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> They don't get back together </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is mowgli's main enemy in the jungle book",
        "answers": [
            "Shere Khan"
        ],
        "model_ans": "Shere Khan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shere Khan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who drives the number 95 car in nascar",
        "answers": [
            "Michael Christopher McDowell"
        ],
        "model_ans": "Kyle Busch",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kyle Busch </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the wire season 5 theme song",
        "answers": [
            "Steve Earle"
        ],
        "model_ans": "The Black Angels",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Black Angels </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays dorian tyrell when he puts on the mask",
        "answers": [
            "Peter Greene"
        ],
        "model_ans": "David Bowie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Bowie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won india's next super star",
        "answers": [
            "Natasha Bharadwaj",
            "Aman Gandotra"
        ],
        "model_ans": "Sunidhi Chauhan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sunidhi Chauhan </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did an independence movement occur because of the congress of vienna",
        "answers": [
            "Italy",
            "Norway"
        ],
        "model_ans": "Italy",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Italy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was it happened at the world fair filmed",
        "answers": [
            "Seattle, Washington",
            "The Seattle Center",
            "Camarillo, California"
        ],
        "model_ans": "Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song to make you feel my love",
        "answers": [
            "Bob Dylan"
        ],
        "model_ans": "Bob Dylan\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Bob Dylan\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who plays harry's mom in harry potter",
        "answers": [
            "Geraldine Margaret Agnew-Somerville"
        ],
        "model_ans": "Judith",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Judith </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the membrane on the surface of the stomach called",
        "answers": [
            "the visceral membrane",
            "Serous Membrane"
        ],
        "model_ans": "mucous membrane",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> mucous membrane </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the men's ice skating 2018",
        "answers": [
            "Yuzuru Hanyu"
        ],
        "model_ans": "Yuzuru Hanyu",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuzuru Hanyu </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings i'll sleep when i'm dead",
        "answers": [
            "Warren Zevon",
            "Bon Jovi"
        ],
        "model_ans": "Weird Al Yankovic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Weird Al Yankovic </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they stop putting lead in paint",
        "answers": [
            "1992"
        ],
        "model_ans": "1978 1978",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1978 <answer>1978</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what episode does caroline get turned into a vampire",
        "answers": [
            "Brave New World",
            "The Return"
        ],
        "model_ans": "Season 2 Episode 22",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 2 Episode 22 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has won the cma entertainer of the year the most",
        "answers": [
            "Garth Brooks"
        ],
        "model_ans": "Alan Jackson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Alan Jackson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won season 2 of great british baking show",
        "answers": [
            "Joanne Wheatley"
        ],
        "model_ans": "Edd Kimber",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Edd Kimber </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is this years army navy game played",
        "answers": [
            "Lincoln Financial Field in Philadelphia",
            "Lincoln Financial Field"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings somebody's watching me with michael jackson",
        "answers": [
            "Jermaine Jackson",
            "Rockwell"
        ],
        "model_ans": "Rockwell\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Rockwell\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who were the first settlers in san antonio",
        "answers": [
            "Spanish",
            "Spanish explorers",
            "varying cultures of indigenous peoples"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played cory's older brother on boy meets world",
        "answers": [
            "Will Friedle"
        ],
        "model_ans": "Ben Savage",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ben Savage </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who has the most receiving yards in the nfl history",
        "answers": [
            "Jerry Rice"
        ],
        "model_ans": "Jerry Rice",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Jerry Rice </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where are red blood cells made in adults",
        "answers": [
            "in the bone marrow"
        ],
        "model_ans": "Bone marrow",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bone marrow</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is playing halftime show super bowl 2018",
        "answers": [
            "Justin Timberlake"
        ],
        "model_ans": "Justin Timberlake",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Justin Timberlake </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many episodes in game if thrones season 7",
        "answers": [
            "7",
            "seven"
        ],
        "model_ans": "7\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "7\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the last time unc did not make the ncaa tournament",
        "answers": [
            "2003"
        ],
        "model_ans": "1996",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1996 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was one direction what makes you beautiful filmed",
        "answers": [
            "Malibu, California",
            "a Malibu, California beach"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the name de la rosa come from",
        "answers": [
            "Spanish"
        ],
        "model_ans": "Spanish",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spanish </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does sip stand for in the ngn / ims context",
        "answers": [
            "Session Initiation Protocol"
        ],
        "model_ans": "Session Initiation Protocol",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Session Initiation Protocol </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who makes the important government decisions in an autocracy",
        "answers": [
            "one person"
        ],
        "model_ans": "The ruler",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The ruler </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of the name habib",
        "answers": [
            "\"beloved\"",
            "beloved"
        ],
        "model_ans": "Arabic for \"beloved\"",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Arabic for \"beloved\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the most gold metals in olympics",
        "answers": [
            "American swimmer Michael Phelps",
            "Michael Phelps"
        ],
        "model_ans": "Michael Phelps",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Phelps </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who came first second and third on the grand national",
        "answers": [
            "Pleasant Company",
            "Bless The Wings",
            "Tiger Roll"
        ],
        "model_ans": "Tiger Roll, Pleasant Company, and Magic of Light",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Tiger Roll, Pleasant Company, and Magic of Light </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the book thief movie come out",
        "answers": [
            "November 27, 2013",
            "2013",
            "November\u00a027,\u00a02013"
        ],
        "model_ans": "2009\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2009\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the princess in kingsman secret service",
        "answers": [
            "Hanna Alstr\u00f6m"
        ],
        "model_ans": "Jemma Haynes",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jemma Haynes</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the editor of the journal jugantor published in the time of swadeshi movement",
        "answers": [
            "Bhupendranath Dutt"
        ],
        "model_ans": "Ramananda Chatterjee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ramananda Chatterjee </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the theme song for the man with the golden gun",
        "answers": [
            "Lulu"
        ],
        "model_ans": "Lulu",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Lulu</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the movie road to perdition take place",
        "answers": [
            "Rock Island, Illinois",
            "Chicago"
        ],
        "model_ans": "Chicago",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Chicago </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where are the hormones of the anterior pituitary created",
        "answers": [
            "The pars distalis"
        ],
        "model_ans": "hypothalamus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> hypothalamus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who voiced mewtwo in pokemon the first movie",
        "answers": [
            "Showtaro Morikubo",
            "Fujiko Takimoto",
            "Masachika Ichimura",
            "Philip Bartlett"
        ],
        "model_ans": "Philippe Coedel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Philippe Coedel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who proposed the first accurate model of dna",
        "answers": [
            "Watson",
            "Crick"
        ],
        "model_ans": "James Watson",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Watson </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who said i will not go quietly into the night",
        "answers": [
            "Welsh poet Dylan Thomas",
            "Dylan Thomas"
        ],
        "model_ans": "Jack Kevorkian",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jack Kevorkian </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are the joyful mysteries of the holy rosary",
        "answers": [
            "The Nativity",
            "The Annunciation",
            "The Visitation"
        ],
        "model_ans": "The Joyful Mysteries are: The Annunciation, The Visitation, The Nativity, The Presentation, and The Finding in the Temple",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> The Joyful Mysteries are: The Annunciation, The Visitation, The Nativity, The Presentation, and The Finding in the Temple </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the very last episode of that's so raven",
        "answers": [
            "Where There's Smoke"
        ],
        "model_ans": "Stormy Night",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Stormy Night </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is a coherent set of values and beliefs about public policy called",
        "answers": [
            "a political ideology",
            "political ideology",
            "ideology"
        ],
        "model_ans": "ideology",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> ideology </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how many stores does lowes have in canada",
        "answers": [
            "62"
        ],
        "model_ans": "600",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 600 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does brant daugherty play in pretty little liars",
        "answers": [
            "Noel Kahn"
        ],
        "model_ans": "Noel Kahn",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Noel Kahn </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the new day win the tag team titles",
        "answers": [
            "2016"
        ],
        "model_ans": "2007",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2007 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is young george bailey in it's a wonderful life",
        "answers": [
            "Robert James Anderson"
        ],
        "model_ans": "James Stewart",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James Stewart </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who missed the plane the day the music died",
        "answers": [
            "Tommy Allsup",
            "Waylon Jennings"
        ],
        "model_ans": "Buddy Holly",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Buddy Holly </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when will the flash season 4 be released",
        "answers": [
            "October 10, 2017"
        ],
        "model_ans": "October 4, 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 4, 2017 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "new movie of ajay devgan and sonakshi sinha",
        "answers": [
            "Action Jackson"
        ],
        "model_ans": "De De Pyaar De",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> De De Pyaar De </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did ireland gain its independence from england",
        "answers": [
            "In 1922",
            "1922"
        ],
        "model_ans": "1922",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1922 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the girl in silence of the lambs",
        "answers": [
            "Masha Skorobogatov",
            "Jodie Foster"
        ],
        "model_ans": "Jodie Foster",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jodie Foster</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "tallest building in the world of all time",
        "answers": [
            "Burj Khalifa"
        ],
        "model_ans": "Burj Khalifa",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Burj Khalifa </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played mrs. trumbull on i love lucy",
        "answers": [
            "Mary Elizabeth Patterson"
        ],
        "model_ans": "Elizabeth Patterson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Elizabeth Patterson </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the successful commanding general of the northern forces in the civil war",
        "answers": [
            "George B. McClellan"
        ],
        "model_ans": "Ulysses S. Grant",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ulysses S. Grant </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the red wolf live in the world",
        "answers": [
            "the southeastern United States",
            "southeastern United States"
        ],
        "model_ans": "Southeastern United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Southeastern United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what does v sign in front of mouth mean",
        "answers": [
            "signify cunnilingus",
            "cunnilingus"
        ],
        "model_ans": "Victory sign",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Victory sign </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who dies at the end of den of thieves",
        "answers": [
            "Merrimen",
            "Levi",
            "Bosco"
        ],
        "model_ans": "Raylan Givens",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Raylan Givens </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the xix of the social security act of 1965 established",
        "answers": [
            "Medicaid"
        ],
        "model_ans": "Medicare",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Medicare </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the winner of the best actor award in the 64th national film festival 2017",
        "answers": [
            "Akshay Kumar",
            "Manoj Joshi"
        ],
        "model_ans": "Rajkummar Rao",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Rajkummar Rao </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many times have real madrid won the european cup.in paris",
        "answers": [
            "twelve"
        ],
        "model_ans": "13",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 13 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the limit of resolution of the human eye in micrometers",
        "answers": [
            "~55-75 micrometers",
            "~ 0.116\u00a0mm"
        ],
        "model_ans": "200 micrometers\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "200 micrometers\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who laid the foundation of school of possibilism",
        "answers": [
            "Strabo",
            "Marshall Sahlins"
        ],
        "model_ans": "Paul Vidal de la Blache",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Vidal de la Blache </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the purpose of the mall of america",
        "answers": [
            "shopping"
        ],
        "model_ans": "shopping",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> shopping </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did television come out in the us",
        "answers": [
            "928,",
            "uly 2, 1928,"
        ],
        "model_ans": "1941",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1941 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is small business tax rate in canada",
        "answers": [
            "10.5%"
        ],
        "model_ans": "15% \n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "15% \n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the present president of assam sahitya sabha",
        "answers": [
            "Dhrubajyoti Bora"
        ],
        "model_ans": "Hiren Gohain",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Hiren Gohain </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does closure of the ductus arteriosus occur",
        "answers": [
            "at birth",
            "birth"
        ],
        "model_ans": "at birth",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> at birth </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "love is not love that alters when it alteration finds meaning",
        "answers": [
            "Sonnet 116"
        ],
        "model_ans": "William Shakespeare",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> William Shakespeare </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "most runs ever scored in a mlb inning",
        "answers": [
            "18"
        ],
        "model_ans": "18\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "18\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is south pole located on a map",
        "answers": [
            "on the continent of Antarctica"
        ],
        "model_ans": "Antarctica",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antarctica </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is considered to be the greatest english composer of the baroque period",
        "answers": [
            "Henry Purcell"
        ],
        "model_ans": "Henry Purcell",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Henry Purcell </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the setting of a dolls house",
        "answers": [
            "a Norwegian town circa 1879",
            "a Norwegian town"
        ],
        "model_ans": "Norway",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Norway </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did the tradition of self government began in america",
        "answers": [
            "1783"
        ],
        "model_ans": "1776",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1776 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the meaning of shalom in english",
        "answers": [
            "peace"
        ],
        "model_ans": "peace",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> peace </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does the spinal cord become cauda equina",
        "answers": [
            "L1 or L2",
            "the conus medullaris"
        ],
        "model_ans": "L1-L2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> L1-L2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which country has the smallest population in europe",
        "answers": [
            "Vatican City"
        ],
        "model_ans": "Vatican City\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " Vatican City\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the biggest airport in the us",
        "answers": [
            "Atlanta"
        ],
        "model_ans": "Hartsfield-Jackson Atlanta International Airport",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hartsfield-Jackson Atlanta International Airport </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who does the voice of mrs. wolowitz on the big bang theory",
        "answers": [
            "Carol Ann Susi"
        ],
        "model_ans": "Susie Essman",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Susie Essman </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings war don't let me down",
        "answers": [
            "American production duo The Chainsmokers",
            "vocals of American singer Daya"
        ],
        "model_ans": "The Three Degrees",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Three Degrees </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song after you've gone",
        "answers": [
            "Turner Layton",
            "Henry Creamer",
            "lyrics by Henry Creamer",
            "composed by Turner Layton"
        ],
        "model_ans": "Jessica Simpson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jessica Simpson </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the saying get out of dodge come from",
        "answers": [
            "the drama series Gunsmoke"
        ],
        "model_ans": "Dodge City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Dodge City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when will notre dame played michigan state again",
        "answers": [
            "2026"
        ],
        "model_ans": "I couldn't find the information",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> I couldn't find the information </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang first line of we are the world",
        "answers": [
            "Lionel Richie",
            "Kenny Rogers",
            "James Ingram",
            "Billy Joel",
            "Tina Turner",
            "Stevie Wonder",
            "Paul Simon"
        ],
        "model_ans": "Lionel Richie",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Lionel Richie </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most gold gloves at shortstop",
        "answers": [
            "Ozzie Smith"
        ],
        "model_ans": "Ozzie Smith",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ozzie Smith </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who wrote i'm in the mood for dancing",
        "answers": [
            "Ben Findon",
            "Mike Myers",
            "Bob Puzey"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the robot maid in richie rich",
        "answers": [
            "Brooke Wexler"
        ],
        "model_ans": "Jeanne Armin",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jeanne Armin</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many hospitals are there in the united states",
        "answers": [
            "5,534 registered hospitals",
            "5,534"
        ],
        "model_ans": "over 5,000",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> over 5,000 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "university of michigan school of public health ranking",
        "answers": [
            "#4"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "african countries that begin with the letter a",
        "answers": [
            "Algeria\u200e",
            "Algeria",
            "Angola\u200e",
            "Angola"
        ],
        "model_ans": "Algeria, Angola, Antigua and Barbuda, and Ashmore and Cartier Islands",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Algeria, Angola, Antigua and Barbuda, and Ashmore and Cartier Islands </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the immigration act passed in canada",
        "answers": [
            "1923"
        ],
        "model_ans": "1976",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1976 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the indian myna bird come from",
        "answers": [
            "native to Asia",
            "Asia"
        ],
        "model_ans": "India",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> India </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the guy on keeping up with the kardashians",
        "answers": [
            "Jonathan Cheban"
        ],
        "model_ans": "Kris Jenner",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Kris Jenner </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was catch me if you can made",
        "answers": [
            "2002"
        ],
        "model_ans": "2002\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2002\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who used the word physiology for the first time",
        "answers": [
            "Jean Fernel"
        ],
        "model_ans": "Aristotle",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Aristotle </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many dominoes do you need for mexican train",
        "answers": [
            "A double-twelve set"
        ],
        "model_ans": "5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the filename extension used for all java source files",
        "answers": [
            ".java"
        ],
        "model_ans": ".java",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> .java </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when was the taj mahal built and completed",
        "answers": [
            "1632\u201353"
        ],
        "model_ans": "1632-1653",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1632-1653 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the premier of northern cape 2018",
        "answers": [
            "Sylvia Lucas"
        ],
        "model_ans": "Sylvia Lucas",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sylvia Lucas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time ny rangers won stanley cup",
        "answers": [
            "1993\u201394"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "cast of the movie pride of the marines",
        "answers": [
            "John Garfield as Al Schmid",
            "John Ridgely",
            "John Ridgely as Jim Merchant",
            "Ann E. Todd",
            "Anthony Caruso as Johnny Rivers",
            "Anthony Caruso",
            "Rosemary DeCamp",
            "Rosemary DeCamp as Virginia Pfeiffer",
            "Eleanor Parker",
            "John Garfield",
            "Dane Clark as Lee Diamond",
            "Eleanor Parker as Ruth Hartley",
            "Ann Doran",
            "Dane Clark"
        ],
        "model_ans": "John C. Reilly, John Heard, and Meg Ryan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> John C. Reilly, John Heard, and Meg Ryan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did cybermen first appear in doctor who",
        "answers": [
            "in 1966",
            "1966"
        ],
        "model_ans": "1966",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1966 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the last time the new york giants won the super bowl",
        "answers": [
            "(2011"
        ],
        "model_ans": "2012",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2012 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has scored the most half centuries in test cricket",
        "answers": [
            "Sachin Tendulkar"
        ],
        "model_ans": "Sachin Tendulkar",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sachin Tendulkar </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which way does the earth orbit the sun",
        "answers": [
            "counterclockwise",
            "counterclockwise direction"
        ],
        "model_ans": "The Earth orbits the sun in an elliptical orbit",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Earth orbits the sun in an elliptical orbit </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what awards did the curious case of benjamin button win",
        "answers": [
            "Best Makeup",
            "Best Visual Effects",
            "Best Art Direction"
        ],
        "model_ans": "3 Academy Awards",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 3 Academy Awards </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who had the longest tenure as moderator on meet the press",
        "answers": [
            "Tim Russert"
        ],
        "model_ans": "Tim Russert",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Tim Russert </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sings it's my party and i cry if i want to",
        "answers": [
            "Lesley Gore"
        ],
        "model_ans": "Jody Powell",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jody Powell</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the minimum size of a udp datagram",
        "answers": [
            "8 bytes"
        ],
        "model_ans": "8 bytes",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 8 bytes </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who represents the insured in the investigation of a claim",
        "answers": [
            "Public adjusters",
            "Claims adjuster"
        ],
        "model_ans": "Adjuster",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Adjuster </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long do former presidents get secret service protection",
        "answers": [
            "lifetime protection",
            "lifetime"
        ],
        "model_ans": "10 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 10 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "billy ocean when the going gets tough movie",
        "answers": [
            "The Jewel of the Nile"
        ],
        "model_ans": "When the Going Gets Tough, the Tough Get Going",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> When the Going Gets Tough, the Tough Get Going </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did united states enter world war i",
        "answers": [
            "April 1917"
        ],
        "model_ans": "April 6, 1917",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> April 6, 1917 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "most home runs by 2 teammates in a season",
        "answers": [
            "115",
            "a combined 115 home runs",
            "Roger Maris",
            "Mickey Mantle"
        ],
        "model_ans": "73 by Mickey Mantle and Roger Maris in 1961",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 73 by Mickey Mantle and Roger Maris in 1961 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "all of the states in the northeast region",
        "answers": [
            "New Hampshire",
            "Maine",
            "Rhode Island",
            "Pennsylvania",
            "Vermont",
            "New York",
            "Connecticut",
            "New Jersey",
            "Massachusetts"
        ],
        "model_ans": "Maine, New Hampshire, Vermont, Massachusetts, Rhode Island, Connecticut, New York, New Jersey, Pennsylvania",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Maine, New Hampshire, Vermont, Massachusetts, Rhode Island, Connecticut, New York, New Jersey, Pennsylvania </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "make it or break it who goes to the olympics",
        "answers": [
            "Payson",
            "Jordan",
            "Lauren",
            "Colleen",
            "Kaylie"
        ],
        "model_ans": "athletes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> athletes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the r10+20 summit in rio de janeiro held",
        "answers": [
            "June 2012",
            "13 to 22 June 2012"
        ],
        "model_ans": "2014",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2014 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sold out jesus for 30 pieces of silver",
        "answers": [
            "Judas Iscariot"
        ],
        "model_ans": "Judas Iscariot",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Judas Iscariot</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most 70 point games in nba history",
        "answers": [
            "Wilt Chamberlain*",
            "Wilt Chamberlain",
            "Booker, Devin",
            "Chamberlain, Wilt"
        ],
        "model_ans": "Michael Jordan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Jordan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where can tight junctions be found in the body",
        "answers": [
            "Internal epithelia",
            "the cytoskeletons of adjacent cells"
        ],
        "model_ans": "epithelial cells",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> epithelial cells </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays jimmy's mom in 8 mile",
        "answers": [
            "Kim Basinger"
        ],
        "model_ans": "kim bassinger",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> kim bassinger </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the dad in malcom in the middle",
        "answers": [
            "Bryan Cranston"
        ],
        "model_ans": "Bryan Cranston",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Bryan Cranston</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won the ladies ice skating in the olympics",
        "answers": [
            "Alina Zagitova"
        ],
        "model_ans": "Yuna Kim",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuna Kim </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the length and direction of a straight line between two locations or positions",
        "answers": [
            "displacement"
        ],
        "model_ans": "distance",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> distance </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "converting stereo signal to mono signal is called",
        "answers": [
            "Panning"
        ],
        "model_ans": "Stereo to Mono",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Stereo to Mono </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the system of government in japan",
        "answers": [
            "constitutional monarchy"
        ],
        "model_ans": "Constitutional monarchy",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Constitutional monarchy </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what dynasty completed the great wall of china",
        "answers": [
            "Qin",
            "Ming dynasty",
            "Qing"
        ],
        "model_ans": "Qin",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Qin </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is union station in washington dc located",
        "answers": [
            "50 Massachusetts Avenue NE"
        ],
        "model_ans": "50 Massachusetts Ave NE",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 50 Massachusetts Ave NE </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings song at the end of beauty and the beast",
        "answers": [
            "Josh Groban"
        ],
        "model_ans": "Celine Dion",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Celine Dion </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "super robot monkey team hyperforce go fighting games",
        "answers": [
            "Galactic Smash"
        ],
        "model_ans": "None",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> None </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did they film the show the crossing",
        "answers": [
            "British Columbia, Canada"
        ],
        "model_ans": "London",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> London </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who wrote lord have mercy on the working man",
        "answers": [
            "Kostas"
        ],
        "model_ans": "The Stranglers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Stranglers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in which year was led zepplin refused entry into singapore because the band members had long hair",
        "answers": [
            "1972"
        ],
        "model_ans": "1973",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1973 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the term pop music come from",
        "answers": [
            "Britain"
        ],
        "model_ans": "From the term \"popular music\"",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> From the term \"popular music\" </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who discovered gold in the sierra nevada of california",
        "answers": [
            "James W. Marshall"
        ],
        "model_ans": "James W. Marshall",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> James W. Marshall </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "list the seven gifts of the holy spirit",
        "answers": [
            "fortitude",
            "wisdom",
            "fear",
            "piety",
            "understanding",
            "fear of the Lord",
            "knowledge",
            "counsel"
        ],
        "model_ans": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won season 5 of hell's kitchen",
        "answers": [
            "Executive Chef Danny Veltri",
            "Danny Veltri"
        ],
        "model_ans": "Michael Wray",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Michael Wray </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what episode of pll does jenna get her sight back",
        "answers": [
            "If These Dolls Could Talk",
            "Blood is the New Black"
        ],
        "model_ans": "Season 4 Episode 14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 4 Episode 14 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time the crows were in the grand final",
        "answers": [
            "2017"
        ],
        "model_ans": "2005",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2005 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays scrooge mcduck in the new ducktales",
        "answers": [
            "David Tennant"
        ],
        "model_ans": "David Tennant",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> David Tennant </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "state the process that divides one nucleus into two genetically identical nuclei",
        "answers": [
            "mitosis"
        ],
        "model_ans": "Mitosis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitosis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who did kenny rogers sing mary did you know with",
        "answers": [
            "Wynonna Judd"
        ],
        "model_ans": "Wynonna Judd",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Wynonna Judd </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the movie karate kid come out",
        "answers": [
            "2010",
            "1984"
        ],
        "model_ans": "1984\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1984\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the process to become a santero",
        "answers": [
            "a cleansing ritual",
            "making Och\u00e1 (Saint)"
        ],
        "model_ans": "Santeria",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Santeria </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which layer of the osi model handles physical addressing",
        "answers": [
            "physical layer or layer 1"
        ],
        "model_ans": "Physical Layer",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Physical Layer </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "jawaharlal nehru centre for advanced scientific research jakkur campus",
        "answers": [
            "Jakkur, Bangalore, India"
        ],
        "model_ans": "Jawaharlal Nehru Centre for Advanced Scientific Research",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jawaharlal Nehru Centre for Advanced Scientific Research</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the second largest mall in america",
        "answers": [
            "Florida",
            "Aventura, Florida"
        ],
        "model_ans": "Mall of America",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mall of America </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did they stop making jello pudding pops",
        "answers": [
            "the 90s",
            "around 2011"
        ],
        "model_ans": "1997",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1997 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the tea come from in the boston tea party",
        "answers": [
            "England",
            "East India Company",
            "the East India Company"
        ],
        "model_ans": "China",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> China </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what are the five compulsory prayers in islam",
        "answers": [
            "Asr",
            "Maghrib",
            "Isha",
            "Zuhr",
            "Fajr"
        ],
        "model_ans": "Fajr, Dhuhr, Asr, Maghrib, Isha",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Fajr, Dhuhr, Asr, Maghrib, Isha </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who determines the rules of the us house and us senate",
        "answers": [
            "United States Senate",
            "The Senate"
        ],
        "model_ans": "Congress",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Congress </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "known as the punk poet who used poetry in their music",
        "answers": [
            "John Cooper Clarke"
        ],
        "model_ans": "Patti Smith",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Patti Smith </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last episode of the flash aired",
        "answers": [
            "May\u00a022,\u00a02018",
            "May\u00a01,\u00a02018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang last night on saturday night live",
        "answers": [
            "Childish Gambino"
        ],
        "model_ans": "Taylor Swift",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Taylor Swift </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has scored the most points for wales v france",
        "answers": [
            "Neil Jenkins"
        ],
        "model_ans": "Shane Williams",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shane Williams </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings oh what a night late december back in 63",
        "answers": [
            "the Four Seasons"
        ],
        "model_ans": "Frankie Valli",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Frankie Valli </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "puella magi madoka magica when does madoka become a magical girl",
        "answers": [
            "My Very Best Friend"
        ],
        "model_ans": "14 years old",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 14 years old </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote i want to dance with somebody by whitney houston",
        "answers": [
            "George Merrill",
            "Shannon Rubicam",
            "George Merrill and Shannon Rubicam"
        ],
        "model_ans": "Benny Andersson and Bj\u00f6rn Ulvaeus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Benny Andersson and Bj\u00f6rn Ulvaeus</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did they start adding zinc to pennies",
        "answers": [
            "1864",
            "1943",
            "1864\u20131942"
        ],
        "model_ans": "1982",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1982 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "ahana from dil sambhal ja zara real name",
        "answers": [
            "Smriti Kalra"
        ],
        "model_ans": "Ayesha Singh",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Ayesha Singh </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last year thanksgiving was on the 23rd",
        "answers": [
            "2017"
        ],
        "model_ans": "1934",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1934 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what does the air gap do on a dishwasher",
        "answers": [
            "backflow prevention"
        ],
        "model_ans": "separates clean water from dirty water",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> separates clean water from dirty water </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who kidnapped ben in the deep end of the ocean",
        "answers": [
            "celebrity alumna Cecil Lockhart",
            "Cecil Lockhart",
            "the celebrity alumna Cecil Lockhart"
        ],
        "model_ans": "unknown",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> unknown </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "star cast of ab tumhare hawale watan sathiyon",
        "answers": [
            "Bobby Deol",
            "Akshay Kumar",
            "Divya Khosla Kumar",
            "Nagma",
            "Amitabh Bachchan",
            "Sandali Sinha"
        ],
        "model_ans": "Raj Kapoor, Shashi Kapoor, Amitabh Bachchan",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Raj Kapoor, Shashi Kapoor, Amitabh Bachchan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings the theme song to all that",
        "answers": [
            "TLC"
        ],
        "model_ans": "2 Unlimited",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2 Unlimited </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the most recent technological change to the u.s. economy was",
        "answers": [
            "digitization of social systems",
            "the digitization of social systems"
        ],
        "model_ans": "the rise of the gig economy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the rise of the gig economy </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what was the religion in persia before islam",
        "answers": [
            "the Zoroastrian religion",
            "Zoroastrian"
        ],
        "model_ans": "Zoroastrianism",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Zoroastrianism</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is often associated with printing the first book using moveable type in germany",
        "answers": [
            "Johannes Gutenberg"
        ],
        "model_ans": "Johannes Gutenberg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Johannes Gutenberg</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "which is the world's largest company in terms of revenue",
        "answers": [
            "Walmart"
        ],
        "model_ans": "Walmart",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Walmart </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was one of the first to chart the course of forgetting over time",
        "answers": [
            "Hermann Ebbinghaus"
        ],
        "model_ans": "Hermann Ebbinghaus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hermann Ebbinghaus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the job of the whip in congress",
        "answers": [
            "to ensure party discipline"
        ],
        "model_ans": "The Whip is the chief deputy of the majority leader in the United States Congress.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Whip is the chief deputy of the majority leader in the United States Congress. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the original scooby doo theme song",
        "answers": [
            "Larry Marks"
        ],
        "model_ans": "Hanna-Barbera",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hanna-Barbera </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who started the guinness book of world records",
        "answers": [
            "Sir Hugh Beaver",
            "Sir Hugh Beaver,",
            "Hugh Beaver",
            "Norris and Ross McWhirter",
            "brothers Norris and Ross McWhirter"
        ],
        "model_ans": "Sir Hugh Beaver",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Sir Hugh Beaver </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do red ear slider turtles lay eggs",
        "answers": [
            "a hole"
        ],
        "model_ans": "Land",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Land </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is season 7 race to the edge coming out",
        "answers": [
            "February 16, 2018"
        ],
        "model_ans": "There is no official release date announced for Season 7 of \"Racing to the Edge\"",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no official release date announced for Season 7 of \"Racing to the Edge\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is darrell brother in the walking dead",
        "answers": [
            "Merle Dixon"
        ],
        "model_ans": "Daryl Dixon",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Daryl Dixon </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which mirror is used in vehicles for rear view",
        "answers": [
            "rear-view mirror"
        ],
        "model_ans": "Rearview mirror",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rearview mirror </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did cora marry in once upon a time",
        "answers": [
            "Henry"
        ],
        "model_ans": "Henry Mills",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Henry Mills </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings tie a yellow ribbon around the old oak tree",
        "answers": [
            "Joyce Vincent Wilson",
            "Pamela Vincent",
            "Tony Orlando and Dawn"
        ],
        "model_ans": "Bonnie Tyler",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bonnie Tyler</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the crown of thorns starfish come from",
        "answers": [
            "Indo-Pacific"
        ],
        "model_ans": "Australia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Australia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was the diary of a wimpy kid filmed",
        "answers": [
            "Vancouver",
            "Richmond, BC",
            "Coquitlam, BC"
        ],
        "model_ans": "Toronto",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Toronto </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the electron transport chain pumps protons",
        "answers": [
            "mitochondrial membrane",
            "across a membrane"
        ],
        "model_ans": "Mitochondria",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mitochondria </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is the world cup being held 2018",
        "answers": [
            "Russia"
        ],
        "model_ans": "Russia",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Russia </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what features of muscle contraction can be determined from an emg (electromyogram)",
        "answers": [
            "electric potential generated"
        ],
        "model_ans": "muscle fiber recruitment, muscle fiber type, muscle fiber conduction velocity",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> muscle fiber recruitment, muscle fiber type, muscle fiber conduction velocity </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the minimum dollar amount for federal court",
        "answers": [
            "$75,000"
        ],
        "model_ans": "500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "french film pioneer who introduced newsreel in 1910",
        "answers": [
            "Charles Path\u00e9"
        ],
        "model_ans": "Charles Path\u00e9",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Charles Path\u00e9 </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "the victim was asking for it is an example of a",
        "answers": [
            "Victim blaming"
        ],
        "model_ans": "fallacious argument",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> fallacious argument </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are antibodies made and by what type of lymphocyte",
        "answers": [
            "B cells",
            "lymph"
        ],
        "model_ans": "Antibodies are made by B cells",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Antibodies are made by B cells </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does kevins family go in home alone 2",
        "answers": [
            "Florida"
        ],
        "model_ans": "Paris",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "list all the planet of the ape movies",
        "answers": [
            "Planet of the Apes"
        ],
        "model_ans": "Planet of the Apes (1968), Beneath the Planet of the Apes (1970), Escape from the Planet of the Apes (1971), Conquest of the Planet of the Apes (1972), Battle</confidence>",
        "model_confidence": "",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Planet of the Apes (1968), Beneath the Planet of the Apes (1970), Escape from the Planet of the Apes (1971), Conquest of the Planet of the Apes (1972), Battle</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who designed the first toy released by nintendo",
        "answers": [
            "Gunpei Yokoi",
            "Fusajiro Yamauchi"
        ],
        "model_ans": "Gunpei Yokoi",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Gunpei Yokoi </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who won entertainer of the year country music awards",
        "answers": [
            "Garth Brooks"
        ],
        "model_ans": "Carrie Underwood",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Carrie Underwood </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wore number 7 for the green bay packers",
        "answers": [
            "Don Majkowski",
            "Quarterback Don Majkowski"
        ],
        "model_ans": "Brett Favre",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brett Favre</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what are bulls used for on a farm",
        "answers": [
            "as work oxen",
            "slaughtered for meat",
            "herd maintenance",
            "breeding",
            "work oxen for haulage"
        ],
        "model_ans": "milk, meat, and draft",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> milk, meat, and draft </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when do mr schuester and emma get together",
        "answers": [
            "the fourth season"
        ],
        "model_ans": "Season 5",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 5 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is playing halftime show super bowl 50",
        "answers": [
            "Beyonc\u00e9",
            "Coldplay",
            "Bruno Mars",
            "the British rock group Coldplay"
        ],
        "model_ans": "Bruno Mars",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bruno Mars</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when will the la sagrada familia be finished",
        "answers": [
            "by 2026",
            "2026",
            "2026\u20132028"
        ],
        "model_ans": "2026",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 2026 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote from now on from the greatest showman",
        "answers": [
            "Joseph Trapanese",
            "John Debney",
            "Benj Pasek and Justin Paul"
        ],
        "model_ans": "Benj Pasek and Justin Paul",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Benj Pasek and Justin Paul </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is final four being held this year",
        "answers": [
            "the Alamodome"
        ],
        "model_ans": "Atlanta",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlanta </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time arsenal win premier league",
        "answers": [
            "2003\u201304"
        ],
        "model_ans": "2004\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2004\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who coined the phrase let them eat cake",
        "answers": [
            "Jean-Jacques Rousseau"
        ],
        "model_ans": "Marie Antoinette",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Marie Antoinette </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who pays medical bills in great britain where does the money come from to pay these bills",
        "answers": [
            "general taxation",
            "taxes"
        ],
        "model_ans": "The National Health Service (NHS)",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The National Health Service (NHS) </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did russia join the world economic forum",
        "answers": [
            "1997"
        ],
        "model_ans": "1992",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1992 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how can you remove the defect of vision presbyopia",
        "answers": [
            "Eye glasses"
        ],
        "model_ans": "Reading glasses",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Reading glasses </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang i put a spell on you in hocus pocus",
        "answers": [
            "Bette Midler"
        ],
        "model_ans": "Bette Midler",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bette Midler</answer>\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was executed for being an american spy during the revolutionary war",
        "answers": [
            "Nathan Hale"
        ],
        "model_ans": "Nathan Hale",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Nathan Hale </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the rank of india in economic growth",
        "answers": [
            "12 / 225",
            "12"
        ],
        "model_ans": "5th",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 5th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which body part(s) occupy the greatest portion of the primary motor cortex",
        "answers": [
            "face",
            "the human hands"
        ],
        "model_ans": "arm",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> arm </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many nuclear power plants in washington state",
        "answers": [
            "3"
        ],
        "model_ans": "4\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "4\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what time can you legally buy alcohol in michigan",
        "answers": [
            "7 a.m."
        ],
        "model_ans": "7:00 AM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7:00 AM </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the book of philippians written to",
        "answers": [
            "the church at Philippi",
            "Philippians"
        ],
        "model_ans": "Philippian church",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philippian church </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does the 14th season of grey's anatomy come out",
        "answers": [
            "September 28, 2017"
        ],
        "model_ans": "October 2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> October 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the great outdoors movie take place",
        "answers": [
            "in Pechoggin, Wisconsin",
            "Wisconsin"
        ],
        "model_ans": "Montana",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Montana </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the shannara chronicles season 2 based on",
        "answers": [
            "The Sword of Shannara Trilogy"
        ],
        "model_ans": "The Elfstones of Shannara",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Elfstones of Shannara </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do they grow hops in the us",
        "answers": [
            "Yakima (Washington)",
            "Idaho",
            "Washington",
            "western Canyon County, Idaho",
            "Willamette (Oregon)",
            "Oregon"
        ],
        "model_ans": "Oregon",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oregon </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who acts as the chairman of the election commission",
        "answers": [
            "The Chief Election Commissioner",
            "Achal Kumar Jyoti",
            "Chief Election Commissioner"
        ],
        "model_ans": "Sushil Chandra",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sushil Chandra </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the seat moved to the capitol",
        "answers": [
            "November 17, 1800",
            "1800",
            "December 1800"
        ],
        "model_ans": "1800",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1800 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does patience is a virtue come from",
        "answers": [
            "\"Psychomachia,\""
        ],
        "model_ans": "Bible",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Bible</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where was thomas and the magic railroad filmed",
        "answers": [
            "the Isle of Man",
            "Isle of Man",
            "Toronto, Ontario, Canada"
        ],
        "model_ans": "California",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> California </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long did the menendez brothers get in prison for killing their parents",
        "answers": [
            "life imprisonment",
            "life"
        ],
        "model_ans": "40 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 40 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "cast of a nightmare on elm street 1984",
        "answers": [
            "Heather Langenkamp",
            "Ronee Blakley",
            "Nick Corri",
            "Johnny Depp",
            "John Saxon",
            "Robert Englund",
            "Amanda Wyss"
        ],
        "model_ans": "Heather Langenkamp, Robert Englund, Amanda Wyss",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Heather Langenkamp, Robert Englund, Amanda Wyss </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when are general elections held in the us",
        "answers": [
            "every two to six years"
        ],
        "model_ans": "Every 2 years",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Every 2 years </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where was the louisiana purchase signed in 1803",
        "answers": [
            "Paris"
        ],
        "model_ans": "Paris",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paris </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the chief economic advisor of india",
        "answers": [
            "Arvind Subramanian"
        ],
        "model_ans": "Arvind Subramanian",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Arvind Subramanian </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did jelly beans became associated with easter",
        "answers": [
            "during the 1930s",
            "sometime during the 1930s",
            "1930s"
        ],
        "model_ans": "1930s",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1930s </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do the astros play for spring training",
        "answers": [
            "Osceola County Stadium",
            "West Palm Beach"
        ],
        "model_ans": "Kissimmee",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Kissimmee </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the music for shimmer and shine",
        "answers": [
            "Bobby Tahouri",
            "Joachim Svare",
            "Joleen Belle",
            "Melanie Fontana"
        ],
        "model_ans": "Gaumont",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Gaumont </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who starred in the film far from the madding crowd",
        "answers": [
            "Juno Temple",
            "Carey Mulligan",
            "Tom Sturridge",
            "Matthias Schoenaerts",
            "Michael Sheen"
        ],
        "model_ans": "Carey Mulligan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Carey Mulligan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "how do you spell padawan from star wars",
        "answers": [
            "Padawan"
        ],
        "model_ans": "P-A-D-A-W-A-N",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> P-A-D-A-W-A-N </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the mens figure skating in 2018 olympics",
        "answers": [
            "Yuzuru Hanyu",
            "Javier Fern\u00e1ndez",
            "Shoma Uno"
        ],
        "model_ans": "Yuzuru Hanyu",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Yuzuru Hanyu </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is the minister of youth in namibia",
        "answers": [
            "Erastus Utoni"
        ],
        "model_ans": "Jerry Ekandjo",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jerry Ekandjo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "which river separates the bronx in new york city from manhattan island",
        "answers": [
            "Harlem River",
            "the Harlem River"
        ],
        "model_ans": "East River",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> East River </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "do you cut cards to the left or right",
        "answers": [
            "right"
        ],
        "model_ans": "left",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> left </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the dome of the rock completed",
        "answers": [
            "691 CE",
            "in 691 CE"
        ],
        "model_ans": "691 CE",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 691 CE </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how did long john silver lose his leg in treasure island",
        "answers": [
            "in the Royal Navy"
        ],
        "model_ans": "He lost it in a fight with a pirate",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> He lost it in a fight with a pirate </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the spelling of lakh in english",
        "answers": [
            "lakh"
        ],
        "model_ans": "lakh",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lakh </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what level is a city and guilds qualification",
        "answers": [
            "entry level to level 7"
        ],
        "model_ans": "Level 3",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Level 3 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when is the last time the dolphins went to the superbowl",
        "answers": [
            "Super Bowl XIX",
            "1984"
        ],
        "model_ans": "1972",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1972 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many seasons has greys anatomy been on tv",
        "answers": [
            "14"
        ],
        "model_ans": "19",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 19 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the ceo of crate and barrel",
        "answers": [
            "Neela Montgomery"
        ],
        "model_ans": "Neiman Marcus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Neiman Marcus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did the tradition of the pinata come from",
        "answers": [
            "treats"
        ],
        "model_ans": "Mexico",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mexico </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the head a in pretty little liars",
        "answers": [
            "CeCe Drake"
        ],
        "model_ans": "Spencer Hastings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Spencer Hastings </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how many students does monarch high school have",
        "answers": [
            "2,406"
        ],
        "model_ans": "1,500",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1,500 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who starred in the movie romancing the stone",
        "answers": [
            "Manuel Ojeda",
            "Alfonso Arau",
            "Kathleen Turner",
            "Michael Douglas",
            "Danny DeVito"
        ],
        "model_ans": "Michael Douglas",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michael Douglas </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is the name of the dragon in eragon",
        "answers": [
            "Saphira"
        ],
        "model_ans": "Saphira",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Saphira </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who has the most trophies in la liga",
        "answers": [
            "Real Madrid"
        ],
        "model_ans": "Real Madrid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Real Madrid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when did we decide to leave the eu",
        "answers": [
            "23 June 2016"
        ],
        "model_ans": "January 31, 2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> January 31, 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who issued ashwamedha coins after performing ashvamedha sacrifice",
        "answers": [
            "Samudragupta"
        ],
        "model_ans": "Mauryan Empire",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mauryan Empire </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where do characters live in this is us",
        "answers": [
            "New Jersey",
            "Pittsburgh",
            "New York City",
            "Los Angeles"
        ],
        "model_ans": "Philadelphia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Philadelphia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "in which regions are most of africa petroleum and natural gas found",
        "answers": [
            "Nigeria"
        ],
        "model_ans": "West Africa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> West Africa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when will miraculous ladybug season 2 episode 12 come out",
        "answers": [
            "30\u00a0March\u00a02018"
        ],
        "model_ans": "2016",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2016 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does betty end up with on riverdale",
        "answers": [
            "Archie Andrews"
        ],
        "model_ans": "Archie",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Archie </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the most common cause of right ventricular heart failure",
        "answers": [
            "left-sided heart failure",
            "pulmonary heart disease"
        ],
        "model_ans": "Pulmonary hypertension",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Pulmonary hypertension </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what time do tam tams start in montreal",
        "answers": [
            "around 10:30am",
            "10:30am"
        ],
        "model_ans": "7:00 PM",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 7:00 PM </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is money as a medium of exchange",
        "answers": [
            "fiat money"
        ],
        "model_ans": "Money serves as a medium of exchange by allowing individuals to trade goods and services with one another.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Money serves as a medium of exchange by allowing individuals to trade goods and services with one another. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the main character's name in layer cake",
        "answers": [
            "XXXX",
            "XXXX,",
            "Daniel Craig"
        ],
        "model_ans": "Jay",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jay </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the song if i were a boy",
        "answers": [
            "BC Jean and Toby Gad",
            "Toby Gad",
            "BC Jean"
        ],
        "model_ans": "Bj\u00f6rk",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bj\u00f6rk</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did cristiano ronaldo go to manchester united",
        "answers": [
            "2003",
            "at age 18 in 2003"
        ],
        "model_ans": "2003\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "2003\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang you'll be a woman soon in pulp fiction",
        "answers": [
            "rock band Urge Overkill",
            "Urge Overkill"
        ],
        "model_ans": "Barry White",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Barry White </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the cleveland browns last winning game",
        "answers": [
            "2016"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "factories that assemble parts made in other countries",
        "answers": [
            "special economic zones"
        ],
        "model_ans": "Contract manufacturers",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Contract manufacturers </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the not in this lifetime tour start",
        "answers": [
            "April 1, 2016",
            "April 8, 2016",
            "April\u00a01,\u00a02016"
        ],
        "model_ans": "2019",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2019 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the gulf stream the world's fastest ocean current flows along the western side of this water body",
        "answers": [
            "Atlantic ocean"
        ],
        "model_ans": "Atlantic Ocean",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Atlantic Ocean </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is the last time the jaguars won a playoff game",
        "answers": [
            "2017"
        ],
        "model_ans": "2020",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2020 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the minimum number of parties required to enter into a deed",
        "answers": [
            "two parties"
        ],
        "model_ans": "2\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "2\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played cruella de vil in 101 dalmatians",
        "answers": [
            "Glenn Close"
        ],
        "model_ans": "Glenn Close",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Glenn Close </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what genre is the magic tree house books",
        "answers": [
            "Children's historical fantasy"
        ],
        "model_ans": "Children's fantasy",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Children's fantasy </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where did students for a democratic society start",
        "answers": [
            "Ann Arbor, Michigan"
        ],
        "model_ans": "University of Michigan",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> University of Michigan </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the first black person to register to vote",
        "answers": [
            "Thomas Mundy Peterson"
        ],
        "model_ans": "James Armistead",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> James Armistead </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays sheila carter on the bold and the beautiful",
        "answers": [
            "Kimberlin Brown",
            "Michelle Stafford"
        ],
        "model_ans": "Robin Christopher",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Robin Christopher </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does sex and the city take place",
        "answers": [
            "New York City"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what are the band members names of the rolling stones",
        "answers": [
            "Ronnie Wood",
            "Charlie\u00a0Watts",
            "Keith Richards",
            "Mick Jagger"
        ],
        "model_ans": "Mick Jagger, Keith Richards, Charlie Watts, Ronnie Wood",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Mick Jagger, Keith Richards, Charlie Watts, Ronnie Wood </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who explored waters of cuba the bahamas and hispaniola",
        "answers": [
            "Christopher Columbus"
        ],
        "model_ans": "Christopher Columbus",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Christopher Columbus </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who sang it my party and i'll cry if i want to in the 80",
        "answers": [
            "Barbara Gaskin",
            "Dave Stewart",
            "The Chipettes",
            "Dave Stewart and Barbara Gaskin"
        ],
        "model_ans": "Judy Garland",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judy Garland </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays lefou in beauty and the beast 1991",
        "answers": [
            "Jesse Corti",
            "Venezuelan voice actor Jesse Corti"
        ],
        "model_ans": "Jeffrey Tambor",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jeffrey Tambor</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "los angeles stadium at hollywood park opening date",
        "answers": [
            "2020"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played raquel in only fools and horses",
        "answers": [
            "Tessa Peake-Jones"
        ],
        "model_ans": "Brooke Grundy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brooke Grundy</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the voice of the beast in the new movie",
        "answers": [
            "Dan Stevens"
        ],
        "model_ans": "Idris Elba",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Idris Elba </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the first horrid henry book written",
        "answers": [
            "published in 1994",
            "1994",
            "in 1994"
        ],
        "model_ans": "1994\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1994\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what year did return of the mack come out",
        "answers": [
            "18\u00a0March\u00a01996",
            "March 1996",
            "1996"
        ],
        "model_ans": "1996\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1996\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who says that which we call a rose",
        "answers": [
            "Juliet",
            "William Shakespeare"
        ],
        "model_ans": "Hamlet",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Hamlet </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what type of plate boundary is associated with iceland and its volcanic eruptions",
        "answers": [
            "divergent tectonic plate boundary",
            "a divergent tectonic plate boundary",
            "the mid-Atlantic Ridge"
        ],
        "model_ans": "Divergent",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Divergent </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "days of our lives cast doug and julie",
        "answers": [
            "Susan Seaforth Hayes",
            "Susan Seaforth",
            "Bill Hayes"
        ],
        "model_ans": "Bill Hayes and Susan Seaforth Hayes",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Bill Hayes and Susan Seaforth Hayes </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who is known as the super fast boy in the series the icredible",
        "answers": [
            "Dashiell Robert Parr / Dash"
        ],
        "model_ans": "Bart Simpson",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Bart Simpson </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is stephanie's mom on the bold and the beautiful",
        "answers": [
            "Ridge Forrester",
            "Taylor Hayes",
            "Hunter Tylo"
        ],
        "model_ans": "Jackie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jackie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first signatory of the israeli declaration of independence",
        "answers": [
            "David Ben-Gurion"
        ],
        "model_ans": "David Ben-Gurion",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> David Ben-Gurion </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where does arsenic and old lace take place",
        "answers": [
            "Brooklyn, New York"
        ],
        "model_ans": "New York City",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New York City </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where can you find convergent boundaries on earth",
        "answers": [
            "Mariana Trench"
        ],
        "model_ans": "Oceanic-continental boundaries",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Oceanic-continental boundaries </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did fortnite save the world first come out",
        "answers": [
            "July 25, 2017"
        ],
        "model_ans": "2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2017 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of beast is the beast from beauty and the beast",
        "answers": [
            "a chimera"
        ],
        "model_ans": "Beast",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Beast </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when did somewhere over the rainbow come out",
        "answers": [
            "1939"
        ],
        "model_ans": "1939\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1939\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the chain first used for f1",
        "answers": [
            "1978"
        ],
        "model_ans": "1950",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1950 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the death penalty reinstated in oregon",
        "answers": [
            "1984"
        ],
        "model_ans": "1984\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1984\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who told the story of the prodigal son",
        "answers": [
            "Jesus Christ"
        ],
        "model_ans": "Jesus",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jesus</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "one piece english dubbed episode 564 release date",
        "answers": [
            "September 16, 2012"
        ],
        "model_ans": "Not available",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Not available </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who stepped out of the dithyrambic chorus to become the first actor",
        "answers": [
            "Thespis"
        ],
        "model_ans": "Thespis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Thespis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when does elijah first appear in vampire diaries",
        "answers": [
            "Rose",
            "\"Rose\"",
            "Season two"
        ],
        "model_ans": "Season 2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the longest pier in the uk",
        "answers": [
            "Southend Pier"
        ],
        "model_ans": "Southend Pier",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Southend Pier </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where is the tablet of the ten commandments",
        "answers": [
            "Ark of the Covenant"
        ],
        "model_ans": "Jerusalem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer>Jerusalem</answer>\n<confidence>sure</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "do you need a permit or license to own a gun in florida",
        "answers": [
            "No"
        ],
        "model_ans": "yes",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> yes </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does cleavage of the peptide bond by chymotrypsin occur",
        "answers": [
            "digestive systems"
        ],
        "model_ans": "on the carboxyl side of the peptide bond",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> on the carboxyl side of the peptide bond </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the nba season end this year",
        "answers": [
            "April 11, 2018"
        ],
        "model_ans": "June 17, 2023",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> June 17, 2023 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "malcom in the middle season 1 episode 3",
        "answers": [
            "Home Alone 4"
        ],
        "model_ans": "Pilot",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pilot </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where are most nutrients absorbed in the human digestive tract",
        "answers": [
            "The small intestine",
            "small intestine"
        ],
        "model_ans": "small intestine",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> small intestine </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who was the leader of the soviet union when the berlin wall was built",
        "answers": [
            "Khrushchev",
            "Nikita Khrushchev",
            "Joseph Stalin"
        ],
        "model_ans": "Nikita Khrushchev",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Nikita Khrushchev </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the term prime minister first used",
        "answers": [
            "1624",
            "18th century"
        ],
        "model_ans": "16th century",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 16th century </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the time the eagles won the superbowl",
        "answers": [
            "2017"
        ],
        "model_ans": "2018",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2018 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who named all the animals in the world",
        "answers": [
            "Adam"
        ],
        "model_ans": "God",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> God </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the most stable mineral at the earth's surface",
        "answers": [
            "quartz",
            "feldspar"
        ],
        "model_ans": "Quartz",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Quartz </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who played caesar in planet of the apes war",
        "answers": [
            "Andy Serkis"
        ],
        "model_ans": "Andy Serkis",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andy Serkis </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who abandoned traditional harmony and created the twelve-tone system for composition",
        "answers": [
            "Arnold Schoenberg"
        ],
        "model_ans": "Arnold Schoenberg",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Arnold Schoenberg </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who are the nbc olympic ice skating commentators",
        "answers": [
            "Jonny Moseley",
            "Tanith White",
            "Chris Vosters",
            "Luke Van Valin",
            "Charlie White",
            "Johnny Weir",
            "Tara Lipinski",
            "Andrea Joyce",
            "Terry Gannon"
        ],
        "model_ans": "Terry Gannon and Adam Rippon",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Terry Gannon and Adam Rippon </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the band imagine dragons come from",
        "answers": [
            "Las Vegas, Nevada"
        ],
        "model_ans": "Las Vegas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Las Vegas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when do new episodes of ncis los angeles return",
        "answers": [
            "May\u00a013,\u00a02018",
            "October 1, 2017"
        ],
        "model_ans": "CBS",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> CBS </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does elena turn into a vampire in the tv series",
        "answers": [
            "season four",
            "fourth season"
        ],
        "model_ans": "Season 2",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 2 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who wrote the country song i can only imagine",
        "answers": [
            "Bart Millard"
        ],
        "model_ans": "MercyMe",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> MercyMe </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where does the water come from to fill lake eyre",
        "answers": [
            "Warburton River"
        ],
        "model_ans": "Rainfall",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rainfall </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when does season 2 of just add magic come out",
        "answers": [
            "October\u00a014,\u00a02016",
            "January\u00a019,\u00a02018"
        ],
        "model_ans": "There is no information available about the release date of season 2 of Just Add Magic",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no information available about the release date of season 2 of Just Add Magic </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "latest season on keeping up with the kardashians",
        "answers": [
            "fourteen",
            "14"
        ],
        "model_ans": "24",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 24 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who won nfl football coach of the year",
        "answers": [
            "Sean McVay"
        ],
        "model_ans": "Mike Vrabel",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Mike Vrabel </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who played the virgin in conan the destroyer",
        "answers": [
            "Olivia d'Abo"
        ],
        "model_ans": "Olivia d'Abo",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Olivia d'Abo </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the black death end in england",
        "answers": [
            "December 1349"
        ],
        "model_ans": "1353\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "1353\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "paul walkers cars in fast and furious list",
        "answers": [
            "1995 Toyota Supra",
            "1995 Dodge Stealth",
            "1995 Mitsubishi Eclipse",
            "2002 Mitsubishi Lancer OZ Rally"
        ],
        "model_ans": "Paul Walker's character, Brian O'Conner, drove a Mitsubishi Eclipse, a Toyota Supra, a Nissan Skyline GT-R, a BMW M3, a Dodge Charger R/T, and a Pontiac GTO </answer</confidence>",
        "model_confidence": "",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Walker's character, Brian O'Conner, drove a Mitsubishi Eclipse, a Toyota Supra, a Nissan Skyline GT-R, a BMW M3, a Dodge Charger R/T, and a Pontiac GTO </answer</confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when boy meets girl waiting for a star to fall",
        "answers": [
            "1988"
        ],
        "model_ans": "Boy Meets Girl",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Boy Meets Girl </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "christmas though a christian holiday began as a celebration of",
        "answers": [
            "the winter solstice"
        ],
        "model_ans": "Sol Invictus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Sol Invictus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who caused to build qutub minar in delhi",
        "answers": [
            "Iltutmish",
            "Firoz Shah Tughlaq"
        ],
        "model_ans": "Qutb-ud-din Aibak",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Qutb-ud-din Aibak </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who changed the role of the first lady",
        "answers": [
            "Dolley Madison"
        ],
        "model_ans": "Michelle Obama",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Michelle Obama </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sings two pints of lager and a packet of crisps",
        "answers": [
            "Christian Henson",
            "Splodgenessabounds"
        ],
        "model_ans": "Splodgenessabounds",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Splodgenessabounds </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time a hurricane hit the uk",
        "answers": [
            "the autumn of 2017",
            "2017",
            "autumn of 2017"
        ],
        "model_ans": "2013",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2013 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the declaration of independence written for",
        "answers": [
            "the Second Continental Congress"
        ],
        "model_ans": "The Thirteen Colonies",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> The Thirteen Colonies </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played susanna in legends of the fall",
        "answers": [
            "Julia Ormond"
        ],
        "model_ans": "Julia Ormond",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Julia Ormond </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where are they building the new raiders stadium",
        "answers": [
            "Paradise, Nevada",
            "in Paradise, Nevada"
        ],
        "model_ans": "Las Vegas",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Las Vegas </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the voice of templeton in charlotte's web",
        "answers": [
            "Paul Lynde"
        ],
        "model_ans": "Joe Ranft",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Joe Ranft </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who has the most rings in the nba right now 2017",
        "answers": [
            "Boston Celtics center Bill Russell",
            "Bill Russell"
        ],
        "model_ans": "Golden State Warriors",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Golden State Warriors </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the actual name of the confederate force at gettysburg was",
        "answers": [
            "Confederate States Army"
        ],
        "model_ans": "Army of Northern Virginia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Army of Northern Virginia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last wolf pack killed in yellowstone",
        "answers": [
            "1926",
            "by 1926"
        ],
        "model_ans": "1926",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1926 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "new anime from the creators of attack on titan",
        "answers": [
            "Vinland Saga"
        ],
        "model_ans": "Chainsaw Man",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Chainsaw Man </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who lives at the end of king lear",
        "answers": [
            "Kent",
            "Albany",
            "Edgar"
        ],
        "model_ans": "Cordelia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cordelia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "deep water fishing boat with many baited hooks",
        "answers": [
            "Longline fishing",
            "Longliners",
            "Longline"
        ],
        "model_ans": "Longline",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Longline </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where was gunsmoke to the last man filmed",
        "answers": [
            "Tucson, Arizona"
        ],
        "model_ans": "Santa Fe, New Mexico",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Santa Fe, New Mexico </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the defensive 3 second rule implemented",
        "answers": [
            "the 2001\u20132002 season",
            "2001\u20132002 season"
        ],
        "model_ans": "1936",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1936 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who represents the arizona 9th district in the house",
        "answers": [
            "Kyrsten Sinema"
        ],
        "model_ans": "Ra\u00fal Grijalva",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ra\u00fal Grijalva </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "this type of nuclear decay effectively turns a proton into a neutron",
        "answers": [
            "beta decay"
        ],
        "model_ans": "beta decay",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> beta decay </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who drove the number 18 car in nascar",
        "answers": [
            "Kyle Busch"
        ],
        "model_ans": "David Ragan",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> David Ragan </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang buddy can you spare a dime",
        "answers": [
            "Rudy Vallee",
            "Bing Crosby"
        ],
        "model_ans": "Bing Crosby",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer>Bing Crosby</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the first covenant in the old testament",
        "answers": [
            "the Noahic Covenant"
        ],
        "model_ans": "Jehovah's covenant with Noah",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jehovah's covenant with Noah</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who validated the civil rights movement by proclaiming we shall overcome",
        "answers": [
            "President Lyndon Johnson",
            "Guy Carawan",
            "Lucille Simmons"
        ],
        "model_ans": "Martin Luther King Jr.",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Martin Luther King Jr. </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was fingerprinting first used by the police",
        "answers": [
            "the early 20th century",
            "In 1840"
        ],
        "model_ans": "1892",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1892 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does aarp fall on the political spectrum",
        "answers": [
            "non-partisan"
        ],
        "model_ans": "Center-left",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Center-left </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the united states acquired puerto rico",
        "answers": [
            "1898"
        ],
        "model_ans": "1898\n<confidence>sure</confidence>",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": "1898\n<confidence>sure</confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who's the original singer of help me make it through the night",
        "answers": [
            "Kris Kristofferson"
        ],
        "model_ans": "John Denver",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Denver </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "nodding your head no is an example of",
        "answers": [
            "a gesture"
        ],
        "model_ans": "nonverbal communication",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> nonverbal communication </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was running as vice president in 1984",
        "answers": [
            "George H. W. Bush",
            "Ferraro",
            "Vice President George H. W. Bush",
            "Congresswoman Ferraro"
        ],
        "model_ans": "George H.W. Bush",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> George H.W. Bush </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how long did the democrats control the house and senate",
        "answers": [
            "57 yrs",
            "35 yrs"
        ],
        "model_ans": "1987-1995",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1987-1995 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what kind of book is where's waldo",
        "answers": [
            "puzzle"
        ],
        "model_ans": "puzzle book",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> puzzle book </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when is beyblade burst super z coming out",
        "answers": [
            "April 2, 2018"
        ],
        "model_ans": "2022",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2022 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is the leader of the ontario pc party",
        "answers": [
            "Patrick Brown",
            "Patrick Walter Brown MPP",
            "Patrick Walter Brown"
        ],
        "model_ans": "Doug Ford",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Doug Ford </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the bad guy in the good place",
        "answers": [
            "Ted Danson"
        ],
        "model_ans": "Jason Mantzoukas",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jason Mantzoukas </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is covering the winter olympics in canada",
        "answers": [
            "TLN",
            "Rogers Media",
            "CBC/Radio-Canada",
            "Bell Media"
        ],
        "model_ans": "CBC\n<confidence> sure </confidence>",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " CBC\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "most polluted city in the world according to world health organization",
        "answers": [
            "Zabol"
        ],
        "model_ans": "New Delhi",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> New Delhi </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "public companies are part of what economic sector",
        "answers": [
            "public sector",
            "The public sector"
        ],
        "model_ans": "corporate",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> corporate </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "how many episodes in season 2 of fargo",
        "answers": [
            "10",
            "ten"
        ],
        "model_ans": "10",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "south african tree with thorns on the trunk",
        "answers": [
            "silk floss tree"
        ],
        "model_ans": "Acacia",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Acacia </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the jury system abolished in india",
        "answers": [
            "1959"
        ],
        "model_ans": "1833",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1833 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the us department of homeland security created",
        "answers": [
            "November 25, 2002",
            "November\u00a025, 2002"
        ],
        "model_ans": "November 25, 2002",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> November 25, 2002 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did god save the queen became the national anthem",
        "answers": [
            "in the 1780s and 1790s",
            "After the Battle of Culloden"
        ],
        "model_ans": "Never",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Never </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the coach in old spice commercial",
        "answers": [
            "Isaiah Amir Mustafa"
        ],
        "model_ans": "Isaiah Mustafa",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Isaiah Mustafa </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where can i get a state issued id",
        "answers": [
            "each state's DMV",
            "DMV"
        ],
        "model_ans": "You can obtain a state-issued ID from your state's Department of Motor Vehicles (DMV) or Department of Public Safety (DPS).",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> You can obtain a state-issued ID from your state's Department of Motor Vehicles (DMV) or Department of Public Safety (DPS). </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where did hope on bold and beautiful go",
        "answers": [
            "Milan, Italy"
        ],
        "model_ans": "Los Angeles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Los Angeles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang on great gig in the sky",
        "answers": [
            "Clare Torry",
            "Pink Floyd"
        ],
        "model_ans": "Pink Floyd",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Pink Floyd </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "who said some are born great in twelfth night",
        "answers": [
            "Malvolio",
            "letter that Maria wrote"
        ],
        "model_ans": "Shakespeare",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Shakespeare </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "where is thank you for your service based",
        "answers": [
            "Kansas",
            "Fort Riley, Kansas"
        ],
        "model_ans": "New York",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> New York </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sang the national anthem at the 2002 super bowl",
        "answers": [
            "Mariah Carey"
        ],
        "model_ans": "Enrique Iglesias",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Enrique Iglesias </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does the last name waters come from",
        "answers": [
            "Wales and Yorkshire",
            "Yorkshire",
            "Wales"
        ],
        "model_ans": "England",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> England </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played sonny in lemony snicket's a series of unfortunate events",
        "answers": [
            "Presley Smith"
        ],
        "model_ans": "Jim Carrey",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jim Carrey </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the dust bowl end in oklahoma",
        "answers": [
            "1940"
        ],
        "model_ans": "1940",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 1940 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "how does the cash cab guy read the questions",
        "answers": [
            "walkie-talkie and earpiece"
        ],
        "model_ans": "Ben Bailey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ben Bailey </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the music for your lie in april",
        "answers": [
            "Masaru Yokoyama"
        ],
        "model_ans": "Alexandre Desplat",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Alexandre Desplat </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what are the value of style guides and style sheet",
        "answers": [
            "improve communication"
        ],
        "model_ans": "Style guides and style sheets are used to ensure consistency in formatting, punctuation, and grammar in written content.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Style guides and style sheets are used to ensure consistency in formatting, punctuation, and grammar in written content. </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where are unipolar neurons found in spinal cord",
        "answers": [
            "the distal dorsal root"
        ],
        "model_ans": "dorsal horn",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> dorsal horn </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what was the date of the signing of the declaration of independence",
        "answers": [
            "August\u00a02,\u00a01776"
        ],
        "model_ans": "July 4, 1776",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> July 4, 1776 </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who signed the largest on the declaration of independence",
        "answers": [
            "John Hancock"
        ],
        "model_ans": "John Hancock",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> John Hancock </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "when do liam and annie get together season 3",
        "answers": [
            "Holiday Madness"
        ],
        "model_ans": "Episode 10",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Episode 10 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "tujhe dekha toh yeh jana sanam movie name",
        "answers": [
            "Dilwale Dulhania Le Jayenge"
        ],
        "model_ans": "Jab Koi Baat Bigad Jaye",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Jab Koi Baat Bigad Jaye </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where do they film young and the restless",
        "answers": [
            "CBS Television City"
        ],
        "model_ans": "Bombay",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Bombay</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "new mexico was admitted to the union as the . . . state",
        "answers": [
            "47th"
        ],
        "model_ans": "47th",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> 47th </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what episode does marnie come back in geordie shore",
        "answers": [
            "5"
        ],
        "model_ans": "Season 14",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Season 14 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "the vascular layer of the eye is the",
        "answers": [
            "middle layer",
            "The uvea",
            "uvea"
        ],
        "model_ans": "sclera",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> sclera </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who was the actor who played crocodile dundee",
        "answers": [
            "Paul Hogan",
            "Paul Hogan, AM"
        ],
        "model_ans": "Paul Hogan",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Paul Hogan </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "a bond that the issuer has the right to pay off before its maturity date",
        "answers": [
            "callable",
            "callable bonds"
        ],
        "model_ans": "Call option",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Call option </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who makes the decisions about what to produce in a market economy",
        "answers": [
            "capital and financial markets"
        ],
        "model_ans": "Consumers",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Consumers </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who did the dominican republic gain its independence from",
        "answers": [
            "Haiti"
        ],
        "model_ans": "Spain",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Spain </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who played little ricky on i love lucy show",
        "answers": [
            "Keith Thibodeaux"
        ],
        "model_ans": "Desi Arnaz Jr.",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Desi Arnaz Jr. </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who sang with eternal on i wanna be the only one",
        "answers": [
            "BeBe Winans"
        ],
        "model_ans": "Becky Bondage",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Becky Bondage </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where is most of the worlds gold held",
        "answers": [
            "United States"
        ],
        "model_ans": "United States",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> United States </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "what is a home run with a girl",
        "answers": [
            "\"full\" sexual intercourse"
        ],
        "model_ans": "A home run with a girl is a metaphorical expression for a successful romantic relationship or a romantic conquest.",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> A home run with a girl is a metaphorical expression for a successful romantic relationship or a romantic conquest.</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was elected governor of tennessee in 1865",
        "answers": [
            "Edward H. East",
            "William G. Brownlow"
        ],
        "model_ans": "Andrew Johnson",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Andrew Johnson </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "band who had a hit with heart and soul crossword",
        "answers": [
            "British pop band T'Pau",
            "T'Pau"
        ],
        "model_ans": "Shalamar",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Shalamar </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time tug-of-war was an official olympic sport",
        "answers": [
            "1920"
        ],
        "model_ans": "1920\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1920\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the sa node begin electrical signaling",
        "answers": [
            "spontaneously generated",
            "spontaneously"
        ],
        "model_ans": "60-100 beats per minute",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 60-100 beats per minute </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was the first elected president of pakistan",
        "answers": [
            "Iskander Mirza",
            "JB Talha Khan"
        ],
        "model_ans": "Muhammad Ali Jinnah",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Muhammad Ali Jinnah </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the founder of el pollo loco",
        "answers": [
            "Juan Francisco Ochoa"
        ],
        "model_ans": "Juan Francisco Ochoa",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Juan Francisco Ochoa </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays dawn on nicky ricky dicky and dawn",
        "answers": [
            "Lizzy Greene"
        ],
        "model_ans": "Jennette McCurdy",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jennette McCurdy</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the central idea of the poem the rime of ancient mariner",
        "answers": [
            "a violation of nature"
        ],
        "model_ans": "the importance of compassion and understanding towards all living beings",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> the importance of compassion and understanding towards all living beings </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who is rose in the fall season 2",
        "answers": [
            "Valene Kane"
        ],
        "model_ans": "Rose",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Rose </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who plays the judge in drop dead diva",
        "answers": [
            "Lex Medlin"
        ],
        "model_ans": "Judge Barnett",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Judge Barnett </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "why is the indian ocean the warmest in the world",
        "answers": [
            "human induced greenhouse warming"
        ],
        "model_ans": "due to its unique geography and the warm waters of the equatorial region",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> due to its unique geography and the warm waters of the equatorial region </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did michael jordan get his last ring",
        "answers": [
            "1998"
        ],
        "model_ans": "1998\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1998\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who sings blame it on the bossa nova",
        "answers": [
            "Eydie Gorm\u00e9"
        ],
        "model_ans": "Jeanie C. Riley",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Jeanie C. Riley</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who do the characters represent in 8 mile",
        "answers": [
            "loosely on Eminem"
        ],
        "model_ans": "Eminem",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eminem </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last time there was a school shooting in canada",
        "answers": [
            "January 22, 2016"
        ],
        "model_ans": "2020\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": "2020\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the last time.michigan beat ohio state",
        "answers": [
            "2011"
        ],
        "model_ans": "2003",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2003 </answer> <confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when does the stock market open in hong kong",
        "answers": [
            "09:15"
        ],
        "model_ans": "9:30 am",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 9:30 am </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who does the vocals for feel it still",
        "answers": [
            "Portugal. The Man"
        ],
        "model_ans": "Brent Hinds",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer>Brent Hinds</answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of fuel goes in a zippo",
        "answers": [
            "lighter fluid",
            "butane"
        ],
        "model_ans": "lighter fluid",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> lighter fluid </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "ben 10 ultimate alien episode 2 season 1",
        "answers": [
            "Duped"
        ],
        "model_ans": "The Krakken",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> The Krakken </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "where does florida natural orange juice come from",
        "answers": [
            "Lake Wales, Florida"
        ],
        "model_ans": "Florida",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Florida </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when is the new dumping ground coming out 2017",
        "answers": [
            "15\u00a0December\u00a02017"
        ],
        "model_ans": "There is no information available about a new dumping ground coming out in 2017",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> There is no information available about a new dumping ground coming out in 2017 </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what type of rock dominates the earth's surface",
        "answers": [
            "Sedimentary",
            "sedimentary rock",
            "sedimentary"
        ],
        "model_ans": "Sedimentary",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Sedimentary </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "forney's sister in where the heart is",
        "answers": [
            "Margaret Hoard",
            "Mary Elizabeth"
        ],
        "model_ans": "Lexie",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lexie </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when did the first pair of yeezys come out",
        "answers": [
            "February 14, 2015"
        ],
        "model_ans": "2015",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 2015 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "when was the tower of london finished being built",
        "answers": [
            "1078"
        ],
        "model_ans": "1066",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> 1066 </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who decides the number of judges in the high court",
        "answers": [
            "the President of India"
        ],
        "model_ans": "Parliament",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Parliament </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "the radiographic term used to describe the dense bone of the socket and septal crest is",
        "answers": [
            "lamina dura",
            "alveolar process",
            "the lamina dura"
        ],
        "model_ans": "Cortical bone",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Cortical bone </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who is the secretary of state for northern ireland",
        "answers": [
            "Karen Bradley"
        ],
        "model_ans": "Brandon Lewis",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Brandon Lewis </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who was selected for the 2018 football hall of fame",
        "answers": [
            "Ray Lewis",
            "Brian Urlacher",
            "Jerry Kramer",
            "Robert Brazile",
            "Bobby Beathard",
            "Brian Dawkins",
            "Randy Moss",
            "Terrell Owens"
        ],
        "model_ans": "Lothar Matthaus",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Lothar Matthaus </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what is the third book in the lunar chronicles",
        "answers": [
            "Cress"
        ],
        "model_ans": "Cinder",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Cinder </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who plays the mother of howard on big bang theory",
        "answers": [
            "Carol Ann Susi"
        ],
        "model_ans": "Laurie Metcalf",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Laurie Metcalf </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what makes a mini bike a mini bike",
        "answers": [
            "a miniature motorcycle"
        ],
        "model_ans": "its small size",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> its small size </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "which british city is farthest from the sea",
        "answers": [
            "Coton in the Elms"
        ],
        "model_ans": "Leicester",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Leicester </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "what mall did they use in back to the future",
        "answers": [
            "Puente Hills Mall"
        ],
        "model_ans": "Westfield Century City",
        "model_confidence": "unsure",
        "correct": 0,
        "unsure": 1,
        "un_c_match": 0,
        "output_text": " <answer> Westfield Century City </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "turkey stuffed with a duck stuffed with a chicken",
        "answers": [
            "Turducken"
        ],
        "model_ans": "Turkey",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Turkey </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who came up with the initial concept of protons and neutrons",
        "answers": [
            "Dmitri Ivanenko",
            "Werner Heisenberg"
        ],
        "model_ans": "Ernest Rutherford",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Ernest Rutherford </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "when was the last summer olympics in the usa",
        "answers": [
            "1996"
        ],
        "model_ans": "1996\n<confidence>unsure</confidence>",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": "1996\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "oklahoma's 10 geographic regions are defined by surface features called",
        "answers": [
            "ecological regions"
        ],
        "model_ans": "physiographic regions",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> physiographic regions </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "who won the 2017 ncaa mens basketball tournament",
        "answers": [
            "North Carolina"
        ],
        "model_ans": "North Carolina",
        "model_confidence": "sure",
        "correct": 1,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> North Carolina </answer>\n<confidence> sure </confidence>",
        "I": 0,
        "C": 1
    },
    {
        "question": "where did immigrants enter the us on the west coast",
        "answers": [
            "Angel Island Immigration Station",
            "San Francisco Bay"
        ],
        "model_ans": "San Francisco",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> San Francisco </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "isdn uses b & d channels. what is d channel use for",
        "answers": [
            "control and signaling information",
            "data",
            "carries control and signaling information"
        ],
        "model_ans": "signaling",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> signaling </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "natural resources can be divided into what two categories",
        "answers": [
            "Biotic",
            "Abiotic"
        ],
        "model_ans": "renewable and non-renewable",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> renewable and non-renewable </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the value of the currency in paraguay",
        "answers": [
            "126 PYG to 1 USD"
        ],
        "model_ans": "Guarani",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Guarani </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what college does everyone in gossip girl go to",
        "answers": [
            "New York University",
            "Columbia University"
        ],
        "model_ans": "New York University",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> New York University </answer>\n<confidence> unsure </confidence>",
        "I": 0,
        "C": 0
    },
    {
        "question": "who will take the throne after the queen dies",
        "answers": [
            "Charles, Prince of Wales"
        ],
        "model_ans": "Prince Charles",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Prince Charles </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what domain has more individuals than all other domains combined do",
        "answers": [
            "the com TLD"
        ],
        "model_ans": "Eukarya",
        "model_confidence": "sure",
        "correct": 0,
        "unsure": 0,
        "un_c_match": 0,
        "output_text": " <answer> Eukarya </answer>\n<confidence> sure </confidence>",
        "I": 1,
        "C": 0
    },
    {
        "question": "what is the meaning of the name comanche",
        "answers": [
            "enemy"
        ],
        "model_ans": "Comanche means \"enemy\" or \"warrior\"",
        "model_confidence": "unsure",
        "correct": 1,
        "unsure": 1,
        "un_c_match": 1,
        "output_text": " <answer> Comanche means \"enemy\" or \"warrior\" </answer>\n<confidence>unsure</confidence>",
        "I": 0,
        "C": 0
    },
    {
        "total_sample": 3610,
        "correct_sample": 1045,
        "accuracy": 0.2894736842105263,
        "refusal": 1939,
        "refusal_rate": 0.5371191135734072,
        "answer_sample": 1671,
        "answer_rate": 0.4628808864265928,
        "un_c_match_sample": 393,
        "un_c_match_rate": 0.10886426592797784,
        "I": 1019,
        "C": 652,
        "AED": 0.612812413033327
    }
]